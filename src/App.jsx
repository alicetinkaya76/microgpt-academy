import React from "react";
import { useState, useEffect, useCallback, useRef, useMemo } from "react";


// â”€â”€â”€ i18n SYSTEM â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const LangContext = React.createContext('tr');
const useLang = () => React.useContext(LangContext);

// Helper: if value is {tr,en} object, pick by lang. Otherwise return as-is.
const tx = (val, lang) => {
  if (val && typeof val === 'object' && !React.isValidElement(val) && !Array.isArray(val) && (val.tr || val.en)) {
    return val[lang] || val.tr || val.en || '';
  }
  return val;
};

// UI string translations
const UI = {
  // Navigation
  weekLabel: { tr: "Hafta", en: "Week" },
  nextSection: { tr: "Sonraki â†’", en: "Next â†’" },
  prevSection: { tr: "â† Ã–nceki", en: "â† Previous" },
  sections: { tr: "BÃ¶lÃ¼mler", en: "Sections" },
  completed: { tr: "tamamlandÄ±", en: "completed" },
  
  // Tabs
  tabLecture: { tr: "ğŸ“– Ders", en: "ğŸ“– Lecture" },
  tabExplore: { tr: "ğŸ”¬ KeÅŸfet", en: "ğŸ”¬ Explore" },
  tabGenerate: { tr: "âœ¨ Ãœret", en: "âœ¨ Generate" },
  tabTrain: { tr: "ğŸ”„ EÄŸit", en: "ğŸ”„ Train" },
  tabArch: { tr: "ğŸ—ï¸ Mimari", en: "ğŸ—ï¸ Architecture" },
  
  // Generation tab
  generateName: { tr: "Ä°sim Ãœret", en: "Generate Name" },
  autoGenerate: { tr: "Otomatik Ãœret", en: "Auto Generate" },
  stopGen: { tr: "Durdur", en: "Stop" },
  reset: { tr: "SÄ±fÄ±rla", en: "Reset" },
  temperature: { tr: "SÄ±caklÄ±k", en: "Temperature" },
  step: { tr: "AdÄ±m", en: "Step" },
  token: { tr: "Token", en: "Token" },
  probability: { tr: "OlasÄ±lÄ±k", en: "Probability" },
  generated: { tr: "Ãœretilen", en: "Generated" },
  history: { tr: "GeÃ§miÅŸ", en: "History" },
  
  // Training tab
  startTraining: { tr: "EÄŸitimi BaÅŸlat", en: "Start Training" },
  stopTraining: { tr: "Durdur", en: "Stop" },
  trainingStep: { tr: "EÄŸitim AdÄ±mÄ±", en: "Training Step" },
  loss: { tr: "KayÄ±p", en: "Loss" },
  samples: { tr: "Ã–rnekler", en: "Samples" },
  speed: { tr: "HÄ±z", en: "Speed" },
  
  // Architecture tab
  archTitle: { tr: "Transformer Mimarisi", en: "Transformer Architecture" },
  parameters: { tr: "Parametreler", en: "Parameters" },
  totalParams: { tr: "TOPLAM PARAMETRE", en: "TOTAL PARAMETERS" },
  
  // Explore tab
  details: { tr: "Detaylar", en: "Details" },
  probDist: { tr: "OlasÄ±lÄ±k DaÄŸÄ±lÄ±mÄ±", en: "Probability Distribution" },
  attentionWeights: { tr: "Dikkat AÄŸÄ±rlÄ±klarÄ±", en: "Attention Weights" },
  embeddings: { tr: "GÃ¶mme VektÃ¶rleri", en: "Embeddings" },
  head: { tr: "Kafa", en: "Head" },
  
  // Instructor mode
  instructorMode: { tr: "ğŸ‘¨â€ğŸ« Hoca Modu", en: "ğŸ‘¨â€ğŸ« Instructor Mode" },
  lessonPlan: { tr: "ğŸ“‹ Ders PlanÄ±", en: "ğŸ“‹ Lesson Plan" },
  cheatSheet: { tr: "ğŸ“ Kopya KaÄŸÄ±dÄ±", en: "ğŸ“ Cheat Sheet" },
  
  // Tools
  glossary: { tr: "ğŸ“š SÃ¶zlÃ¼k", en: "ğŸ“š Glossary" },
  quiz: { tr: "ğŸ§ª Quiz", en: "ğŸ§ª Quiz" },
  codeMap: { tr: "ğŸ’» Kod HaritasÄ±", en: "ğŸ’» Code Map" },
  resources: { tr: "ğŸ“ Kaynaklar", en: "ğŸ“ Resources" },
  
  // Common
  clickToExplore: { tr: "TÄ±klayarak keÅŸfedin", en: "Click to explore" },
  showMore: { tr: "Daha fazla gÃ¶ster", en: "Show more" },
  close: { tr: "Kapat", en: "Close" },
  search: { tr: "Ara...", en: "Search..." },
  code: { tr: "Kod", en: "Code" },
  example: { tr: "Ã–rnek", en: "Example" },
  input: { tr: "Girdi", en: "Input" },
  output: { tr: "Ã‡Ä±ktÄ±", en: "Output" },
  
  // Viz
  vizBoxStages: { tr: "AÅŸamalÄ± Pipeline", en: "Stage Pipeline" },
  forward: { tr: "Ä°leri", en: "Forward" },
  backward: { tr: "Geri", en: "Backward" },
  
  // Language toggle
  langTR: { tr: "ğŸ‡¹ğŸ‡· TÃ¼rkÃ§e", en: "ğŸ‡¹ğŸ‡· TÃ¼rkÃ§e" },
  langEN: { tr: "ğŸ‡¬ğŸ‡§ English", en: "ğŸ‡¬ğŸ‡§ English" },
};

const u = (key, lang) => UI[key]?.[lang] || UI[key]?.tr || key;


// â”€â”€â”€ DATA & CONSTANTS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const NAMES = ["emma","olivia","sophia","mia","charlotte","amelia","harper","evelyn","abigail","emily","ella","madison","scarlett","aria","grace","chloe","penelope","riley","layla","nora","zoey","mila","aubrey","hannah","lily","addison","luna","brooklyn","leah","stella","hazel","violet","aurora","lucy","anna","samantha","caroline","maya","sarah","eva","emilia","autumn","quinn","ruby","willow","cora","lydia","clara","vivian","nova","liam","noah","oliver","elijah","james","william","benjamin","lucas","henry","alexander","mason","michael","ethan","daniel","jacob","logan","jackson","levi","sebastian","jack","owen","theodore","aiden","samuel","joseph","john","david","wyatt","matthew","luke","asher","carter","julian","leo","jayden","gabriel","isaac","lincoln","anthony","hudson","dylan","ezra","thomas","caleb"];
const CHARS = ["<BOS>","<EOS>",..."abcdefghijklmnopqrstuvwxyz".split("")];
const VOCAB = CHARS.length;
const stoi = Object.fromEntries(CHARS.map((c, i) => [c, i]));
const itos = Object.fromEntries(CHARS.map((c, i) => [i, c]));
const BOS = 0, EOS = 1;

// â”€â”€â”€ MATH UTILS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
function gauss(s = 0.02) { let u = 0, v = 0; while (!u) u = Math.random(); while (!v) v = Math.random(); return s * Math.sqrt(-2 * Math.log(u)) * Math.cos(2 * Math.PI * v); }
function softmax(x) { const m = Math.max(...x); const e = x.map(v => Math.exp(v - m)); const s = e.reduce((a, b) => a + b); return e.map(v => v / s); }
function softmaxArr(x) { const m = Math.max(...x); const e = x.map(v => Math.exp(v - m)); const s = e.reduce((a, b) => a + b); return e.map(v => v / s); }
function rmsnorm(x) { const ms = x.reduce((a, v) => a + v * v, 0) / x.length; return x.map(v => v / Math.sqrt(ms + 1e-5)); }
function matmul(x, w) { return w.map(r => r.reduce((s, v, i) => s + v * x[i], 0)); }
function relu2(x) { return x.map(v => v > 0 ? v * v : 0); }
function smpl(p) { const r = Math.random(); let c = 0; for (let i = 0; i < p.length; i++) { c += p[i]; if (r < c) return i; } return p.length - 1; }

function createModel(nE = 16, nH = 4, bs = 8) {
  const M = (r, c, s = 0.02) => Array.from({ length: r }, () => Array.from({ length: c }, () => gauss(s)));
  return { sd: { wte: M(VOCAB, nE), wpe: M(bs, nE), wq: M(nE, nE), wk: M(nE, nE), wv: M(nE, nE), wo: M(nE, nE, 0), fc1: M(4 * nE, nE), fc2: M(nE, 4 * nE, 0) }, nE, nH, hd: nE / nH, bs };
}

function fwd(m, tid, pid, K, V) {
  const { sd, nE, nH, hd } = m;
  const te = sd.wte[tid], pe = sd.wpe[pid % m.bs];
  let x = te.map((t, i) => t + pe[i]);
  const D = { te: [...te], pe: [...pe], x0: [...x] };
  let xr = [...x]; x = rmsnorm(x); D.xn = [...x];
  const q = matmul(x, sd.wq), k = matmul(x, sd.wk), v = matmul(x, sd.wv);
  D.q = [...q]; D.k = [...k]; D.v = [...v];
  K.push(k); V.push(v);
  const AW = []; let xA = [];
  for (let h = 0; h < nH; h++) {
    const s = h * hd, qh = q.slice(s, s + hd);
    const sc = K.map(ki => { const kh = ki.slice(s, s + hd); return qh.reduce((a, v2, j) => a + v2 * kh[j], 0) / Math.sqrt(hd); });
    const w = softmax(sc);
    AW.push({ sc: [...sc], w: [...w] });
    const o = Array(hd).fill(0);
    V.forEach((vi, t) => { const vh = vi.slice(s, s + hd); vh.forEach((v2, j) => { o[j] += w[t] * v2; }); });
    xA.push(...o);
  }
  D.AW = AW;
  x = matmul(xA, sd.wo); x = x.map((a, i) => a + xr[i]);
  xr = [...x]; x = rmsnorm(x);
  const h1 = matmul(x, sd.fc1); D.mlpH = [...h1];
  const h2 = relu2(h1); D.mlpAct = [...h2];
  const h3 = matmul(h2, sd.fc2);
  x = h3.map((a, i) => a + xr[i]);
  const logits = matmul(x, sd.wte), probs = softmax(logits);
  D.logits = [...logits]; D.probs = [...probs];
  return { logits, probs, D };
}

// â”€â”€â”€ LECTURE CONTENT â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// â”€â”€â”€ EXPANDED LECTURE CONTENT â€” FULL SEMESTER â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const WEEKS = [
  {
    id: "intro", week: 0, title: { tr: "GiriÅŸ & CanlÄ± Demo", en: "Introduction & Live Demo" }, icon: "ğŸš€", color: "#0EA5E9",
    subtitle: { tr: "microGPT nedir, neden sÄ±fÄ±rdan, kurulum, Ã§alÄ±ÅŸtÄ±rma, sonuÃ§larÄ± gÃ¶zlemleme", en: "What is microGPT, why from scratch, setup, running, observing results" },
    sections: [
      {
        title: { tr: "Derse HoÅŸ Geldiniz â€” Ne Ã–ÄŸreneceksiniz?", en: "Welcome â€” What You Will Learn" },
        viz: "coursePipeline",
        content: "243 satÄ±r saf Python ile tam bir GPT â€” satÄ±r satÄ±r anlayacaksÄ±nÄ±z. HiÃ§bir dÄ±ÅŸ kÃ¼tÃ¼phane yok. YukarÄ±daki pipeline'Ä±n her aÅŸamasÄ±nÄ± ayrÄ± bir hafta iÅŸleyeceÄŸiz.",
        highlight: "\"This file is the complete algorithm. Everything else is just efficiency.\" â€” Andrej Karpathy"
      },
      {
        title: { tr: "Ã–n Bilgi: Yapay Sinir AÄŸÄ± Nedir?", en: "Background: What is a Neural Network?" },
        viz: "neuralNetBasics",
        content: "Sinir aÄŸÄ± = Ã¶ÄŸrenilebilir parametreli bir fonksiyon. 3 sekmeyi keÅŸfedin: ğŸ”¬ NÃ¶ron'da kaydÄ±rÄ±cÄ±larla aÄŸÄ±rlÄ±klarÄ± deÄŸiÅŸtirip Ã§Ä±ktÄ±yÄ± canlÄ± gÃ¶rÃ¼n. ğŸŒŠ Veri AkÄ±ÅŸÄ±'nda verinin nÃ¶rondan nasÄ±l geÃ§tiÄŸini adÄ±m adÄ±m izleyin. ğŸ¯ Mini EÄŸitim'de modelin ev fiyatÄ±nÄ± tahmin etmeyi nasÄ±l Ã¶ÄŸrendiÄŸini simÃ¼le edin.",
        highlight: "EÄŸitim = bu kaydÄ±rÄ±cÄ±larÄ± (wâ‚, wâ‚‚, b) veriye gÃ¶re OTOMATÄ°K ayarlama. GPT'de 3,648 tane var!"
      },
      {
        title: { tr: "Ã–n Bilgi: Dil Modeli Nedir?", en: "Background: What is a Language Model?" },
        viz: "langModelConcept",
        content: "Dil modeli = 'sonraki token ne olabilir?' sorusuna cevap veren olasÄ±lÄ±k makinesi. 3 sekmeyi keÅŸfedin: ğŸ² Autoregressive Ãœretim'de 'emma' isminin harf harf nasÄ±l Ã¼retildiÄŸini izleyin. ğŸ“± Telefon Analojisi'nde harf yazarak autocomplete'in GPT ile aynÄ± mantÄ±kta Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± gÃ¶rÃ¼n. ğŸ“š 'emma' EÄŸitimi'nde her harf Ã§iftinin olasÄ±lÄ±ÄŸÄ±nÄ± eÄŸitim Ã¶ncesi/sonrasÄ± karÅŸÄ±laÅŸtÄ±rÄ±n.",
        highlight: "GPT = telefon autocompletenin Ã§ok bÃ¼yÃ¼k Ã¶lÃ§ekli hali. AynÄ± mantÄ±k: Ã¶nceki tokenlara bakarak sonrakini tahmin et."
      },
      {
        title: { tr: "Ne YapÄ±yor Bu Kod? â€” CanlÄ± Pipeline", en: "What Does This Code Do? â€” Live Pipeline" },
        viz: "livePipeline",
        content: "YukarÄ±daki animasyonda â–¶ butonuna basÄ±n â€” 'emma' isminin 9 aÅŸamalÄ± yolculuÄŸunu adÄ±m adÄ±m izleyin. Her kutuya tÄ±klayarak o aÅŸamanÄ±n detayÄ±nÄ± gÃ¶rebilirsiniz.",
        code: `# Tek komutla Ã§alÄ±ÅŸtÄ±rÄ±n:
$ python3 microgpt.py
# vocab size: 28, num params: 3648
# step 1/1000 | loss 3.33 â† rastgele
# step 1000   | loss 2.00 â† Ã¶ÄŸrendi!
# sample 0: kamrin â† yeni, gerÃ§ekÃ§i isim!`,
        highlight: "Her kutuya tÄ±klayarak o aÅŸamanÄ±n detayÄ±nÄ± gÃ¶rebilirsiniz"
      },
      {
        title: { tr: "Neden SÄ±fÄ±rdan? Framework KarÅŸÄ±laÅŸtÄ±rma", en: "Why From Scratch? Framework Comparison" },
        viz: "frameworkCompare",
        content: "YukarÄ±daki panelde 'ArkasÄ±nda ne var?' butonuna tÄ±klayÄ±n â€” PyTorch'un 3 satÄ±rÄ±nÄ±n arkasÄ±nda neler gizlendiÄŸini gÃ¶rÃ¼n. microgpt.py'de aynÄ± iÅŸlem aÃ§Ä±kÃ§a yazÄ±lmÄ±ÅŸ.",
        highlight: "Framework = verimlilik aracÄ±, algoritma deÄŸil. Ã–nce algoritmayÄ± anlayÄ±n, sonra framework hÄ±zlandÄ±rsÄ±n."
      },
      {
        title: { tr: "Ã–n KoÅŸullar & Kurulum", en: "Prerequisites & Setup" },
        content: "Tek gereksinim: Python 3.6+. pip install gerekmez â€” sadece os, math, random kullanÄ±lÄ±r.",
        code: `# Python kontrol:
$ python3 --version  # 3.6+ yeterli

# pip install GEREKMÄ°YOR!
import os      # dosya kontrolÃ¼
import math    # log, exp
import random  # rastgele sayÄ±lar`,
        highlight: "pip install gerekmez â€” sadece os, math, random kullanÄ±lÄ±r"
      },
      {
        title: { tr: "Kodu Ä°ndirme & Ä°lk Ã‡alÄ±ÅŸtÄ±rma", en: "Download & First Run" },
        content: "GitHub Gist'ten tek dosya indirin ve Ã§alÄ±ÅŸtÄ±rÄ±n. Loss dÃ¼ÅŸÃ¼yorsa her ÅŸey doÄŸru!",
        code: `# Ä°ndir:
$ curl -o microgpt.py https://gist.githubusercontent.com/karpathy/.../microgpt.py

# Ã‡alÄ±ÅŸtÄ±r (hÄ±zlÄ± test):
$ python3 microgpt.py --num_steps 200

# Loss dÃ¼ÅŸÃ¼yorsa â†’ model Ã¶ÄŸreniyor âœ“`,
        highlight: "Loss dÃ¼ÅŸÃ¼yorsa her ÅŸey doÄŸru!"
      },
      {
        title: { tr: "7 Temel Parametre â€” Ä°nteraktif Lab", en: "7 Core Parameters â€” Interactive Lab" },
        viz: "paramDist",
        content: "AÅŸaÄŸÄ±daki kaydÄ±rÄ±cÄ±larla parametreleri deÄŸiÅŸtirin â€” parametre sayÄ±sÄ±, bellek ve komut satÄ±rÄ± komutu canlÄ± gÃ¼ncellenir. n_embd artÄ±nca parametreler KARESEL bÃ¼yÃ¼r!",
        code: `# VarsayÄ±lan:
$ python3 microgpt.py  # 3,648 param

# BÃ¼yÃ¼k model:
$ python3 microgpt.py --n_embd 32 --n_layer 2
# â†’ ~14K param (4Ã— artÄ±ÅŸ!)`,
        highlight: "n_embd artÄ±nca parametreler KARESEL bÃ¼yÃ¼r!"
      },
      {
        title: { tr: "Kendi Verinizi Kullanma", en: "Using Your Own Data" },
        content: "input.txt'i deÄŸiÅŸtirerek TÃ¼rkÃ§e isimler, ÅŸehir adlarÄ± veya hayvan isimleri Ã¶ÄŸretebilirsiniz. Vocab otomatik hesaplanÄ±r.",
        code: `# TÃ¼rkÃ§e isim verisi:
$ cat > input.txt << EOF
ahmet
mehmet
ayse
fatma
zeynep
EOF
$ python3 microgpt.py --num_steps 500
# SonuÃ§: mehet, aysun, fatem...`,
        highlight: "Vocab otomatik hesaplanÄ±r"
      },
      {
        title: { tr: "Ãœretim Evrimi â€” CanlÄ± SimÃ¼lasyon", en: "Generation Evolution â€” Live Simulation" },
        viz: "trainingEvolution",
        content: "â–¶ BaÅŸlat'a basÄ±n â€” eÄŸitim boyunca loss'un dÃ¼ÅŸÃ¼ÅŸÃ¼nÃ¼ ve Ã¼retilen isimlerin kalite artÄ±ÅŸÄ±nÄ± canlÄ± izleyin. KaydÄ±rÄ±cÄ± ile istediÄŸiniz aÅŸamaya zÄ±playabilirsiniz.",
        highlight: "AdÄ±m 1: 'xqwpzml' (rastgele) â†’ AdÄ±m 1000: 'ellora' (gerÃ§ekÃ§i). AynÄ± 3,648 parametre â€” sadece eÄŸitim!"
      },
      {
        title: { tr: "GPT Ailesi â€” Ã–lÃ§ek Kulesi", en: "GPT Family â€” Scale Tower" },
        viz: "gptScaleTower",
        content: "Kulelerin Ã¼zerine gelin â€” her modelin detaylarÄ±nÄ± gÃ¶rÃ¼n. microGPT bir bisiklet, GPT-4 bir uzay mekiÄŸi â€” ama aynÄ± fizik kurallarÄ± geÃ§erli.",
        highlight: "Bu kodu anlarsanÄ±z GPT-4'Ã¼n %90'Ä±nÄ± anlarsÄ±nÄ±z. Kalan %10: RoPE, GQA, SwiGLU, MoE."
      }
    ]
  },

  {
    id: "tokenization", week: 1, title: { tr: "Tokenization & Embedding", en: "Tokenization & Embedding" }, icon: "ğŸ”¤", color: "#8B5CF6",
    subtitle: { tr: "Metni sayÄ±lara, sayÄ±larÄ± vektÃ¶rlere Ã§evirme â€” modelin dÃ¼nyayÄ± gÃ¶rme biÃ§imi", en: "Converting text to numbers, numbers to vectors â€” how the model sees the world" },
    sections: [
      {
        title: { tr: "Ã–n Bilgi: Bilgisayarlar Metni NasÄ±l Ä°ÅŸler?", en: "Background: How Do Computers Process Text?" },
        viz: "tokenFlow",
        content: "Bilgisayarlar metin iÅŸleyemez â€” her ÅŸey sayÄ±sal olmalÄ±dÄ±r. Tokenization = metni modelin anlayacaÄŸÄ± ID dizisine Ã§evirme. Bu kodda her karakter = bir token.",
        highlight: "Tokenization = modelin 'gÃ¶zlÃ¼ÄŸÃ¼'. FarklÄ± tokenizer = farklÄ± dÃ¼nya gÃ¶rÃ¼ÅŸÃ¼."
      },
      {
        title: { tr: "Temel TanÄ±mlar â€” Token, Vocab, Logit", en: "Key Definitions â€” Token, Vocab, Logit" },
        viz: "neuralNetBasics",
        content: "Token = modelin iÅŸlediÄŸi en kÃ¼Ã§Ã¼k birim (bu kodda karakter). Vocabulary = tÃ¼m token kÃ¼mesi (a-z + BOS = 27). Logit = modelin ham Ã§Ä±ktÄ± skorlarÄ± (softmax Ã¶ncesi).",
        highlight: "Metin â†’ sayÄ± â†’ vektÃ¶r dÃ¶nÃ¼ÅŸÃ¼mÃ¼ olmadan model hiÃ§bir ÅŸey yapamaz."
      },
      {
        title: { tr: "ğŸ® Tokenizer Oyun AlanÄ± â€” CanlÄ± SimÃ¼lasyon", en: "ğŸ® Tokenizer Playground â€” Live Simulation" },
        viz: "tokenizerPlayground",
        content: "YukarÄ±ya bir isim yazÄ±n ve â–¶ butonuna basÄ±n â€” tokenization'Ä±n 4 adÄ±mÄ±nÄ± canlÄ± izleyin: karakterlere ayrÄ±lma â†’ ID'lere Ã§evrilme â†’ BOS eklenmesi â†’ eÄŸitim Ã§iftlerinin oluÅŸmasÄ±.",
        code: `# Vocabulary oluÅŸturma:
uchars = sorted(set(''.join(docs)))  # ['a'...'z']
BOS = len(uchars)  # = 26 (Ã¶zel token)

# Tokenize etme:
tokens = [BOS] + [uchars.index(ch) for ch in doc] + [BOS]
# "emma" â†’ [26, 4, 12, 12, 0, 26]`,
        highlight: "YukarÄ±ya bir isim yazÄ±n ve â–¶ butonuna basÄ±n â€” tokenization'Ä±n 4 adÄ±mÄ±nÄ± canlÄ± iz"
      },
      {
        title: { tr: "Ã–n Bilgi: VektÃ¶r Nedir? Neden KullanÄ±rÄ±z?", en: "Background: What is a Vector? Why Use Them?" },
        viz: "vectorConcept",
        content: "VektÃ¶r = sÄ±ralÄ± sayÄ±lar listesi. Benzer ÅŸeyler â†’ yakÄ±n vektÃ¶rler. Bu kodda her token 16 boyutlu bir vektÃ¶rle temsil edilir.",
        highlight: "Embedding = token'Ä± vektÃ¶re Ã§evirme. EÄŸitim sonunda benzer tokenlar yakÄ±n vektÃ¶rlere sahip olur."
      },
      {
        title: { tr: "Token Embedding: ID â†’ VektÃ¶r DÃ¶nÃ¼ÅŸÃ¼mÃ¼", en: "Token Embedding: ID â†’ Vector Transform" },
        viz: "embeddingFlow",
        content: "Embedding tablosu [27Ã—16]. Ä°ÅŸlem basit tablo arama: wte[token_id] â†’ 16-boyutlu vektÃ¶r. BaÅŸlangÄ±Ã§ta rastgele, eÄŸitimle anlam kazanÄ±r.",
        code: `tok_emb = state_dict['wte'][token_id]
# 'a' â†’ ID=0 â†’ wte[0] = [0.02, -0.01, ...]
# EÄŸitim sonrasÄ±: sesli harfler yakÄ±n vektÃ¶rlerde`,
        highlight: "BaÅŸlangÄ±Ã§ta rastgele, eÄŸitimle anlam kazanÄ±r"
      },
      {
        title: { tr: "Position Embedding: SÄ±ra Bilgisi Ekleme", en: "Position Embedding: Adding Order Information" },
        viz: "embeddingFlow",
        content: "Transformer sÄ±ra bilgisi Ä°Ã‡ERMEZ! Position embedding ile her konuma (0-7) Ã¶zgÃ¼ vektÃ¶r eklenir: x = tok_emb + pos_emb.",
        code: `pos_emb = state_dict['wpe'][pos_id]
x = [t + p for t, p in zip(tok_emb, pos_emb)]
# AynÄ± 'a' â†’ pos 0 ve pos 3'te FARKLI temsil`,
        highlight: "Transformer sÄ±ra bilgisi Ä°Ã‡ERMEZ! Position embedding ile her konuma (0-7) Ã¶zgÃ¼ v"
      },
      {
        title: { tr: "Ã–n Bilgi: Matris Ã‡arpÄ±mÄ± (Linear Transform)", en: "Background: Matrix Multiplication (Linear Transform)" },
        viz: "matrixMul",
        content: "Her Ã§Ä±ktÄ± = girdi vektÃ¶rÃ¼ ile aÄŸÄ±rlÄ±k satÄ±rÄ±nÄ±n dot product'Ä±. Transformer'da HER projeksiyon (Wq, Wk, Wv, fc1, fc2) bir matris Ã§arpÄ±mÄ±.",
        code: `def linear(x, weight):
    return [sum(wi*xi for wi,xi in zip(wo,x))
            for wo in weight]
# Wq [16Ã—16] Ã— x [16] = q [16]  (256 Ã§arpma)`,
        highlight: "Transformer'da HER projeksiyon (Wq, Wk, Wv, fc1, fc2) bir matris Ã§arpÄ±mÄ±"
      },
      {
        title: { tr: "Weight Tying & Parametre DaÄŸÄ±lÄ±mÄ±", en: "Weight Tying & Parameter Distribution" },
        viz: "paramDist",
        content: "AynÄ± wte matrisi hem giriÅŸ (lookup) hem Ã§Ä±kÄ±ÅŸ (matris Ã§arpÄ±mÄ±) iÃ§in kullanÄ±lÄ±r â€” weight tying. 3,648 parametrenin %56'sÄ± MLP'de!",
        code: `# GÄ°RÄ°Å: tok_emb = wte[token_id]     # lookup
# Ã‡IKIÅ: logits = linear(x, wte)      # matris Ã§arpÄ±mÄ±
# AynÄ± matris! â†’ 432 param tasarrufu`,
        highlight: "3,648 parametrenin %56'sÄ± MLP'de!"
      },
      {
        title: { tr: "Softmax â€” Skorlardan OlasÄ±lÄ±klara", en: "Softmax â€” From Scores to Probabilities" },
        viz: "softmaxViz",
        content: "Softmax ham skorlarÄ± olasÄ±lÄ±k daÄŸÄ±lÄ±mÄ±na Ã§evirir: P(i) = exp(xi)/Î£exp(xj). Numerik trick: exp(xi-max) ile overflow Ã¶nlenir.",
        code: `def softmax(logits):
    max_val = max(val.data for val in logits)
    exps = [(val - max_val).exp() for val in logits]
    return [e / sum(exps) for e in exps]
# [2.0, 1.0, 0.1] â†’ [0.659, 0.242, 0.099]`,
        highlight: "Numerik trick: exp(xi-max) ile overflow Ã¶nlenir"
      }
    ]
  },

  {
    id: "autograd", week: 2, title: { tr: "Autograd & Backpropagation", en: "Autograd & Backpropagation" }, icon: "â›“ï¸", color: "#F59E0B",
    subtitle: { tr: "Otomatik tÃ¼rev alma, hesaplama grafÄ±, chain rule â€” derin Ã¶ÄŸrenmenin temeli", en: "Automatic differentiation, computation graph, chain rule â€” the foundation of deep learning" },
    sections: [
      {
        title: { tr: "Ã–n Bilgi: TÃ¼rev Nedir? Neden LazÄ±m?", en: "Background: What is a Derivative? Why Do We Need It?" },
        viz: "derivative",
        content: "TÃ¼rev = deÄŸiÅŸim hÄ±zÄ±. f(x) = xÂ² ise f'(3) = 6. Derin Ã¶ÄŸrenmede: âˆ‚L/âˆ‚w = 'w'yi deÄŸiÅŸtirirsem loss ne olur?' Negatif yÃ¶nde gÃ¼ncelle â†’ loss azalÄ±r.",
        highlight: "TÃ¼rev = 'bu parametreyi hangi yÃ¶nde deÄŸiÅŸtirmeliyim ki loss azalsÄ±n?' sorusunun cevabÄ±."
      },
      {
        title: { tr: "Ã–n Bilgi: KÄ±smi TÃ¼rev ve Gradient", en: "Background: Partial Derivatives and Gradients" },
        viz: "derivative",
        content: "f(a,b) = aÃ—b ise âˆ‚f/âˆ‚a = b, âˆ‚f/âˆ‚b = a (diÄŸerini sabit tut). Gradient = tÃ¼m kÄ±smi tÃ¼revlerin vektÃ¶rÃ¼. Gradient descent = gradient'in ters yÃ¶nÃ¼nde adÄ±m at.",
        code: `# f(a,b) = aÃ—b + aÂ²  (a=2, b=3 â†’ f=10)
# âˆ‚f/âˆ‚a = b + 2a = 7  (a'yÄ± 1â†‘ â†’ fâ‰ˆ7â†‘)
# âˆ‚f/âˆ‚b = a = 2        (b'yi 1â†‘ â†’ fâ‰ˆ2â†‘)
# Gradient: âˆ‡f = [7, 2]
# Minimum: a -= lrÃ—7, b -= lrÃ—2`,
        highlight: "Gradient descent = gradient'in ters yÃ¶nÃ¼nde adÄ±m at"
      },
      {
        title: { tr: "ğŸ® Autograd Oyun AlanÄ± â€” CanlÄ± Backward Pass", en: "ğŸ® Autograd Playground â€” Live Backward Pass" },
        viz: "autogradPlayground",
        content: "YukarÄ±da a, b, c deÄŸerlerini kaydÄ±rÄ±cÄ±larla deÄŸiÅŸtirin ve â–¶ Backward butonuna basÄ±n â€” chain rule adÄ±mlarÄ±nÄ±n hesaplama grafÄ± Ã¼zerinde nasÄ±l ilerlediÄŸini canlÄ± izleyin!",
        highlight: "Autograd = derin Ã¶ÄŸrenmeyi mÃ¼mkÃ¼n kÄ±lan teknoloji. Bu kodda ~30 satÄ±rla sÄ±fÄ±rdan yazÄ±lmÄ±ÅŸtÄ±r."
      },
      {
        title: { tr: "Value SÄ±nÄ±fÄ± â€” 4 Temel BileÅŸen", en: "Value Class â€” 4 Core Components" },
        viz: "opGradTable",
        content: "Her sayÄ± Value nesnesi olarak sarmalanÄ±r: data (deÄŸer), grad (tÃ¼rev, baÅŸta 0), _children (girdi dÃ¼ÄŸÃ¼mleri), _local_grads (yerel tÃ¼revler).",
        code: `class Value:
    __slots__ = ('data','grad','_children','_local_grads')
    def __init__(self, data, children=(), local_grads=()):
        self.data = data; self.grad = 0
        self._children = children
        self._local_grads = local_grads`,
        highlight: "Her sayÄ± Value nesnesi olarak sarmalanÄ±r: data (deÄŸer), grad (tÃ¼rev, baÅŸta 0), _"
      },
      {
        title: { tr: "OperatÃ¶r Overloading â€” Otomatik Graf OluÅŸturma", en: "Operator Overloading â€” Automatic Graph Building" },
        viz: "opGradTable",
        content: "a+b, a*b gibi iÅŸlemler otomatik graf oluÅŸturur. Her operasyon yerel gradient'ini bilir: toplamaâ†’(1,1), Ã§arpmaâ†’(b,a), ReLUâ†’(a>0?1:0).",
        code: `def __mul__(self, other):
    other = other if isinstance(other, Value) else Value(other)
    return Value(self.data * other.data,
        (self, other), (other.data, self.data))
# âˆ‚(aÃ—b)/âˆ‚a = b, âˆ‚(aÃ—b)/âˆ‚b = a`,
        highlight: "Her operasyon yerel gradient'ini bilir: toplamaâ†’(1,1), Ã§arpmaâ†’(b,a), ReLUâ†’(a>0?1:0)"
      },
      {
        title: { tr: "Chain Rule & Backward Pass", en: "Chain Rule & Backward Pass" },
        viz: "compGraph",
        content: "Chain rule: f(g(x)) tÃ¼revi = f'(g(x)) Ã— g'(x). TÃ¼revler geri doÄŸru Ã‡ARPILIR. Topological sort ile doÄŸru sÄ±rada, self.grad=1'den baÅŸlayarak hesaplanÄ±r.",
        code: `def backward(self):
    topo = [];

// â”€â”€â”€ ENGLISH CONTENT OVERLAY â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const EN_CONTENT = {
  intro: [
    { content: "A complete GPT in 243 lines of pure Python â€” you will understand every single line. No external libraries. We will cover each stage of the pipeline above in separate weeks.", highlight: "\"This file is the complete algorithm. Everything else is just efficiency.\" â€” Andrej Karpathy" },
    { content: "A neural network = a function with learnable parameters. Explore 3 tabs: ğŸ”¬ Neuron â€” adjust weights with sliders and see the output live. ğŸŒŠ Data Flow â€” follow data through a neuron step by step. ğŸ¯ Mini Training â€” simulate how a model learns to predict house prices.", highlight: "Training = automatically adjusting these sliders (wâ‚, wâ‚‚, b) based on data. GPT has 3,648 of them!" },
    { content: "A language model = a probability machine that answers 'what could the next token be?' Explore 3 tabs: ğŸ² Autoregressive Generation â€” watch how 'emma' is generated letter by letter. ğŸ“± Phone Analogy â€” see how phone autocomplete works on the same principle as GPT. ğŸ“š 'emma' Training â€” compare pre/post training probabilities for each letter pair.", highlight: "GPT = a massively scaled-up version of phone autocomplete. Same logic: predict the next token based on previous ones." },
    { content: "Press â–¶ in the animation above â€” follow the 9-step journey of generating 'emma' step by step. Click each box to see details of that stage.", highlight: "Click each box to see the details of that stage" },
    { content: "Click 'What\'s behind it?' in the panel above â€” see what\'s hidden behind PyTorch\'s 3 lines. In microgpt.py, the same operation is written explicitly.", highlight: "Framework = efficiency tool, not the algorithm. Understand the algorithm first, then let the framework speed things up." },
    { content: "Only requirement: Python 3.6+. No pip install needed â€” only os, math, random are used.", highlight: "No pip install needed â€” only os, math, random are used" },
    { content: "Download a single file from GitHub Gist and run it. If loss is decreasing, everything is working!", highlight: "If loss is decreasing, everything is working!" },
    { content: "Change the parameters with sliders below â€” parameter count, memory, and command line command update live. When n_embd increases, parameters grow QUADRATICALLY!", highlight: "When n_embd increases, parameters grow QUADRATICALLY!" },
    { content: "You can teach Turkish names, city names, or animal names by changing input.txt. Vocabulary is computed automatically.", highlight: "Vocabulary is computed automatically" },
    { content: "Loss start ~3.33 (random guessing among 27 tokens = -log(1/27)). If it drops below 2.0, the model has learned significant patterns. Generated names look realistic even if they\'re not in the training set.", highlight: "Loss < 2.0 means the model has learned! The generated names are new â€” not memorized." },
  ],
  tokenization: [
    { content: "Computers only understand numbers. Tokenization = splitting text into pieces (tokens) and converting each to a number. microGPT uses character-level: each letter = one token. GPT-4 uses BPE: frequent word pieces become single tokens.", highlight: "microGPT: 'emma' â†’ ['e','m','m','a'] â†’ [4,12,12,0]. Character-level = simplest possible tokenizer." },
    { content: "Token, Vocab, BOS, EOS â€” key concepts explained one by one. Token = smallest unit. Vocab = complete set of tokens. microGPT vocab = 27 (a-z + space).", highlight: "Vocab size directly affects model size. More tokens = more parameters = more expressive but harder to train." },
    { content: "Type characters below and watch how they get tokenized in real-time. Compare character-level tokenization with BPE. See how different tokenizers handle the same text differently.", highlight: "BPE learns frequent patterns: 'the' becomes one token instead of three." },
    { content: "A vector = a list of numbers describing something. One number isn\'t enough to describe a letter â€” we need multiple dimensions. Like GPS: latitude alone isn\'t enough, you need longitude too.", highlight: "Embedding dimension (d=16 in microGPT) = how many numbers describe each token. More dimensions = richer description." },
    { content: "Embedding table [27Ã—16]. Operation is simple table lookup: wte[token_id] â†’ 16-dimensional vector. Initially random, gains meaning through training.", highlight: "Initially random, gains meaning through training" },
    { content: "Transformer has no notion of order. Position embedding adds a unique 16-dimensional vector to each position. Without it, 'ab' and 'ba' would look identical.", highlight: "Without position embedding, the model cannot distinguish 'ab' from 'ba'!" },
    { content: "Matrix multiplication = the fundamental operation of neural networks. It transforms vectors from one space to another. Every layer in GPT is essentially a matrix multiplication.", highlight: "Matrix multiplication: the single most important operation in deep learning." },
    { content: "The same embedding matrix is used for both input and output. Input: token_id â†’ vector. Output: vector â†’ logits over vocabulary. This reduces parameters by half!", highlight: "Weight tying: same matrix for input and output = 50% fewer parameters in the embedding layer!" },
    { content: "Softmax converts raw scores (logits) to probabilities. Three properties: all values between 0-1, sum to 1, preserves order. Temperature parameter controls the sharpness of the distribution.", highlight: "Softmax = the bridge between raw model outputs and probabilities." },
  ],
  autograd: [
    { content: "Derivative = how fast does the output change when you slightly change the input? If f(x) = xÂ², then f\'(x) = 2x. At x=3: rate of change = 6. This is the foundation of learning.", highlight: "Derivative is the compass of optimization: it tells us which direction to go and how big of a step to take." },
    { content: "With multiple inputs, we take the derivative with respect to each one separately. Gradient = collection of all partial derivatives. It points in the steepest ascent direction.", highlight: "Gradient = the steepest direction. Go opposite to minimize loss." },
    { content: "Build computation graphs, set values, and watch gradients flow backward in real-time. This is exactly what happens inside GPT during training.", highlight: "Every forward pass builds a graph. Backward pass computes gradients through this graph." },
    { content: "4 components: data (the number), grad (gradient, starts at 0), _backward (gradient computation function), _children (input nodes). Together they enable automatic differentiation.", highlight: "Value class = the atom of autograd. Everything builds on these 4 components." },
    { content: "When you write c = a + b, Python calls __add__. We override this to also build the computation graph. Result: math works normally AND the graph is built automatically.", highlight: "Operator overloading = the magic trick that makes autograd feel like normal math." },
    { content: "Chain rule: derivative of a composition = product of derivatives. f(g(x))\' = f\'(g(x)) Ã— g\'(x). Backward pass applies this rule from output to input, through the entire graph.", highlight: "Chain rule is the mathematical foundation of backpropagation." },
    { content: "Topological sort ensures we process nodes in the right order. Gradient accumulation (+=, not =): when a variable is used multiple times, gradients ADD UP.", highlight: "Critical: grad += (not =!) â€” Gradients ACCUMULATE." },
    { content: "Our Value class: Python, CPU, educational, ~50 lines. PyTorch Tensor: C++/CUDA, GPU, production, millions of lines. Same algorithm, vastly different scale.", highlight: "Same algorithm, vastly different scale. Understanding Value = understanding PyTorch internals." },
  ],
  attention: [
    { content: "RNN processes sequentially â†’ can\'t parallelize â†’ slow. Information from early words fades in long sentences. Attention: every word can directly look at every other word.", highlight: "RNN: O(n) steps, Transformer: O(1) steps. Everyone sees everyone!" },
    { content: "Dot product measures how similar two vectors are. Large positive = very similar, near zero = unrelated, large negative = opposite. This is how attention decides which tokens to focus on.", highlight: "Dot product = the similarity engine of attention." },
    { content: "Each token creates 3 vectors: Q (what am I looking for?), K (what do I contain?), V (here is my information). High QÂ·K score â†’ take more of that token\'s V.", highlight: "Library analogy: Q = topic you\'re searching for, K = book label, V = book content." },
    { content: "Attention(Q,K,V) = softmax(QKáµ€/âˆšd)V. The âˆšd scaling prevents dot products from getting too large, which would make softmax too sharp (one-hot).", highlight: "Scaling by âˆšd is crucial: without it, gradients vanish in softmax\'s flat regions." },
    { content: "Instead of one attention with d dimensions, use h heads each with d/h dimensions. Different heads learn different patterns: one might focus on position, another on phonetics.", highlight: "Multi-head = ensemble of specialists. Each head captures different relationships." },
    { content: "In generation, future tokens don\'t exist yet. Causal mask sets future attention scores to -âˆ â†’ softmax makes them 0. The model can only look backward.", highlight: "Causal mask: the fundamental constraint that makes autoregressive generation possible." },
  ],
  transformer: [
    { content: "RMSNorm normalizes the vector. ~30% faster than LayerNorm: no mean subtraction. Prevents gradient explosion by keeping values in a reasonable range.", highlight: "RMSNorm = LayerNorm minus the mean subtraction. Simpler and faster." },
    { content: "2-layer network: expand 4Ã— then compress back. fc1: dâ†’4d (expand information), ReGLU activation (filter), fc2: 4dâ†’d (compress back). This is where the model stores knowledge.", highlight: "MLP = the model\'s knowledge store. Attention routes information, MLP processes it." },
    { content: "x = x + sublayer(x). Without residuals, gradients vanish in deep networks. Residual connections create a direct path for gradients to flow through.", highlight: "Residual connections = the information highway. They are what make deep networks trainable." },
    { content: "Input â†’ RMSNorm â†’ Self-Attention â†’ Residual â†’ RMSNorm â†’ MLP â†’ Residual â†’ Output. This is the complete transformer block. microGPT has exactly 1 such block.", highlight: "One block = Norm + Attention + Residual + Norm + MLP + Residual. Stack N of these = GPT." },
    { content: "Follow dimension changes through the entire model: token_id (scalar) â†’ embedding (d) â†’ attention Q,K,V (d) â†’ head split (d/h per head) â†’ merge (d) â†’ MLP (4dâ†’d) â†’ logits (vocab).", highlight: "Understanding dimension flow = understanding the architecture." },
  ],
  training: [
    { content: "Cross-entropy measures surprise: if the model assigns high probability to the correct answer, loss is low. L = -log(P(target)). Starting loss â‰ˆ 3.33 = random guessing among 27 tokens.", highlight: "Low probability â†’ high surprise â†’ high loss. Training = reducing surprise." },
    { content: "Imagine a hilly landscape where height = loss. Gradient descent = always walk downhill. The gradient tells you the steepest direction. Step size = learning rate.", highlight: "Gradient descent: the optimization algorithm behind virtually all of deep learning." },
    { content: "Too large â†’ oscillate and diverge. Too small â†’ painfully slow. The sweet spot depends on the problem. Common trick: start large, decay over time (learning rate schedule).", highlight: "Learning rate is the single most important hyperparameter in training." },
    { content: "Adam = SGD + momentum + adaptive learning rate. Momentum: use past gradients for smoother updates. Adaptive: each parameter gets its own learning rate. This is what microGPT uses.", highlight: "Adam: the default optimizer for transformers. Combines the best ideas in optimization." },
    { content: "Complete loop: forward pass â†’ compute loss â†’ backward pass â†’ update parameters â†’ zero gradients â†’ repeat. 500+ iterations. Loss goes from 3.33 to ~2.0.", highlight: "Training loop = the heartbeat of machine learning. Forward â†’ Loss â†’ Backward â†’ Update â†’ Repeat." },
  ],
  inference: [
    { content: "Training: forward + backward + update (parallel, gradients needed). Inference: forward only (sequential, no gradients â†’ fast, low memory). Training = studying for an exam, Inference = taking the exam.", highlight: "Training = learning, Inference = applying what was learned. Very different computational profiles." },
    { content: "Generate one token at a time: feed current sequence â†’ get probability distribution â†’ sample next token â†’ append â†’ repeat until EOS. Each step requires a full forward pass.", highlight: "Autoregressive = each new token depends on ALL previous tokens." },
    { content: "Temperature < 1: sharper distribution â†’ more predictable. Temperature > 1: flatter â†’ more creative/random. Top-k: only consider the k most likely tokens, ignore the rest.", highlight: "Temperature controls the creativity-coherence tradeoff." },
    { content: "Without cache: re-compute attention for ALL previous tokens at each step. With KV cache: store K,V from previous steps, only compute for the new token. Huge speedup!", highlight: "KV cache: the key optimization that makes autoregressive generation practical." },
    { content: "Explore all 3,648 parameters: where are they, what do they do? Weight initialization: small random values (Gaussian, Ïƒ=0.02). Too large â†’ explosion, too small â†’ vanishing signals.", highlight: "Initialization matters: the right starting point makes training much easier." },
  ],
  evolution: [
    { content: "More parameters = lower loss, but with diminishing returns. Chinchilla scaling: optimal compute allocation between model size and data. Key insight: most models are undertrained!", highlight: "Scaling laws: the empirical foundation of modern AI. Predictable performance from compute budget." },
    { content: "From CPUs to GPUs to TPUs to custom AI chips. GPU parallelism is what makes transformer training feasible. Memory bandwidth is often the bottleneck.", highlight: "Hardware evolution drives AI capability. Each generation enables 10Ã— larger models." },
    { content: "Data collection â†’ cleaning â†’ tokenization â†’ training â†’ evaluation. Modern models train on trillions of tokens. Data quality matters as much as quantity.", highlight: "Data pipeline: garbage in, garbage out. The most important and least glamorous part of AI." },
    { content: "BPE â†’ WordPiece â†’ Unigram â†’ SentencePiece. Evolution towards: language-agnostic, efficient, robust tokenization. Modern tokenizers handle 100K+ vocabulary.", highlight: "Tokenization has evolved from simple character splits to sophisticated subword algorithms." },
    { content: "Full attention is O(nÂ²). Solutions: sparse attention, linear attention, flash attention. FlashAttention: same result, 2-4Ã— faster through memory-aware computation.", highlight: "FlashAttention: the breakthrough that made long-context models practical." },
    { content: "LLaMA, Mistral, Phi, Gemma, Qwen â€” the open source ecosystem is thriving. Open weights enable research, fine-tuning, and deployment without API dependencies.", highlight: "Open source AI: democratizing access to state-of-the-art models." },
    { content: "MoE (Mixture of Experts), multimodal models, agents, reasoning chains, RLHF/DPO alignment. The field is evolving at unprecedented speed.", highlight: "The pace of AI innovation continues to accelerate. Today\'s cutting edge is tomorrow\'s baseline." },
  ],
  paper: [
    { content: "In 2017, Google researchers discarded RNNs and CNNs entirely and built the Transformer model using only attention. Better results AND much faster.", highlight: "Old approach (RNN): processes each word SEQUENTIALLY. Transformer looks at ALL words simultaneously." },
    { content: "RNN is sequential â†’ can\'t parallelize â†’ slow. Information from early words is lost in long sentences. Gradient explosion/vanishing occurs.", highlight: "RNN: O(n) steps, Transformer: O(1) steps. Everyone sees everyone!" },
    { content: "Query: What am I looking for? Key: What do I have? Value: Here\'s my information. High QÂ·K â†’ take more information from that word\'s Value!", highlight: "Library analogy: Query = topic you\'re searching for, Key = book label, Value = book content." },
    { content: "3 key formulas: â‘  Dot Product â‘¡ Softmax â‘¢ Scaled Dot-Product Attention. Explore each with sliders.", highlight: "Attention(Q,K,V) = softmax(QKáµ€/âˆšd)V â€” the paper\'s most famous formula." },
    { content: "Encoder understands the input sentence (6 layers). Decoder generates the output sentence (6 layers). Each layer: Attention + FFN + Residual + LayerNorm.", highlight: "Decoder has causal mask: cannot see future words!" },
    { content: "Transformer has no notion of order! Sin/cos waves add a unique \'fingerprint\' to each position. Different frequencies capture patterns at different scales.", highlight: "Low dimensions change fast (treble), high dimensions change slow (bass) â€” like a piano!" },
    { content: "4.5M sentence pairs, 8Ã— P100 GPU, 3.5 days. ENâ†’DE: 28.4 BLEU (record!). ENâ†’FR: 41.8 BLEU. Warmup + label smoothing + dropout.", highlight: "Base model: 65M parameters. Big model: 213M parameters. Today\'s GPT-4: ~1T+ parameters!" },
    { content: "90K+ citations! GPT, BERT, ViT, DALL-E, AlphaFold, Copilot â€” all Transformer-based. A 15-page paper changed all of AI.", highlight: "Not just language: vision (ViT), protein (AlphaFold), music (MusicGen), code (Copilot)." },
  ],
};
 visited = set()
    def build_topo(v):
        if v not in visited:
            visited.add(v)
            for child in v._children: build_topo(child)
            topo.append(v)
    build_topo(self)
    self.grad = 1  # âˆ‚L/âˆ‚L = 1
    for v in reversed(topo):
        for child, lg in zip(v._children, v._local_grads):
            child.grad += lg * v.grad  # chain rule!`,
        highlight: "Topological sort ile doÄŸru sÄ±rada, self.grad=1'den baÅŸlayarak hesaplanÄ±r"
      },
      {
        title: "Somut Ã–rnek: L = (a Ã— b) + c",
        viz: "compGraph",
        content: "a=2, b=3, c=1 â†’ d=6, L=7. Backward: âˆ‚L/âˆ‚L=1, âˆ‚L/âˆ‚d=1, âˆ‚L/âˆ‚c=1, âˆ‚L/âˆ‚a=b=3, âˆ‚L/âˆ‚b=a=2. Autograd oyun alanÄ±nda bizzat deneyin!",
        highlight: "a.grad=3 â†’ a'yÄ± 1 birim artÄ±rÄ±rsak loss 3 birim artar. Optimizer bu bilgiyi kullanÄ±r."
      },
      {
        title: "Gradient ToplanmasÄ± (+=) Neden Kritik?",
        viz: "compGraph",
        content: "L = aÃ—a ise âˆ‚L/âˆ‚a = 2a. += ile iki yoldan gelen gradient toplanÄ±r â†’ doÄŸru. = ile sadece son yol kalÄ±r â†’ yanlÄ±ÅŸ! Weight tying, residual'da bu durum sÃ¼rekli olur.",
        code: `a = Value(3); L = a * a  # a Ä°KÄ° KEZ kullanÄ±lÄ±r
# += ile: a.grad = 3 + 3 = 6 = 2a  âœ“
# =  ile: a.grad = 3  â† YANLIÅ! (2a=6 olmalÄ±)`,
        highlight: "= ile sadece son yol kalÄ±r â†’ yanlÄ±ÅŸ! Weight tying, residual'da bu durum sÃ¼rekli olur"
      },
      {
        title: "Bu Kod vs. PyTorch KarÅŸÄ±laÅŸtÄ±rma",
        viz: "opGradTable",
        content: "Birebir aynÄ± gradient deÄŸerleri! Fark: Value=skaler (~30 satÄ±r Python), Tensor=N-boyutlu (~100K+ satÄ±r C++/CUDA, GPU ile milyonlarca kat hÄ±zlÄ±).",
        highlight: "Her eÄŸitim adÄ±mÄ±nda p.grad = 0 yapÄ±lmazsa gradient birikir â†’ model patlar!"
      }
    ]
  },

  {
    id: "attention", week: 3, title: { tr: "Self-Attention MekanizmasÄ±", en: "Self-Attention Mechanism" }, icon: "ğŸ”", color: "#10B981",
    subtitle: { tr: "QÂ·Káµ€/âˆšd â†’ Softmax â†’ V â€” Transformer'Ä±n kalbi", en: "QÂ·Káµ€/âˆšd â†’ Softmax â†’ V â€” The heart of the Transformer" },
    sections: [
      {
        title: "Ã–n Bilgi: RNN'den Attention'a",
        viz: "rnnToAttn",
        content: "2017 Ã¶ncesi RNN/LSTM standardÄ±: sÄ±ralÄ±, yavaÅŸ, uzun mesafe baÄŸÄ±mlÄ±lÄ±klarÄ±nÄ± unutur. 'Attention Is All You Need' â†’ RNN'yi kaldÄ±r, SADECE attention kullan = Transformer.",
        highlight: "Transformer = Attention + Feed-Forward, RNN yok. Bu basit fikir tÃ¼m modern AI'Ä± mÃ¼mkÃ¼n kÄ±ldÄ±."
      },
      {
        title: "Self-Attention â€” Sezgisel Anlama",
        viz: "attentionFlow",
        content: "Her token Ã¶nceki tokenlara bakarak bilgi toplar. BazÄ±larÄ±na Ã§ok dikkat eder (yÃ¼ksek aÄŸÄ±rlÄ±k), bazÄ±larÄ±nÄ± yok sayar. Bu aÄŸÄ±rlÄ±klar dinamik â€” her girdi iÃ§in yeniden hesaplanÄ±r.",
        highlight: "Attention = dinamik, veri-baÄŸÄ±mlÄ± aÄŸÄ±rlÄ±klama. Statik deÄŸil â€” her girdi iÃ§in farklÄ±."
      },
      {
        title: "Query, Key, Value â€” 3 FarklÄ± Rol",
        viz: "attentionFlow",
        content: "Q = 'ne arÄ±yorum?', K = 'bende ne var?', V = 'bilgim nedir'. QÂ·K dot product = uyum skoru. YÃ¼ksek skor â†’ V'den daha Ã§ok bilgi al.",
        code: `q = linear(x, state_dict['attn_wq'])  # [16]â†’[16]
k = linear(x, state_dict['attn_wk'])
v = linear(x, state_dict['attn_wv'])
# QÂ·K yÃ¼ksek â†’ o token'a Ã§ok dikkat et`,
        highlight: "YÃ¼ksek skor â†’ V'den daha Ã§ok bilgi al"
      },
      {
        title: "ğŸ® Attention Oyun AlanÄ± â€” Head KalÄ±plarÄ±nÄ± KeÅŸfet",
        viz: "attentionPlayground",
        content: "YukarÄ±da 4 farklÄ± head seÃ§ip 'Banana' kelimesinde her token'Ä±n nelere dikkat ettiÄŸini gÃ¶rÃ¼n. SatÄ±rlara tÄ±klayarak dikkat daÄŸÄ±lÄ±mÄ±nÄ± inceleyin â€” her head farklÄ± kalÄ±p Ã¶ÄŸrenir!",
        highlight: "Her head baÄŸÄ±msÄ±z attention hesabÄ± yapar. Biri sesli-sessiz uyumunu, diÄŸeri pozisyon yakÄ±nlÄ±ÄŸÄ±nÄ± Ã¶ÄŸrenebilir."
      },
      {
        title: "Scaled Dot-Product â€” Tam Hesaplama",
        viz: "attentionFlow",
        content: "4 adÄ±m: QÂ·K (skor) â†’ Ã·âˆšd (scaling) â†’ softmax (olasÄ±lÄ±k) â†’ Ã—V (bilgi toplama). âˆšd bÃ¶lme kritik: boyut bÃ¼yÃ¼yÃ¼nce softmax spike yapar, gradient kaybolur.",
        code: `for t in range(len(keys)):
    score[t] = dot(q, keys[t]) / sqrt(head_dim)
weights = softmax(scores)
out = weighted_sum(weights, values)
# Attention(Q,K,V) = softmax(QÂ·Káµ€/âˆšd)Â·V`,
        highlight: "âˆšd bÃ¶lme kritik: boyut bÃ¼yÃ¼yÃ¼nce softmax spike yapar, gradient kaybolur"
      },
      {
        title: "Ã–n Bilgi: Dot Product â€” Benzerlik Ã–lÃ§Ã¼mÃ¼",
        viz: "dotProduct",
        content: "aÂ·b = Î£ aáµ¢Ã—báµ¢. AynÄ± yÃ¶n â†’ pozitif (benzer), dik â†’ 0 (ilgisiz), ters â†’ negatif (zÄ±t). QÂ·K = sorgu ile anahtar ne kadar uyumlu?",
        code: `# qÂ·k1 = 0.2+0.06+0.02+0.03 = 0.31 (benzer!)
# qÂ·k2 = -0.25-0.09-0.04-0.01 = -0.39 (zÄ±t)
# â†’ q, k1'e daha Ã§ok dikkat edecek`,
        highlight: "QÂ·K = sorgu ile anahtar ne kadar uyumlu?"
      },
      {
        title: "Multi-Head & Causal Masking",
        viz: "causalMask",
        content: "16 boyut â†’ 4 head Ã— 4 dim. Her head baÄŸÄ±msÄ±z attention yapar, sonra birleÅŸtirilip Wo ile projekte edilir. Causal mask: her token sadece Ã–NCEKÄ°LERÄ° gÃ¶rÃ¼r.",
        code: `# Multi-head: her head 4 boyutluk dilim
for h in range(4):
    q_h = q[h*4:(h+1)*4]
    # baÄŸÄ±msÄ±z attention â†’ concatenate â†’ Wo
# Causal: KV cache = doÄŸal mask`,
        highlight: "Causal mask: her token sadece Ã–NCEKÄ°LERÄ° gÃ¶rÃ¼r"
      },
      {
        title: "Attention Ã‡Ä±ktÄ±sÄ± & Linear Projeksiyon",
        viz: "residualViz",
        content: "4 head birleÅŸtirilir (4Ã—4=16), Wo matrisi ile projekte edilir, residual eklenir: x = WoÃ—heads + x_residual. Wo sÄ±fÄ±rda baÅŸlar â†’ baÅŸta identity.",
        code: `# 6 linear projeksiyon: Wq, Wk, Wv, Wo, fc1, fc2
# Hepsi aynÄ±: x Ã— W (bias yok, modern trend)`,
        highlight: "Wo sÄ±fÄ±rda baÅŸlar â†’ baÅŸta identity"
      }
    ]
  },

  {
    id: "transformer", week: 4, title: { tr: "Transformer BloklarÄ±", en: "Transformer Blocks" }, icon: "ğŸ§±", color: "#EC4899",
    subtitle: { tr: "RMSNorm, MLP, Residual â€” tam mimari, katman katman", en: "RMSNorm, MLP, Residual â€” full architecture, layer by layer" },
    sections: [
      {
        title: "Genel Mimari â€” BÃ¼yÃ¼k Resim",
        viz: "archPipeline",
        content: "Bir Transformer katmanÄ± = Attention + MLP. Her blok Ã¶ncesi RMSNorm, sonrasÄ± residual. AkÄ±ÅŸ: x â†’ norm â†’ attn â†’ +x â†’ norm â†’ MLP â†’ +x â†’ Ã§Ä±ktÄ±.",
        highlight: "Pre-norm: norm â†’ block â†’ +residual. Modern modellerin standardÄ± â€” daha kararlÄ± eÄŸitim."
      },
      {
        title: "ğŸ® Transformer BloÄŸu â€” AdÄ±m AdÄ±m SimÃ¼lasyon",
        viz: "transformerBlockFlow",
        content: "â–¶ AkÄ±ÅŸ butonuna basÄ±n ve 8 aÅŸamayÄ± sÄ±rayla izleyin: girdi â†’ RMSNorm â†’ Attention â†’ +Residual â†’ RMSNorm â†’ MLP â†’ +Residual â†’ Ã§Ä±ktÄ±. Kutulara tÄ±klayarak adÄ±m atlayÄ±n.",
        highlight: "Her aÅŸama bir iÅŸlev: Norm=kararlÄ±lÄ±k, Attn=bilgi toplama, MLP=bilgi iÅŸleme, Residual=gradient highway."
      },
      {
        title: "RMSNorm â€” NasÄ±l Ã‡alÄ±ÅŸÄ±r?",
        viz: "normCompare",
        content: "RMS = âˆšmean(xÂ²). Her elemanÄ± RMS'e bÃ¶l â†’ normalize. LayerNorm'dan farkÄ±: ortalama Ã§Ä±karmaz â†’ %30 daha hÄ±zlÄ±, eÅŸdeÄŸer kalite.",
        code: `def rmsnorm(x):
    ms = sum(xi*xi for xi in x) / len(x)
    scale = (ms + 1e-5) ** -0.5
    return [xi * scale for xi in x]`,
        highlight: "LayerNorm'dan farkÄ±: ortalama Ã§Ä±karmaz â†’ %30 daha hÄ±zlÄ±, eÅŸdeÄŸer kalite"
      },
      {
        title: "MLP Bloku â€” Feed-Forward Network",
        viz: "mlpFlow",
        content: "Her token'Ä± baÄŸÄ±msÄ±z iÅŸler: geniÅŸlet (16â†’64) â†’ ReLUÂ² aktive â†’ daralt (64â†’16). ~%40 nÃ¶ron 'Ã¶lÃ¼' kalÄ±r (sparse = iyi!).",
        code: `h = linear(x, state_dict['mlp_fc1'])  # 16â†’64
h = [xi.relu()**2 for xi in h]        # ReLUÂ²
x = linear(h, state_dict['mlp_fc2'])  # 64â†’16
x = [a+b for a,b in zip(x, x_res)]   # +residual`,
        highlight: "~%40 nÃ¶ron 'Ã¶lÃ¼' kalÄ±r (sparse = iyi!)"
      },
      {
        title: "Ã–n Bilgi: Aktivasyon Fonksiyonu Neden Gerekli?",
        viz: "activation",
        content: "Aktivasyon olmadan derin aÄŸ = tek matris Ã§arpÄ±mÄ± (Wâ‚ƒÃ—Wâ‚‚Ã—Wâ‚Ã—x = WÃ—x). Non-linearity her katmana farklÄ± karar sÄ±nÄ±rÄ± Ã¶ÄŸretir.",
        highlight: "Aktivasyon = non-linearity. Onsuz derin aÄŸ = basit matris Ã§arpÄ±mÄ±. TÃ¼m gÃ¼Ã§ buradan gelir."
      },
      {
        title: "Residual BaÄŸlantÄ±lar â€” Gradient Highway",
        viz: "residualViz",
        content: "x = f(x) + x. Gradient doÄŸrudan giriÅŸe akar: âˆ‚L/âˆ‚x = âˆ‚L/âˆ‚out Ã— (âˆ‚f/âˆ‚x + 1). +1 terimi = kestirme yol. Wo ve fc2 sÄ±fÄ±rda baÅŸlar â†’ baÅŸta identity.",
        code: `# Attention: x = attention(norm(x)) + x_res
# MLP:       x = mlp(norm(x)) + x_res
# Gradient: +1 terimi gradient'in kaybolmasÄ±nÄ± Ã¶nler`,
        highlight: "Wo ve fc2 sÄ±fÄ±rda baÅŸlar â†’ baÅŸta identity"
      },
      {
        title: "Weight Initialization â€” Kritik BaÅŸlatma",
        viz: "weightInit",
        content: "Genel parametreler: std=0.08 â‰ˆ 1/âˆšn_embd. Wo ve fc2: std=0 â†’ baÅŸta residual = identity. Ã‡ok bÃ¼yÃ¼k â†’ patlama, Ã§ok kÃ¼Ã§Ã¼k â†’ kaybolma.",
        code: `# Genel: random.gauss(0, 0.08)
# Wo, fc2: random.gauss(0, 0.0)  â† sÄ±fÄ±ra yakÄ±n
# â†’ BaÅŸta: x â‰ˆ x + 0 = x (identity)`,
        highlight: "Ã‡ok bÃ¼yÃ¼k â†’ patlama, Ã§ok kÃ¼Ã§Ã¼k â†’ kaybolma"
      },
      {
        title: "RMSNorm vs LayerNorm â€” KarÅŸÄ±laÅŸtÄ±rma",
        viz: "normCompare",
        content: "LayerNorm: Î¼ Ã§Ä±kar, Ïƒ'ya bÃ¶l, Î³ ve Î² uygula (4 iÅŸlem). RMSNorm: sadece RMS'e bÃ¶l, Î³ uygula (2 iÅŸlem). LLaMA, Mistral, Gemma hep RMSNorm.",
        highlight: "Ortalama Ã§Ä±karmak gereksiz bulundu â€” %30 hÄ±z kazancÄ±, sÄ±fÄ±r kalite kaybÄ±."
      }
    ]
  },

  {
    id: "training", week: 5, title: { tr: "EÄŸitim DÃ¶ngÃ¼sÃ¼", en: "Training Loop" }, icon: "ğŸ”„", color: "#EF4444",
    subtitle: { tr: "Loss, optimizer, learning rate â€” modeli Ã¶ÄŸretme sanatÄ±", en: "Loss, optimizer, learning rate â€” the art of teaching a model" },
    sections: [
      {
        title: "Ã–n Bilgi: Optimizasyon Nedir?",
        viz: "gradDescent",
        content: "Optimizasyon = loss fonksiyonunun minimumunu bulma. 3,648 boyutlu uzayda en alÃ§ak noktayÄ± arÄ±yoruz. Gradient descent = her adÄ±mda gradient'in ters yÃ¶nÃ¼nde kÃ¼Ã§Ã¼k adÄ±m.",
        highlight: "Derin Ã¶ÄŸrenme = fonksiyon optimizasyonu. Loss'u minimize eden parametreleri bulmak = tÃ¼m iÅŸ."
      },
      {
        title: "Gradient Descent â€” Sezgisel Anlama",
        viz: "gradDescent",
        content: "GÃ¶zleri kapalÄ± daÄŸda: en dik yokuÅŸu hissedip (gradient) tersine adÄ±m at (gÃ¼ncelleme). AdÄ±m boyutu = learning rate. Ã‡ok bÃ¼yÃ¼k â†’ patlama, Ã§ok kÃ¼Ã§Ã¼k â†’ yavaÅŸ.",
        code: `p.data -= learning_rate * p.grad
# grad>0 â†’ p azalt, grad<0 â†’ p artÄ±r, grad=0 â†’ minimum`,
        highlight: "Ã‡ok bÃ¼yÃ¼k â†’ patlama, Ã§ok kÃ¼Ã§Ã¼k â†’ yavaÅŸ"
      },
      {
        title: "ğŸ® EÄŸitim SimÃ¼lasyonu â€” LR Etkisini Dene",
        viz: "trainingSim",
        content: "YukarÄ±da learning rate kaydÄ±rÄ±cÄ±sÄ±nÄ± ayarlayÄ±p â–¶ EÄŸit butonuna basÄ±n. Loss eÄŸrisinin nasÄ±l deÄŸiÅŸtiÄŸini gÃ¶zlemleyin: Ã§ok yÃ¼ksek LR â†’ patlama, Ã§ok dÃ¼ÅŸÃ¼k â†’ yavaÅŸ Ã¶ÄŸrenme, doÄŸru LR â†’ gÃ¼zel dÃ¼ÅŸÃ¼ÅŸ!",
        highlight: "LR Ã§ok bÃ¼yÃ¼k â†’ diverge, Ã§ok kÃ¼Ã§Ã¼k â†’ Ã§ok yavaÅŸ. Ä°yi bÃ¶lge: 0.005-0.05 arasÄ±."
      },
      {
        title: "Cross-Entropy Loss",
        viz: "lossTable",
        content: "L = -log(P(doÄŸru_token)). P=1â†’L=0, P=1/27â†’Lâ‰ˆ3.33 (rastgele). EÄŸitimle loss dÃ¼ÅŸer: 3.33 â†’ 2.8 â†’ 2.0 â†’ 1.5.",
        code: `loss_t = -probs[target_id].log()
loss = (1/n) * sum(losses)  # ortalama
# BaÅŸlangÄ±Ã§ â‰ˆ 3.33, hedef < 2.0`,
        highlight: "EÄŸitimle loss dÃ¼ÅŸer: 3.33 â†’ 2.8 â†’ 2.0 â†’ 1.5"
      },
      {
        title: "Ã–n Bilgi: Log Fonksiyonu â€” Neden?",
        viz: "crossEntropyGraph",
        content: "-log(p): p=1â†’0, pâ†’0â†’âˆ. DÃ¼ÅŸÃ¼k olasÄ±lÄ±ÄŸa aÄŸÄ±r ceza. Ã‡arpÄ±mlarÄ± toplama Ã§evirir (numerik kararlÄ±lÄ±k). Bilgi teorisi: sÃ¼rpriz Ã¶lÃ§Ã¼sÃ¼.",
        highlight: "-log(p) = sÃ¼rpriz. Beklenmeyen olay â†’ yÃ¼ksek sÃ¼rpriz â†’ yÃ¼ksek loss. Model sÃ¼rprizi minimize eder."
      },
      {
        title: "Adam Optimizer â€” SGD'nin Evrimi",
        viz: "adamEvolution",
        content: "SGD sorunlarÄ±: tek lr, gÃ¼rÃ¼ltÃ¼ye duyarlÄ±. Adam = Momentum (yÃ¶n) + RMSprop (Ã¶lÃ§ek). Her parametre kendi adaptif lr'Ä±nÄ± alÄ±r. NLP standardÄ±.",
        code: `m[i] = 0.85*m[i] + 0.15*p.grad      # momentum
v[i] = 0.99*v[i] + 0.01*p.grad**2   # adaptif Ã¶lÃ§ek
p.data -= lr * m_hat / (v_hat**0.5 + 1e-8)
p.grad = 0  # â† KRÄ°TÄ°K sÄ±fÄ±rlama!`,
        highlight: "SGD sorunlarÄ±: tek lr, gÃ¼rÃ¼ltÃ¼ye duyarlÄ±"
      },
      {
        title: "Learning Rate Decay & EÄŸitim DÃ¶ngÃ¼sÃ¼",
        viz: "lrDecay",
        content: "Linear decay: lr_t = lr Ã— (1 - step/num_steps). Modern: warmup + cosine decay. Tam dÃ¶ngÃ¼: forward â†’ loss â†’ backward â†’ adam gÃ¼ncelle â†’ grad sÄ±fÄ±rla â†’ tekrarla.",
        code: `lr_t = learning_rate * (1 - step / num_steps)
# step=0: lr=0.01, step=500: 0.005, step=1000: 0.0`,
        highlight: "Tam dÃ¶ngÃ¼: forward â†’ loss â†’ backward â†’ adam gÃ¼ncelle â†’ grad sÄ±fÄ±rla â†’ tekrarla"
      },
      {
        title: "Gradient SÄ±fÄ±rlama â€” Neden Åart?",
        viz: "trainingCycle",
        content: "Backward += ile gradient biriktirir. SÄ±fÄ±rlanmazsa: 0.5 â†’ 0.8 â†’ 1.5 â†’ âˆ â†’ model patlar! Her adÄ±mda p.grad = 0 yapÄ±lmalÄ±.",
        code: `for i, p in enumerate(params):
    p.data -= lr_t * m_hat / (v_hat**0.5 + 1e-8)
    p.grad = 0  # â† BU SATIR OLMADAN MODEL PATLAR`,
        highlight: "SÄ±fÄ±rlanmazsa: 0.5 â†’ 0.8 â†’ 1.5 â†’ âˆ â†’ model patlar! Her adÄ±mda p.grad = 0 yapÄ±lmalÄ±"
      }
    ]
  },

  {
    id: "inference", week: 6, title: "Inference & Text Generation", icon: "âœ¨", color: "#6366F1",
    subtitle: { tr: "Autoregressive sampling, temperature, KV cache â€” modelin konuÅŸma zamanÄ±", en: "Autoregressive sampling, temperature, KV cache â€” when the model speaks" },
    sections: [
      {
        title: "EÄŸitim vs Inference â€” Fark Nedir?",
        viz: "inferenceTimeline",
        content: "EÄŸitim: forward + backward + gÃ¼ncelle (paralel, gradient gerekli). Inference: sadece forward (sÄ±ralÄ±, gradient yok â†’ hÄ±zlÄ±, az bellek). EÄŸitim = sÄ±nav Ã§alÄ±ÅŸmak, Inference = sÄ±nav vermek.",
        highlight: "Inference'da backward pass YOK â†’ daha az bellek, daha hÄ±zlÄ±. Ama autoregressive olduÄŸu iÃ§in sÄ±ralÄ±."
      },
      {
        title: "Autoregressive Generation â€” AdÄ±m AdÄ±m",
        viz: "inferenceTimeline",
        content: "BOS ile baÅŸla â†’ model Ã§alÄ±ÅŸtÄ±r â†’ 27 olasÄ±lÄ±k â†’ temperature Ã¶lÃ§ekle â†’ softmax â†’ Ã¶rnekle â†’ BOS/EOS ise DUR, deÄŸilse tekrarla. SonuÃ§: 'kamrin' gibi yeni isimler!",
        code: `token_id = BOS; sample = []
for pos_id in range(block_size):
    logits = gpt(token_id, pos_id, keys, values)
    probs = softmax([l/temperature for l in logits])
    token_id = random.choices(range(27), weights=probs)[0]
    if token_id == BOS: break
    sample.append(uchars[token_id])`,
        highlight: "SonuÃ§: 'kamrin' gibi yeni isimler!"
      },
      {
        title: "ğŸ® Ãœretim Oyun AlanÄ± â€” Temperature Etkisini Dene",
        viz: "generationPlayground",
        content: "YukarÄ±da temperature kaydÄ±rÄ±cÄ±sÄ±nÄ± ayarlayÄ±p â–¶ Ãœret butonuna basÄ±n. DÃ¼ÅŸÃ¼k T â†’ her zaman aynÄ± isim, yÃ¼ksek T â†’ kaotik harfler. Softmax daÄŸÄ±lÄ±m ÅŸeklinin nasÄ±l deÄŸiÅŸtiÄŸini gÃ¶zlemleyin!",
        highlight: "DÃ¼ÅŸÃ¼k T â†’ deterministik (tekrar), Tâ‰ˆ0.8 â†’ dengeli (yaratÄ±cÄ± ama gerÃ§ekÃ§i), yÃ¼ksek T â†’ kaotik."
      },
      {
        title: "Temperature Scaling â€” YaratÄ±cÄ±lÄ±k KontrolÃ¼",
        viz: "temperatureViz",
        content: "probs = softmax(logits/T). Tâ†’0: greedy (deterministik). T=0.8: dengeli. T=1: orijinal daÄŸÄ±lÄ±m. T>1: dÃ¼z (rastgele). Fizik analojisi: dÃ¼ÅŸÃ¼k T â†’ dÃ¼zenli, yÃ¼ksek T â†’ kaotik.",
        code: `# T=0.5: [0.876, 0.117, 0.007] â† sivri
# T=1.0: [0.659, 0.242, 0.099] â† dengeli
# T=2.0: [0.387, 0.337, 0.276] â† dÃ¼z`,
        highlight: "Fizik analojisi: dÃ¼ÅŸÃ¼k T â†’ dÃ¼zenli, yÃ¼ksek T â†’ kaotik"
      },
      {
        title: "Sampling Stratejileri",
        viz: "samplingViz2",
        content: "Bu kodda: random sampling (tam daÄŸÄ±lÄ±mdan). Alternatifler: Greedy (argmax), Top-k (en yÃ¼ksek k token), Top-p/Nucleus (kÃ¼mÃ¼latif olasÄ±lÄ±k eÅŸiÄŸi). Production: genelde top-p + temperature.",
        highlight: "Bu kod en basit stratejiyi kullanÄ±r. Production modeller genelde top-p (nucleus) tercih eder."
      },
      {
        title: "KV Cache â€” O(nÂ²) â†’ O(n)",
        viz: "kvCache",
        content: "Ã–nceki pozisyonlarÄ±n K,V vektÃ¶rlerini sakla. Her yeni token iÃ§in sadece 1 K,V hesapla, Ã¶ncekiler cache'ten oku. Bu kodda Python listesi, production'da Paged Attention.",
        code: `keys[layer_idx].append(k)    # cache'e ekle
values[layer_idx].append(v)
# pos=5: keys = [kâ‚€,...,kâ‚…] â† Ã¶ncekiler hazÄ±r!`,
        highlight: "Bu kodda Python listesi, production'da Paged Attention"
      },
      {
        title: "Inference Pipeline â€” UÃ§tan Uca Ã–rnek",
        viz: "inferenceTimeline",
        content: "'kamrin': BOSâ†’'k'(P=.08)â†’'a'(.15)â†’'m'(.11)â†’'r'(.09)â†’'i'(.22)â†’'n'(.18)â†’BOS(.31)â†’DUR. Veri setinde yok ama Ä°ngilizce yapÄ±sÄ±na uygun!",
        highlight: "Model olasÄ±lÄ±k Ã¼retir, sampling seÃ§er. FarklÄ± temperature/seed â†’ farklÄ± isimler."
      },
      {
        title: "Bu Kod vs Production GPT â€” KapanÄ±ÅŸ",
        viz: "whatsMissing",
        content: "Birebir aynÄ± algoritma! Fark sadece Ã¶lÃ§ek: 3,648 vs 1T+ parametre, 8 vs 128K+ context, dakikalar vs aylar eÄŸitim, $0 vs $100M+ maliyet. TEMELDEKÄ° MATEMATÄ°K AYNI. Tebrikler!",
        highlight: "243 satÄ±r Python ile GPT'nin tÃ¼m temellerini Ã¶ÄŸrendiniz. ArtÄ±k 'sihir' deÄŸil, anlaÅŸÄ±lÄ±r matematik!"
      }
    ]
  },

  {
    id: "evolution", week: 7, title: { tr: "Modern AI'a Evrim", en: "Evolution to Modern AI" }, icon: "ğŸŒ", color: "#14B8A6",
    subtitle: { tr: "243 satÄ±rdan ChatGPT'ye â€” Ã¶lÃ§ek, donanÄ±m, yazÄ±lÄ±m ve paradigma deÄŸiÅŸimleri", en: "From 243 lines to ChatGPT â€” scale, hardware, software, and paradigm shifts" },
    sections: [
      {
        title: "Scaling Laws â€” Daha BÃ¼yÃ¼k = Daha Ä°yi?",
        viz: "scalingLaws",
        content: "Kaplanick et al. (2020): loss âˆ 1/N^Î±. Parametre, veri ve hesaplama artÄ±nca loss dÃ¼ÅŸer â€” gÃ¼Ã§ yasasÄ± iliÅŸkisi. Chinchilla (2022): optimal oran = 20 token/parametre.",
        code: `# Scaling Law (Kaplanick et al. 2020):
# L(N) = a / N^b  (N=parametre sayÄ±sÄ±)
# microGPT:  N=3,648   â†’ loss â‰ˆ 2.0
# GPT-2:     N=1.5B    â†’ loss â‰ˆ 0.8
# GPT-3:     N=175B    â†’ loss â‰ˆ 0.5
# Chinchilla: optimal D/N â‰ˆ 20 (token/param)`,
        highlight: "microGPT'den GPT-4'e geÃ§iÅŸ 'yeni matematik' deÄŸil, AYNI matematiÄŸin 1 milyon kat bÃ¼yÃ¼tÃ¼lmesi."
      },
      {
        title: "ğŸ® Evrim Zaman Ã‡izelgesi â€” GPT-1'den BugÃ¼ne",
        viz: "evolutionTimeline",
        content: "AÅŸaÄŸÄ±daki zaman Ã§izelgesinde her modele tÄ±klayÄ±p parametre, veri, yenilik ve maliyet bilgilerini inceleyin. microGPT'den GPT-4'e 6 bÃ¼yÃ¼klÃ¼k mertebesi fark â€” ama temel aynÄ±!",
        highlight: "2018'den 2024'e: 117M â†’ 1.8T parametre, $10K â†’ $100M+ maliyet. Ama Transformer temeli hiÃ§ deÄŸiÅŸmedi."
      },
      {
        title: "DonanÄ±m Evrimi â€” CPU â†’ GPU â†’ TPU",
        viz: "hardwareEvolution",
        content: "CPU: sÄ±ralÄ±, genel amaÃ§lÄ±. GPU: binlerce kÃ¼Ã§Ã¼k Ã§ekirdek, paralel matris Ã§arpÄ±mÄ± (NVIDIA A100: 312 TFLOPS). TPU: Google'Ä±n Ã¶zel AI Ã§ipi. Yeni: Groq LPU, Cerebras WSE.",
        highlight: "GPU olmadan modern AI yok. A100 tek Ã§ipte 80GB bellek, 312 TFLOPS â€” microGPT'yi saniyede milyonlarca kez Ã§alÄ±ÅŸtÄ±rÄ±r."
      },
      {
        title: "EÄŸitim Pipeline'Ä± â€” Pre-training â†’ RLHF",
        viz: "trainingPipeline",
        content: "3 aÅŸama: (1) Pre-training: internet-Ã¶lÃ§eÄŸinde metin, next-token prediction â€” bu derste Ã¶ÄŸrendiÄŸiniz! (2) SFT: insan yazÄ±mÄ± soru-cevap ile fine-tune. (3) RLHF/DPO: insan tercihleri ile hizalama.",
        code: `# 3-AÅŸamalÄ± Modern LLM EÄŸitimi:
# 1. Pre-training (bu ders!):
#    loss = -log(P(next_token | prev_tokens))
#    Veri: internet (~13T token)
#    Maliyet: ~%95 toplam bÃ¼tÃ§e

# 2. SFT (Supervised Fine-Tuning):
#    (soru, cevap) Ã§iftleri ile fine-tune
#    ~100K Ã¶rnek

# 3. RLHF (Human Alignment):
#    reward_model = train(human_preferences)
#    policy = PPO(model, reward_model)`,
        highlight: "Pre-training = ham gÃ¼Ã§, SFT = yetenek, RLHF = 'iyi davranÄ±ÅŸ'. microGPT sadece adÄ±m 1'i yapÄ±yor."
      },
      {
        title: "Tokenization Evrimi â€” Karakter â†’ BPE â†’ SentencePiece",
        viz: "tokenEvolution",
        content: "microGPT: karakter dÃ¼zeyi (27 token). BPE (GPT-2): alt-kelime (~50K token, 'playing'â†’'play'+'ing'). SentencePiece (LLaMA): Unicode-aware. tiktoken (GPT-4): ~100K token.",
        highlight: "Daha iyi tokenizer = daha az token = daha uzun context = daha iyi anlama. Ama temel fikir aynÄ±: metinâ†’ID."
      },
      {
        title: "Attention Evrimi â€” Vanilla â†’ Flash â†’ Sliding Window",
        viz: "attentionEvolution",
        content: "Vanilla: O(nÂ²) bellek ve hesaplama. Multi-Query (2019): K,V paylaÅŸÄ±mÄ±. Flash Attention (2022): IO-aware â†’ 2-4Ã— hÄ±zlÄ±. Sliding Window (Mistral): sabit pencere â†’ âˆ context.",
        highlight: "Flash Attention = aynÄ± matematik, farklÄ± bellek eriÅŸim dÃ¼zeni. SonuÃ§ deÄŸiÅŸmez, hÄ±z 4Ã— artar."
      },
      {
        title: "AÃ§Ä±k Kaynak Devrimi â€” LLaMA, Mistral, DeepSeek",
        viz: "opensourceMap",
        content: "2023 kÄ±rÄ±lma noktasÄ±: LLaMA â†’ aÃ§Ä±k aÄŸÄ±rlÄ±klar, araÅŸtÄ±rma patlamasÄ±. Mistral 7B: kÃ¼Ã§Ã¼k ama gÃ¼Ã§lÃ¼. DeepSeek-V3: MoE, Ã¼cretsiz API. Qwen, Gemma, Command-R: Ã§eÅŸitlilik.",
        highlight: "AÃ§Ä±k kaynak modeller GPT-4 seviyesine yaklaÅŸÄ±yor. microGPT'nin prensipleri bunlarÄ±n HEPSÄ°NDE aynÄ±."
      },
      {
        title: "GÃ¼ncel Trendler â€” MoE, RAG, Agent, Multimodal",
        viz: "trendsRadar",
        content: "MoE: 8 uzman, her token 2 uzmanÄ± aktive eder â†’ verimlilik. RAG: dÄ±ÅŸ bilgi ile zenginleÅŸtirme. Agent: araÃ§ kullanÄ±mÄ± (kod, arama). Multimodal: metin+gÃ¶rÃ¼ntÃ¼+ses.",
        highlight: "Her trend, bu derste Ã¶ÄŸrendiÄŸiniz Transformer temelinin Ã¼stÃ¼ne inÅŸa edilir. Temel saÄŸlam = her ÅŸey mÃ¼mkÃ¼n."
      }
    ]
  },

  {
    id: "paper", week: "B",
    title: "Attention Is All You Need",
    subtitle: { tr: "Vaswani et al. 2017 â€” Transformer makalesinin interaktif keÅŸfi", en: "Vaswani et al. 2017 â€” Interactive exploration of the Transformer paper" },
    color: "#6366F1",
    icon: "ğŸ“„",
    sections: [
      { title: { tr: "Transformer Nedir?", en: "What is a Transformer?" }, content: "2017'de Google araÅŸtÄ±rmacÄ±larÄ± RNN ve CNN'leri tamamen atÄ±p sadece attention kullanan Transformer modelini yaptÄ±. Hem daha iyi sonuÃ§ hem Ã§ok daha hÄ±zlÄ±.", highlight: "Eski yÃ¶ntemde (RNN) model her sÃ¶zcÃ¼ÄŸÃ¼ SIRAYLA iÅŸler. Transformer TÃœM sÃ¶zcÃ¼klere aynÄ± anda bakar.", viz: "tePaperGiris" },
      { title: { tr: "Eski Modellerin SorunlarÄ±", en: "Problems with Old Models" }, content: "RNN sÄ±ralÄ± Ã§alÄ±ÅŸÄ±r â†’ paralel olamaz â†’ yavaÅŸ. Uzun cÃ¼mlelerde erken sÃ¶zcÃ¼klerin bilgisi kaybolur. Gradient patlamasÄ±/sÃ¶nmesi yaÅŸanÄ±r.", highlight: "RNN: O(n) adÄ±m, Transformer: O(1) adÄ±m. Herkes herkesi gÃ¶rÃ¼r!", viz: "tePaperEskiMod" },
      { title: { tr: "Attention MekanizmasÄ±", en: "Attention Mechanism" }, content: "Query: Ne arÄ±yorum? Key: Bende ne var? Value: Ä°ÅŸte bilgim. QÂ·K yÃ¼ksekse â†’ o kelimenin Value'sundan Ã§ok bilgi al!", highlight: "KÃ¼tÃ¼phane analojisi: Query = aradÄ±ÄŸÄ±nÄ±z konu, Key = kitap etiketi, Value = kitabÄ±n iÃ§eriÄŸi.", viz: "tePaperAttention" },
      { title: { tr: "Matematik: Softmax, Dot Product, Multi-Head", en: "Math: Softmax, Dot Product, Multi-Head" }, content: "3 temel formÃ¼l: â‘  Dot Product â‘¡ Softmax â‘¢ Scaled Dot-Product Attention. Her birini kaydÄ±rÄ±cÄ±larla keÅŸfedin.", highlight: "Attention(Q,K,V) = softmax(QKáµ€/âˆšd)V â€” makalenin en Ã¼nlÃ¼ formÃ¼lÃ¼.", viz: "tePaperMat" },
      { title: { tr: "Mimari: Encoder-Decoder", en: "Architecture: Encoder-Decoder" }, content: "Encoder girdi cÃ¼mlesini anlar (6 katman). Decoder Ã§Ä±ktÄ± cÃ¼mlesini Ã¼retir (6 katman). Her katmanda: Attention + FFN + Residual + LayerNorm.", highlight: "Decoder'da causal mask: gelecek kelimeleri gÃ¶remez!", viz: "tePaperMimari" },
      { title: { tr: "Pozisyon Kodlama", en: "Positional Encoding" }, content: "Transformer sÄ±ra bilmez! sin/cos dalgalarÄ±yla her pozisyona benzersiz bir 'parmak izi' eklenir. FarklÄ± frekanslar farklÄ± Ã¶lÃ§eklerde kalÄ±p yakalar.", highlight: "DÃ¼ÅŸÃ¼k boyutlar hÄ±zlÄ± deÄŸiÅŸir (tiz), yÃ¼ksek boyutlar yavaÅŸ deÄŸiÅŸir (bas) â€” piyano gibi!", viz: "tePaperPoz" },
      { title: { tr: "EÄŸitim ve SonuÃ§lar", en: "Training and Results" }, content: "4.5M cÃ¼mle Ã§ifti, 8Ã— P100 GPU, 3.5 gÃ¼n. ENâ†’DE: 28.4 BLEU (rekor!). ENâ†’FR: 41.8 BLEU. Warmup + label smoothing + dropout.", highlight: "Base model: 65M parametre. Big model: 213M parametre. BugÃ¼nkÃ¼ GPT-4: ~1T+ parametre!", viz: "tePaperEgitim" },
      { title: { tr: "DÃ¼nyayÄ± NasÄ±l DeÄŸiÅŸtirdi?", en: "How Did It Change the World?" }, content: "90K+ atÄ±f! GPT, BERT, ViT, DALL-E, AlphaFold, Copilot â€” hepsi Transformer tabanlÄ±. 15 sayfalÄ±k makale tÃ¼m AI'Ä± deÄŸiÅŸtirdi.", highlight: "Sadece dil deÄŸil: gÃ¶rÃ¼ntÃ¼ (ViT), protein (AlphaFold), mÃ¼zik (MusicGen), kod (Copilot).", viz: "tePaperEtki" },
    ]
  },
];

// â”€â”€â”€ ARCHITECTURE STEPS (for interactive explorer) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const ARCH_STEPS = [
  { key: "embed", title: "Token Embedding", sub: { tr: "ID â†’ VektÃ¶r", en: "ID â†’ Vector" }, color: "#0EA5E9", icon: "T",
    desc: "Her karakter (28 token) â†’ 16 boyutlu sÃ¼rekli vektÃ¶re dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼r. Embedding tablosu (28Ã—16) eÄŸitimle Ã¶ÄŸrenilir.",
    detail: "Basit lookup: 'a'â†’ID 2â†’wte[2]. Backpropagation ile anlam kazanÄ±r. Ã‡Ä±ktÄ±da da aynÄ± matris kullanÄ±lÄ±r (weight tying).",
    code: `# wte: [28 x 16] Ã¶ÄŸrenilebilir matris
tok_emb = wte[token_id]
# 'a' (ID=2) -> [0.02, -0.01, 0.015, ...]
# Ä°lk baÅŸta rastgele, eÄŸitimle anlam kazanÄ±r` },
  { key: "pos", title: "Position Embedding", sub: { tr: "SÄ±ra Bilgisi", en: "Order Info" }, color: "#8B5CF6", icon: "P",
    desc: "Transformer sÄ±ra bilmez. Pozisyon embedding her konuma Ã¶zgÃ¼ 16-boyutlu vektÃ¶r ekler.",
    detail: "Ã–ÄŸrenilebilir pozisyon embedding (8Ã—16 matris). x = tok_emb + pos_emb. 'ab' â‰  'ba' olur.",
    code: `pos_emb = wpe[position_id]  # [8x16]
x = [t + p for t, p in zip(tok_emb, pos_emb)]
# AynÄ± 'a' pos=0 ve pos=3'te farklÄ± vektÃ¶r` },
  { key: "norm", title: "RMSNorm", sub: { tr: "Normalizasyon", en: "Normalization" }, color: "#F59E0B", icon: "N",
    desc: "VektÃ¶r normalize edilir. LayerNorm'dan ~%30 hÄ±zlÄ±: ortalama Ã§Ä±karma yok.",
    detail: "RMS = sqrt(mean(xÂ²)), scale = 1/sqrt(RMS+Îµ). Gradient patlamasÄ±nÄ± engeller.",
    code: `def rmsnorm(x):
  ms = sum(xi*xi for xi in x) / len(x)
  scale = (ms + 1e-5) ** -0.5
  return [xi * scale for xi in x]` },
  { key: "attn", title: "Self-Attention", sub: "QÂ·Káµ€/âˆšd â†’ Softmax â†’ V", color: "#10B981", icon: "A",
    desc: "Her token 'kime dikkat etmeliyim?' sorar. 4 head Ã— 4 boyut. Causal mask gelecek tokenlarÄ± gizler.",
    detail: "Query-Key uyumu â†’ attention aÄŸÄ±rlÄ±klarÄ± â†’ Value bilgiyi taÅŸÄ±r. Her head farklÄ± kalÄ±p Ã¶ÄŸrenir.",
    code: `q, k, v = linear(x, Wq/Wk/Wv)
for h in range(4):
  scores = QÂ·K^T / sqrt(4)
  weights = softmax(scores)
  out_h = Î£ w[t] Ã— V[t]
# Concat 4Ã—4=16 â†’ linear â†’ 16` },
  { key: "mlp", title: "MLP Block", sub: "Expand â†’ ReLUÂ² â†’ Compress", color: "#EC4899", icon: "M",
    desc: "16â†’64 geniÅŸlet, ReLUÂ² aktive et, 64â†’16 daralt. ~%40 nÃ¶ron 'Ã¶lÃ¼' (sparse).",
    detail: "ReLUÂ² = max(0,x)Â². Normal ReLU'dan keskin. Residual connection ile girdi eklenir.",
    code: `h = linear(x, fc1)        # 16 â†’ 64
h = [max(0,hi)**2 for hi in h]
out = linear(h, fc2)      # 64 â†’ 16
x = out + x_residual` },
  { key: "output", title: "Output Head", sub: "Logits â†’ Sampling", color: "#EF4444", icon: "O",
    desc: "Embedding matrisinin transpozu ile Ã§arpÄ±larak 28 logit Ã¼retilir. Temperature Ã¶lÃ§ekler, softmax olasÄ±lÄ±ÄŸa Ã§evirir.",
    detail: "Weight tying: Ã§Ä±ktÄ± = embedding matrisi. T<1 deterministik, T>1 yaratÄ±cÄ±.",
    code: `logits = linear(x, wte)    # [16]->[28]
logits = [l/T for l in logits]
probs = softmax(logits)
next = random.choices(range(28), weights=probs)` }
];

// â”€â”€â”€ REUSABLE UI COMPONENTS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

const Spark = ({ data, w = 100, h = 24, color = "#0EA5E9" }) => {
  if (data.length < 2) return null;
  const mn = Math.min(...data), mx = Math.max(...data), rg = mx - mn || 1;
  const pts = data.map((v, i) => `${(i / (data.length - 1)) * w},${h - ((v - mn) / rg) * h * 0.85 - h * 0.05}`).join(" ");
  return <svg width={w} height={h}><polygon points={`0,${h} ${pts} ${w},${h}`} fill={`${color}15`}/><polyline points={pts} fill="none" stroke={color} strokeWidth="1.5" strokeLinecap="round"/></svg>;
};

const InfoCard = ({ value, label, color = "#0EA5E9", icon, sub }) => (
  <div style={{ background: "rgba(255,255,255,0.02)", border: "1px solid rgba(255,255,255,0.06)", borderRadius: 14, padding: "12px 14px", position: "relative", overflow: "hidden" }}>
    <div style={{ position: "absolute", top: -10, right: -10, width: 44, height: 44, borderRadius: "50%", background: `${color}08` }} />
    <div style={{ fontSize: 12, color: "#64748B", textTransform: "uppercase", letterSpacing: ".12em", marginBottom: 5, display: "flex", alignItems: "center", gap: 5 }}>
      {icon && <span>{icon}</span>}{label}
    </div>
    <div style={{ fontSize: 21, fontWeight: 700, color, fontFamily: "'Fira Code', monospace" }}>{value}</div>
    {sub && <div style={{ fontSize: 11, color: "#475569", marginTop: 2 }}>{sub}</div>}
  </div>
);

const ProbDist = ({ probs, tgt, topK = 14 }) => {
  if (!probs) return null;
  const items = probs.map((p, i) => ({ ch: itos[i], p, i })).sort((a, b) => b.p - a.p).slice(0, topK);
  const mx = items[0]?.p || 1;
  return (
    <div style={{ display: "flex", flexDirection: "column", gap: 3 }}>
      <div style={{ fontSize: 13, color: "#64748B", marginBottom: 4 }}>
        Her Ã§ubuk bir token olasÄ±lÄ±ÄŸÄ±. <span style={{ color: "#10B981" }}>YeÅŸil</span> = seÃ§ilen token.
      </div>
      {items.map((it, rk) => {
        const isT = it.i === tgt;
        const w = Math.max(3, (it.p / mx) * 100);
        return (
          <div key={it.i} style={{ display: "flex", alignItems: "center", gap: 7, height: 22 }}>
            <span style={{ width: 20, textAlign: "center", fontFamily: "'Fira Code', monospace", fontSize: 17, fontWeight: 700, color: isT ? "#10B981" : "#94A3B8" }}>
              {it.ch === "<BOS>" ? "â—†" : it.ch === "<EOS>" ? "â– " : it.ch}
            </span>
            <div style={{ flex: 1, height: 14, background: "rgba(255,255,255,0.04)", borderRadius: 7, overflow: "hidden" }}>
              <div style={{ height: "100%", width: `${w}%`, borderRadius: 7, background: isT ? "linear-gradient(90deg,#10B981,#34D399)" : rk === 0 ? "linear-gradient(90deg,#0EA5E9,#38BDF8)" : "linear-gradient(90deg,#334155,#475569)", transition: "width .6s cubic-bezier(.34,1.56,.64,1)" }} />
            </div>
            <span style={{ width: 48, textAlign: "right", fontFamily: "'Fira Code', monospace", fontSize: 13, color: isT ? "#10B981" : rk < 3 ? "#94A3B8" : "#475569" }}>
              {(it.p * 100).toFixed(1)}%
            </span>
          </div>
        );
      })}
    </div>
  );
};

const AttnMat = ({ weights, tokens, head, setHead }) => {
  if (!weights?.length) return null;
  const nH = weights.length;
  const hColors = ["#0EA5E9", "#8B5CF6", "#10B981", "#F59E0B"];
  return (
    <div>
      <div style={{ fontSize: 13, color: "#64748B", marginBottom: 8 }}>
        Her hÃ¼cre, satÄ±rdaki token'Ä±n sÃ¼tundaki token'a ne kadar dikkat ettiÄŸini gÃ¶sterir. Koyu = yÃ¼ksek dikkat.
      </div>
      <div style={{ display: "flex", gap: 4, marginBottom: 10 }}>
        {Array.from({ length: nH }, (_, h) => (
          <button key={h} onClick={() => setHead(h)} style={{ flex: 1, padding: "7px 0", borderRadius: 8, border: "none", cursor: "pointer", fontFamily: "'Fira Code', monospace", fontSize: 14, fontWeight: 700, background: head === h ? hColors[h] : "rgba(255,255,255,0.04)", color: head === h ? "#fff" : "#64748B", transition: "all .25s" }}>
            Head {h}
          </button>
        ))}
      </div>
      <div style={{ display: "inline-flex" }}>
        <div style={{ display: "flex", flexDirection: "column", marginTop: 22 }}>
          {tokens.map((t, r) => (
            <div key={r} style={{ height: 32, display: "flex", alignItems: "center", justifyContent: "flex-end", paddingRight: 6 }}>
              <span style={{ fontSize: 14, color: "#94A3B8", fontFamily: "'Fira Code', monospace", fontWeight: 600 }}>
                {t === "<BOS>" ? "â—†" : t === "<EOS>" ? "â– " : t}
              </span>
            </div>
          ))}
        </div>
        <div>
          <div style={{ display: "flex" }}>
            {tokens.map((t, c) => (
              <div key={c} style={{ width: 32, height: 22, display: "flex", alignItems: "flex-end", justifyContent: "center" }}>
                <span style={{ fontSize: 12, color: "#64748B", fontFamily: "'Fira Code', monospace" }}>
                  {t === "<BOS>" ? "â—†" : t === "<EOS>" ? "â– " : t}
                </span>
              </div>
            ))}
          </div>
          {tokens.map((t, r) => {
            const isL = r === tokens.length - 1;
            return (
              <div key={r} style={{ display: "flex" }}>
                {tokens.map((t2, c) => {
                  const msk = c > r;
                  const w = isL && weights[head]?.w[c] || 0;
                  return (
                    <div key={c} style={{
                      width: 32, height: 32, display: "flex", alignItems: "center", justifyContent: "center", margin: 0.5,
                      borderRadius: 4, background: msk ? "rgba(255,255,255,0.01)" : isL ? `rgba(14,165,233,${w})` : `rgba(14,165,233,${c <= r ? 0.06 : 0})`,
                      fontSize: 13, fontFamily: "'Fira Code', monospace", color: isL && w > 0.4 ? "#fff" : isL ? "rgba(14,165,233,.7)" : "#1E293B", transition: "all .4s"
                    }}>
                      {isL ? w.toFixed(1) : msk ? "Ã—" : "Â·"}
                    </div>
                  );
                })}
              </div>
            );
          })}
        </div>
      </div>
      <div style={{ display: "flex", gap: 12, marginTop: 8, fontSize: 13, color: "#64748B" }}>
        <span>â–  koyu = yÃ¼ksek dikkat</span>
        <span>Ã— = causal mask (gelecek gizli)</span>
        <span>Son satÄ±r = aktif token</span>
      </div>
    </div>
  );
};

const MLPViz = ({ hidden, activated }) => {
  if (!hidden) return null;
  const n = 64, cols = 16;
  const mx = Math.max(...hidden.map(Math.abs), 0.01);
  const mxA = Math.max(...activated.map(Math.abs), 0.01);
  const aliveCount = activated.filter(v => v > 0).length;
  const deadCount = activated.filter(v => v === 0).length;
  return (
    <div>
      <div style={{ fontSize: 13, color: "#64748B", marginBottom: 8 }}>
        Her kare bir nÃ¶ron. <span style={{ color: "#0EA5E9" }}>Mavi</span> = pozitif, <span style={{ color: "#EF4444" }}>KÄ±rmÄ±zÄ±</span> = negatif. ReLUÂ² sonrasÄ± negatifler sÄ±fÄ±ra dÃ¼ÅŸer (Ã¶lÃ¼ nÃ¶ronlar).
      </div>
      <div style={{ display: "flex", gap: 20, flexWrap: "wrap", alignItems: "flex-start" }}>
        <div>
          <div style={{ fontSize: 14, color: "#94A3B8", marginBottom: 6, fontWeight: 600 }}>Linear â†’ 64 nÃ¶ron</div>
          <div style={{ display: "flex", flexWrap: "wrap", gap: 1.5, width: cols * 18 }}>
            {hidden.slice(0, n).map((v, i) => {
              const int = Math.abs(v) / mx;
              return <div key={i} style={{ width: 16, height: 16, borderRadius: 3, background: v > 0 ? `rgba(14,165,233,${int})` : `rgba(239,68,68,${int})`, transition: "all .3s" }} title={`n${i}: ${v.toFixed(3)}`} />;
            })}
          </div>
        </div>
        <div style={{ display: "flex", alignItems: "center", fontSize: 21, color: "#64748B", fontWeight: 700, padding: "30px 0" }}>â†’ ReLUÂ² â†’</div>
        <div>
          <div style={{ fontSize: 14, color: "#94A3B8", marginBottom: 6, fontWeight: 600 }}>Aktivasyon sonrasÄ±</div>
          <div style={{ display: "flex", flexWrap: "wrap", gap: 1.5, width: cols * 18 }}>
            {activated.slice(0, n).map((v, i) => {
              const dead = v === 0;
              const int = Math.min(1, v / mxA);
              return <div key={i} style={{ width: 16, height: 16, borderRadius: 3, background: dead ? "rgba(255,255,255,0.02)" : `rgba(16,185,129,${int})`, border: dead ? "1px solid rgba(255,255,255,0.04)" : "none", transition: "all .3s" }} title={`n${i}: ${v.toFixed(3)}${dead ? (lang==="tr"?" Ã–LÃœ":" DEAD") : ""}`} />;
            })}
          </div>
        </div>
      </div>
      <div style={{ marginTop: 10, display: "flex", gap: 16, fontSize: 14, color: "#64748B" }}>
        <span>{lang === "tr" ? "Aktif:" : "Active:"} <strong style={{ color: "#10B981" }}>{aliveCount}</strong>/64</span>
        <span>{lang === "tr" ? "Ã–lÃ¼:" : "Dead:"} <strong style={{ color: "#EF4444" }}>{deadCount}</strong>/64</span>
        <span>Sparsity: <strong style={{ color: "#F59E0B" }}>{((deadCount / 64) * 100).toFixed(0)}%</strong></span>
      </div>
    </div>
  );
};

const EmbedViz = ({ dbg }) => {
  if (!dbg) return null;
  const sections = [
    { label: "Token Embedding", data: dbg.te, desc: lang === "tr" ? "wte[token_id] â€” karakter vektÃ¶rÃ¼" : "wte[token_id] â€” character vector" },
    { label: "+ Position Emb", data: dbg.pe, desc: lang === "tr" ? "wpe[pos_id] â€” konum vektÃ¶rÃ¼" : "wpe[pos_id] â€” position vector" },
    { label: lang === "tr" ? "= BirleÅŸik" : "= Combined", data: dbg.x0, desc: lang === "tr" ? "tok_emb + pos_emb â€” nihai girdi" : "tok_emb + pos_emb â€” final input" }
  ];
  return (
    <div>
      <div style={{ fontSize: 13, color: "#64748B", marginBottom: 10 }}>
        Her Ã§ubuk vektÃ¶rÃ¼n bir boyutu. <span style={{ color: "#0EA5E9" }}>Mavi</span> = pozitif, <span style={{ color: "#EF4444" }}>KÄ±rmÄ±zÄ±</span> = negatif. YoÄŸunluk = bÃ¼yÃ¼klÃ¼k.
      </div>
      <div style={{ display: "flex", gap: 20, flexWrap: "wrap" }}>
        {sections.map((sec, si) => (
          <div key={si}>
            <div style={{ fontSize: 15, color: "#E2E8F0", marginBottom: 2, fontWeight: 600 }}>{sec.label}</div>
            <div style={{ fontSize: 12, color: "#475569", marginBottom: 6 }}>{sec.desc}</div>
            <div style={{ display: "flex", gap: 2 }}>
              {sec.data.map((v, i) => {
                const mx = Math.max(...sec.data.map(Math.abs));
                return <div key={i} style={{ width: 14, height: 32, borderRadius: 3, background: v > 0 ? `rgba(14,165,233,${Math.abs(v) / mx})` : `rgba(239,68,68,${Math.abs(v) / mx})` }} title={`dim${i}: ${v.toFixed(4)}`} />;
              })}
            </div>
          </div>
        ))}
      </div>
    </div>
  );
};

const Pipeline = ({ steps, active }) => (
  <div style={{ display: "flex", alignItems: "center", gap: 4 }}>
    {steps.map((s, i) => (
      <div key={i} style={{ display: "flex", alignItems: "center", gap: 4 }}>
        <div style={{
          width: 36, height: 36, borderRadius: 10, display: "flex", alignItems: "center", justifyContent: "center",
          fontSize: 16, fontWeight: 700, color: i <= active ? "#fff" : "#475569", transition: "all .4s cubic-bezier(.34,1.56,.64,1)",
          transform: i === active ? "scale(1.2)" : "scale(1)", background: i <= active ? s.color : "rgba(255,255,255,0.03)",
          boxShadow: i === active ? `0 0 16px ${s.color}50` : "none", opacity: i <= active ? 1 : 0.35
        }}>
          {s.icon}
        </div>
        {i < steps.length - 1 && <div style={{ width: 18, height: 2, background: i < active ? s.color : "rgba(255,255,255,0.05)", borderRadius: 1, transition: "all .3s" }} />}
      </div>
    ))}
  </div>
);

const CodeBlock = ({ code, title }) => (
  <div style={{ background: "#0A0F1A", borderRadius: 12, border: "1px solid rgba(255,255,255,0.06)", overflow: "hidden" }}>
    <div style={{ padding: "6px 14px", background: "rgba(255,255,255,.03)", borderBottom: "1px solid rgba(255,255,255,.06)", display: "flex", alignItems: "center", gap: 6 }}>
      <div style={{ width: 7, height: 7, borderRadius: "50%", background: "#EF4444" }} />
      <div style={{ width: 7, height: 7, borderRadius: "50%", background: "#F59E0B" }} />
      <div style={{ width: 7, height: 7, borderRadius: "50%", background: "#10B981" }} />
      <span style={{ marginLeft: 6, fontSize: 13, color: "#475569" }}>{title || "microgpt.py"}</span>
    </div>
    <pre style={{ margin: 0, padding: 16, fontSize: 14.5, lineHeight: 1.7, fontFamily: "'Fira Code', monospace", color: "#94A3B8", whiteSpace: "pre-wrap", overflowX: "auto" }}>{code}</pre>
  </div>
);

const DimFlow = ({ activeIdx = -1 }) => {
  const dims = [
    { l: "ID", d: "1", c: "#64748B" }, { l: "Emb", d: "[16]", c: "#0EA5E9" },
    { l: "+Pos", d: "[16]", c: "#8B5CF6" }, { l: "Norm", d: "[16]", c: "#F59E0B" },
    { l: "QKV", d: "4Ã—[4]", c: "#10B981" }, { l: "MLPâ†‘", d: "[64]", c: "#EC4899" },
    { l: "MLPâ†“", d: "[16]", c: "#EC4899" }, { l: "Out", d: "[28]", c: "#EF4444" }
  ];
  return (
    <div style={{ display: "flex", alignItems: "center", flexWrap: "wrap", gap: 4 }}>
      {dims.map((d, i) => (
        <div key={i} style={{ display: "flex", alignItems: "center", gap: 4 }}>
          <div style={{
            padding: "3px 8px", borderRadius: 6, fontSize: 12, fontWeight: 600,
            background: i <= activeIdx ? `${d.c}20` : "rgba(255,255,255,0.02)",
            color: i <= activeIdx ? d.c : "#1E293B",
            border: `1px solid ${i <= activeIdx ? `${d.c}40` : "transparent"}`,
            transition: "all .3s"
          }}>
            {d.l} <span style={{ fontFamily: "'Fira Code', monospace" }}>{d.d}</span>
          </div>
          {i < 7 && <span style={{ color: "#1E293B", fontSize: 13 }}>â†’</span>}
        </div>
      ))}
    </div>
  );
};

// â”€â”€â”€ LECTURE VISUALIZATION COMPONENTS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const VB = { bg: "#0A0F1A", card: "#111827", border: "rgba(255,255,255,0.06)", muted: "#64748B", dim: "#475569", txt: "#94A3B8" };
const VizBox = ({ children, title, color = "#0EA5E9" }) => (<div style={{ margin: "16px 0", background: VB.bg, border: `1px solid ${VB.border}`, borderRadius: 14, overflow: "hidden" }}>{title && <div style={{ padding: "8px 16px", borderBottom: `1px solid ${VB.border}`, display: "flex", alignItems: "center", gap: 8 }}><div style={{ width: 6, height: 6, borderRadius: "50%", background: color }} /><span style={{ fontSize: 14, fontWeight: 600, color }}>{title}</span></div>}<div style={{ padding: 16 }}>{children}</div></div>);
const FlowArrow = ({ color = "#475569" }) => (<div style={{ display: "flex", alignItems: "center", padding: "0 2px", color, fontSize: 17, fontWeight: 700 }}>â†’</div>);
const FlowBox = ({ label, sub, color, small, active }) => (<div style={{ padding: small ? "5px 10px" : "8px 14px", borderRadius: 8, minWidth: small ? 50 : 70, background: active ? `${color}20` : `${color}0A`, border: `1.5px solid ${color}30`, textAlign: "center", transition: "all .3s", transform: active ? "scale(1.05)" : "scale(1)", boxShadow: active ? `0 0 12px ${color}25` : "none" }}><div style={{ fontSize: small ? 10 : 12, fontWeight: 700, color, fontFamily: "'Fira Code', monospace" }}>{label}</div>{sub && <div style={{ fontSize: 11, color: VB.muted, marginTop: 2 }}>{sub}</div>}</div>);
const StatBox = ({ value, label, color }) => (<div style={{ textAlign: "center", padding: "6px 10px", background: `${color}08`, borderRadius: 8, border: `1px solid ${color}15`, minWidth: 60 }}><div style={{ fontSize: 19, fontWeight: 800, color, fontFamily: "'Fira Code', monospace" }}>{value}</div><div style={{ fontSize: 11, color: VB.muted }}>{label}</div></div>);

const CoursePipelineViz = () => { const [active, setActive] = useState(0); const [autoPlay, setAutoPlay] = useState(true); useEffect(() => { if (!autoPlay) return; const t = setInterval(() => setActive(a => (a+1)%7), 2500); return () => clearInterval(t); }, [autoPlay]); const stages = [{l:lang==="tr"?"Veri":"Data",s:"input.txt",c:"#0EA5E9",i:"ğŸ“„",week:lang==="tr"?"Hafta 1":"Week 1",desc:lang==="tr"?"Metin dosyasÄ± okunur. microGPT'de TÃ¼rk isimleri (32K satÄ±r). Her karakter bir token olur â€” vocab: a-z + boÅŸluk = 27 sembol.":"Text file is read. In microGPT, English names (32K lines). Each character becomes a token â€” vocab: a-z + space = 27 symbols."},{l:"Tokenizer",s:"charsâ†’ids",c:"#8B5CF6",i:"ğŸ”¤",week:lang==="tr"?"Hafta 1":"Week 1",desc:lang==="tr"?"Karakterler sayÄ±lara dÃ¶nÃ¼ÅŸÃ¼r: 'emma' â†’ [BOS, 4, 12, 12, 0, BOS]. BOS baÅŸlangÄ±Ã§/bitiÅŸ iÅŸareti. Her ID embedding tablosunda bir satÄ±r seÃ§er.":"Characters become numbers: 'emma' â†’ [BOS, 4, 12, 12, 0, BOS]. BOS marks start/end. Each ID selects a row in the embedding table."},{l:"Model",s:"Emb+Attn+MLP",c:"#10B981",i:"ğŸ§ ",week:lang==="tr"?"Hafta 3-4":"Week 3-4",desc:lang==="tr"?"Token ID'ler 16 boyutlu vektÃ¶rlere dÃ¶nÃ¼ÅŸÃ¼r (embedding). Attention her tokenin diÄŸerlerinden bilgi almasÄ±nÄ± saÄŸlar. MLP bu bilgiyi iÅŸler.":"Token IDs become 16-dimensional vectors (embedding). Attention lets each token gather info from others. MLP processes this info."},{l:"Loss",s:"Cross-Entropy",c:"#EF4444",i:"ğŸ“‰",week:lang==="tr"?"Hafta 5":"Week 5",desc:lang==="tr"?"Model 'e' dediyse ama doÄŸru cevap 'm' ise, kayÄ±p yÃ¼ksek olur. KayÄ±p = -log(doÄŸru tokene verilen olasÄ±lÄ±k). DÃ¼ÅŸÃ¼k loss = iyi model.":"If model said 'e' but correct answer is 'm', loss is high. Loss = -log(probability given to correct token). Low loss = good model."},{l:"Backprop",s:"Autograd",c:"#F59E0B",i:"â›“",week:lang==="tr"?"Hafta 2":"Week 2",desc:lang==="tr"?"KayÄ±p geriye doÄŸru yayÄ±lÄ±r. Her parametreye 'bu kaybÄ± azaltmak iÃ§in seni ne kadar deÄŸiÅŸtirmeliyim?' sorusunun cevabÄ± hesaplanÄ±r (gradient).":"Loss propagates backward. For each parameter: 'how much should I change you to reduce this loss?' is computed (gradient)."},{l:"Update",s:"Adam",c:"#EC4899",i:"ğŸ”§",week:lang==="tr"?"Hafta 5":"Week 5",desc:lang==="tr"?"Gradient yÃ¶nÃ¼nde kÃ¼Ã§Ã¼k bir adÄ±m at: w = w - lr Ã— grad. Adam optimizer momentum ve adaptif lr ile bunu akÄ±llÄ±ca yapar. Sonra grad sÄ±fÄ±rlanÄ±r.":"Take a small step in gradient direction: w = w - lr Ã— grad. Adam optimizer does this smartly with momentum and adaptive lr. Then grad is zeroed."},{l:"Inference",s:"Sampling",c:"#6366F1",i:"âœ¨",week:lang==="tr"?"Hafta 6":"Week 6",desc:lang==="tr"?"EÄŸitilmiÅŸ model yeni isimler Ã¼retir: 'A' ver â†’ 'Ahmet' Ã§Ä±kar. Her adÄ±mda olasÄ±lÄ±k daÄŸÄ±lÄ±mÄ±ndan bir token Ã¶rneklenir. Temperature yaratÄ±cÄ±lÄ±ÄŸÄ± kontrol eder.":"Trained model generates new names: give 'A' â†’ get 'Ahmet'. Each step samples a token from the probability distribution. Temperature controls creativity."}]; return (<VizBox title={lang === "tr" ? "7 AÅŸamalÄ± Pipeline â€” TÃ¼m Ders HaritasÄ±" : "7-Stage Pipeline â€” Full Course Map"} color="#0EA5E9"><div style={{fontSize:13,color:"#94A3B8",marginBottom:10,lineHeight:1.6}}>{lang === "tr" ? (<>AÅŸaÄŸÄ±daki kutularÄ±n her biri microGPT'nin bir adÄ±mÄ±nÄ± temsil eder. <strong style={{color:"#F59E0B"}}>TÄ±klayarak</strong> detaylarÄ± gÃ¶rÃ¼n.</>) : (<>Each box represents a step of microGPT. <strong style={{color:"#F59E0B"}}>Click</strong> to see details.</>)</div><div style={{display:"flex",alignItems:"center",gap:4,flexWrap:"wrap",justifyContent:"center"}}>{stages.map((s,i)=>(<div key={i} style={{display:"flex",alignItems:"center",gap:4}}><div onClick={()=>{setAutoPlay(false);setActive(i);}} style={{padding:"10px 12px",borderRadius:10,textAlign:"center",minWidth:80,cursor:"pointer",background:i===active?`${s.c}20`:`${s.c}08`,border:`1.5px solid ${i===active?s.c:`${s.c}20`}`,transform:i===active?"scale(1.08)":"scale(1)",transition:"all .4s cubic-bezier(.34,1.56,.64,1)"}}><div style={{fontSize:21,marginBottom:2}}>{s.i}</div><div style={{fontSize:14,fontWeight:700,color:s.c}}>{s.l}</div><div style={{fontSize:11,color:VB.muted}}>{s.s}</div></div>{i<6&&<FlowArrow color={i===active?s.c:VB.dim}/>}</div>))}</div><div style={{marginTop:12,padding:"14px 16px",borderRadius:12,background:`${stages[active].c}08`,border:`1.5px solid ${stages[active].c}25`,transition:"all .4s"}}><div style={{display:"flex",justifyContent:"space-between",alignItems:"center",marginBottom:6}}><span style={{fontSize:16,fontWeight:800,color:stages[active].c}}>{stages[active].i} {stages[active].l}</span><span style={{fontSize:12,padding:"2px 8px",borderRadius:6,background:`${stages[active].c}15`,color:stages[active].c,fontWeight:600}}>{stages[active].week}</span></div><div style={{fontSize:14,color:"#CBD5E1",lineHeight:1.7}}>{stages[active].desc}</div></div><div style={{marginTop:8,padding:"6px 12px",background:"rgba(245,158,11,.06)",borderRadius:8,textAlign:"center"}}><span style={{fontSize:13,color:"#F59E0B"}}>{lang === "tr" ? "â† EÄŸitim DÃ¶ngÃ¼sÃ¼: forward â†’ loss â†’ backward â†’ update â†’ tekrarla (500+ adÄ±m) â†’" : "â† Training Loop: forward â†’ loss â†’ backward â†’ update â†’ repeat (500+ steps) â†’"}</span></div></VizBox>); };

const TokenFlowViz = () => { const steps = [{l:'"anna"',s:lang==="tr"?"Girdi":"Input",c:"#0EA5E9"},{l:"a n n a",s:lang==="tr"?"Karakter AyÄ±r":"Split Chars",c:"#8B5CF6"},{l:"2 15 15 2",s:lang==="tr"?"ID Ã‡evir":"To IDs",c:"#10B981"},{l:"0 2 15 15 2 0",s:"+BOS",c:"#F59E0B"}]; return (<VizBox title={lang === "tr" ? "Tokenization AkÄ±ÅŸÄ±" : "Tokenization Flow"} color="#8B5CF6"><div style={{display:"flex",alignItems:"center",gap:6,justifyContent:"center",flexWrap:"wrap"}}>{steps.map((s,i)=>(<div key={i} style={{display:"flex",alignItems:"center",gap:6}}><FlowBox label={s.l} sub={s.s} color={s.c}/>{i<3&&<FlowArrow color={s.c}/>}</div>))}</div><div style={{display:"flex",gap:16,marginTop:14,justifyContent:"center",flexWrap:"wrap"}}><div style={{background:VB.card,padding:"8px 14px",borderRadius:8}}><span style={{fontSize: 12,color:VB.muted}}>EÄŸitim Ã§iftleri: </span><span style={{fontSize: 13,fontFamily:"'Fira Code',monospace",color:"#10B981"}}>(BOSâ†’a),(aâ†’n),(nâ†’n),(nâ†’a),(aâ†’BOS)</span></div></div></VizBox>); };

const EmbeddingFlowViz = () => { const bars = useMemo(()=>Array.from({length:16},()=>-0.3+Math.random()*0.6),[]); const posBars = useMemo(()=>Array.from({length:16},()=>-0.1+Math.random()*0.2),[]); const sumBars = useMemo(()=>bars.map((b,i)=>b+posBars[i]),[bars,posBars]); const mx = Math.max(...bars.map(Math.abs),...posBars.map(Math.abs),...sumBars.map(Math.abs),0.01); const BarRow = ({data,label,color})=>(<div><div style={{fontSize: 13,color,fontWeight:600,marginBottom:4}}>{label}</div><div style={{display:"flex",gap:2}}>{data.map((v,i)=>(<div key={i} style={{width:16,height:28,borderRadius:3,background:v>0?`rgba(14,165,233,${Math.abs(v)/mx})`:`rgba(239,68,68,${Math.abs(v)/mx})`}} title={`dim${i}: ${v.toFixed(3)}`}/>))}</div></div>); return (<VizBox title={lang === "tr" ? "Embedding â†’ Position â†’ BirleÅŸim" : "Embedding â†’ Position â†’ Combination"} color="#0EA5E9"><div style={{display:"flex",gap:20,alignItems:"flex-start",flexWrap:"wrap"}}><BarRow data={bars} label="Token Emb (wte['a'])" color="#0EA5E9"/><div style={{display:"flex",alignItems:"center",height:42,fontSize: 19,color:VB.muted,fontWeight:700}}>+</div><BarRow data={posBars} label="Pos Emb (wpe[0])" color="#8B5CF6"/><div style={{display:"flex",alignItems:"center",height:42,fontSize: 19,color:VB.muted,fontWeight:700}}>=</div><BarRow data={sumBars} label="x = tok + pos" color="#10B981"/></div><div style={{marginTop:8,fontSize: 12,color:VB.dim}}>Her Ã§ubuk = 1 boyut. Mavi=pozitif, KÄ±rmÄ±zÄ±=negatif. 16-boyutlu vektÃ¶r.</div></VizBox>); };

const CompGraphViz = () => { const nodes = [{l:"a",v:"2",g:"3",cx:13,cy:20,c:"#0EA5E9"},{l:"b",v:"3",g:"2",cx:13,cy:65,c:"#0EA5E9"},{l:"d=aÃ—b",v:"6",g:"1",cx:53,cy:37,c:"#F59E0B"},{l:"c",v:"1",g:"1",cx:53,cy:78,c:"#0EA5E9"},{l:"L=d+c",v:"7",g:"1",cx:90,cy:55,c:"#EF4444"}]; return (<VizBox title={lang === "tr" ? "Hesaplama GrafÄ± â€” L = (a Ã— b) + c" : "Computation Graph â€” L = (a Ã— b) + c"} color="#F59E0B"><div style={{display:"flex",gap:20,flexWrap:"wrap"}}><svg viewBox="0 0 120 95" style={{width:320,height:250}}><line x1="22" y1="24" x2="42" y2="37" stroke="#0EA5E9" strokeWidth="0.7" strokeDasharray="2,2"/><line x1="22" y1="68" x2="42" y2="42" stroke="#0EA5E9" strokeWidth="0.7" strokeDasharray="2,2"/><line x1="64" y1="40" x2="80" y2="55" stroke="#F59E0B" strokeWidth="0.7" strokeDasharray="2,2"/><line x1="62" y1="80" x2="80" y2="60" stroke="#0EA5E9" strokeWidth="0.7" strokeDasharray="2,2"/><text x="2" y="8" fill="#0EA5E9" fontSize="4" fontWeight="600">FORWARD â†’</text><text x="82" y="8" fill="#EF4444" fontSize="4" fontWeight="600">â† BACKWARD</text>{nodes.map((n,i)=>(<g key={i}><ellipse cx={n.cx} cy={n.cy} rx="13" ry="8" fill="#111827" stroke={n.c} strokeWidth="0.7"/><text x={n.cx} y={n.cy-1} fill={n.c} fontSize="4" fontWeight="700" textAnchor="middle">{n.l}</text><text x={n.cx} y={n.cy+5} fill="#64748B" fontSize="2.5" textAnchor="middle">data={n.v} grad={n.g}</text></g>))}</svg><div style={{flex:1,minWidth:200}}><div style={{fontSize: 14,fontWeight:600,color:"#F59E0B",marginBottom:6}}>{lang === "tr" ? "Chain Rule AdÄ±mlarÄ±" : "Chain Rule Steps"}</div>{[{eq:"âˆ‚L/âˆ‚L = 1",c:"#EF4444",n:lang==="tr"?"baÅŸlangÄ±Ã§":"start"},{eq:"âˆ‚L/âˆ‚d = 1Ã—1 = 1",c:"#F59E0B",n:"âˆ‚(d+c)/âˆ‚d"},{eq:"âˆ‚L/âˆ‚c = 1Ã—1 = 1",c:"#0EA5E9",n:"âˆ‚(d+c)/âˆ‚c"},{eq:"âˆ‚L/âˆ‚a = 1Ã—b = 3",c:"#0EA5E9",n:"âˆ‚(aÃ—b)/âˆ‚a=b"},{eq:"âˆ‚L/âˆ‚b = 1Ã—a = 2",c:"#0EA5E9",n:"âˆ‚(aÃ—b)/âˆ‚b=a"}].map((s,i)=>(<div key={i} style={{display:"flex",alignItems:"center",gap:8,padding:"4px 8px",borderRadius:6,marginBottom:3,background:`${s.c}08`}}><span style={{fontSize: 14,fontFamily:"'Fira Code',monospace",fontWeight:600,color:s.c}}>{s.eq}</span><span style={{fontSize: 12,color:VB.dim}}>{s.n}</span></div>))}<div style={{marginTop:8,padding:"6px 10px",borderRadius:6,background:"rgba(239,68,68,.06)",border:"1px solid rgba(239,68,68,.15)"}}><span style={{fontSize: 12,color:"#EF4444",fontWeight:600}}>{lang === "tr" ? "Kritik: grad += (= deÄŸil!) â€” Gradientler TOPLANIR." : "Critical: grad += (not =!) â€” Gradients ACCUMULATE."}</span></div></div></div></VizBox>); };

const OpGradTableViz = () => { const ops = [{op:"z = a + b",g:"âˆ‚z/âˆ‚a=1, âˆ‚z/âˆ‚b=1",c:"#0EA5E9"},{op:"z = a Ã— b",g:"âˆ‚z/âˆ‚a=b, âˆ‚z/âˆ‚b=a",c:"#10B981"},{op:"z = log(a)",g:"âˆ‚z/âˆ‚a = 1/a",c:"#8B5CF6"},{op:"z = exp(a)",g:"âˆ‚z/âˆ‚a = exp(a)",c:"#F59E0B"},{op:"z = relu(a)",g:"âˆ‚z/âˆ‚a = (a>0?1:0)",c:"#EC4899"},{op:"z = aâ¿",g:"âˆ‚z/âˆ‚a = nÂ·aâ¿â»Â¹",c:"#EF4444"}]; return (<VizBox title={lang === "tr" ? "OperatÃ¶r â†’ Yerel Gradient Tablosu" : "Operator â†’ Local Gradient Table"} color="#10B981"><div style={{display:"grid",gridTemplateColumns:"repeat(3,1fr)",gap:6}}>{ops.map((o,i)=>(<div key={i} style={{padding:"10px 12px",borderRadius:8,background:`${o.c}08`,borderLeft:`3px solid ${o.c}`}}><div style={{fontSize: 15,fontWeight:700,fontFamily:"'Fira Code',monospace",color:o.c}}>{o.op}</div><div style={{fontSize: 13,fontFamily:"'Fira Code',monospace",color:VB.txt,marginTop:3}}>{o.g}</div></div>))}</div></VizBox>); };

const ArchPipelineViz = () => { const [hov,setHov]=useState(-1); const pipe=[{l:"Token\nEmbed",s:"wte[id]â†’[16]",c:"#0EA5E9"},{l:"Pos\nEmbed",s:"+wpe[pos]",c:"#8B5CF6"},{l:"RMS\nNorm",s:"x/âˆš(rms+Îµ)",c:"#F59E0B"},{l:"Self\nAttn",s:"QÂ·Káµ€/âˆšdâ†’V",c:"#10B981"},{l:"MLP",s:"fc1â†’ReLUÂ²â†’fc2",c:"#EC4899"},{l:"LM\nHead",s:"â†’logits[28]",c:"#EF4444"}]; return (<VizBox title="GPT Forward Pass â€” Tam Mimari" color="#10B981"><div style={{display:"flex",alignItems:"center",gap:4,justifyContent:"center",flexWrap:"wrap"}}>{pipe.map((p,i)=>(<div key={i} style={{display:"flex",alignItems:"center",gap:4}} onMouseEnter={()=>setHov(i)} onMouseLeave={()=>setHov(-1)}><div style={{padding:"12px 14px",borderRadius:10,textAlign:"center",minWidth:85,background:hov===i?`${p.c}20`:`${p.c}0A`,border:`1.5px solid ${hov===i?p.c:`${p.c}30`}`,transform:hov===i?"scale(1.08)":"scale(1)",transition:"all .3s cubic-bezier(.34,1.56,.64,1)",boxShadow:hov===i?`0 0 16px ${p.c}20`:"none"}}><div style={{fontSize: 15,fontWeight:700,color:p.c,whiteSpace:"pre-line",lineHeight:1.3}}>{p.l}</div><div style={{fontSize: 11,color:VB.muted,marginTop:3,fontFamily:"'Fira Code',monospace"}}>{p.s}</div></div>{i<5&&<FlowArrow color={p.c}/>}</div>))}</div><div style={{display:"flex",gap:6,marginTop:12,justifyContent:"center",flexWrap:"wrap"}}><div style={{padding:"4px 10px",borderRadius:6,background:"rgba(16,185,129,.08)",fontSize: 12,color:"#10B981",fontFamily:"'Fira Code',monospace"}}>â†° Residual: x = attn(norm(x)) + x</div><div style={{padding:"4px 10px",borderRadius:6,background:"rgba(236,72,153,.08)",fontSize: 12,color:"#EC4899",fontFamily:"'Fira Code',monospace"}}>â†° Residual: x = mlp(norm(x)) + x</div></div></VizBox>); };

const AttentionFlowViz = () => { const hc=["#0EA5E9","#10B981","#F59E0B","#EC4899"]; return (<VizBox title={lang === "tr" ? "Self-Attention â€” DetaylÄ± AkÄ±ÅŸ" : "Self-Attention â€” Detailed Flow"} color="#10B981"><div style={{display:"flex",gap:24,flexWrap:"wrap"}}><div><div style={{fontSize: 14,fontWeight:600,color:"#0EA5E9",marginBottom:8}}>{lang === "tr" ? "1. Q, K, V Ãœretimi" : "1. Q, K, V Generation"}</div><div style={{display:"flex",alignItems:"center",gap:6}}><FlowBox label="x [16]" color="#94A3B8" small/><div style={{display:"flex",flexDirection:"column",gap:4}}>{[{l:"Q",c:"#10B981"},{l:"K",c:"#F59E0B"},{l:"V",c:"#EC4899"}].map(p=>(<div key={p.l} style={{display:"flex",alignItems:"center",gap:4}}><FlowArrow color={VB.dim}/><FlowBox label={`W${p.l.toLowerCase()}Â·x`} color={p.c} small/><FlowArrow color={VB.dim}/><FlowBox label={`${p.l} [16]`} color={p.c} small/></div>))}</div></div></div><div><div style={{fontSize: 14,fontWeight:600,color:"#10B981",marginBottom:8}}>{lang === "tr" ? "2. Scaled Dot-Product" : "2. Scaled Dot-Product"}</div><div style={{display:"flex",alignItems:"center",gap:4}}>{[{l:"QÂ·Káµ€",c:"#10B981"},{l:"Ã·âˆšd",c:"#F59E0B"},{l:"Softmax",c:"#8B5CF6"},{l:"Ã—V",c:"#EC4899"}].map((s,i)=>(<div key={i} style={{display:"flex",alignItems:"center",gap:4}}><FlowBox label={s.l} color={s.c} small active/>{i<3&&<FlowArrow color={VB.dim}/>}</div>))}</div><div style={{fontSize: 14,fontWeight:600,color:"#8B5CF6",marginTop:12,marginBottom:6}}>{lang === "tr" ? "3. Multi-Head (4 Ã— 4 dim)" : "3. Multi-Head (4 Ã— 4 dim)"}</div><div style={{display:"flex",gap:4}}>{[0,1,2,3].map(h=>(<div key={h} style={{flex:1,padding:"8px 6px",borderRadius:8,textAlign:"center",background:`${hc[h]}10`,border:`1.5px solid ${hc[h]}30`}}><div style={{fontSize: 13,fontWeight:700,color:hc[h]}}>Head {h}</div><div style={{fontSize: 11,color:VB.muted,fontFamily:"'Fira Code',monospace"}}>q[{h*4}:{h*4+4}]</div></div>))}</div></div></div></VizBox>); };

const CausalMaskViz = () => { const toks=["B","a","n","n","a"]; const wts=[[1.0],[.4,.6],[.2,.3,.5],[.1,.2,.3,.4],[.05,.15,.2,.25,.35]]; return (<VizBox title="Causal Attention Matrix" color="#F59E0B"><div style={{display:"flex",gap:20,alignItems:"flex-start",flexWrap:"wrap"}}><div><div style={{display:"flex",marginLeft:28}}>{toks.map((t,i)=>(<div key={i} style={{width:36,textAlign:"center",fontSize: 13,color:VB.muted,fontFamily:"'Fira Code',monospace"}}>{t}</div>))}</div>{toks.map((t,r)=>(<div key={r} style={{display:"flex",alignItems:"center"}}><div style={{width:24,fontSize: 13,color:VB.muted,fontFamily:"'Fira Code',monospace",textAlign:"right",paddingRight:4}}>{t}</div>{toks.map((_,c)=>{const masked=c>r;const w=!masked&&wts[r]?(wts[r][c]||0):0;return(<div key={c} style={{width:34,height:34,margin:1,borderRadius:4,display:"flex",alignItems:"center",justifyContent:"center",fontSize: 11,fontFamily:"'Fira Code',monospace",background:masked?"rgba(255,255,255,0.02)":`rgba(16,185,129,${w*0.9})`,color:masked?"#1E293B":w>0.3?"#fff":"rgba(16,185,129,.6)"}}>{masked?"âœ—":w.toFixed(1)}</div>);})}</div>))}<div style={{marginTop:6,fontSize: 12,color:VB.dim}}><span style={{color:"#10B981"}}>â– </span> koyu=yÃ¼ksek dikkat <span style={{color:"#1E293B"}}>âœ—</span>=mask</div></div><div style={{flex:1,minWidth:180}}><div style={{fontSize: 13,color:VB.txt,lineHeight:1.6}}><strong style={{color:"#F59E0B"}}>Causal masking:</strong> Her token sadece kendisi ve Ã¶nceki token'lara bakabilir.<br/><br/><strong style={{color:"#10B981"}}>Bu kodda mask yok!</strong> KV cache doÄŸal masking saÄŸlar â€” gelecek tokenlar cache'te yok.</div></div></div></VizBox>); };

const MLPFlowViz = () => { const neurons=useMemo(()=>Array.from({length:64},()=>Math.random()>0.38),[]); return (<VizBox title={lang === "tr" ? "MLP Block â€” GeniÅŸlet â†’ Aktive Et â†’ Daralt" : "MLP Block â€” Expand â†’ Activate â†’ Compress"} color="#EC4899"><div style={{display:"flex",alignItems:"center",gap:4,justifyContent:"center",flexWrap:"wrap",marginBottom:12}}>{[{l:"x [16]",c:"#94A3B8"},{l:"RMSNorm",c:"#F59E0B"},{l:"fc1: 16â†’64",c:"#8B5CF6"},{l:"ReLUÂ²",c:"#EC4899"},{l:"fc2: 64â†’16",c:"#10B981"},{l:"+residual",c:"#EF4444"}].map((s,i)=>(<div key={i} style={{display:"flex",alignItems:"center",gap:4}}><FlowBox label={s.l} color={s.c} small/>{i<5&&<FlowArrow color={VB.dim}/>}</div>))}</div><div><div style={{fontSize: 13,color:VB.muted,marginBottom:6}}>64 NÃ¶ron (ReLUÂ² sonrasÄ±): <span style={{color:"#EC4899"}}>â– </span> {lang === "tr" ? "aktif" : "active"} <span style={{color:"#1E293B"}}>â–¡</span> {lang === "tr" ? "Ã¶lÃ¼" : "dead"}</div><div style={{display:"flex",flexWrap:"wrap",gap:2,maxWidth:340}}>{neurons.map((a,i)=>(<div key={i} style={{width:16,height:16,borderRadius:3,background:a?"rgba(236,72,153,0.5)":"rgba(255,255,255,0.03)",border:a?"none":"1px solid rgba(255,255,255,0.04)"}}/>))}</div><div style={{marginTop:6,display:"flex",gap:16,fontSize: 13,color:VB.muted}}><span>{lang === "tr" ? "Aktif:" : "Active:"} <strong style={{color:"#10B981"}}>{neurons.filter(Boolean).length}</strong>/64</span><span>{lang === "tr" ? "Ã–lÃ¼:" : "Dead:"} <strong style={{color:"#EF4444"}}>{neurons.filter(n=>!n).length}</strong>/64</span><span>Sparsity: <strong style={{color:"#F59E0B"}}>{((neurons.filter(n=>!n).length/64)*100).toFixed(0)}%</strong></span></div></div></VizBox>); };

const ParamDistViz = () => { const params=[{l:"wte (Token Emb)",v:432,c:"#0EA5E9",d:"27Ã—16"},{l:"wpe (Pos Emb)",v:128,c:"#8B5CF6",d:"8Ã—16"},{l:"Q,K,V,O (Attn)",v:1024,c:"#10B981",d:"4Ã—[16Ã—16]"},{l:"fc1+fc2 (MLP)",v:2048,c:"#EC4899",d:"64Ã—16+16Ã—64"}]; const total=params.reduce((s,p)=>s+p.v,0); const mx=Math.max(...params.map(p=>p.v)); return (<VizBox title={lang === "tr" ? "Parametre DaÄŸÄ±lÄ±mÄ± â€” 3,648 DeÄŸer" : "Parameter Distribution â€” 3,648 Values"} color="#EC4899"><div style={{display:"flex",gap:20,flexWrap:"wrap"}}><div style={{flex:1,minWidth:260}}>{params.map((p,i)=>(<div key={i} style={{marginBottom:8}}><div style={{display:"flex",justifyContent:"space-between",marginBottom:3}}><span style={{fontSize: 13,color:p.c,fontWeight:600}}>{p.l}</span><span style={{fontSize: 13,fontFamily:"'Fira Code',monospace",color:VB.muted}}>{p.v} ({((p.v/total)*100).toFixed(0)}%)</span></div><div style={{height:14,background:"rgba(255,255,255,0.03)",borderRadius:7,overflow:"hidden"}}><div style={{height:"100%",width:`${(p.v/mx)*100}%`,borderRadius:7,background:p.c,transition:"width .6s"}}/></div><div style={{fontSize: 11,color:VB.dim,marginTop:2}}>{p.d}</div></div>))}</div><div style={{display:"flex",flexDirection:"column",gap:6}}><StatBox value="3,648" label=lang === "tr" ? "Toplam" : "Total" color="#0EA5E9"/><StatBox value="56%" label=lang === "tr" ? "MLP PayÄ±" : "MLP Share" color="#EC4899"/><StatBox value="28%" label=lang === "tr" ? "Attn PayÄ±" : "Attn Share" color="#10B981"/></div></div></VizBox>); };

const TrainingCycleViz = () => { const [phase,setPhase]=useState(0); useEffect(()=>{const t=setInterval(()=>setPhase(p=>(p+1)%4),1200);return()=>clearInterval(t);},[]);const phases=[{l:"FORWARD",s:"gpt(tok,pos)â†’logits",c:"#0EA5E9",i:"â†’"},{l:"LOSS",s:"CE=-log(P_target)",c:"#EF4444",i:"ğŸ“‰"},{l:"BACKWARD",s:"loss.backward()â†’grads",c:"#F59E0B",i:"â†"},{l:"UPDATE",s:"p-=lrÃ—mÌ‚/(âˆšvÌ‚+Îµ)",c:"#10B981",i:"ğŸ”§"}]; return (<VizBox title={lang === "tr" ? "EÄŸitim DÃ¶ngÃ¼sÃ¼ â€” Cycle" : "Training Loop â€” Cycle"} color="#F59E0B"><div style={{display:"flex",justifyContent:"center",gap:10,flexWrap:"wrap"}}>{phases.map((p,i)=>(<div key={i} style={{display:"flex",alignItems:"center",gap:10}}><div style={{padding:"14px 18px",borderRadius:12,textAlign:"center",minWidth:110,background:i===phase?`${p.c}20`:`${p.c}08`,border:`2px solid ${i===phase?p.c:`${p.c}20`}`,transform:i===phase?"scale(1.1)":"scale(1)",transition:"all .4s cubic-bezier(.34,1.56,.64,1)",boxShadow:i===phase?`0 0 20px ${p.c}30`:"none"}}><div style={{fontSize: 19,marginBottom:2}}>{p.i}</div><div style={{fontSize: 16,fontWeight:700,color:p.c}}>{p.l}</div><div style={{fontSize: 11,fontFamily:"'Fira Code',monospace",color:VB.muted,marginTop:2}}>{p.s}</div></div>{i<3&&<div style={{fontSize: 19,color:i===phase?p.c:VB.dim,transition:"color .3s"}}>â†’</div>}</div>))}</div><div style={{marginTop:10,textAlign:"center",fontSize: 13,color:VB.muted}}>{lang === "tr" ? "Her step tekrarlanÄ±r" : "Each step repeats"} â€¢ <span style={{color:"#EF4444"}}>Kritik: p.grad = 0</span></div></VizBox>); };

const LossTableViz = () => { const rows=[{p:"1.0",l:"0.00",n:lang === "tr" ? "MÃ¼kemmel" : "Perfect",c:"#10B981"},{p:"0.5",l:"0.69",n:lang === "tr" ? "YarÄ± yarÄ±ya" : "Half & half",c:"#F59E0B"},{p:"0.1",l:"2.30",n:lang === "tr" ? "KÃ¶tÃ¼" : "Bad",c:"#EF4444"},{p:"1/27",l:"3.33",n:lang === "tr" ? "Rastgele(baÅŸlangÄ±Ã§)" : "Random(start)",c:"#EF4444"}]; return (<VizBox title="Cross-Entropy: P(target) vs Loss" color="#EF4444"><div style={{display:"flex",gap:20,flexWrap:"wrap"}}><div>{rows.map((r,i)=>(<div key={i} style={{display:"flex",alignItems:"center",gap:8,padding:"6px 10px",borderRadius:6,marginBottom:4,background:`${r.c}08`}}><span style={{width:60,fontSize: 14,fontFamily:"'Fira Code',monospace",color:VB.txt}}>P={r.p}</span><span style={{width:50,fontSize: 14,fontFamily:"'Fira Code',monospace",fontWeight:700,color:r.c}}>L={r.l}</span><span style={{fontSize: 13,color:VB.muted}}>{r.n}</span></div>))}</div><div style={{padding:"10px 14px",background:VB.card,borderRadius:8}}><div style={{fontSize: 16,fontFamily:"'Fira Code',monospace",color:"#EF4444",fontWeight:700}}>L = -(1/n) Î£ log P(target_i)</div><div style={{fontSize: 13,color:VB.muted,marginTop:6,lineHeight:1.5}}>DÃ¼ÅŸÃ¼k P â†’ yÃ¼ksek sÃ¼rpriz â†’ yÃ¼ksek loss<br/>BaÅŸlangÄ±Ã§: L â‰ˆ 3.33 = -log(1/27)</div></div></div></VizBox>); };

const AdamEvolutionViz = () => { const opts=[{l:"SGD",eq:"p-=lrÃ—g",d:lang==="tr"?"Basit":"Simple",c:"#64748B"},{l:"Momentum",eq:"m=Î²â‚m+g",d:lang==="tr"?"YÃ¶n bilgisi":"Direction info",c:"#F59E0B"},{l:"RMSprop",eq:"v=Î²â‚‚v+gÂ²",d:lang==="tr"?"Adaptif":"Adaptive",c:"#8B5CF6"},{l:"Adam â˜…",eq:"mÌ‚/(âˆšvÌ‚+Îµ)",d:lang==="tr"?"BirleÅŸik":"Combined",c:"#10B981"}]; return (<VizBox title="SGD â†’ Momentum â†’ RMSprop â†’ Adam" color="#10B981"><div style={{display:"flex",alignItems:"center",gap:6,justifyContent:"center",flexWrap:"wrap"}}>{opts.map((o,i)=>(<div key={i} style={{display:"flex",alignItems:"center",gap:6}}><div style={{padding:"10px 14px",borderRadius:10,textAlign:"center",minWidth:100,background:`${o.c}0A`,border:`1.5px solid ${o.c}30`}}><div style={{fontSize: 15,fontWeight:700,color:o.c}}>{o.l}</div><div style={{fontSize: 12,fontFamily:"'Fira Code',monospace",color:VB.muted,marginTop:2}}>{o.eq}</div><div style={{fontSize: 11,color:VB.dim,marginTop:2}}>{o.d}</div></div>{i<3&&<FlowArrow color={VB.dim}/>}</div>))}</div></VizBox>); };

const InferenceTimelineViz = () => { const [step,setStep]=useState(0); const steps=[{inp:"BOS",out:"k",p:".08"},{inp:"k",out:"a",p:".15"},{inp:"a",out:"m",p:".11"},{inp:"m",out:"r",p:".09"},{inp:"r",out:"i",p:".22"},{inp:"i",out:"n",p:".18"},{inp:"n",out:"BOS",p:".31"}]; useEffect(()=>{const t=setInterval(()=>setStep(s=>(s+1)%8),1000);return()=>clearInterval(t);},[]);return (<VizBox title="Autoregressive Generation â€” 'kamrin'" color="#6366F1"><div style={{display:"flex",gap:4,justifyContent:"center",flexWrap:"wrap"}}>{steps.map((s,i)=>(<div key={i} style={{display:"flex",flexDirection:"column",alignItems:"center",gap:3,opacity:i<step?1:0.3,transition:"opacity .4s"}}><div style={{padding:"4px 10px",borderRadius:6,fontSize: 15,fontFamily:"'Fira Code',monospace",fontWeight:700,color:"#0EA5E9",background:"rgba(14,165,233,.1)"}}>{s.inp}</div><div style={{fontSize: 13,color:VB.dim}}>â†“GPT</div><div style={{padding:"4px 10px",borderRadius:6,fontSize: 15,fontFamily:"'Fira Code',monospace",fontWeight:700,color:s.out==="BOS"?"#EF4444":"#10B981",background:s.out==="BOS"?"rgba(239,68,68,.1)":"rgba(16,185,129,.1)"}}>{s.out}</div><div style={{fontSize: 11,fontFamily:"'Fira Code',monospace",color:VB.dim}}>P={s.p}</div></div>))}</div><div style={{marginTop:10,textAlign:"center",padding:"6px 14px",background:"rgba(16,185,129,.06)",borderRadius:8}}><span style={{fontSize: 15,color:VB.muted}}>SonuÃ§: </span><span style={{fontSize: 19,fontFamily:"'Fira Code',monospace",fontWeight:800,color:"#10B981"}}>"kamrin"</span><span style={{fontSize: 13,color:VB.dim}}> â€” veri setinde yok ama yapÄ±ya uygun!</span></div></VizBox>); };

const TemperatureViz = () => { const logits=[2.4,1.8,0.5,-0.3,-1.0]; const labels=["a","n","e","i","t"]; const calcP=(t)=>{const s=logits.map(l=>l/t);const mx=Math.max(...s);const e=s.map(l=>Math.exp(l-mx));const sm=e.reduce((a,b)=>a+b);return e.map(v=>v/sm);}; const temps=[{t:0.2,label:"T=0.2 (sivri)",c:"#0EA5E9"},{t:0.8,label:"T=0.8 (dengeli)",c:"#10B981"},{t:1.5,label:"T=1.5 (dÃ¼z)",c:"#EF4444"}]; return (<VizBox title="Temperature Etkisi" color="#F59E0B"><div style={{display:"flex",gap:14,flexWrap:"wrap"}}>{temps.map((tmp,ti)=>{const probs=calcP(tmp.t);const mx=Math.max(...probs);return(<div key={ti} style={{flex:1,minWidth:140}}><div style={{fontSize: 14,fontWeight:600,color:tmp.c,marginBottom:6}}>{tmp.label}</div>{probs.map((p,i)=>(<div key={i} style={{display:"flex",alignItems:"center",gap:4,marginBottom:3}}><span style={{width:14,fontSize: 13,fontFamily:"'Fira Code',monospace",color:VB.muted}}>{labels[i]}</span><div style={{flex:1,height:12,background:"rgba(255,255,255,0.03)",borderRadius:6,overflow:"hidden"}}><div style={{height:"100%",width:`${(p/mx)*100}%`,borderRadius:6,background:tmp.c}}/></div><span style={{width:35,fontSize: 11,fontFamily:"'Fira Code',monospace",color:VB.dim,textAlign:"right"}}>{(p*100).toFixed(0)}%</span></div>))}</div>);})}</div><div style={{marginTop:8,fontSize: 12,color:VB.dim}}>Tâ†“: sivri(deterministik) â€¢ T=1: orijinal â€¢ Tâ†‘: dÃ¼z(rastgele)</div></VizBox>); };

const KVCacheViz = () => (<VizBox title="KV Cache â€” O(nÂ²) â†’ O(n)" color="#10B981"><div style={{display:"flex",gap:20,flexWrap:"wrap"}}><div><div style={{fontSize: 13,color:VB.muted,marginBottom:6}}>Cache BÃ¼yÃ¼me</div>{[0,1,2,3,4].map(pos=>(<div key={pos} style={{display:"flex",alignItems:"center",gap:6,marginBottom:4}}><span style={{width:44,fontSize: 12,fontFamily:"'Fira Code',monospace",color:VB.muted}}>pos={pos}</span>{Array.from({length:pos+1},(_,k)=>(<div key={k} style={{padding:"3px 8px",borderRadius:4,fontSize: 12,fontFamily:"'Fira Code',monospace",background:k===pos?"rgba(16,185,129,.2)":"rgba(14,165,233,.1)",color:k===pos?"#10B981":"#0EA5E9",fontWeight:k===pos?700:400}}>k{k}</div>))}{pos<4&&<span style={{fontSize: 11,color:"#10B981"}}>â†yeni</span>}</div>))}</div><div style={{flex:1,minWidth:200,display:"flex",gap:10}}><div style={{flex:1,padding:"8px 12px",borderRadius:8,background:"rgba(239,68,68,.06)"}}><div style={{fontSize: 13,fontWeight:600,color:"#EF4444"}}>Cache Yok</div><div style={{fontSize: 12,color:VB.muted,marginTop:4}}>pos=5: 6 token hesapla</div><div style={{fontSize: 15,fontFamily:"'Fira Code',monospace",fontWeight:700,color:"#EF4444",marginTop:4}}>O(nÂ²)</div></div><div style={{flex:1,padding:"8px 12px",borderRadius:8,background:"rgba(16,185,129,.06)"}}><div style={{fontSize: 13,fontWeight:600,color:"#10B981"}}>KV Cache</div><div style={{fontSize: 12,color:VB.muted,marginTop:4}}>pos=5: 1 yeni+5 cache</div><div style={{fontSize: 15,fontFamily:"'Fira Code',monospace",fontWeight:700,color:"#10B981",marginTop:4}}>O(n)</div></div></div></div></VizBox>);

const GPTFamilyViz = () => { const ms=[{n:"Bu Kod â˜…",p:"~5K",l:"1",e:"16",c:"8",y:"2024",cl:"#0EA5E9"},{n:"GPT-1",p:"117M",l:"12",e:"768",c:"512",y:"2018",cl:"#94A3B8"},{n:"GPT-2",p:"1.5B",l:"48",e:"1,600",c:"1K",y:"2019",cl:"#94A3B8"},{n:"GPT-3",p:"175B",l:"96",e:"12,288",c:"2K",y:"2020",cl:"#94A3B8"},{n:"GPT-4",p:"~1T+",l:"?",e:"?",c:"128K",y:"2023",cl:"#94A3B8"}]; return (<VizBox title={lang === "tr" ? "GPT Ailesi KarÅŸÄ±laÅŸtÄ±rma" : "GPT Family Comparison"} color="#6366F1"><div style={{overflowX:"auto"}}><div style={{display:"grid",gridTemplateColumns:"120px repeat(5,1fr)",gap:2,minWidth:450}}>{["Model","Param","Layer","n_embd","Context",lang === "tr" ? lang === "tr" ? "YÄ±l" : "Year" : "Year"].map((h,i)=>(<div key={i} style={{padding:"6px 8px",background:"rgba(255,255,255,0.04)",fontSize: 12,fontWeight:700,color:"#0EA5E9"}}>{h}</div>))}{ms.map((m,ri)=>[m.n,m.p,m.l,m.e,m.c,m.y].map((cell,ci)=>(<div key={`${ri}-${ci}`} style={{padding:"5px 8px",fontSize: 13,fontFamily:ci>0?"'Fira Code',monospace":"inherit",fontWeight:ci===0||ri===0?700:400,color:ri===0?m.cl:VB.txt,background:ri===0?`${m.cl}08`:"transparent"}}>{cell}</div>)))}</div></div><div style={{marginTop:10,padding:"6px 12px",background:"rgba(16,185,129,.06)",borderRadius:8,fontSize: 13,color:"#10B981"}}>Temel mekanizma hep aynÄ±: attention + MLP + residual + norm + CE + backprop + Adam</div></VizBox>); };

const ResidualViz = () => (<VizBox title="Residual Connections â€” Gradient Highway" color="#10B981"><div style={{display:"flex",gap:24,flexWrap:"wrap"}}><div><div style={{fontSize: 14,fontWeight:600,color:"#EF4444",marginBottom:6}}>Residual OLMADAN</div><div style={{display:"flex",alignItems:"center",gap:4}}>{[1,.7,.4,.15,.05].map((op,i)=>(<div key={i} style={{display:"flex",alignItems:"center",gap:4}}><div style={{padding:"6px 10px",borderRadius:6,background:`rgba(239,68,68,${op})`,fontSize: 13,fontFamily:"'Fira Code',monospace",color:op>0.3?"#fff":"#EF4444"}}>f{i+1}</div>{i<4&&<span style={{color:VB.dim,fontSize: 13}}>â†’</span>}</div>))}</div><div style={{fontSize: 12,color:"#EF4444",marginTop:4}}>Gradient kÃ¼Ã§Ã¼lÃ¼r â†’ uzak katmanlar Ã¶ÄŸrenemez</div></div><div><div style={{fontSize: 14,fontWeight:600,color:"#10B981",marginBottom:6}}>Residual Ä°LE</div><div style={{display:"flex",alignItems:"center",gap:4}}>{[1,1,1,1,1].map((_,i)=>(<div key={i} style={{display:"flex",alignItems:"center",gap:4}}><div style={{padding:"6px 10px",borderRadius:6,background:"rgba(16,185,129,0.5)",fontSize: 13,fontFamily:"'Fira Code',monospace",color:"#fff"}}>f{i+1}+x</div>{i<4&&<span style={{color:VB.dim,fontSize: 13}}>â†’</span>}</div>))}</div><div style={{fontSize: 12,color:"#10B981",marginTop:4}}>âˆ‚y/âˆ‚x = âˆ‚f/âˆ‚x + 1 â† +1 her zaman geÃ§er!</div></div></div></VizBox>);

const SoftmaxViz = () => { const logits=[2.4,0.0,-1.5]; const labels=["A","B","C"]; const mx=Math.max(...logits); const exps=logits.map(l=>Math.exp(l-mx)); const sum=exps.reduce((a,b)=>a+b); const probs=exps.map(e=>e/sum); return (<VizBox title={lang === "tr" ? "Softmax: Logits â†’ OlasÄ±lÄ±k" : "Softmax: Logits â†’ Probability"} color="#8B5CF6"><div style={{display:"flex",gap:16,alignItems:"center",justifyContent:"center",flexWrap:"wrap"}}><div style={{textAlign:"center"}}><div style={{fontSize: 13,color:VB.muted,marginBottom:4}}>Logits</div>{logits.map((l,i)=>(<div key={i} style={{fontSize: 17,fontFamily:"'Fira Code',monospace",color:VB.txt,padding:"2px 0"}}>{labels[i]}: {l.toFixed(1)}</div>))}</div><div style={{fontSize: 21,color:VB.dim}}>â†’</div><div style={{textAlign:"center"}}><div style={{fontSize: 13,color:VB.muted,marginBottom:4}}>exp(x-max)</div>{exps.map((e,i)=>(<div key={i} style={{fontSize: 17,fontFamily:"'Fira Code',monospace",color:"#F59E0B",padding:"2px 0"}}>{e.toFixed(2)}</div>))}</div><div style={{fontSize: 21,color:VB.dim}}>â†’</div><div style={{textAlign:"center"}}><div style={{fontSize: 13,color:VB.muted,marginBottom:4}}>Ã· toplam</div>{probs.map((p,i)=>(<div key={i} style={{display:"flex",alignItems:"center",gap:6,padding:"2px 0"}}><span style={{fontSize: 17,fontFamily:"'Fira Code',monospace",color:"#10B981",fontWeight:700}}>{(p*100).toFixed(0)}%</span><div style={{width:80,height:12,background:"rgba(255,255,255,0.03)",borderRadius:6,overflow:"hidden"}}><div style={{height:"100%",width:`${p*100}%`,borderRadius:6,background:"#10B981"}}/></div></div>))}</div></div><div style={{marginTop:8,textAlign:"center",fontSize: 12,color:VB.dim}}>max-subtraction trick: exp(1000)=âˆ â†’ exp(1000-1000)=1 âœ“</div></VizBox>); };

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// NEW VISUALIZATION COMPONENTS â€” Inspired by PPTX Enriched Visual Guide
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

const NeuralNetBasicsViz = () => {
  const [tab, setTab] = useState(0);
  // Tab 0: Interactive neuron
  const [w1, setW1] = useState(0.5);
  const [w2, setW2] = useState(-0.3);
  const [bias, setBias] = useState(0.1);
  const x1 = 2.0, x2 = 3.0;
  const raw = w1 * x1 + w2 * x2 + bias;
  const out = Math.max(0, raw);

  // Tab 1: data flow animation
  const [flowStep, setFlowStep] = useState(0);
  useEffect(() => { const t = setInterval(() => setFlowStep(s => (s + 1) % 5), 1200); return () => clearInterval(t); }, []);

  // Tab 2: mini training sim
  const [trainStep, setTrainStep] = useState(0);
  const [training, setTraining] = useState(false);
  const stages = [
    { w: [0.1, 0.2], b: 0, loss: 12.5, label: lang === "tr" ? "Rastgele baÅŸlangÄ±Ã§" : "Random start" },
    { w: [0.8, 1.0], b: 0.5, loss: 5.2, label: lang === "tr" ? "AdÄ±m 10" : "Step 10" },
    { w: [2.0, 2.5], b: 0.8, loss: 1.8, label: lang === "tr" ? "AdÄ±m 50" : "Step 50" },
    { w: [3.0, 2.0], b: 1.0, loss: 0.1, label: lang === "tr" ? "AdÄ±m 100 â€” yakÄ±nsadÄ± âœ“" : "Step 100 â€” converged âœ“" },
  ];
  const ts = stages[trainStep];
  const trainData = [{x:[1,2],t:5,l:lang==="tr"?"1 oda, 2mÂ²":"1 room, 2mÂ²"},{x:[3,4],t:19,l:lang==="tr"?"3 oda, 4mÂ²":"3 rooms, 4mÂ²"},{x:[2,3],t:11,l:lang==="tr"?"2 oda, 3mÂ²":"2 rooms, 3mÂ²"}];
  useEffect(() => {
    if (!training) return;
    const t = setInterval(() => setTrainStep(s => { if (s >= 3) { setTraining(false); return 3; } return s + 1; }), 1200);
    return () => clearInterval(t);
  }, [training]);

  const tabs = [{l:lang === "tr" ? "ğŸ”¬ Ä°nteraktif NÃ¶ron" : "ğŸ”¬ Interactive Neuron",c:"#0EA5E9"},{l:lang === "tr" ? "ğŸŒŠ Veri AkÄ±ÅŸÄ±" : "ğŸŒŠ Data Flow",c:"#8B5CF6"},{l:lang === "tr" ? "ğŸ¯ Mini EÄŸitim" : "ğŸ¯ Mini Training",c:"#10B981"}];

  return (<VizBox title={lang === "tr" ? "Yapay Sinir AÄŸÄ± â€” Ä°nteraktif KeÅŸif" : "Neural Network â€” Interactive Exploration"} color="#0EA5E9">
    <div style={{display:"flex",gap:4,marginBottom:12}}>
      {tabs.map((t,i)=>(<button key={i} onClick={()=>setTab(i)} style={{flex:1,padding:"6px 8px",borderRadius:8,border:"none",cursor:"pointer",background:tab===i?`${t.c}20`:"rgba(255,255,255,0.03)",color:tab===i?t.c:"#64748B",fontSize: 13,fontWeight:700,fontFamily:"inherit",borderBottom:tab===i?`2px solid ${t.c}`:"2px solid transparent",transition:"all .3s"}}>{t.l}</button>))}
    </div>

    {/* TAB 0: Interactive Neuron */}
    {tab===0 && (<div style={{display:"flex",gap:16,flexWrap:"wrap"}}>
      <svg viewBox="0 0 220 100" style={{width:340,height:160,flexShrink:0}}>
        <line x1="40" y1="25" x2="110" y2="50" stroke={w1>=0?"#0EA5E9":"#EF4444"} strokeWidth={Math.abs(w1)*2+0.5} opacity="0.6"/>
        <line x1="40" y1="75" x2="110" y2="50" stroke={w2>=0?"#0EA5E9":"#EF4444"} strokeWidth={Math.abs(w2)*2+0.5} opacity="0.6"/>
        <line x1="110" y1="50" x2="180" y2="50" stroke={out>0?"#10B981":"#64748B"} strokeWidth="1.5"/>
        <circle cx="40" cy="25" r="7" fill="#0EA5E920" stroke="#0EA5E9" strokeWidth="1"/>
        <text x="40" y="27" fill="#0EA5E9" fontSize="6" fontWeight="700" textAnchor="middle">xâ‚={x1}</text>
        <circle cx="40" cy="75" r="7" fill="#0EA5E920" stroke="#0EA5E9" strokeWidth="1"/>
        <text x="40" y="77" fill="#0EA5E9" fontSize="6" fontWeight="700" textAnchor="middle">xâ‚‚={x2}</text>
        <circle cx="110" cy="18" r="5" fill="#F59E0B20" stroke="#F59E0B" strokeWidth="0.8"/>
        <text x="110" y="20" fill="#F59E0B" fontSize="5" fontWeight="600" textAnchor="middle">b</text>
        <line x1="110" y1="23" x2="110" y2="43" stroke="#F59E0B" strokeWidth="0.5" strokeDasharray="2,2"/>
        <circle cx="110" cy="50" r="10" fill={raw>0?"#10B98120":"#EF444420"} stroke={raw>0?"#10B981":"#EF4444"} strokeWidth="1.2"/>
        <text x="110" y="48" fill="#E2E8F0" fontSize="4" fontWeight="600" textAnchor="middle">Î£+ReLU</text>
        <text x="110" y="55" fill="#94A3B8" fontSize="3.5" textAnchor="middle">{raw.toFixed(2)}</text>
        <circle cx="180" cy="50" r="7" fill={out>0?"#10B98130":"#64748B20"} stroke={out>0?"#10B981":"#64748B"} strokeWidth="1"/>
        <text x="180" y="52" fill={out>0?"#10B981":"#64748B"} fontSize="7" fontWeight="800" textAnchor="middle">{out.toFixed(2)}</text>
        <text x="68" y="32" fill={w1>=0?"#0EA5E9":"#EF4444"} fontSize="5" fontWeight="700" textAnchor="middle">wâ‚={w1.toFixed(1)}</text>
        <text x="68" y="70" fill={w2>=0?"#0EA5E9":"#EF4444"} fontSize="5" fontWeight="700" textAnchor="middle">wâ‚‚={w2.toFixed(1)}</text>
        <text x="110" y="92" fill="#94A3B8" fontSize="3.5" textAnchor="middle">y = ReLU({w1.toFixed(1)}Ã—{x1} + ({w2.toFixed(1)})Ã—{x2} + {bias.toFixed(1)}) = {out.toFixed(2)}</text>
      </svg>
      <div style={{flex:1,minWidth:180}}>
        <div style={{fontSize: 13,fontWeight:700,color:"#F59E0B",marginBottom:8}}>{lang === "tr" ? "ğŸ›ï¸ AÄŸÄ±rlÄ±klarÄ± DeÄŸiÅŸtir:" : "ğŸ›ï¸ Adjust Weights:"}</div>
        {[{label:"wâ‚",val:w1,set:setW1,color:"#0EA5E9"},{label:"wâ‚‚",val:w2,set:setW2,color:"#8B5CF6"},{label:"bias",val:bias,set:setBias,color:"#F59E0B"}].map((s,i)=>(
          <div key={i} style={{marginBottom:6}}>
            <div style={{display:"flex",justifyContent:"space-between",fontSize: 13}}>
              <span style={{color:s.color,fontWeight:600}}>{s.label}</span>
              <span style={{fontFamily:"'Fira Code',monospace",color:"#E2E8F0"}}>{s.val.toFixed(1)}</span>
            </div>
            <input type="range" min={-2} max={2} step="0.1" value={s.val} onChange={e=>s.set(+e.target.value)} style={{width:"100%",accentColor:s.color}}/>
          </div>
        ))}
        <div style={{padding:"6px 8px",borderRadius:8,background:raw<0?"rgba(239,68,68,.08)":"rgba(16,185,129,.08)",fontSize: 13,color:raw<0?"#EF4444":"#10B981",fontWeight:600}}>
          {raw<0?(lang==="tr"?`â›” ReLU: ${raw.toFixed(2)} < 0 â†’ Ã§Ä±ktÄ± 0 (nÃ¶ron kapalÄ±)`:`â›” ReLU: ${raw.toFixed(2)} < 0 â†’ output 0 (neuron off)`):(lang==="tr"?`âœ… ReLU: ${raw.toFixed(2)} > 0 â†’ Ã§Ä±ktÄ± ${out.toFixed(2)} (nÃ¶ron aÃ§Ä±k)`:`âœ… ReLU: ${raw.toFixed(2)} > 0 â†’ output ${out.toFixed(2)} (neuron on)`)}
        </div>
        <div style={{marginTop:6,fontSize: 12,color:"#64748B"}}>{lang==="tr"?"ğŸ’¡ Deneyin: wâ‚‚'yi negatif yapÄ±n â†’ bir girdinin etkisini TERSÄ°NE Ã§evirir!":"ğŸ’¡ Try it: make wâ‚‚ negative â†’ reverses the effect of that input!"}</div>
      </div>
    </div>)}

    {/* TAB 1: Data Flow Animation */}
    {tab===1 && (<div>
      <div style={{display:"flex",gap:4,justifyContent:"center",alignItems:"center",flexWrap:"wrap",marginBottom:10}}>
        {[{l:lang==="tr"?"Girdi":"Input",v:"xâ‚=2, xâ‚‚=3",c:"#0EA5E9"},{l:lang==="tr"?"Ã— AÄŸÄ±rlÄ±k":"Ã— Weight",v:"Ã—wâ‚, Ã—wâ‚‚",c:"#F59E0B"},{l:lang==="tr"?"Î£ Toplam":"Î£ Sum",v:"1.0+(-0.9)+0.1",c:"#8B5CF6"},{l:"ReLU",v:"max(0, 0.2)",c:"#EC4899"},{l:lang==="tr"?"Ã‡Ä±ktÄ±":"Output",v:"0.2",c:"#10B981"}].map((n,i)=>(
          <div key={i} style={{display:"flex",alignItems:"center",gap:4}}>
            <div style={{padding:"8px 10px",borderRadius:10,textAlign:"center",minWidth:70,background:i<=flowStep?`${n.c}18`:"rgba(255,255,255,0.02)",border:`1.5px solid ${i===flowStep?n.c:i<flowStep?`${n.c}40`:"rgba(255,255,255,0.05)"}`,transform:i===flowStep?"scale(1.1)":"scale(1)",transition:"all .4s",boxShadow:i===flowStep?`0 0 14px ${n.c}25`:"none"}}>
              <div style={{fontSize: 13,fontWeight:700,color:n.c}}>{n.l}</div>
              <div style={{fontSize: 11,fontFamily:"'Fira Code',monospace",color:"#94A3B8",marginTop:2}}>{n.v}</div>
            </div>
            {i<4&&<div style={{fontSize: 15,color:i<flowStep?n.c:"#1E293B",transition:"color .4s"}}>â†’</div>}
          </div>
        ))}
      </div>
      <div style={{padding:10,borderRadius:10,background:"rgba(255,255,255,0.02)",border:"1px solid rgba(255,255,255,0.05)"}}>
        {[
          {text:lang==="tr"?"â‘  Girdi deÄŸerleri nÃ¶rona gelir: xâ‚=2.0, xâ‚‚=3.0":"â‘  Input values arrive at the neuron: xâ‚=2.0, xâ‚‚=3.0",c:"#0EA5E9"},
          {text:lang==="tr"?"â‘¡ Her girdi kendi aÄŸÄ±rlÄ±ÄŸÄ±yla Ã§arpÄ±lÄ±r: 2.0Ã—0.5=1.0 ve 3.0Ã—(-0.3)=-0.9":"â‘¡ Each input is multiplied by its weight: 2.0Ã—0.5=1.0 and 3.0Ã—(-0.3)=-0.9",c:"#F59E0B"},
          {text:lang==="tr"?"â‘¢ Ã‡arpÄ±mlar + bias toplanÄ±r: 1.0 + (-0.9) + 0.1 = 0.2":"â‘¢ Products + bias are summed: 1.0 + (-0.9) + 0.1 = 0.2",c:"#8B5CF6"},
          {text:lang==="tr"?"â‘£ ReLU aktivasyonu: max(0, 0.2) = 0.2 â†’ pozitif, geÃ§ir!":"â‘£ ReLU activation: max(0, 0.2) = 0.2 â†’ positive, pass!",c:"#EC4899"},
          {text:lang==="tr"?"â‘¤ Ã‡Ä±ktÄ± = 0.2 â†’ sonraki katmana veya tahmin olarak gider":"â‘¤ Output = 0.2 â†’ goes to next layer or becomes the prediction",c:"#10B981"},
        ].map((s,i)=>(
          <div key={i} style={{display:"flex",gap:8,alignItems:"center",padding:"3px 0",opacity:i===flowStep?1:0.25,transition:"opacity .4s"}}>
            <div style={{width:16,height:16,borderRadius:"50%",background:`${s.c}20`,display:"flex",alignItems:"center",justifyContent:"center",flexShrink:0}}>
              <span style={{fontSize: 11,fontWeight:800,color:s.c}}>{i+1}</span>
            </div>
            <span style={{fontSize: 13,color:i===flowStep?"#E2E8F0":"#64748B"}}>{s.text}</span>
          </div>
        ))}
      </div>
      <div style={{marginTop:8,padding:"6px 10px",borderRadius:8,background:"rgba(14,165,233,.06)",fontSize: 12,color:"#0EA5E9"}}>
        {lang==="tr"?"GPT'de bu akÄ±ÅŸ 3,648 parametre ve 243 satÄ±r boyunca gerÃ§ekleÅŸir â€” aynÄ± mantÄ±k, daha fazla nÃ¶ron!":"In GPT this flow happens across 3,648 parameters and 243 lines â€” same logic, more neurons!"}
      </div>
    </div>)}

    {/* TAB 2: Mini Training Simulation */}
    {tab===2 && (<div>
      <div style={{display:"flex",gap:8,marginBottom:10}}>
        <div style={{flex:1,padding:12,borderRadius:12,background:`${ts.loss<1?"#10B981":ts.loss<5?"#F59E0B":"#EF4444"}10`,border:`1.5px solid ${ts.loss<1?"#10B981":ts.loss<5?"#F59E0B":"#EF4444"}30`,textAlign:"center",transition:"all .4s"}}>
          <div style={{fontSize: 12,color:"#64748B"}}>{lang==="tr"?"Loss (hata)":"Loss (error)"}</div>
          <div style={{fontSize: 31,fontWeight:800,color:ts.loss<1?"#10B981":ts.loss<5?"#F59E0B":"#EF4444",fontFamily:"'Fira Code',monospace"}}>{ts.loss.toFixed(1)}</div>
          <div style={{fontSize: 13,color:"#94A3B8",marginTop:2}}>{ts.label}</div>
        </div>
        <div style={{flex:1,padding:12,borderRadius:12,background:"rgba(255,255,255,0.02)"}}>
          <div style={{fontSize: 12,color:"#64748B",marginBottom:4}}>{lang === "tr" ? "Ã–ÄŸrenilen aÄŸÄ±rlÄ±klar" : "Learned weights"}</div>
          {[{l:lang==="tr"?"wâ‚ (oda)":"wâ‚ (rooms)",v:ts.w[0],c:"#0EA5E9"},{l:lang==="tr"?"wâ‚‚ (alan)":"wâ‚‚ (area)",v:ts.w[1],c:"#8B5CF6"},{l:"bias",v:ts.b,c:"#F59E0B"}].map((p,i)=>(
            <div key={i} style={{display:"flex",justifyContent:"space-between",fontSize: 15,fontFamily:"'Fira Code',monospace",marginBottom:2}}>
              <span style={{color:p.c}}>{p.l}</span>
              <span style={{color:"#E2E8F0",fontWeight:700}}>{p.v.toFixed(1)}</span>
            </div>
          ))}
        </div>
      </div>
      <div style={{fontSize: 13,color:"#64748B",marginBottom:6}}>{lang==="tr"?"Tahminler: fiyat = wâ‚Ã—oda + wâ‚‚Ã—alan + b":"Predictions: price = wâ‚Ã—rooms + wâ‚‚Ã—area + b"}</div>
      <div style={{display:"flex",gap:6,flexWrap:"wrap"}}>
        {trainData.map((d,i)=>{ const pred=ts.w[0]*d.x[0]+ts.w[1]*d.x[1]+ts.b; const err=Math.abs(pred-d.t); return (
          <div key={i} style={{flex:1,minWidth:110,padding:8,borderRadius:8,background:"rgba(255,255,255,0.02)",border:"1px solid rgba(255,255,255,0.05)"}}>
            <div style={{fontSize: 12,color:"#64748B"}}>{d.l}</div>
            <div style={{display:"flex",justifyContent:"space-between",marginTop:4}}>
              <span style={{fontSize: 14,fontFamily:"'Fira Code',monospace",color:err<1?"#10B981":"#EF4444"}}>â†’{pred.toFixed(1)}</span>
              <span style={{fontSize: 14,fontFamily:"'Fira Code',monospace",color:"#94A3B8"}}>{lang==="tr"?"hedef":"target"}:{d.t}</span>
            </div>
            <div style={{height:3,borderRadius:2,background:"rgba(255,255,255,0.05)",marginTop:4}}>
              <div style={{height:"100%",borderRadius:2,width:`${Math.max(0,100-err*8)}%`,background:err<1?"#10B981":err<5?"#F59E0B":"#EF4444",transition:"all .5s"}}/>
            </div>
          </div>
        );})}
      </div>
      <div style={{display:"flex",gap:6,marginTop:10,justifyContent:"center"}}>
        <button onClick={()=>{setTrainStep(0);setTraining(true);}} style={{padding:"6px 16px",borderRadius:8,border:"none",background:"#10B981",color:"#fff",fontSize: 14,fontWeight:700,cursor:"pointer",fontFamily:"inherit"}}>{lang === "tr" ? "â–¶ EÄŸitimi BaÅŸlat" : "â–¶ Start Training"}</button>
        <button onClick={()=>setTraining(false)} style={{padding:"6px 10px",borderRadius:8,border:"1px solid rgba(255,255,255,.1)",background:"transparent",color:"#94A3B8",fontSize: 14,cursor:"pointer",fontFamily:"inherit"}}>â¸</button>
        <input type="range" min={0} max={3} value={trainStep} onChange={e=>{setTraining(false);setTrainStep(+e.target.value);}} style={{flex:1,accentColor:"#10B981"}}/>
      </div>
      <div style={{marginTop:8,padding:"6px 10px",borderRadius:8,background:"rgba(16,185,129,.06)",fontSize: 12,color:"#10B981"}}>
        {lang==="tr"?"Loss 12.5 â†’ 0.1 dÃ¼ÅŸtÃ¼! Model ev fiyatÄ±nÄ± doÄŸru tahmin etmeyi Ã–ÄRENDÄ°. GPT'de aynÄ± mantÄ±k â€” ama harf tahmin ediyor.":"Loss dropped 12.5 â†’ 0.1! The model LEARNED to predict house prices correctly. Same logic in GPT â€” but predicting characters."}
      </div>
    </div>)}
  </VizBox>);
};

const LangModelConceptViz = () => {
  const [tab, setTab] = useState(0);

  // Tab 0: Autoregressive generation step-by-step
  const [genStep, setGenStep] = useState(0);
  const [genAuto, setGenAuto] = useState(false);
  const genSteps = [
    { ctx: "BOS", probs: [{ch:"e",p:8},{ch:"a",p:7},{ch:"m",p:5},{ch:"s",p:4}], pick: "e", reason: lang==="tr"?"BOS'tan sonra en olasÄ± baÅŸlangÄ±Ã§ harfi":"Most likely starting letter after BOS" },
    { ctx: "BOS â†’ e", probs: [{ch:"m",p:14},{ch:"l",p:12},{ch:"v",p:6},{ch:"d",p:5}], pick: "m", reason: lang==="tr"?"Ä°ngilizce isimlerde 'em' Ã§ok yaygÄ±n (emma, emily)":"'em' is very common in English names (emma, emily)" },
    { ctx: "... â†’ e â†’ m", probs: [{ch:"m",p:18},{ch:"i",p:10},{ch:"a",p:8},{ch:"e",p:5}], pick: "m", reason: lang==="tr"?"Ã‡ift 'mm' kalÄ±bÄ± (emma, emmy, summer)":"Double 'mm' pattern (emma, emmy, summer)" },
    { ctx: "... â†’ m â†’ m", probs: [{ch:"a",p:22},{ch:"y",p:12},{ch:"i",p:8},{ch:"e",p:6}], pick: "a", reason: lang==="tr"?"'mma' bitiÅŸi Ã§ok gÃ¼Ã§lÃ¼ (emma, gemma)":"'mma' ending is very strong (emma, gemma)" },
    { ctx: "... â†’ m â†’ a", probs: [{ch:"EOS",p:30},{ch:"r",p:10},{ch:"n",p:8},{ch:"l",p:5}], pick: "EOS", reason: lang==="tr"?"4-harfli isim tamamlandÄ± â€” model durmasÄ±nÄ± biliyor":"4-letter name complete â€” the model knows when to stop" },
  ];
  const gs = genSteps[genStep];
  const builtName = ["","e","em","emm","emma","emmaâœ“"][genStep+1] || "";
  useEffect(() => {
    if (!genAuto) return;
    const t = setInterval(() => setGenStep(s => { if (s >= genSteps.length-1) { setGenAuto(false); return s; } return s+1; }), 1500);
    return () => clearInterval(t);
  }, [genAuto]);

  // Tab 1: Phone autocomplete interactive
  const [typed, setTyped] = useState("");
  const autocompleteDB = {
    "": [{w:"bugÃ¼n",p:15},{w:"merhaba",p:12},{w:"nasÄ±l",p:10},{w:"teÅŸekkÃ¼r",p:8}],
    "b": [{w:"bugÃ¼n",p:30},{w:"ben",p:20},{w:"bir",p:18},{w:"bence",p:10}],
    "bu": [{w:"bugÃ¼n",p:45},{w:"burasÄ±",p:15},{w:"bu",p:12},{w:"burada",p:8}],
    "bug": [{w:"bugÃ¼n",p:65},{w:"buÄŸday",p:10},{w:"bugÃ¼ne",p:8},{w:"bug",p:5}],
    "bugÃ¼": [{w:"bugÃ¼n",p:80},{w:"bugÃ¼ne",p:10},{w:"bugÃ¼nkÃ¼",p:5},{w:"bugÃ¼nlÃ¼k",p:3}],
    "bugÃ¼n": [{w:"hava",p:25},{w:"Ã§ok",p:18},{w:"ne",p:15},{w:"gÃ¼zel",p:12}],
  };
  const suggestions = autocompleteDB[typed.toLowerCase()] || [{w:"...",p:0},{w:"...",p:0},{w:"...",p:0},{w:"...",p:0}];

  // Tab 2: emma training walkthrough
  const [trainPair, setTrainPair] = useState(0);
  const pairs = [
    { input: "BOS", target: "e", pBefore: 3.6, pAfter: 8.2, color: "#0EA5E9" },
    { input: "e", target: "m", pBefore: 2.1, pAfter: 14.5, color: "#8B5CF6" },
    { input: "m", target: "m", pBefore: 5.0, pAfter: 18.0, color: "#10B981" },
    { input: "m", target: "a", pBefore: 7.2, pAfter: 22.3, color: "#F59E0B" },
    { input: "a", target: "EOS", pBefore: 4.0, pAfter: 30.1, color: "#EC4899" },
  ];
  const tp = pairs[trainPair];

  const tabs = [{l:lang === "tr" ? "ğŸ² Autoregressive Ãœretim" : "ğŸ² Autoregressive Generation",c:"#10B981"},{l:lang === "tr" ? "ğŸ“± Telefon Analojisi" : "ğŸ“± Phone Analogy",c:"#8B5CF6"},{l:lang === "tr" ? "ğŸ“š 'emma' EÄŸitimi" : "ğŸ“š 'emma' Training",c:"#F59E0B"}];

  return (<VizBox title={lang === "tr" ? "Dil Modeli â€” Ä°nteraktif KeÅŸif" : "Language Model â€” Interactive Exploration"} color="#8B5CF6">
    <div style={{display:"flex",gap:4,marginBottom:12}}>
      {tabs.map((t,i)=>(<button key={i} onClick={()=>setTab(i)} style={{flex:1,padding:"6px 6px",borderRadius:8,border:"none",cursor:"pointer",background:tab===i?`${t.c}20`:"rgba(255,255,255,0.03)",color:tab===i?t.c:"#64748B",fontSize: 12,fontWeight:700,fontFamily:"inherit",borderBottom:tab===i?`2px solid ${t.c}`:"2px solid transparent",transition:"all .3s"}}>{t.l}</button>))}
    </div>

    {/* TAB 0: Autoregressive Generation */}
    {tab===0 && (<div>
      {/* Built name display */}
      <div style={{textAlign:"center",marginBottom:12}}>
        <div style={{fontSize: 12,color:"#64748B",marginBottom:4}}>{lang === "tr" ? "OluÅŸan isim:" : "Generated name:"}</div>
        <div style={{display:"inline-flex",gap:2}}>
          {(builtName||" ").split("").map((ch,i)=>(
            <div key={i} style={{width:28,height:32,borderRadius:6,display:"flex",alignItems:"center",justifyContent:"center",fontSize: 19,fontWeight:800,fontFamily:"'Fira Code',monospace",color:ch==="âœ“"?"#10B981":"#E2E8F0",background:ch==="âœ“"?"rgba(16,185,129,.15)":"rgba(14,165,233,.1)",border:`1.5px solid ${ch==="âœ“"?"#10B981":"#0EA5E930"}`}}>{ch}</div>
          ))}
        </div>
      </div>
      {/* Current step */}
      <div style={{padding:12,borderRadius:12,background:"rgba(16,185,129,.04)",border:"1px solid rgba(16,185,129,.15)",marginBottom:10}}>
        <div style={{display:"flex",gap:12,alignItems:"center",flexWrap:"wrap"}}>
          <div style={{minWidth:100}}>
            <div style={{fontSize: 11,color:"#64748B"}}>{lang === "tr" ? "BaÄŸlam" : "Context"}</div>
            <div style={{fontSize: 15,fontFamily:"'Fira Code',monospace",fontWeight:700,color:"#0EA5E9",marginTop:2}}>{gs.ctx}</div>
          </div>
          <div style={{fontSize: 19,color:"#64748B"}}>â†’</div>
          <div style={{flex:1}}>
            <div style={{fontSize: 11,color:"#64748B",marginBottom:4}}>{lang==="tr"?"OlasÄ±lÄ±k daÄŸÄ±lÄ±mÄ± (28 token Ã¼zerinde, ilk 4):":"Probability distribution (over 28 tokens, top 4):"}</div>
            <div style={{display:"flex",gap:4,flexWrap:"wrap"}}>
              {gs.probs.map((pr,i)=>(
                <div key={i} style={{display:"flex",alignItems:"center",gap:4,padding:"3px 8px",borderRadius:6,background:pr.ch===gs.pick?"rgba(16,185,129,.15)":"rgba(255,255,255,0.03)",border:pr.ch===gs.pick?"1.5px solid #10B981":"1px solid rgba(255,255,255,0.05)"}}>
                  <span style={{fontSize: 15,fontFamily:"'Fira Code',monospace",fontWeight:pr.ch===gs.pick?800:400,color:pr.ch===gs.pick?"#10B981":"#94A3B8"}}>{pr.ch}</span>
                  <div style={{width:40,height:8,background:"rgba(255,255,255,0.05)",borderRadius:4,overflow:"hidden"}}>
                    <div style={{height:"100%",width:`${pr.p*3}%`,borderRadius:4,background:pr.ch===gs.pick?"#10B981":"#64748B",transition:"width .5s"}}/>
                  </div>
                  <span style={{fontSize: 11,fontFamily:"'Fira Code',monospace",color:"#64748B"}}>{pr.p}%</span>
                </div>
              ))}
            </div>
          </div>
        </div>
        <div style={{marginTop:8,padding:"4px 8px",borderRadius:6,background:"rgba(16,185,129,.06)",fontSize: 12,color:"#10B981"}}>
          {lang==="tr"?"âœ“ SeÃ§ilen:":"âœ“ Selected:"} <strong>{gs.pick}</strong> â€” {gs.reason}
        </div>
      </div>
      <div style={{display:"flex",gap:6,justifyContent:"center"}}>
        <button onClick={()=>{setGenStep(0);setGenAuto(true);}} style={{padding:"5px 14px",borderRadius:8,border:"none",background:"#10B981",color:"#fff",fontSize: 14,fontWeight:700,cursor:"pointer",fontFamily:"inherit"}}>{lang === "tr" ? "â–¶ 'emma' Ãœret" : "â–¶ Generate 'emma'"}</button>
        <button onClick={()=>setGenStep(s=>Math.max(0,s-1))} style={{padding:"5px 10px",borderRadius:8,border:"1px solid rgba(255,255,255,.1)",background:"transparent",color:"#94A3B8",fontSize: 14,cursor:"pointer",fontFamily:"inherit"}}>â†</button>
        <button onClick={()=>setGenStep(s=>Math.min(genSteps.length-1,s+1))} style={{padding:"5px 10px",borderRadius:8,border:"1px solid rgba(255,255,255,.1)",background:"transparent",color:"#94A3B8",fontSize: 14,cursor:"pointer",fontFamily:"inherit"}}>â†’</button>
        <button onClick={()=>setGenAuto(false)} style={{padding:"5px 10px",borderRadius:8,border:"1px solid rgba(255,255,255,.1)",background:"transparent",color:"#94A3B8",fontSize: 14,cursor:"pointer",fontFamily:"inherit"}}>â¸</button>
      </div>
    </div>)}

    {/* TAB 1: Phone Autocomplete Analogy */}
    {tab===1 && (<div>
      <div style={{padding:14,borderRadius:12,background:"rgba(139,92,246,.04)",border:"1px solid rgba(139,92,246,.15)",marginBottom:12}}>
        <div style={{display:"flex",alignItems:"center",gap:8,marginBottom:10}}>
          <span style={{fontSize: 21}}>ğŸ“±</span>
          <span style={{fontSize: 14,color:"#8B5CF6",fontWeight:700}}>{lang==="tr"?"Telefon Klavyesi SimÃ¼lasyonu":"Phone Keyboard Simulation"}</span>
          <span style={{fontSize: 12,color:"#64748B"}}>{lang==="tr"?"â€” harf harf yazÄ±n, Ã¶nerileri izleyin":"â€” type letter by letter, watch suggestions"}</span>
        </div>
        {/* Input display */}
        <div style={{display:"flex",alignItems:"center",gap:4,marginBottom:10}}>
          <div style={{flex:1,padding:"8px 12px",borderRadius:8,background:"#0D1117",border:"1px solid rgba(255,255,255,0.1)",fontFamily:"'Fira Code',monospace",fontSize: 17,color:"#E2E8F0",minHeight:20}}>
            {typed || <span style={{color:"#475569"}}>{lang==="tr"?"yazmaya baÅŸlayÄ±n...":"start typing..."}</span>}
            <span style={{color:"#8B5CF6",animation:"blink 1s infinite"}}>|</span>
          </div>
          <button onClick={()=>setTyped("")} style={{padding:"8px 12px",borderRadius:8,border:"1px solid rgba(255,255,255,.1)",background:"transparent",color:"#94A3B8",fontSize: 13,cursor:"pointer",fontFamily:"inherit"}}>{lang==="tr"?"Sil":"Clear"}</button>
        </div>
        {/* Letter buttons */}
        <div style={{display:"flex",gap:3,flexWrap:"wrap",marginBottom:10}}>
          {["b","u","g","Ã¼","n"," ","h","a","v","c","o","k"].map((ch,i)=>(
            <button key={i} onClick={()=>{const nxt = typed+ch; if(autocompleteDB[nxt.toLowerCase()]) setTyped(nxt); else setTyped(nxt.slice(0,-1));}} style={{
              padding:"6px 10px",borderRadius:6,border:"1px solid rgba(255,255,255,.08)",background:"rgba(255,255,255,0.04)",
              color:"#E2E8F0",fontSize: 15,fontFamily:"'Fira Code',monospace",fontWeight:600,cursor:"pointer",minWidth:28,textAlign:"center"
            }}>{ch===" "?"âµ":ch}</button>
          ))}
        </div>
        {/* Suggestions */}
        <div style={{fontSize: 12,color:"#64748B",marginBottom:4}}>{lang === "tr" ? "ğŸ“Š Ã–neriler (olasÄ±lÄ±k sÄ±rasÄ±):" : "ğŸ“Š Suggestions (by probability):"}</div>
        <div style={{display:"flex",gap:4,flexWrap:"wrap"}}>
          {suggestions.map((s,i)=>(
            <div key={i} onClick={()=>{ if(s.w!=="..." && autocompleteDB[s.w.toLowerCase()]) setTyped(s.w); }} style={{
              padding:"6px 10px",borderRadius:8,cursor:s.w==="..."?"default":"pointer",
              background:i===0?"rgba(139,92,246,.15)":"rgba(255,255,255,0.03)",
              border:`1px solid ${i===0?"#8B5CF6":"rgba(255,255,255,0.05)"}`,
              display:"flex",alignItems:"center",gap:6
            }}>
              <span style={{fontSize: 14,fontFamily:"'Fira Code',monospace",fontWeight:i===0?700:400,color:i===0?"#8B5CF6":"#94A3B8"}}>{s.w}</span>
              {s.p>0&&<span style={{fontSize: 11,color:"#64748B"}}>{s.p}%</span>}
            </div>
          ))}
        </div>
      </div>
      <div style={{padding:"8px 12px",borderRadius:8,background:"rgba(139,92,246,.06)",fontSize: 13,color:"#8B5CF6",lineHeight:1.5}}>
        {lang==="tr"?<><strong>BaÄŸlantÄ±:</strong> Telefonunuzun otomatik tamamlamasÄ± = dil modeli! Her ikisi de Ã¶nceki harflere bakarak sonraki olasÄ± devamlarÄ± sÄ±ralar. GPT aynÄ± mantÄ±kta Ã§alÄ±ÅŸÄ±r â€” sadece 175 milyar parametreyle ve tÃ¼m internet verisiyle eÄŸitilmiÅŸtir.</>:<><strong>Connection:</strong> Your phone's autocomplete = language model! Both rank possible continuations by looking at previous letters. GPT works the same way â€” just with 175 billion parameters and trained on all internet data.</>}
      </div>
    </div>)}

    {/* TAB 2: 'emma' Training Walkthrough */}
    {tab===2 && (<div>
      <div style={{fontSize: 13,color:"#94A3B8",marginBottom:8,textAlign:"center"}}>
        {lang==="tr"?<>Model <strong style={{color:"#F59E0B"}}>"emma"</strong> kelimesinden nasÄ±l Ã¶ÄŸrenir? Her harf Ã§ifti bir eÄŸitim Ã¶rneÄŸi:</>:<>How does the model learn from <strong style={{color:"#F59E0B"}}>"emma"</strong>? Each letter pair is a training example:</>}
      </div>
      {/* Pair selector */}
      <div style={{display:"flex",gap:3,justifyContent:"center",marginBottom:10}}>
        {pairs.map((p,i)=>(
          <button key={i} onClick={()=>setTrainPair(i)} style={{
            padding:"6px 10px",borderRadius:8,border:`1.5px solid ${trainPair===i?p.color:`${p.color}30`}`,
            background:trainPair===i?`${p.color}18`:"transparent",
            color:trainPair===i?p.color:"#64748B",fontSize: 14,fontFamily:"'Fira Code',monospace",fontWeight:700,cursor:"pointer"
          }}>{p.input}â†’{p.target}</button>
        ))}
      </div>
      {/* Current pair detail */}
      <div style={{padding:14,borderRadius:12,background:`${tp.color}08`,border:`1.5px solid ${tp.color}20`,transition:"all .3s"}}>
        <div style={{display:"flex",gap:16,alignItems:"center",justifyContent:"center",flexWrap:"wrap",marginBottom:10}}>
          <div style={{textAlign:"center"}}>
            <div style={{fontSize: 11,color:"#64748B"}}>{lang==="tr"?"Girdi":"Input"}</div>
            <div style={{fontSize: 23,fontWeight:800,fontFamily:"'Fira Code',monospace",color:tp.color}}>{tp.input}</div>
          </div>
          <div style={{fontSize: 23,color:"#64748B"}}>â†’ model â†’</div>
          <div style={{textAlign:"center"}}>
            <div style={{fontSize: 11,color:"#64748B"}}>{lang==="tr"?"Hedef":"Target"}</div>
            <div style={{fontSize: 23,fontWeight:800,fontFamily:"'Fira Code',monospace",color:"#10B981"}}>{tp.target}</div>
          </div>
        </div>
        {/* Before/After training comparison */}
        <div style={{display:"flex",gap:8}}>
          <div style={{flex:1,padding:8,borderRadius:8,background:"rgba(239,68,68,.06)",textAlign:"center"}}>
            <div style={{fontSize: 11,color:"#EF4444",fontWeight:600}}>{lang === "tr" ? "EÄÄ°TÄ°M Ã–NCESÄ°" : "BEFORE TRAINING"}</div>
            <div style={{fontSize: 12,color:"#64748B",marginTop:2}}>P('{tp.target}' | '{tp.input}')</div>
            <div style={{fontSize: 23,fontWeight:800,fontFamily:"'Fira Code',monospace",color:"#EF4444"}}>{tp.pBefore}%</div>
            <div style={{height:6,borderRadius:3,background:"rgba(255,255,255,0.05)",marginTop:4}}>
              <div style={{height:"100%",borderRadius:3,width:`${tp.pBefore}%`,background:"#EF4444",transition:"width .5s"}}/>
            </div>
          </div>
          <div style={{display:"flex",alignItems:"center",fontSize: 23,color:"#F59E0B"}}>â†’</div>
          <div style={{flex:1,padding:8,borderRadius:8,background:"rgba(16,185,129,.06)",textAlign:"center"}}>
            <div style={{fontSize: 11,color:"#10B981",fontWeight:600}}>{lang === "tr" ? "EÄÄ°TÄ°M SONRASI" : "AFTER TRAINING"}</div>
            <div style={{fontSize: 12,color:"#64748B",marginTop:2}}>P('{tp.target}' | '{tp.input}')</div>
            <div style={{fontSize: 23,fontWeight:800,fontFamily:"'Fira Code',monospace",color:"#10B981"}}>{tp.pAfter}%</div>
            <div style={{height:6,borderRadius:3,background:"rgba(255,255,255,0.05)",marginTop:4}}>
              <div style={{height:"100%",borderRadius:3,width:`${tp.pAfter}%`,background:"#10B981",transition:"width .5s"}}/>
            </div>
          </div>
        </div>
        <div style={{marginTop:8,fontSize: 12,color:"#64748B",textAlign:"center"}}>
          Loss: -log({tp.pBefore/100}) = {(-Math.log(tp.pBefore/100)).toFixed(2)} â†’ -log({tp.pAfter/100}) = {(-Math.log(tp.pAfter/100)).toFixed(2)}
          <span style={{color:"#10B981",fontWeight:700}}> â†“{((-Math.log(tp.pBefore/100))-(-Math.log(tp.pAfter/100))).toFixed(2)}</span>
        </div>
      </div>
      <div style={{marginTop:8,padding:"6px 10px",borderRadius:8,background:"rgba(245,158,11,.06)",fontSize: 12,color:"#F59E0B"}}>
        {lang==="tr"?'"emma" = 5 eÄŸitim Ã§ifti. 32K isim Ã— ~6 harf = ~192K Ã§ift. Model tÃ¼m bu Ã§iftlerden Ä°ngilizce isim kalÄ±plarÄ±nÄ± Ã¶ÄŸrenir!':'"emma" = 5 training pairs. 32K names Ã— ~6 chars = ~192K pairs. The model learns English name patterns from all these pairs!'}
      </div>
    </div>)}
  </VizBox>);
};

const VectorConceptViz = () => {
  const v1=[3,4], v2=[1,5];
  const dot=v1[0]*v2[0]+v1[1]*v2[1];
  const mag1=Math.sqrt(v1[0]**2+v1[1]**2);
  const mag2=Math.sqrt(v2[0]**2+v2[1]**2);
  const cos=(dot/(mag1*mag2));
  return (<VizBox title={lang === "tr" ? "VektÃ¶r â€” YÃ¶n + BÃ¼yÃ¼klÃ¼k" : "Vector â€” Direction + Magnitude"} color="#8B5CF6">
    <div style={{display:"flex",gap:20,flexWrap:"wrap",alignItems:"flex-start"}}>
      <svg viewBox="-1 -1 8 8" style={{width:180,height:180,background:VB.card,borderRadius:10}}>
        {/* Grid */}
        {[0,1,2,3,4,5,6].map(i=>(<g key={i}><line x1={i} y1="0" x2={i} y2="7" stroke="#ffffff08" strokeWidth="0.05"/><line x1="0" y1={i} x2="7" y2={i} stroke="#ffffff08" strokeWidth="0.05"/></g>))}
        {/* Axes */}
        <line x1="0" y1="0" x2="7" y2="0" stroke="#ffffff15" strokeWidth="0.05"/>
        <line x1="0" y1="0" x2="0" y2="7" stroke="#ffffff15" strokeWidth="0.05"/>
        {/* Vectors */}
        <line x1="0" y1="0" x2={v1[0]} y2={v1[1]} stroke="#0EA5E9" strokeWidth="0.15"/>
        <circle cx={v1[0]} cy={v1[1]} r="0.2" fill="#0EA5E9"/>
        <text x={v1[0]+.3} y={v1[1]} fill="#0EA5E9" fontSize="0.7" fontWeight="600">a=[3,4]</text>
        <line x1="0" y1="0" x2={v2[0]} y2={v2[1]} stroke="#EC4899" strokeWidth="0.15"/>
        <circle cx={v2[0]} cy={v2[1]} r="0.2" fill="#EC4899"/>
        <text x={v2[0]+.3} y={v2[1]} fill="#EC4899" fontSize="0.7" fontWeight="600">b=[1,5]</text>
      </svg>
      <div style={{flex:1,minWidth:220}}>
        <div style={{display:"grid",gridTemplateColumns:"1fr 1fr",gap:6}}>
          <StatBox value={`[${v1}]`} label={lang==="tr"?"VektÃ¶r a":"Vector a"} color="#0EA5E9"/>
          <StatBox value={`[${v2}]`} label={lang==="tr"?"VektÃ¶r b":"Vector b"} color="#EC4899"/>
          <StatBox value={dot.toString()} label="Dot Product aÂ·b" color="#F59E0B"/>
          <StatBox value={cos.toFixed(2)} label={lang==="tr"?"Cosine Benzerlik":"Cosine Similarity"} color="#10B981"/>
        </div>
        <div style={{marginTop:8,fontSize: 13,color:VB.muted,lineHeight:1.5}}>
          <strong style={{color:"#F59E0B"}}>Dot product:</strong> aÂ·b = 3Ã—1 + 4Ã—5 = {dot}<br/>
          <strong style={{color:"#10B981"}}>Cosine:</strong> aÂ·b / (|a|Ã—|b|) = {cos.toFixed(2)}<br/>
          <span style={{fontSize: 12,color:VB.dim}}>{lang==="tr"?"Embedding'de her token = yÃ¼ksek boyutlu vektÃ¶r. Benzer tokenler yakÄ±n yÃ¶nlere iÅŸaret eder.":"In embeddings, each token = high-dimensional vector. Similar tokens point in similar directions."}</span>
        </div>
      </div>
    </div>
  </VizBox>);
};

const MatrixMulViz = () => {
  const W=[[1,2],[3,4],[5,6]], x=[10,20];
  const y=W.map(r=>r[0]*x[0]+r[1]*x[1]);
  const [hi,setHi]=useState(-1);
  return (<VizBox title={lang === "tr" ? "Matris Ã‡arpÄ±mÄ± â€” linear(x, W)" : "Matrix Multiplication â€” linear(x, W)"} color="#F59E0B">
    <div style={{display:"flex",gap:16,alignItems:"center",justifyContent:"center",flexWrap:"wrap"}}>
      <div style={{textAlign:"center"}}>
        <div style={{fontSize: 12,color:VB.muted,marginBottom:4}}>W [3Ã—2]</div>
        <div style={{display:"grid",gridTemplateColumns:"repeat(2,1fr)",gap:2}}>
          {W.flat().map((v,i)=>{
            const r=Math.floor(i/2);
            return <div key={i} style={{width:36,height:28,display:"flex",alignItems:"center",justifyContent:"center",fontSize: 15,fontFamily:"'Fira Code',monospace",borderRadius:4,background:hi===r?`#F59E0B20`:"rgba(255,255,255,0.03)",color:hi===r?"#F59E0B":VB.txt,fontWeight:hi===r?700:400,transition:"all .2s",cursor:"pointer"}} onMouseEnter={()=>setHi(r)} onMouseLeave={()=>setHi(-1)}>{v}</div>;
          })}
        </div>
      </div>
      <div style={{fontSize: 19,color:VB.dim}}>Ã—</div>
      <div style={{textAlign:"center"}}>
        <div style={{fontSize: 12,color:VB.muted,marginBottom:4}}>x [2]</div>
        {x.map((v,i)=>(<div key={i} style={{width:36,height:28,display:"flex",alignItems:"center",justifyContent:"center",fontSize: 15,fontFamily:"'Fira Code',monospace",borderRadius:4,background:"rgba(14,165,233,.1)",color:"#0EA5E9",marginBottom:2}}>{v}</div>))}
      </div>
      <div style={{fontSize: 19,color:VB.dim}}>=</div>
      <div style={{textAlign:"center"}}>
        <div style={{fontSize: 12,color:VB.muted,marginBottom:4}}>y [3]</div>
        {y.map((v,i)=>(<div key={i} style={{width:44,height:28,display:"flex",alignItems:"center",justifyContent:"center",fontSize: 15,fontFamily:"'Fira Code',monospace",borderRadius:4,fontWeight:700,background:hi===i?"rgba(16,185,129,.2)":"rgba(16,185,129,.06)",color:hi===i?"#10B981":VB.txt,transition:"all .2s",cursor:"pointer"}} onMouseEnter={()=>setHi(i)} onMouseLeave={()=>setHi(-1)}>{v}</div>))}
      </div>
    </div>
    {hi>=0 && <div style={{marginTop:8,textAlign:"center",padding:"6px 12px",background:VB.card,borderRadius:8,fontSize: 14,fontFamily:"'Fira Code',monospace",color:"#F59E0B",transition:"all .3s"}}>
      y[{hi}] = {W[hi][0]}Ã—{x[0]} + {W[hi][1]}Ã—{x[1]} = {y[hi]}
    </div>}
    <div style={{marginTop:6,textAlign:"center",fontSize: 12,color:VB.dim}}>Her satÄ±r = bir dot product. Transformer'da Q,K,V,O,fc1,fc2 hep bu iÅŸlem.</div>
  </VizBox>);
};

const DerivativeViz = () => {
  const pts=[];
  for(let x=-3;x<=3;x+=0.2) pts.push({x,y:x*x});
  const xT=1.5, yT=xT*xT, slope=2*xT;
  return (<VizBox title={lang === "tr" ? "TÃ¼rev â€” EÄŸim = DeÄŸiÅŸim HÄ±zÄ±" : "Derivative â€” Slope = Rate of Change"} color="#EC4899">
    <div style={{display:"flex",gap:20,flexWrap:"wrap",alignItems:"flex-start"}}>
      <svg viewBox="-4 -1 8 11" style={{width:220,height:200,background:VB.card,borderRadius:10}}>
        <line x1="-4" y1="0" x2="4" y2="0" stroke="#ffffff10" strokeWidth="0.05"/>
        <line x1="0" y1="-1" x2="0" y2="10" stroke="#ffffff10" strokeWidth="0.05"/>
        <polyline points={pts.map(p=>`${p.x},${p.y}`).join(" ")} fill="none" stroke="#8B5CF6" strokeWidth="0.1"/>
        {/* Tangent line */}
        <line x1={xT-1.5} y1={yT-slope*1.5} x2={xT+1.5} y2={yT+slope*1.5} stroke="#EC4899" strokeWidth="0.08" strokeDasharray="0.2,0.1"/>
        <circle cx={xT} cy={yT} r="0.15" fill="#EC4899"/>
        <text x={xT+.3} y={yT-.3} fill="#EC4899" fontSize="0.6">x={xT}, eÄŸim={slope}</text>
        <text x="1" y="9.5" fill="#8B5CF6" fontSize="0.5">f(x) = xÂ²</text>
      </svg>
      <div style={{flex:1,minWidth:200}}>
        <div style={{display:"flex",flexDirection:"column",gap:6}}>
          {[
            {eq:"f(x) = xÂ²",res:"f'(x) = 2x",n:"Kare fonksiyon",c:"#8B5CF6"},
            {eq:"f(x) = log(x)",res:"f'(x) = 1/x",n:"Loss'ta kullanÄ±lÄ±r",c:"#10B981"},
            {eq:"f(x) = eË£",res:"f'(x) = eË£",n:"Softmax'ta kullanÄ±lÄ±r",c:"#F59E0B"},
            {eq:"f(x) = max(0,x)",res:"f'(x) = (x>0?1:0)",n:"ReLU",c:"#EC4899"},
          ].map((d,i)=>(
            <div key={i} style={{display:"flex",alignItems:"center",gap:8,padding:"5px 10px",borderRadius:6,background:`${d.c}08`}}>
              <span style={{fontSize: 13,fontFamily:"'Fira Code',monospace",color:VB.txt,width:90}}>{d.eq}</span>
              <span style={{fontSize: 13,color:VB.dim}}>â†’</span>
              <span style={{fontSize: 13,fontFamily:"'Fira Code',monospace",color:d.c,fontWeight:600}}>{d.res}</span>
              <span style={{fontSize: 11,color:VB.dim}}>{d.n}</span>
            </div>
          ))}
        </div>
        <div style={{marginTop:8,fontSize: 12,color:VB.dim}}>TÃ¼rev = "bu parametreyi birazcÄ±k deÄŸiÅŸtirirsem loss ne kadar deÄŸiÅŸir?"</div>
      </div>
    </div>
  </VizBox>);
};

const TopoSortViz = () => {
  const [step,setStep]=useState(0);
  const order=["a","b","c","d=aÃ—b","e=d+c","L=f(e)"];
  const revOrder=[...order].reverse();
  useEffect(()=>{const t=setInterval(()=>setStep(s=>(s+1)%7),900);return()=>clearInterval(t);},[]);
  return (<VizBox title="Topological Sort â†’ Reverse = Backward Pass" color="#F59E0B">
    <div style={{display:"flex",gap:20,flexWrap:"wrap"}}>
      <div>
        <div style={{fontSize: 13,fontWeight:600,color:"#0EA5E9",marginBottom:6}}>Forward (Topolojik SÄ±ra)</div>
        <div style={{display:"flex",gap:3,flexWrap:"wrap"}}>{order.map((n,i)=>(
          <div key={i} style={{padding:"6px 10px",borderRadius:6,fontSize: 13,fontFamily:"'Fira Code',monospace",background:i<step?`rgba(14,165,233,${0.15+i*0.1})`:"rgba(255,255,255,0.03)",color:i<step?"#0EA5E9":VB.dim,fontWeight:i===step-1?700:400,transition:"all .3s"}}>{n}</div>
        ))}</div>
      </div>
      <div>
        <div style={{fontSize: 13,fontWeight:600,color:"#EF4444",marginBottom:6}}>Backward (Ters SÄ±ra)</div>
        <div style={{display:"flex",gap:3,flexWrap:"wrap"}}>{revOrder.map((n,i)=>(
          <div key={i} style={{padding:"6px 10px",borderRadius:6,fontSize: 13,fontFamily:"'Fira Code',monospace",background:i<step?`rgba(239,68,68,${0.15+i*0.08})`:"rgba(255,255,255,0.03)",color:i<step?"#EF4444":VB.dim,fontWeight:i===step-1?700:400,transition:"all .3s"}}>{n}</div>
        ))}</div>
      </div>
    </div>
    <div style={{marginTop:8,fontSize: 12,color:VB.dim}}>Post-order DFS â†’ topo sort â†’ reversed â†’ chain rule her dÃ¼ÄŸÃ¼mde uygulanÄ±r</div>
  </VizBox>);
};

const RnnToAttnViz = () => {
  const items=[
    {l:"RNN (2014)",d:"SÄ±ralÄ± iÅŸlem. Uzun mesafe = gradient vanishing",c:"#EF4444",icon:"ğŸ”—"},
    {l:"LSTM/GRU",d:"Gate mekanizmasÄ±. Daha iyi ama hala sÄ±ralÄ±",c:"#F59E0B",icon:"ğŸšª"},
    {l:"Attention (2017)",d:"Her token herkese bakabilir! Paralel.",c:"#10B981",icon:"ğŸ”"},
    {l:"GPT (2018+)",d:"Sadece attention + MLP. Ã–lÃ§eklenebilir!",c:"#0EA5E9",icon:"ğŸš€"},
  ];
  return (<VizBox title="RNN'den Attention'a â€” Tarihsel Evrim" color="#10B981">
    <div style={{display:"flex",alignItems:"center",gap:6,justifyContent:"center",flexWrap:"wrap"}}>
      {items.map((it,i)=>(
        <div key={i} style={{display:"flex",alignItems:"center",gap:6}}>
          <div style={{padding:"10px 14px",borderRadius:10,textAlign:"center",minWidth:110,background:`${it.c}0A`,border:`1.5px solid ${it.c}25`}}>
            <div style={{fontSize: 19,marginBottom:2}}>{it.icon}</div>
            <div style={{fontSize: 14,fontWeight:700,color:it.c}}>{it.l}</div>
            <div style={{fontSize: 11,color:VB.muted,marginTop:2,maxWidth:130}}>{it.d}</div>
          </div>
          {i<3&&<FlowArrow color={VB.dim}/>}
        </div>
      ))}
    </div>
  </VizBox>);
};

const DotProductViz = () => {
  const pairs=[
    {a:lang === "tr" ? "kedi" : "cat",b:lang === "tr" ? "kÃ¶pek" : "dog",sim:.85,c:"#10B981"},
    {a:lang === "tr" ? "kedi" : "cat",b:"araba",sim:.12,c:"#EF4444"},
    {a:lang === "tr" ? "kral" : "king",b:lang === "tr" ? "kraliÃ§e" : "queen",sim:.78,c:"#10B981"},
    {a:lang === "tr" ? "kral" : "king",b:"masa",sim:.05,c:"#EF4444"},
  ];
  return (<VizBox title={lang === "tr" ? "Dot Product â‰ˆ Benzerlik Ã–lÃ§Ã¼sÃ¼" : "Dot Product â‰ˆ Similarity Measure"} color="#F59E0B">
    <div style={{display:"flex",gap:16,flexWrap:"wrap",justifyContent:"center"}}>
      {pairs.map((p,i)=>(
        <div key={i} style={{padding:"8px 12px",borderRadius:8,background:VB.card,minWidth:140,textAlign:"center"}}>
          <div style={{display:"flex",justifyContent:"center",gap:6,marginBottom:6}}>
            <span style={{fontSize: 15,fontFamily:"'Fira Code',monospace",color:"#0EA5E9",fontWeight:600}}>{p.a}</span>
            <span style={{fontSize: 13,color:VB.dim}}>Â·</span>
            <span style={{fontSize: 15,fontFamily:"'Fira Code',monospace",color:"#8B5CF6",fontWeight:600}}>{p.b}</span>
          </div>
          <div style={{height:8,background:"rgba(255,255,255,0.03)",borderRadius:4,overflow:"hidden",marginBottom:4}}>
            <div style={{height:"100%",width:`${p.sim*100}%`,borderRadius:4,background:p.c}}/>
          </div>
          <div style={{fontSize: 13,fontFamily:"'Fira Code',monospace",color:p.c,fontWeight:700}}>{p.sim.toFixed(2)}</div>
        </div>
      ))}
    </div>
    <div style={{marginTop:8,textAlign:"center",fontSize: 12,color:VB.dim}}>Attention'da QÂ·K = "bu token o token'a ne kadar benzer?"</div>
  </VizBox>);
};

const NormCompareViz = () => {
  const x=[2,-1,3,0.5];
  const mean=x.reduce((a,b)=>a+b)/x.length;
  const ms=x.reduce((a,v)=>a+v*v,0)/x.length;
  const lnV=Math.sqrt(x.reduce((a,v)=>a+(v-mean)**2,0)/x.length+1e-5);
  const rmsV=Math.sqrt(ms+1e-5);
  const ln=x.map(v=>((v-mean)/lnV));
  const rms=x.map(v=>v/rmsV);
  return (<VizBox title={lang === "tr" ? "LayerNorm vs RMSNorm KarÅŸÄ±laÅŸtÄ±rma" : "LayerNorm vs RMSNorm Comparison"} color="#F59E0B">
    <div style={{display:"flex",gap:16,flexWrap:"wrap"}}>
      <div style={{flex:1,minWidth:180,padding:"8px 12px",borderRadius:8,background:"rgba(99,102,241,.06)"}}>
        <div style={{fontSize: 14,fontWeight:600,color:"#6366F1",marginBottom:4}}>LayerNorm</div>
        <div style={{fontSize: 12,fontFamily:"'Fira Code',monospace",color:VB.muted}}>1. mean Ã§Ä±kar: x - Î¼</div>
        <div style={{fontSize: 12,fontFamily:"'Fira Code',monospace",color:VB.muted}}>2. variance ile bÃ¶l: / Ïƒ</div>
        <div style={{fontSize: 12,color:VB.dim,marginTop:4}}>SonuÃ§: [{ln.map(v=>v.toFixed(2)).join(", ")}]</div>
      </div>
      <div style={{flex:1,minWidth:180,padding:"8px 12px",borderRadius:8,background:"rgba(245,158,11,.06)"}}>
        <div style={{fontSize: 14,fontWeight:600,color:"#F59E0B",marginBottom:4}}>RMSNorm â˜…</div>
        <div style={{fontSize: 12,fontFamily:"'Fira Code',monospace",color:VB.muted}}>1. RMS = âˆš(mean(xÂ²))</div>
        <div style={{fontSize: 12,fontFamily:"'Fira Code',monospace",color:VB.muted}}>2. x / RMS (mean Ã§Ä±karmak yok!)</div>
        <div style={{fontSize: 12,color:VB.dim,marginTop:4}}>SonuÃ§: [{rms.map(v=>v.toFixed(2)).join(", ")}]</div>
      </div>
    </div>
    <div style={{marginTop:6,textAlign:"center",fontSize: 12,color:VB.dim}}>Girdi: [{x.join(", ")}] â†’ RMSNorm ~%30 hÄ±zlÄ± (1 op az)</div>
  </VizBox>);
};

const ActivationViz = () => {
  const fns=[
    {n:"ReLU",f:x=>Math.max(0,x),c:"#0EA5E9"},
    {n:"ReLUÂ²",f:x=>Math.max(0,x)**2,c:"#EC4899"},
    {n:"GeLU",f:x=>0.5*x*(1+Math.tanh(Math.sqrt(2/Math.PI)*(x+0.044715*x**3))),c:"#10B981"},
  ];
  return (<VizBox title={lang === "tr" ? "Aktivasyon FonksiyonlarÄ± KarÅŸÄ±laÅŸtÄ±rma" : "Activation Functions Comparison"} color="#EC4899">
    <div style={{display:"flex",gap:12,justifyContent:"center",flexWrap:"wrap"}}>
      {fns.map((fn,fi)=>(
        <div key={fi} style={{padding:"8px 12px",borderRadius:8,background:`${fn.c}08`,minWidth:140,textAlign:"center"}}>
          <div style={{fontSize: 14,fontWeight:700,color:fn.c,marginBottom:4}}>{fn.n}</div>
          <svg viewBox="-3 -1 6 5" style={{width:120,height:80}}>
            <line x1="-3" y1="0" x2="3" y2="0" stroke="#ffffff10" strokeWidth="0.05"/>
            <line x1="0" y1="-1" x2="0" y2="4" stroke="#ffffff10" strokeWidth="0.05"/>
            <polyline points={Array.from({length:60},(_, i)=>{const x=-3+i*0.1;return `${x},${-fn.f(x)}`;}).join(" ")} fill="none" stroke={fn.c} strokeWidth="0.08" transform="scale(1,-1) translate(0,0)"/>
          </svg>
          <div style={{display:"flex",gap:8,justifyContent:"center",fontSize: 11,color:VB.muted}}>
            <span>f(-1)={fn.f(-1).toFixed(1)}</span>
            <span>f(0.5)={fn.f(0.5).toFixed(2)}</span>
            <span>f(2)={fn.f(2).toFixed(1)}</span>
          </div>
        </div>
      ))}
    </div>
    <div style={{marginTop:6,textAlign:"center",fontSize: 12,color:VB.dim}}>ReLUÂ² microGPT'de kullanÄ±lÄ±r: kÃ¼Ã§Ã¼kler daha kÃ¼Ã§Ã¼k, bÃ¼yÃ¼kler daha bÃ¼yÃ¼k â†’ sparse</div>
  </VizBox>);
};

const DimensionFlowViz = () => {
  const dims=[
    {l:"ID",d:"1 int",w:15,c:"#94A3B8"},
    {l:"Emb",d:"[16]",w:40,c:"#0EA5E9"},
    {l:"+Pos",d:"[16]",w:40,c:"#8B5CF6"},
    {l:"Norm",d:"[16]",w:40,c:"#F59E0B"},
    {l:"Q,K,V",d:"[16]",w:40,c:"#10B981"},
    {l:"4Ã—[4]",d:"heads",w:55,c:"#10B981"},
    {l:"[64]",d:"MLPâ†‘",w:70,c:"#EC4899"},
    {l:"[16]",d:"MLPâ†“",w:40,c:"#EC4899"},
    {l:"[28]",d:"logits",w:50,c:"#EF4444"},
  ];
  return (<VizBox title={lang === "tr" ? "Boyut AkÄ±ÅŸÄ± â€” Tensor Shape DeÄŸiÅŸimi" : "Dimension Flow â€” Tensor Shape Changes"} color="#0EA5E9">
    <div style={{display:"flex",alignItems:"flex-end",gap:2,justifyContent:"center",flexWrap:"wrap"}}>
      {dims.map((d,i)=>(
        <div key={i} style={{display:"flex",flexDirection:"column",alignItems:"center",gap:2}}>
          <div style={{width:Math.max(d.w*0.6,20),height:d.w,borderRadius:4,background:`${d.c}20`,border:`1px solid ${d.c}40`,display:"flex",alignItems:"center",justifyContent:"center",transition:"all .3s"}}>
            <span style={{fontSize: 11,fontFamily:"'Fira Code',monospace",color:d.c,fontWeight:600,writingMode:"vertical-rl",textOrientation:"mixed"}}>{d.d}</span>
          </div>
          <span style={{fontSize: 10,color:VB.muted,textAlign:"center"}}>{d.l}</span>
          {i<dims.length-1&&<span style={{position:"absolute"}}>â†’</span>}
        </div>
      ))}
    </div>
    <div style={{marginTop:8,display:"flex",gap:8,justifyContent:"center",flexWrap:"wrap",fontSize: 11,color:VB.dim}}>
      <span>{lang==="tr"?"GeniÅŸleme":"Expansion"}: 1 â†’ 16 â†’ 64</span>
      <span>â€¢</span>
      <span>{lang==="tr"?"Daralma":"Compression"}: 64 â†’ 16 â†’ 28</span>
      <span>â€¢</span>
      <span>{lang==="tr"?"MLP = bottleneck mimarisi":"MLP = bottleneck architecture"}</span>
    </div>
  </VizBox>);
};

const GradDescentViz = () => {
  const [step,setStep]=useState(0);
  const path=Array.from({length:15},(_, i)=>{const x=3-i*0.22;return{x,y:x*x*0.5+0.3+Math.sin(x)*0.3};});
  useEffect(()=>{const t=setInterval(()=>setStep(s=>s<14?s+1:0),600);return()=>clearInterval(t);},[]);
  return (<VizBox title={lang === "tr" ? "Gradient Descent â€” DaÄŸdan Ä°nme Analojisi" : "Gradient Descent â€” Descending a Mountain"} color="#10B981">
    <div style={{display:"flex",gap:16,alignItems:"flex-start",flexWrap:"wrap"}}>
      <svg viewBox="-1 -0.5 5 5" style={{width:220,height:180,background:VB.card,borderRadius:10}}>
        {/* Loss landscape */}
        <polyline points={path.map(p=>`${p.x+0.5},${p.y}`).join(" ")} fill="none" stroke="#8B5CF6" strokeWidth="0.06"/>
        {/* Current position */}
        {step<path.length&&<circle cx={path[step].x+0.5} cy={path[step].y} r="0.12" fill="#10B981"/>}
        {/* Arrow showing gradient direction */}
        {step<path.length-1&&step>0&&<line x1={path[step-1].x+0.5} y1={path[step-1].y} x2={path[step].x+0.5} y2={path[step].y} stroke="#10B981" strokeWidth="0.04" strokeDasharray="0.1,0.05"/>}
        <text x="0" y="4.3" fill="#8B5CF6" fontSize="0.35">{lang==="tr"?"param deÄŸeri â†’":"param value â†’"}</text>
        <text x="-0.8" y="2.5" fill="#EF4444" fontSize="0.35" transform="rotate(-90, -0.8, 2.5)">loss â†‘</text>
      </svg>
      <div style={{flex:1,minWidth:200}}>
        {[
          {s:lang==="tr"?"1. Loss hesapla":"1. Compute loss",d:"Forward pass â†’ cross-entropy",c:"#EF4444"},
          {s:lang==="tr"?"2. Gradient hesapla":"2. Compute gradient",d:lang==="tr"?"Backward â†’ âˆ‚L/âˆ‚w (eÄŸim)":"Backward â†’ âˆ‚L/âˆ‚w (slope)",c:"#F59E0B"},
          {s:lang==="tr"?"3. EÄŸim yÃ¶nÃ¼nde adÄ±m at":"3. Step in slope direction",d:"w -= lr Ã— gradient",c:"#10B981"},
          {s:lang==="tr"?"4. Tekrarla":"4. Repeat",d:lang==="tr"?"Loss yeterince dÃ¼ÅŸene kadar":"Until loss is low enough",c:"#0EA5E9"},
        ].map((item,i)=>(
          <div key={i} style={{display:"flex",gap:8,alignItems:"flex-start",padding:"4px 8px",borderRadius:6,marginBottom:4,background:`${item.c}08`}}>
            <div style={{width:18,height:18,borderRadius:"50%",background:item.c,display:"flex",alignItems:"center",justifyContent:"center",fontSize: 12,fontWeight:700,color:"#fff",flexShrink:0}}>{i+1}</div>
            <div><div style={{fontSize: 13,fontWeight:600,color:item.c}}>{item.s}</div><div style={{fontSize: 11,color:VB.dim}}>{item.d}</div></div>
          </div>
        ))}
        <div style={{marginTop:4,fontSize: 12,color:VB.dim}}>Step: {step+1}/15 â€” {lang==="tr"?"LR bÃ¼yÃ¼kse atlar, kÃ¼Ã§Ã¼kse yavaÅŸ iner":"Large LR = jumps, small LR = slow descent"}</div>
      </div>
    </div>
  </VizBox>);
};

const LrDecayViz = () => {
  const steps=20;
  const linear=Array.from({length:steps},(_, i)=>0.01*(1-i/(steps-1)));
  const cosine=Array.from({length:steps},(_, i)=>0.01*0.5*(1+Math.cos(Math.PI*i/(steps-1))));
  const mx=0.01;
  return (<VizBox title="Learning Rate Decay â€” Linear vs Cosine" color="#F59E0B">
    <div style={{display:"flex",gap:16,flexWrap:"wrap"}}>
      <svg viewBox="0 0 200 80" style={{width:300,height:120,background:VB.card,borderRadius:10}}>
        {/* Grid */}
        {[0,1,2,3].map(i=><line key={i} x1="20" y1={10+i*18} x2="190" y2={10+i*18} stroke="#ffffff06" strokeWidth="0.5"/>)}
        {/* Lines */}
        <polyline points={linear.map((v,i)=>`${20+i*(170/(steps-1))},${10+(1-v/mx)*54}`).join(" ")} fill="none" stroke="#F59E0B" strokeWidth="1.5"/>
        <polyline points={cosine.map((v,i)=>`${20+i*(170/(steps-1))},${10+(1-v/mx)*54}`).join(" ")} fill="none" stroke="#8B5CF6" strokeWidth="1.5"/>
        <text x="25" y="75" fill="#F59E0B" fontSize="5">â€” Linear</text>
        <text x="80" y="75" fill="#8B5CF6" fontSize="5">â€” Cosine</text>
        <text x="100" y="8" fill={VB.dim} fontSize="4">lr = 0.01 â†’ 0</text>
      </svg>
      <div style={{flex:1,minWidth:180}}>
        <div style={{display:"flex",flexDirection:"column",gap:6}}>
          <div style={{padding:"6px 10px",borderRadius:6,background:"rgba(245,158,11,.06)"}}>
            <div style={{fontSize: 13,fontWeight:600,color:"#F59E0B"}}>Linear Decay</div>
            <div style={{fontSize: 12,fontFamily:"'Fira Code',monospace",color:VB.muted}}>lr = lrâ‚€ Ã— (1 - step/N)</div>
            <div style={{fontSize: 11,color:VB.dim}}>{lang==="tr"?"Bu kodda kullanÄ±lan. Basit, etkili.":"Used in this code. Simple, effective."}</div>
          </div>
          <div style={{padding:"6px 10px",borderRadius:6,background:"rgba(139,92,246,.06)"}}>
            <div style={{fontSize: 13,fontWeight:600,color:"#8B5CF6"}}>Cosine Decay</div>
            <div style={{fontSize: 12,fontFamily:"'Fira Code',monospace",color:VB.muted}}>lr = lrâ‚€ Ã— Â½(1+cos(Ï€t/T))</div>
            <div style={{fontSize: 11,color:VB.dim}}>{lang==="tr"?"Production'da yaygÄ±n. Daha yumuÅŸak azalma.":"Common in production. Smoother decay."}</div>
          </div>
        </div>
      </div>
    </div>
  </VizBox>);
};

const CrossEntropyGraphViz = () => {
  const pts=[];
  for(let p=0.01;p<=1;p+=0.02) pts.push({p,loss:-Math.log(p)});
  return (<VizBox title={lang === "tr" ? "Cross-Entropy: -log(p) EÄŸrisi" : "Cross-Entropy: -log(p) Curve"} color="#EF4444">
    <div style={{display:"flex",gap:16,alignItems:"flex-start",flexWrap:"wrap"}}>
      <svg viewBox="-0.5 -0.5 6 5.5" style={{width:220,height:180,background:VB.card,borderRadius:10}}>
        <line x1="0" y1="0" x2="5.5" y2="0" stroke="#ffffff10" strokeWidth="0.03"/>
        <line x1="0" y1="0" x2="0" y2="5" stroke="#ffffff10" strokeWidth="0.03"/>
        <polyline points={pts.map(p=>`${p.p*5},${Math.min(5,p.loss)}`).join(" ")} fill="none" stroke="#EF4444" strokeWidth="0.06" transform="scale(1,-1) translate(0,-5)"/>
        <text x="2.5" y="-0.2" fill={VB.dim} fontSize="0.35" textAnchor="middle">P(target) â†’</text>
        <text x="5.2" y="4.8" fill="#10B981" fontSize="0.3">loss=0</text>
        <text x="0.1" y="0.3" fill="#EF4444" fontSize="0.3">loss=âˆ</text>
      </svg>
      <div style={{flex:1,minWidth:180}}>
        <div style={{fontSize: 13,color:VB.muted,lineHeight:1.6,marginBottom:8}}>
          <strong style={{color:"#EF4444"}}>{lang==="tr"?"Sezgi":"Intuition"}:</strong> {lang==="tr"?"P(doÄŸru token) dÃ¼ÅŸÃ¼kse â†’ model Ã§ok ÅŸaÅŸÄ±rÄ±yor â†’ loss yÃ¼ksek":"When P(correct token) is low â†’ model is very surprised â†’ high loss"}
        </div>
        <div style={{display:"flex",flexDirection:"column",gap:4}}>
          {[{p:"1.0",l:"0.00",d:lang === "tr" ? "MÃ¼kemmel tahmin" : "Perfect prediction",c:"#10B981"},
            {p:"0.5",l:"0.69",d:lang === "tr" ? "YarÄ± yarÄ±ya" : "Half & half",c:"#F59E0B"},
            {p:"0.037",l:"3.33",d:lang==="tr"?"Rastgele (1/27)":"Random (1/27)",c:"#EF4444"}
          ].map((r,i)=>(
            <div key={i} style={{display:"flex",alignItems:"center",gap:6,padding:"4px 8px",borderRadius:4,background:`${r.c}08`}}>
              <span style={{fontSize: 13,fontFamily:"'Fira Code',monospace",color:VB.txt,width:48}}>P={r.p}</span>
              <span style={{fontSize: 13,fontFamily:"'Fira Code',monospace",fontWeight:700,color:r.c,width:44}}>L={r.l}</span>
              <span style={{fontSize: 12,color:VB.dim}}>{r.d}</span>
            </div>
          ))}
        </div>
      </div>
    </div>
  </VizBox>);
};

const SamplingViz = () => {
  const probs=[0.35,0.25,0.15,0.10,0.05,0.04,0.03,0.02,0.01];
  const labels=["a","n","i","e","o","r","s","l","t"];
  return (<VizBox title={lang === "tr" ? "Ã–rnekleme Stratejileri â€” Greedy vs Top-K vs Top-P" : "Sampling Strategies â€” Greedy vs Top-K vs Top-P"} color="#6366F1">
    <div style={{display:"flex",gap:12,flexWrap:"wrap",justifyContent:"center"}}>
      {[
        {n:"Greedy",d:lang==="tr"?"Her zaman en yÃ¼ksek":"Always pick highest",k:1,c:"#0EA5E9"},
        {n:"Top-5",d:lang === 'tr' ? "En yÃ¼ksek 5'ten seÃ§" : "Pick from top 5",k:5,c:"#10B981"},
        {n:"Top-P (0.8)",d:lang === 'tr' ? "KÃ¼mÃ¼latif %80'e kadar" : "Up to cumulative 80%",k:6,c:"#F59E0B"},
        {n:lang === "tr" ? "Tam DaÄŸÄ±lÄ±m" : "Full Distribution",d:lang === "tr" ? "TÃ¼m tokenlardan" : "From all tokens",k:9,c:"#8B5CF6"},
      ].map((s,si)=>(
        <div key={si} style={{padding:"8px 10px",borderRadius:8,background:VB.card,minWidth:100}}>
          <div style={{fontSize: 13,fontWeight:700,color:s.c,marginBottom:4}}>{s.n}</div>
          {probs.map((p,i)=>(
            <div key={i} style={{display:"flex",alignItems:"center",gap:4,marginBottom:2,opacity:i<s.k?1:0.2}}>
              <span style={{fontSize: 11,fontFamily:"'Fira Code',monospace",color:VB.txt,width:10}}>{labels[i]}</span>
              <div style={{width:60,height:8,background:"rgba(255,255,255,0.03)",borderRadius:4,overflow:"hidden"}}>
                <div style={{height:"100%",width:`${p*100/.35*60}%`,borderRadius:4,background:i<s.k?s.c:`${s.c}30`}}/>
              </div>
              <span style={{fontSize: 10,fontFamily:"'Fira Code',monospace",color:VB.dim}}>{(p*100).toFixed(0)}%</span>
            </div>
          ))}
          <div style={{fontSize: 10,color:VB.dim,marginTop:4}}>{s.d}</div>
        </div>
      ))}
    </div>
  </VizBox>);
};

const WhatsMissingViz = () => {
  const items=[
    {l:"Batching",from:"1 isim/step",to:"2048/step",c:"#0EA5E9"},
    {l:"GPU Tensors",from:"scalar Value",to:"CUDA tensor",c:"#8B5CF6"},
    {l:"BPE Tokenizer",from:"karakter",to:"subword",c:"#10B981"},
    {l:"Flash Attention",from:"O(nÂ²) bellek",to:"O(n)",c:"#F59E0B"},
    {l:"Mixed Precision",from:"float64",to:"fp16/bf16",c:"#EC4899"},
    {l:"Gradient Clip",from:"yok",to:"max_norm=1",c:"#EF4444"},
  ];
  return (<VizBox title="Bu Kodda Yok â†’ Production'da Var" color="#EF4444">
    <div style={{display:"grid",gridTemplateColumns:"repeat(auto-fill,minmax(180px,1fr))",gap:6}}>
      {items.map((it,i)=>(
        <div key={i} style={{padding:"6px 10px",borderRadius:6,borderLeft:`3px solid ${it.c}`,background:`${it.c}06`}}>
          <div style={{fontSize: 13,fontWeight:700,color:it.c}}>{it.l}</div>
          <div style={{fontSize: 11,fontFamily:"'Fira Code',monospace",color:VB.muted,marginTop:2}}>
            <span style={{color:VB.dim}}>{it.from}</span> â†’ <span style={{color:it.c}}>{it.to}</span>
          </div>
        </div>
      ))}
    </div>
    <div style={{marginTop:6,textAlign:"center",fontSize: 12,color:"#10B981",fontWeight:600}}>Ama Ã§ekirdek aynÄ±: attention + MLP + residual + norm + CE + Adam</div>
  </VizBox>);
};

const WeightInitViz = () => {
  const vals=useMemo(()=>Array.from({length:80},()=>{let u=0,v=0;while(!u)u=Math.random();while(!v)v=Math.random();return 0.08*Math.sqrt(-2*Math.log(u))*Math.cos(2*Math.PI*v);}),[]);
  const mx=Math.max(...vals.map(Math.abs));
  return (<VizBox title="Gaussian Initialization â€” N(0, 0.08)" color="#8B5CF6">
    <div style={{display:"flex",gap:3,flexWrap:"wrap",justifyContent:"center"}}>
      {vals.map((v,i)=>(
        <div key={i} style={{width:12,height:24,display:"flex",alignItems:"flex-end",justifyContent:"center"}}>
          <div style={{width:10,height:`${(Math.abs(v)/mx)*24}px`,borderRadius:2,background:v>0?"rgba(14,165,233,.5)":"rgba(239,68,68,.5)"}}/>
        </div>
      ))}
    </div>
    <div style={{marginTop:6,display:"flex",gap:12,justifyContent:"center",fontSize: 12,color:VB.muted}}>
      <span><span style={{color:"#0EA5E9"}}>â– </span> pozitif</span>
      <span><span style={{color:"#EF4444"}}>â– </span> negatif</span>
      <span>std=0.08 â†’ kÃ¼Ã§Ã¼k â†’ simetri kÄ±rma</span>
    </div>
  </VizBox>);
};


// â”€â”€â”€ PEDAGOGICAL ENHANCEMENT COMPONENTS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// These components address 6 key gaps:
// 1. WhyBox - "Neden bunu yapÄ±yoruz?" motivasyonu
// 2. BridgeBox - "GeÃ§en hafta X Ã¶ÄŸrenmiÅŸtik" geÃ§iÅŸ kÃ¶prÃ¼leri 
// 3. AnalogyBox - GÃ¼nlÃ¼k hayat analojileri
// 4. StepByStep - AdÄ±m adÄ±m sayÄ±sal hesaplama
// 5. TryIt* - Ä°nteraktif "kendin dene" widgetlarÄ±
// 6. ConcreteBox - Soyut kavramlarÄ± somutlaÅŸtÄ±rma

const WhyBox = ({ children, color = "#F59E0B" }) => (
  <div style={{ margin: "14px 0", padding: "14px 18px", borderRadius: 12, background: `${color}08`, border: `1px solid ${color}20`, display: "flex", gap: 12, alignItems: "flex-start" }}>
    <div style={{ width: 32, height: 32, borderRadius: 8, background: `${color}20`, display: "flex", alignItems: "center", justifyContent: "center", fontSize: 19, flexShrink: 0 }}>ğŸ¤”</div>
    <div>
      <div style={{ fontSize: 14, fontWeight: 700, color, marginBottom: 4, textTransform: "uppercase", letterSpacing: ".08em" }}>Neden bunu yapÄ±yoruz?</div>
      <div style={{ fontSize: 15, lineHeight: 1.7, color: "#CBD5E1" }}>{children}</div>
    </div>
  </div>
);

const BridgeBox = ({ from, to, color = "#8B5CF6" }) => (
  <div style={{ margin: "14px 0", padding: "14px 18px", borderRadius: 12, background: `${color}08`, border: `1px solid ${color}20`, display: "flex", gap: 12, alignItems: "flex-start" }}>
    <div style={{ width: 32, height: 32, borderRadius: 8, background: `${color}20`, display: "flex", alignItems: "center", justifyContent: "center", fontSize: 19, flexShrink: 0 }}>ğŸŒ‰</div>
    <div>
      <div style={{ fontSize: 14, fontWeight: 700, color, marginBottom: 4, textTransform: "uppercase", letterSpacing: ".08em" }}>KÃ¶prÃ¼ â€” BaÄŸlantÄ±yÄ± Kur</div>
      <div style={{ fontSize: 15, lineHeight: 1.7, color: "#94A3B8" }}><strong style={{ color: "#0EA5E9" }}>Ã–nceki:</strong> {from}</div>
      <div style={{ fontSize: 15, lineHeight: 1.7, color: "#CBD5E1", marginTop: 4 }}><strong style={{ color: "#10B981" }}>Åimdi:</strong> {to}</div>
    </div>
  </div>
);

const AnalogyBox = ({ title, children, emoji = "ğŸ’¡", color = "#10B981" }) => (
  <div style={{ margin: "14px 0", padding: "14px 18px", borderRadius: 12, background: `${color}08`, border: `1px solid ${color}20`, display: "flex", gap: 12, alignItems: "flex-start" }}>
    <div style={{ width: 32, height: 32, borderRadius: 8, background: `${color}20`, display: "flex", alignItems: "center", justifyContent: "center", fontSize: 19, flexShrink: 0 }}>{emoji}</div>
    <div>
      <div style={{ fontSize: 14, fontWeight: 700, color, marginBottom: 4, textTransform: "uppercase", letterSpacing: ".08em" }}>GÃ¼nlÃ¼k Hayat Analojisi: {title}</div>
      <div style={{ fontSize: 15, lineHeight: 1.7, color: "#CBD5E1" }}>{children}</div>
    </div>
  </div>
);

const ConcreteBox = ({ title, children, color = "#0EA5E9" }) => (
  <div style={{ margin: "14px 0", padding: "14px 18px", borderRadius: 12, background: `${color}08`, border: `1px solid ${color}20` }}>
    <div style={{ fontSize: 14, fontWeight: 700, color, marginBottom: 8, textTransform: "uppercase", letterSpacing: ".08em" }}>ğŸ”¬ SomutlaÅŸtÄ±rma: {title}</div>
    <div style={{ fontSize: 15, lineHeight: 1.7, color: "#CBD5E1" }}>{children}</div>
  </div>
);

// â”€â”€â”€ INTERACTIVE "TRY IT YOURSELF" WIDGETS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

const TryItTokenizer = () => {
  const [input, setInput] = useState("ali");
  const chars = input.toLowerCase().split("").filter(c => /[a-z]/.test(c));
  const ids = chars.map(c => c.charCodeAt(0) - 97 + 2);
  const withBos = [0, ...ids, 1];
  const pairs = withBos.slice(0, -1).map((id, i) => [id, withBos[i + 1]]);
  const tokName = (id) => id === 0 ? "BOS" : id === 1 ? "EOS" : String.fromCharCode(97 + id - 2);
  return (
    <div style={{ margin: "14px 0", padding: "18px", borderRadius: 14, background: "rgba(139,92,246,0.06)", border: "1px solid rgba(139,92,246,0.2)" }}>
      <div style={{ display: "flex", alignItems: "center", gap: 8, marginBottom: 12 }}>
        <span style={{ fontSize: 19 }}>ğŸ®</span>
        <span style={{ fontSize: 15, fontWeight: 700, color: "#8B5CF6", textTransform: "uppercase", letterSpacing: ".08em" }}>Kendin Dene: Tokenizer</span>
      </div>
      <div style={{ marginBottom: 12 }}>
        <label style={{ fontSize: 14, color: "#94A3B8", display: "block", marginBottom: 4 }}>Bir isim yaz (Ä°ngilizce harfler):</label>
        <input
          type="text"
          value={input}
          onChange={e => setInput(e.target.value.slice(0, 8))}
          maxLength={8}
          style={{ padding: "8px 14px", borderRadius: 8, border: "1px solid rgba(139,92,246,0.3)", background: "rgba(0,0,0,0.3)", color: "#E2E8F0", fontSize: 19, fontFamily: "'Fira Code', monospace", fontWeight: 700, width: 200, outline: "none" }}
          placeholder="bir isim yaz..."
        />
      </div>
      {chars.length > 0 && (
        <>
          <div style={{ display: "flex", alignItems: "center", gap: 6, flexWrap: "wrap", marginBottom: 8 }}>
            <span style={{ fontSize: 13, color: "#64748B", width: 80 }}>1. Karakterler:</span>
            {chars.map((c, i) => (
              <div key={i} style={{ width: 32, height: 32, borderRadius: 6, background: "rgba(14,165,233,0.15)", display: "flex", alignItems: "center", justifyContent: "center", fontSize: 19, fontWeight: 700, color: "#0EA5E9", fontFamily: "'Fira Code', monospace" }}>{c}</div>
            ))}
          </div>
          <div style={{ display: "flex", alignItems: "center", gap: 6, flexWrap: "wrap", marginBottom: 8 }}>
            <span style={{ fontSize: 13, color: "#64748B", width: 80 }}>2. Token ID:</span>
            {ids.map((id, i) => (
              <div key={i} style={{ width: 32, height: 32, borderRadius: 6, background: "rgba(16,185,129,0.15)", display: "flex", alignItems: "center", justifyContent: "center", fontSize: 16, fontWeight: 700, color: "#10B981", fontFamily: "'Fira Code', monospace" }}>{id}</div>
            ))}
          </div>
          <div style={{ display: "flex", alignItems: "center", gap: 6, flexWrap: "wrap", marginBottom: 12 }}>
            <span style={{ fontSize: 13, color: "#64748B", width: 80 }}>3. +BOS/EOS:</span>
            {withBos.map((id, i) => (
              <div key={i} style={{ width: 32, height: 32, borderRadius: 6, background: (id === 0 || id === 1) ? "rgba(245,158,11,0.2)" : "rgba(16,185,129,0.15)", display: "flex", alignItems: "center", justifyContent: "center", fontSize: (id === 0 || id === 1) ? 10 : 13, fontWeight: 700, color: (id === 0 || id === 1) ? "#F59E0B" : "#10B981", fontFamily: "'Fira Code', monospace" }}>{id === 0 ? "BOS" : id === 1 ? "EOS" : id}</div>
            ))}
          </div>
          <div style={{ padding: "10px 14px", borderRadius: 8, background: "rgba(0,0,0,0.2)" }}>
            <div style={{ fontSize: 13, color: "#F59E0B", fontWeight: 600, marginBottom: 6 }}>4. EÄŸitim Ã‡iftleri (model bunlarÄ± Ã¶ÄŸrenir):</div>
            <div style={{ display: "flex", gap: 6, flexWrap: "wrap" }}>
              {pairs.map(([a, b], i) => (
                <div key={i} style={{ padding: "4px 8px", borderRadius: 6, background: "rgba(236,72,153,0.1)", fontSize: 14, fontFamily: "'Fira Code', monospace", color: "#EC4899" }}>
                  {tokName(a)}â†’{tokName(b)}
                </div>
              ))}
            </div>
            <div style={{ fontSize: 12, color: "#64748B", marginTop: 6 }}>Toplam {pairs.length} tahmin adÄ±mÄ±. Model her ok iÃ§in "sonraki ne?" sorusunu Ã¶ÄŸrenir.</div>
          </div>
        </>
      )}
    </div>
  );
};

const TryItSoftmax = () => {
  const [temp, setTemp] = useState(1.0);
  const [logits, setLogits] = useState([2.0, 1.0, 0.5, -0.5, -1.0]);
  const labels = ["a", "e", "i", "o", "u"];
  const scaled = logits.map(l => l / temp);
  const mx = Math.max(...scaled);
  const exps = scaled.map(v => Math.exp(v - mx));
  const total = exps.reduce((a, b) => a + b, 0);
  const probs = exps.map(v => v / total);
  const maxP = Math.max(...probs);

  return (
    <div style={{ margin: "14px 0", padding: "18px", borderRadius: 14, background: "rgba(99,102,241,0.06)", border: "1px solid rgba(99,102,241,0.2)" }}>
      <div style={{ display: "flex", alignItems: "center", gap: 8, marginBottom: 12 }}>
        <span style={{ fontSize: 19 }}>ğŸ®</span>
        <span style={{ fontSize: 15, fontWeight: 700, color: "#6366F1", textTransform: "uppercase", letterSpacing: ".08em" }}>Kendin Dene: Softmax & Temperature</span>
      </div>
      <div style={{ marginBottom: 12 }}>
        <label style={{ fontSize: 14, color: "#94A3B8", display: "block", marginBottom: 4 }}>Temperature: <strong style={{ color: "#F59E0B", fontFamily: "'Fira Code', monospace" }}>{temp.toFixed(1)}</strong> {temp < 0.5 ? "(Ã§ok sivri â€” neredeyse greedy)" : temp < 1.0 ? "(sivri â€” yÃ¼ksek olasÄ±lÄ±klÄ±lar baskÄ±n)" : temp === 1.0 ? "(orijinal daÄŸÄ±lÄ±m)" : temp < 1.5 ? "(yumuÅŸak â€” daha rastgele)" : "(Ã§ok dÃ¼z â€” neredeyse rastgele)"}</label>
        <input type="range" min="0.1" max="3.0" step="0.1" value={temp} onChange={e => setTemp(+e.target.value)} style={{ width: "100%", maxWidth: 300 }} />
      </div>
      <div style={{ display: "flex", gap: 16, flexWrap: "wrap", alignItems: "flex-start" }}>
        <div style={{ minWidth: 200 }}>
          <div style={{ fontSize: 13, color: "#64748B", marginBottom: 4 }}>Logits (ham skorlar) â€” kaydÄ±r:</div>
          {logits.map((l, i) => (
            <div key={i} style={{ display: "flex", alignItems: "center", gap: 8, marginBottom: 4 }}>
              <span style={{ width: 16, fontSize: 17, fontWeight: 700, color: "#0EA5E9", fontFamily: "'Fira Code', monospace" }}>{labels[i]}</span>
              <input type="range" min="-3" max="5" step="0.1" value={l} onChange={e => { const n = [...logits]; n[i] = +e.target.value; setLogits(n); }} style={{ width: 100 }} />
              <span style={{ width: 36, fontSize: 14, fontFamily: "'Fira Code', monospace", color: "#94A3B8" }}>{l.toFixed(1)}</span>
            </div>
          ))}
        </div>
        <div style={{ minWidth: 200 }}>
          <div style={{ fontSize: 13, color: "#64748B", marginBottom: 4 }}>Softmax olasÄ±lÄ±klarÄ±:</div>
          {probs.map((p, i) => (
            <div key={i} style={{ display: "flex", alignItems: "center", gap: 8, marginBottom: 4, height: 26 }}>
              <span style={{ width: 16, fontSize: 17, fontWeight: 700, color: p === maxP ? "#10B981" : "#94A3B8", fontFamily: "'Fira Code', monospace" }}>{labels[i]}</span>
              <div style={{ flex: 1, height: 16, background: "rgba(255,255,255,0.04)", borderRadius: 8, overflow: "hidden", maxWidth: 150 }}>
                <div style={{ height: "100%", width: `${p * 100}%`, borderRadius: 8, background: p === maxP ? "#10B981" : "#0EA5E9", transition: "width .3s" }} />
              </div>
              <span style={{ width: 48, fontSize: 14, fontFamily: "'Fira Code', monospace", color: p === maxP ? "#10B981" : "#94A3B8", fontWeight: p === maxP ? 700 : 400 }}>{(p * 100).toFixed(1)}%</span>
            </div>
          ))}
          <div style={{ fontSize: 12, color: "#475569", marginTop: 4 }}>Toplam: {(probs.reduce((a, b) => a + b, 0) * 100).toFixed(1)}%</div>
        </div>
      </div>
      <div style={{ marginTop: 10, padding: "8px 12px", borderRadius: 8, background: "rgba(0,0,0,0.2)", fontSize: 13, color: "#94A3B8", lineHeight: 1.6 }}>
        <strong style={{ color: "#F59E0B" }}>GÃ¶zlem: </strong>
        {temp < 0.5 ? "Ã‡ok dÃ¼ÅŸÃ¼k T â†’ en yÃ¼ksek skorlu token neredeyse %100 olasÄ±lÄ±k alÄ±yor. Model hep aynÄ± ÅŸeyi Ã¼retir." :
         temp < 1.0 ? "DÃ¼ÅŸÃ¼k T â†’ farklar bÃ¼yÃ¼tÃ¼lÃ¼yor. YÃ¼ksek skorlular daha baskÄ±n. GÃ¼venli Ã¼retim." :
         temp === 1.0 ? "T=1 â†’ orijinal model daÄŸÄ±lÄ±mÄ±. EÄŸitimde Ã¶ÄŸrenilen olasÄ±lÄ±klar aynen korunuyor." :
         temp < 2.0 ? "YÃ¼ksek T â†’ farklar kÃ¼Ã§Ã¼lÃ¼yor. DÃ¼ÅŸÃ¼k olasÄ±lÄ±klÄ± tokenlar da ÅŸans kazanÄ±yor. YaratÄ±cÄ± ama riskli." :
         "Ã‡ok yÃ¼ksek T â†’ neredeyse uniform daÄŸÄ±lÄ±m. Ãœretim rastgeleye yakÄ±n. Genelde anlamsÄ±z Ã§Ä±ktÄ±lar."}
      </div>
    </div>
  );
};

const TryItDotProduct = () => {
  const [q, setQ] = useState([0.5, 0.3, -0.2, 0.4]);
  const [k, setK] = useState([0.4, 0.2, -0.1, 0.3]);
  const products = q.map((v, i) => v * k[i]);
  const dot = products.reduce((a, b) => a + b, 0);
  const norm = Math.sqrt(4);
  const scaled = dot / norm;
  return (
    <div style={{ margin: "14px 0", padding: "18px", borderRadius: 14, background: "rgba(16,185,129,0.06)", border: "1px solid rgba(16,185,129,0.2)" }}>
      <div style={{ display: "flex", alignItems: "center", gap: 8, marginBottom: 12 }}>
        <span style={{ fontSize: 19 }}>ğŸ®</span>
        <span style={{ fontSize: 15, fontWeight: 700, color: "#10B981", textTransform: "uppercase", letterSpacing: ".08em" }}>Kendin Dene: Dot Product (Attention Skoru)</span>
      </div>
      <div style={{ display: "flex", gap: 16, flexWrap: "wrap", marginBottom: 12 }}>
        <div>
          <div style={{ fontSize: 13, color: "#10B981", fontWeight: 600, marginBottom: 4 }}>Query (Q) â€” "ne arÄ±yorum?"</div>
          {q.map((v, i) => (
            <div key={i} style={{ display: "flex", alignItems: "center", gap: 4, marginBottom: 3 }}>
              <span style={{ fontSize: 12, color: "#64748B", width: 14 }}>q{i}</span>
              <input type="range" min="-1" max="1" step="0.1" value={v} onChange={e => { const n = [...q]; n[i] = +e.target.value; setQ(n); }} style={{ width: 80 }} />
              <span style={{ width: 30, fontSize: 13, fontFamily: "'Fira Code', monospace", color: "#10B981" }}>{v.toFixed(1)}</span>
            </div>
          ))}
        </div>
        <div>
          <div style={{ fontSize: 13, color: "#F59E0B", fontWeight: 600, marginBottom: 4 }}>Key (K) â€” "bende ne var?"</div>
          {k.map((v, i) => (
            <div key={i} style={{ display: "flex", alignItems: "center", gap: 4, marginBottom: 3 }}>
              <span style={{ fontSize: 12, color: "#64748B", width: 14 }}>k{i}</span>
              <input type="range" min="-1" max="1" step="0.1" value={v} onChange={e => { const n = [...k]; n[i] = +e.target.value; setK(n); }} style={{ width: 80 }} />
              <span style={{ width: 30, fontSize: 13, fontFamily: "'Fira Code', monospace", color: "#F59E0B" }}>{v.toFixed(1)}</span>
            </div>
          ))}
        </div>
      </div>
      <div style={{ padding: "12px 14px", borderRadius: 10, background: "rgba(0,0,0,0.2)" }}>
        <div style={{ fontSize: 13, color: "#64748B", marginBottom: 6 }}>AdÄ±m adÄ±m hesaplama:</div>
        <div style={{ display: "flex", gap: 8, flexWrap: "wrap", marginBottom: 6, alignItems: "center" }}>
          {products.map((p, i) => (
            <div key={i} style={{ display: "flex", alignItems: "center", gap: 2 }}>
              <span style={{ fontSize: 13, fontFamily: "'Fira Code', monospace", color: "#10B981" }}>{q[i].toFixed(1)}</span>
              <span style={{ fontSize: 13, color: "#64748B" }}>Ã—</span>
              <span style={{ fontSize: 13, fontFamily: "'Fira Code', monospace", color: "#F59E0B" }}>{k[i].toFixed(1)}</span>
              <span style={{ fontSize: 13, color: "#64748B" }}>=</span>
              <span style={{ fontSize: 13, fontFamily: "'Fira Code', monospace", color: "#EC4899", fontWeight: 700 }}>{p.toFixed(2)}</span>
              {i < products.length - 1 && <span style={{ fontSize: 13, color: "#64748B", marginLeft: 4 }}>+</span>}
            </div>
          ))}
        </div>
        <div style={{ display: "flex", gap: 16, flexWrap: "wrap" }}>
          <div style={{ fontSize: 15, fontFamily: "'Fira Code', monospace" }}>
            <span style={{ color: "#94A3B8" }}>Q Â· K = </span><span style={{ color: "#0EA5E9", fontWeight: 700 }}>{dot.toFixed(3)}</span>
          </div>
          <div style={{ fontSize: 15, fontFamily: "'Fira Code', monospace" }}>
            <span style={{ color: "#94A3B8" }}>Ã· âˆšd = Ã· {norm.toFixed(1)} = </span><span style={{ color: "#EF4444", fontWeight: 700 }}>{scaled.toFixed(3)}</span>
          </div>
        </div>
        <div style={{ fontSize: 13, color: "#94A3B8", marginTop: 8 }}>
          {scaled > 0.3 ? "ğŸ”¥ YÃ¼ksek skor â†’ bu token'a Ã§ok dikkat edilecek!" :
           scaled > 0 ? "ğŸ‘€ Orta skor â†’ biraz dikkat edilecek." :
           scaled > -0.2 ? "ğŸ˜ DÃ¼ÅŸÃ¼k skor â†’ az dikkat edilecek." :
           "â„ï¸ Negatif skor â†’ neredeyse hiÃ§ dikkat edilmeyecek."}
          <span style={{ color: "#475569" }}> Q ve K'yÄ± kaydÄ±rarak skoru deÄŸiÅŸtir â€” aynÄ± yÃ¶nler yÃ¼ksek, ters yÃ¶nler dÃ¼ÅŸÃ¼k skor verir!</span>
        </div>
      </div>
    </div>
  );
};

const TryItGradient = () => {
  const [x, setX] = useState(3.0);
  const [lr, setLr] = useState(0.1);
  const [history, setHistory] = useState([3.0]);
  const f = v => v * v;
  const grad = v => 2 * v;
  const doStep = () => {
    const newX = x - lr * grad(x);
    setX(Math.round(newX * 1000) / 1000);
    setHistory(h => [...h.slice(-15), newX]);
  };
  const reset = () => { setX(3.0); setHistory([3.0]); };
  const pts = [];
  for (let v = -4; v <= 4; v += 0.15) pts.push({ x: v, y: f(v) });
  const svgW = 280, svgH = 140;
  const toSVG = (px, py) => ({ sx: ((px + 4) / 8) * svgW, sy: svgH - (py / 16) * svgH });
  return (
    <div style={{ margin: "14px 0", padding: "18px", borderRadius: 14, background: "rgba(239,68,68,0.06)", border: "1px solid rgba(239,68,68,0.2)" }}>
      <div style={{ display: "flex", alignItems: "center", gap: 8, marginBottom: 12 }}>
        <span style={{ fontSize: 19 }}>ğŸ®</span>
        <span style={{ fontSize: 15, fontWeight: 700, color: "#EF4444", textTransform: "uppercase", letterSpacing: ".08em" }}>Kendin Dene: Gradient Descent</span>
      </div>
      <div style={{ display: "flex", gap: 20, flexWrap: "wrap", alignItems: "flex-start" }}>
        <div>
          <svg width={svgW} height={svgH} style={{ background: "rgba(0,0,0,0.2)", borderRadius: 10 }}>
            <polyline points={pts.map(p => { const s = toSVG(p.x, p.y); return `${s.sx},${s.sy}`; }).join(" ")} fill="none" stroke="#8B5CF6" strokeWidth="2" />
            {history.map((hx, i) => { const s = toSVG(hx, f(hx)); return <circle key={i} cx={s.sx} cy={s.sy} r={i === history.length - 1 ? 6 : 3} fill={i === history.length - 1 ? "#EF4444" : "rgba(239,68,68,0.3)"} />; })}
            {history.length > 1 && history.slice(0, -1).map((hx, i) => { const s1 = toSVG(hx, f(hx)); const s2 = toSVG(history[i + 1], f(history[i + 1])); return <line key={i} x1={s1.sx} y1={s1.sy} x2={s2.sx} y2={s2.sy} stroke="rgba(239,68,68,0.4)" strokeWidth="1" strokeDasharray="3,2" />; })}
            <text x="4" y="14" fill="#8B5CF6" fontSize="10">f(x) = xÂ²</text>
            <text x="4" y={svgH - 4} fill="#64748B" fontSize="9">min = 0</text>
          </svg>
          <div style={{ display: "flex", gap: 6, marginTop: 8 }}>
            <button onClick={doStep} style={{ padding: "6px 16px", borderRadius: 8, border: "none", background: "#EF4444", color: "#fff", fontSize: 14, fontWeight: 700, cursor: "pointer", fontFamily: "inherit" }}>Bir AdÄ±m At â†’</button>
            <button onClick={reset} style={{ padding: "6px 16px", borderRadius: 8, border: "1px solid rgba(255,255,255,0.1)", background: "transparent", color: "#94A3B8", fontSize: 14, fontWeight: 600, cursor: "pointer", fontFamily: "inherit" }}>{lang === "tr" ? "SÄ±fÄ±rla" : "Reset"}</button>
          </div>
        </div>
        <div style={{ flex: 1, minWidth: 200 }}>
          <div style={{ marginBottom: 8 }}>
            <label style={{ fontSize: 13, color: "#94A3B8" }}>Learning Rate: <strong style={{ color: "#F59E0B" }}>{lr.toFixed(2)}</strong></label>
            <input type="range" min="0.01" max="1.5" step="0.01" value={lr} onChange={e => setLr(+e.target.value)} style={{ width: "100%", maxWidth: 200, display: "block" }} />
            <span style={{ fontSize: 12, color: "#475569" }}>{lr > 1 ? (lang==="tr"?"âš ï¸ Ã‡ok bÃ¼yÃ¼k â€” patlayabilir!":"âš ï¸ Too large â€” may explode!") : lr > 0.3 ? (lang==="tr"?"HÄ±zlÄ± ama riskli":"Fast but risky") : lr > 0.05 ? (lang==="tr"?"Ä°yi denge":"Good balance") : (lang==="tr"?"Ã‡ok yavaÅŸ ama gÃ¼venli":"Very slow but safe")}</span>
          </div>
          <div style={{ padding: "10px 12px", borderRadius: 8, background: "rgba(0,0,0,0.2)", fontSize: 14, fontFamily: "'Fira Code', monospace" }}>
            <div style={{ color: "#94A3B8" }}>x = <span style={{ color: "#0EA5E9", fontWeight: 700 }}>{x.toFixed(3)}</span></div>
            <div style={{ color: "#94A3B8" }}>f(x) = xÂ² = <span style={{ color: "#8B5CF6", fontWeight: 700 }}>{f(x).toFixed(3)}</span></div>
            <div style={{ color: "#94A3B8" }}>gradient = 2x = <span style={{ color: "#F59E0B", fontWeight: 700 }}>{grad(x).toFixed(3)}</span></div>
            <div style={{ color: "#94A3B8", marginTop: 4 }}>x_yeni = {x.toFixed(3)} - {lr.toFixed(2)} Ã— {grad(x).toFixed(3)}</div>
            <div style={{ color: "#10B981", fontWeight: 700 }}>= {(x - lr * grad(x)).toFixed(3)}</div>
          </div>
          <div style={{ marginTop: 8, fontSize: 12, color: "#64748B" }}>
            AdÄ±m sayÄ±sÄ±: {history.length - 1} | Hedef: x = 0 (minimum)
          </div>
          <div style={{ marginTop: 4, fontSize: 13, color: "#94A3B8" }}>
            ğŸ’¡ LR'Ä± 1.0+ yapÄ±p "patlama"yÄ± gÃ¶zlemle. Sonra 0.1'e dÃ¼ÅŸÃ¼rÃ¼p nasÄ±l yakÄ±nsadÄ±ÄŸÄ±nÄ± izle.
          </div>
        </div>
      </div>
    </div>
  );
};

const TryItEmbedding = () => {
  const [tokId, setTokId] = useState(2);
  const [posId, setPosId] = useState(0);
  const rng = (s) => { let st = s; return () => { st = (st * 16807 + 13) % 2147483647; return ((st - 1) / 2147483646 - 0.5) * 0.16; }; };
  const tEmb = useMemo(() => { const r = rng(tokId * 997 + 42); return Array.from({ length: 16 }, () => Math.round(r() * 1000) / 1000); }, [tokId]);
  const pEmb = useMemo(() => { const r = rng(posId * 503 + 77); return Array.from({ length: 16 }, () => Math.round(r() * 500) / 1000); }, [posId]);
  const combined = tEmb.map((v, i) => Math.round((v + pEmb[i]) * 1000) / 1000);
  const chName = tokId === 0 ? "BOS" : tokId === 1 ? "EOS" : String.fromCharCode(95 + tokId);
  const mx = Math.max(...[...tEmb, ...pEmb, ...combined].map(Math.abs), 0.001);
  const Bar = ({ v, color }) => <div style={{ width: 14, height: 28, borderRadius: 3, background: v > 0 ? `rgba(${color},${Math.abs(v) / mx})` : `rgba(${color.split(",").map(c => Math.min(255, parseInt(c) + 80)).join(",")},${Math.abs(v) / mx})`, transition: "all .3s" }} title={v.toFixed(3)} />;

  return (
    <div style={{ margin: "14px 0", padding: "18px", borderRadius: 14, background: "rgba(14,165,233,0.06)", border: "1px solid rgba(14,165,233,0.2)" }}>
      <div style={{ display: "flex", alignItems: "center", gap: 8, marginBottom: 12 }}>
        <span style={{ fontSize: 19 }}>ğŸ®</span>
        <span style={{ fontSize: 15, fontWeight: 700, color: "#0EA5E9", textTransform: "uppercase", letterSpacing: ".08em" }}>Kendin Dene: Embedding Lookup</span>
      </div>
      <div style={{ display: "flex", gap: 16, marginBottom: 12, flexWrap: "wrap" }}>
        <div>
          <label style={{ fontSize: 13, color: "#0EA5E9" }}>Token: <strong>{chName}</strong> (ID={tokId})</label>
          <input type="range" min="0" max="27" step="1" value={tokId} onChange={e => setTokId(+e.target.value)} style={{ width: 150, display: "block" }} />
        </div>
        <div>
          <label style={{ fontSize: 13, color: "#8B5CF6" }}>Pozisyon: <strong>{posId}</strong></label>
          <input type="range" min="0" max="7" step="1" value={posId} onChange={e => setPosId(+e.target.value)} style={{ width: 150, display: "block" }} />
        </div>
      </div>
      <div style={{ display: "flex", gap: 12, alignItems: "flex-start", flexWrap: "wrap" }}>
        <div>
          <div style={{ fontSize: 13, color: "#0EA5E9", fontWeight: 600, marginBottom: 4 }}>wte[{tokId}] Token Emb</div>
          <div style={{ display: "flex", gap: 2 }}>{tEmb.map((v, i) => <Bar key={i} v={v} color="14,165,233" />)}</div>
        </div>
        <div style={{ display: "flex", alignItems: "center", height: 42, fontSize: 21, color: "#64748B", fontWeight: 700 }}>+</div>
        <div>
          <div style={{ fontSize: 13, color: "#8B5CF6", fontWeight: 600, marginBottom: 4 }}>wpe[{posId}] Pos Emb</div>
          <div style={{ display: "flex", gap: 2 }}>{pEmb.map((v, i) => <Bar key={i} v={v} color="139,92,246" />)}</div>
        </div>
        <div style={{ display: "flex", alignItems: "center", height: 42, fontSize: 21, color: "#64748B", fontWeight: 700 }}>=</div>
        <div>
          <div style={{ fontSize: 13, color: "#10B981", fontWeight: 600, marginBottom: 4 }}>x (girdi vektÃ¶rÃ¼)</div>
          <div style={{ display: "flex", gap: 2 }}>{combined.map((v, i) => <Bar key={i} v={v} color="16,185,129" />)}</div>
        </div>
      </div>
      <div style={{ marginTop: 10, padding: "8px 12px", borderRadius: 8, background: "rgba(0,0,0,0.2)", fontSize: 13, color: "#94A3B8" }}>
        ğŸ’¡ Token ve pozisyonu deÄŸiÅŸtirerek vektÃ¶rlerin nasÄ±l farklÄ±laÅŸtÄ±ÄŸÄ±nÄ± gÃ¶zlemle. AynÄ± harf farklÄ± pozisyonlarda farklÄ± vektÃ¶r alÄ±r!
      </div>
    </div>
  );
};

const StepByStepCalc = ({ title, steps, color = "#F59E0B" }) => {
  const [step, setStep] = useState(0);
  return (
    <div style={{ margin: "14px 0", padding: "18px", borderRadius: 14, background: `${color}06`, border: `1px solid ${color}20` }}>
      <div style={{ display: "flex", alignItems: "center", gap: 8, marginBottom: 12 }}>
        <span style={{ fontSize: 19 }}>ğŸ”¢</span>
        <span style={{ fontSize: 15, fontWeight: 700, color, textTransform: "uppercase", letterSpacing: ".08em" }}>AdÄ±m AdÄ±m: {title}</span>
      </div>
      <div style={{ display: "flex", flexDirection: "column", gap: 4, marginBottom: 12 }}>
        {steps.map((s, i) => (
          <div key={i} style={{ display: "flex", gap: 8, alignItems: "flex-start", padding: "6px 10px", borderRadius: 8, background: i <= step ? `${color}10` : "transparent", opacity: i <= step ? 1 : 0.3, transition: "all .3s", cursor: "pointer" }} onClick={() => setStep(i)}>
            <div style={{ width: 22, height: 22, borderRadius: 6, background: i <= step ? color : "rgba(255,255,255,0.05)", display: "flex", alignItems: "center", justifyContent: "center", fontSize: 13, fontWeight: 700, color: i <= step ? "#fff" : "#475569", flexShrink: 0 }}>{i + 1}</div>
            <div>
              <div style={{ fontSize: 14, fontWeight: 600, color: i <= step ? color : "#475569" }}>{s.label}</div>
              {i <= step && <div style={{ fontSize: 15, fontFamily: "'Fira Code', monospace", color: "#E2E8F0", marginTop: 2 }}>{s.calc}</div>}
              {i <= step && s.note && <div style={{ fontSize: 13, color: "#64748B", marginTop: 2 }}>{s.note}</div>}
            </div>
          </div>
        ))}
      </div>
      <div style={{ display: "flex", gap: 6 }}>
        <button onClick={() => setStep(Math.max(0, step - 1))} disabled={step <= 0} style={{ padding: "5px 12px", borderRadius: 6, border: "1px solid rgba(255,255,255,0.08)", background: "transparent", color: step > 0 ? "#94A3B8" : "#1E293B", fontSize: 13, fontWeight: 600, cursor: step > 0 ? "pointer" : "not-allowed", fontFamily: "inherit" }}>{lang === "tr" ? "â† Ã–nceki" : "â† Previous"}</button>
        <button onClick={() => setStep(Math.min(steps.length - 1, step + 1))} disabled={step >= steps.length - 1} style={{ padding: "5px 12px", borderRadius: 6, border: "none", background: step < steps.length - 1 ? color : "#1E293B", color: "#fff", fontSize: 13, fontWeight: 600, cursor: step < steps.length - 1 ? "pointer" : "not-allowed", fontFamily: "inherit" }}>{lang === "tr" ? "Sonraki â†’" : "Next â†’"}</button>
        <button onClick={() => setStep(steps.length - 1)} style={{ padding: "5px 12px", borderRadius: 6, border: "1px solid rgba(255,255,255,0.08)", background: "transparent", color: "#94A3B8", fontSize: 13, fontWeight: 600, cursor: "pointer", fontFamily: "inherit" }}>TÃ¼mÃ¼</button>
      </div>
    </div>
  );
};

// â”€â”€â”€ SECTION ENHANCEMENT DATA â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// Maps sectionKey â†’ extra pedagogical content

const TryItParams = () => {
  const [nEmbd, setNEmbd] = useState(16);
  const [nLayer, setNLayer] = useState(1);
  const [nHead, setNHead] = useState(4);
  const [blockSize, setBlockSize] = useState(8);
  const [lr, setLr] = useState(0.01);
  const vocabSize = 28;

  const headDim = nEmbd / nHead;
  const validHead = nEmbd % nHead === 0;

  // Calculate parameter count
  const wte = vocabSize * nEmbd;
  const wpe = blockSize * nEmbd;
  const perLayer = nEmbd * nEmbd * 4 + 4 * nEmbd * nEmbd; // attn(Wq,Wk,Wv,Wo) + mlp(fc1: n_embd*4*n_embd + fc2: 4*n_embd*n_embd)
  const attnParams = nEmbd * nEmbd * 4; // Wq, Wk, Wv, Wo each n_embdÃ—n_embd
  const mlpParams = nEmbd * (4 * nEmbd) + (4 * nEmbd) * nEmbd;
  const layerParams = attnParams + mlpParams;
  const totalParams = wte + wpe + layerParams * nLayer;

  const memKB = (totalParams * 4 / 1024).toFixed(1);

  const lrFeedback = lr >= 0.1 ? "âš ï¸ Ã‡ok yÃ¼ksek! Model patlayabilir" : lr <= 0.0001 ? "ğŸŒ Ã‡ok dÃ¼ÅŸÃ¼k â€” eÄŸitim Ã§ok yavaÅŸ olur" : lr <= 0.001 ? "ğŸ¢ GÃ¼venli ama yavaÅŸ" : "âœ… Ä°yi denge";

  return (
    <div style={{ margin: "18px 0", padding: 20, borderRadius: 16, background: "rgba(14,165,233,0.04)", border: "1px solid rgba(14,165,233,0.15)" }}>
      <div style={{ display: "flex", alignItems: "center", gap: 8, marginBottom: 14 }}>
        <span style={{ fontSize: 19 }}>ğŸ›ï¸</span>
        <span style={{ fontSize: 15, fontWeight: 700, color: "#0EA5E9", textTransform: "uppercase", letterSpacing: ".06em" }}>Parametre LaboratuvarÄ±</span>
        <span style={{ fontSize: 13, color: "#64748B" }}>â€” kaydÄ±rÄ±cÄ±larÄ± deÄŸiÅŸtirin, etkiyi gÃ¶rÃ¼n</span>
      </div>

      <div style={{ display: "grid", gridTemplateColumns: "1fr 1fr", gap: 12, marginBottom: 16 }}>
        {/* n_embd */}
        <div style={{ padding: 12, borderRadius: 10, background: "rgba(0,0,0,0.15)" }}>
          <div style={{ display: "flex", justifyContent: "space-between", marginBottom: 4 }}>
            <span style={{ fontSize: 13, fontWeight: 700, color: "#0EA5E9" }}>n_embd</span>
            <span style={{ fontSize: 15, fontWeight: 800, color: "#E2E8F0", fontFamily: "'Fira Code', monospace" }}>{nEmbd}</span>
          </div>
          <input type="range" min={4} max={128} step={4} value={nEmbd} onChange={e => { const v = +e.target.value; setNEmbd(v); if (v % nHead !== 0) setNHead(Math.max(1, Math.min(v, nHead))); }} style={{ width: "100%", accentColor: "#0EA5E9" }} />
          <div style={{ fontSize: 12, color: "#64748B", marginTop: 2 }}>Embedding boyutu (4-128)</div>
        </div>

        {/* n_layer */}
        <div style={{ padding: 12, borderRadius: 10, background: "rgba(0,0,0,0.15)" }}>
          <div style={{ display: "flex", justifyContent: "space-between", marginBottom: 4 }}>
            <span style={{ fontSize: 13, fontWeight: 700, color: "#8B5CF6" }}>n_layer</span>
            <span style={{ fontSize: 15, fontWeight: 800, color: "#E2E8F0", fontFamily: "'Fira Code', monospace" }}>{nLayer}</span>
          </div>
          <input type="range" min={1} max={12} value={nLayer} onChange={e => setNLayer(+e.target.value)} style={{ width: "100%", accentColor: "#8B5CF6" }} />
          <div style={{ fontSize: 12, color: "#64748B", marginTop: 2 }}>Katman sayÄ±sÄ± (1-12)</div>
        </div>

        {/* n_head */}
        <div style={{ padding: 12, borderRadius: 10, background: "rgba(0,0,0,0.15)" }}>
          <div style={{ display: "flex", justifyContent: "space-between", marginBottom: 4 }}>
            <span style={{ fontSize: 13, fontWeight: 700, color: "#10B981" }}>n_head</span>
            <span style={{ fontSize: 15, fontWeight: 800, color: validHead ? "#E2E8F0" : "#EF4444", fontFamily: "'Fira Code', monospace" }}>{nHead}</span>
          </div>
          <input type="range" min={1} max={16} value={nHead} onChange={e => setNHead(+e.target.value)} style={{ width: "100%", accentColor: "#10B981" }} />
          <div style={{ fontSize: 12, color: validHead ? "#64748B" : "#EF4444", marginTop: 2 }}>
            {validHead ? `Head sayÄ±sÄ± â†’ head_dim = ${nEmbd}/${nHead} = ${headDim}` : `âš ï¸ n_embd(${nEmbd}) % n_head(${nHead}) â‰  0!`}
          </div>
        </div>

        {/* block_size */}
        <div style={{ padding: 12, borderRadius: 10, background: "rgba(0,0,0,0.15)" }}>
          <div style={{ display: "flex", justifyContent: "space-between", marginBottom: 4 }}>
            <span style={{ fontSize: 13, fontWeight: 700, color: "#EC4899" }}>block_size</span>
            <span style={{ fontSize: 15, fontWeight: 800, color: "#E2E8F0", fontFamily: "'Fira Code', monospace" }}>{blockSize}</span>
          </div>
          <input type="range" min={4} max={64} value={blockSize} onChange={e => setBlockSize(+e.target.value)} style={{ width: "100%", accentColor: "#EC4899" }} />
          <div style={{ fontSize: 12, color: "#64748B", marginTop: 2 }}>Context window (4-64 token)</div>
        </div>

        {/* learning_rate */}
        <div style={{ padding: 12, borderRadius: 10, background: "rgba(0,0,0,0.15)", gridColumn: "1 / -1" }}>
          <div style={{ display: "flex", justifyContent: "space-between", marginBottom: 4 }}>
            <span style={{ fontSize: 13, fontWeight: 700, color: "#F59E0B" }}>learning_rate</span>
            <span style={{ fontSize: 15, fontWeight: 800, color: "#E2E8F0", fontFamily: "'Fira Code', monospace" }}>{lr}</span>
          </div>
          <input type="range" min={0.0001} max={0.2} step={0.0001} value={lr} onChange={e => setLr(+parseFloat(e.target.value).toFixed(4))} style={{ width: "100%", accentColor: "#F59E0B" }} />
          <div style={{ fontSize: 12, color: "#64748B", marginTop: 2 }}>{lrFeedback}</div>
        </div>
      </div>

      {/* Results panel */}
      <div style={{ padding: 14, borderRadius: 12, background: "rgba(14,165,233,0.08)", border: "1px solid rgba(14,165,233,0.2)" }}>
        <div style={{ fontSize: 14, fontWeight: 700, color: "#0EA5E9", marginBottom: 8 }}>ğŸ“Š Hesaplanan Model Boyutu</div>
        <div style={{ display: "grid", gridTemplateColumns: "1fr 1fr 1fr", gap: 8 }}>
          <div style={{ textAlign: "center", padding: 8, borderRadius: 8, background: "rgba(0,0,0,0.2)" }}>
            <div style={{ fontSize: 21, fontWeight: 800, color: "#E2E8F0", fontFamily: "'Fira Code', monospace" }}>{totalParams.toLocaleString()}</div>
            <div style={{ fontSize: 11, color: "#64748B", marginTop: 2 }}>TOPLAM PARAMETRE</div>
          </div>
          <div style={{ textAlign: "center", padding: 8, borderRadius: 8, background: "rgba(0,0,0,0.2)" }}>
            <div style={{ fontSize: 21, fontWeight: 800, color: "#8B5CF6", fontFamily: "'Fira Code', monospace" }}>{memKB} KB</div>
            <div style={{ fontSize: 11, color: "#64748B", marginTop: 2 }}>BELLEK (float32)</div>
          </div>
          <div style={{ textAlign: "center", padding: 8, borderRadius: 8, background: "rgba(0,0,0,0.2)" }}>
            <div style={{ fontSize: 21, fontWeight: 800, color: "#10B981", fontFamily: "'Fira Code', monospace" }}>{validHead ? headDim : "â€”"}</div>
            <div style={{ fontSize: 11, color: "#64748B", marginTop: 2 }}>HEAD DIM</div>
          </div>
        </div>
        <div style={{ marginTop: 10, display: "flex", flexDirection: "column", gap: 3 }}>
          <div style={{ display: "flex", justifyContent: "space-between", fontSize: 13 }}>
            <span style={{ color: "#64748B" }}>wte (token emb)</span>
            <span style={{ color: "#94A3B8", fontFamily: "'Fira Code', monospace" }}>{vocabSize}Ã—{nEmbd} = {wte.toLocaleString()}</span>
          </div>
          <div style={{ display: "flex", justifyContent: "space-between", fontSize: 13 }}>
            <span style={{ color: "#64748B" }}>wpe (pos emb)</span>
            <span style={{ color: "#94A3B8", fontFamily: "'Fira Code', monospace" }}>{blockSize}Ã—{nEmbd} = {wpe.toLocaleString()}</span>
          </div>
          <div style={{ display: "flex", justifyContent: "space-between", fontSize: 13 }}>
            <span style={{ color: "#64748B" }}>attention (Wq+Wk+Wv+Wo)</span>
            <span style={{ color: "#94A3B8", fontFamily: "'Fira Code', monospace" }}>4Ã—{nEmbd}Ã—{nEmbd} = {attnParams.toLocaleString()} Ã— {nLayer}L</span>
          </div>
          <div style={{ display: "flex", justifyContent: "space-between", fontSize: 13 }}>
            <span style={{ color: "#64748B" }}>mlp (fc1+fc2)</span>
            <span style={{ color: "#94A3B8", fontFamily: "'Fira Code', monospace" }}>{nEmbd}Ã—{4 * nEmbd} + {4 * nEmbd}Ã—{nEmbd} = {mlpParams.toLocaleString()} Ã— {nLayer}L</span>
          </div>
        </div>
        <div style={{ marginTop: 8, fontSize: 12, color: "#64748B", fontStyle: "italic" }}>
          {totalParams <= 5000 ? "ğŸŸ¢ Ã‡ok kÃ¼Ã§Ã¼k â€” saniyeler iÃ§inde eÄŸitilir" :
           totalParams <= 50000 ? "ğŸŸ¡ Orta â€” birkaÃ§ dakika CPU'da" :
           totalParams <= 500000 ? "ğŸŸ  BÃ¼yÃ¼kÃ§e â€” 30+ dk CPU, GPU Ã¶nerilir" :
           "ğŸ”´ Ã‡ok bÃ¼yÃ¼k â€” saf Python ile saatler sÃ¼rer, PyTorch/GPU ÅŸart"}
        </div>
      </div>

      {/* Command line preview */}
      <div style={{ marginTop: 10, padding: 10, borderRadius: 8, background: "#0D1117", fontFamily: "'Fira Code', monospace", fontSize: 13, color: "#7EE787" }}>
        $ python3 microgpt.py --n_embd {nEmbd} --n_layer {nLayer} --n_head {nHead} --block_size {blockSize} --learning_rate {lr}
      </div>
    </div>
  );
};

// â”€â”€â”€ REAL CODE MAPPING â€” microgpt.py gerÃ§ek kod parÃ§alarÄ± â”€â”€â”€â”€â”€â”€â”€
const REAL_CODE = {
  // WEEK 0 â€” GiriÅŸ
  "week0_s0": {
    label: "microgpt.py â€¢ satÄ±r 1-6",
    lines: [1, 6],
    code: `"""
The most atomic way to train and inference
a GPT LLM in pure, dependency-free Python.
Differences from GPT-2 are minor: rmsnorm
instead of layer norm, no biases, square
ReLU instead of GeLU nonlinearity.
"""`,
    notes: [
      "DosyanÄ±n en tepesi â€” projenin manifestosu",
      "Saf Python, baÄŸÄ±mlÄ±lÄ±k yok (PyTorch/NumPy yok)",
      "GPT-2'den farklar: RMSNorm, bias yok, ReLUÂ²",
    ]
  },
  "week0_s5": {
    label: "microgpt.py â€¢ satÄ±r 8-12",
    lines: [8, 12],
    code: `import os       # dosya kontrolÃ¼
import math     # math.log, math.exp
import random   # random.seed, random.choices
import argparse # komut satÄ±rÄ± argÃ¼manlarÄ±`,
    notes: [
      "Sadece 4 standart kÃ¼tÃ¼phane â€” hiÃ§bir pip install yok!",
      "os: input.txt var mÄ± diye kontrol eder",
      "math: log (loss hesabÄ±) ve exp (softmax) iÃ§in",
      "random: parametre baÅŸlatma ve sampling iÃ§in",
    ]
  },
  "week0_s7": {
    label: "microgpt.py â€¢ satÄ±r 14-27",
    lines: [14, 27],
    code: `# CLI arguments
parser = argparse.ArgumentParser()
parser.add_argument('--n_embd', type=int,
    default=16)
parser.add_argument('--n_layer', type=int,
    default=1)
parser.add_argument('--block_size', type=int,
    default=8)
parser.add_argument('--num_steps', type=int,
    default=1000)
parser.add_argument('--n_head', type=int,
    default=4)
parser.add_argument('--learning_rate', type=float,
    default=1e-2)
parser.add_argument('--seed', type=int,
    default=42)
args = parser.parse_args()
random.seed(args.seed)
n_embd, block_size, n_layer, n_head = \\
    args.n_embd, args.block_size, \\
    args.n_layer, args.n_head
head_dim = n_embd // n_head`,
    notes: [
      "argparse: komut satÄ±rÄ±ndan parametre deÄŸiÅŸtirmeye izin verir",
      "TÃ¼m varsayÄ±lanlar (16, 1, 8, 1000, 4, 0.01, 42) burada",
      "head_dim = n_embd // n_head = 16 // 4 = 4",
      "random.seed(42): tekrarlanabilirlik iÃ§in sabit tohum",
    ]
  },
  "week0_s8": {
    label: "microgpt.py â€¢ satÄ±r 29-36",
    lines: [29, 36],
    code: `# Dataset: names dataset (one name per line)
if not os.path.exists('input.txt'):
    import urllib.request
    urllib.request.urlretrieve(
      'https://raw.githubusercontent.com/'
      'karpathy/makemore/refs/heads/master/'
      'names.txt', 'input.txt')
with open('input.txt', 'r') as file:
    text = file.read()
docs = [line.strip()
    for line in text.strip().split('\\n')
    if line.strip()]
random.shuffle(docs)`,
    notes: [
      "Veri yoksa otomatik indirir (32K Ä°ngilizce isim)",
      "Her satÄ±r bir 'dokÃ¼man' (isim)",
      "shuffle â†’ eÄŸitim sÄ±rasÄ±nda rastgele sÄ±ra",
      "Kendi input.txt dosyanÄ±zla deÄŸiÅŸtirebilirsiniz!",
    ]
  },
  // WEEK 1 â€” Tokenizer
  "week1_s2": {
    label: "microgpt.py â€¢ satÄ±r 38-44",
    lines: [38, 44],
    code: `# Tokenizer: character-level with BOS/EOS
chars = ['<BOS>', '<EOS>'] + \\
    sorted(list(set(''.join(docs))))
vocab_size = len(chars)
stoi = {ch:i for i,ch in enumerate(chars)}
itos = {i:ch for i,ch in enumerate(chars)}
BOS, EOS = stoi['<BOS>'], stoi['<EOS>']
print(f"vocab size: {vocab_size}")`,
    notes: [
      "chars: ['<BOS>','<EOS>','a','b',...,'z'] â†’ 28 token",
      "stoi: stringâ†’integer sÃ¶zlÃ¼ÄŸÃ¼ (Ã¶rn: 'a'â†’2)",
      "itos: integerâ†’string sÃ¶zlÃ¼ÄŸÃ¼ (Ã¶rn: 2â†’'a')",
      "BOS=0, EOS=1: Ã¶zel baÅŸlangÄ±Ã§/bitiÅŸ tokenlarÄ±",
    ]
  },
  // WEEK 1 â€” Embedding & Model Init
  "week1_s4": {
    label: "microgpt.py â€¢ satÄ±r 107-119",
    lines: [107, 119],
    code: `# Model parameter initialization
matrix = lambda nout, nin, std=0.02: \\
  [[Value(random.gauss(0, std))
    for _ in range(nin)]
   for _ in range(nout)]

state_dict = {
  'wte': matrix(vocab_size, n_embd),  # [28Ã—16]
  'wpe': matrix(block_size, n_embd),  # [8Ã—16]
}
for i in range(n_layer):
  state_dict[f'layer{i}.attn_wq'] = \\
      matrix(n_embd, n_embd)           # [16Ã—16]
  state_dict[f'layer{i}.attn_wk'] = \\
      matrix(n_embd, n_embd)
  state_dict[f'layer{i}.attn_wv'] = \\
      matrix(n_embd, n_embd)
  state_dict[f'layer{i}.attn_wo'] = \\
      matrix(n_embd, n_embd, std=0)    # sÄ±fÄ±r init!
  state_dict[f'layer{i}.mlp_fc1'] = \\
      matrix(4*n_embd, n_embd)         # [64Ã—16]
  state_dict[f'layer{i}.mlp_fc2'] = \\
      matrix(n_embd, 4*n_embd, std=0)  # [16Ã—64]

params = [p for mat in state_dict.values()
          for row in mat for p in row]`,
    notes: [
      "matrix(): her eleman bir Value nesnesi â†’ autograd'a baÄŸlÄ±",
      "wte: token embedding [28Ã—16] â€” her token 16-dim vektÃ¶r",
      "wpe: pozisyon embedding [8Ã—16] â€” her pozisyon 16-dim",
      "attn_wo ve mlp_fc2 sÄ±fÄ±r std ile baÅŸlar (residual kararlÄ±lÄ±ÄŸÄ±)",
      "params: tÃ¼m Ã¶ÄŸrenilebilir parametrelerin dÃ¼z listesi â†’ optimizer iÃ§in",
    ]
  },
  // WEEK 1 â€” Softmax
  "week1_s8": {
    label: "microgpt.py â€¢ satÄ±r 124-128",
    lines: [124, 128],
    code: `def softmax(logits):
    max_val = max(v.data for v in logits)
    exps = [(v - max_val).exp()
            for v in logits]
    total = sum(exps)
    return [e / total for e in exps]`,
    notes: [
      "max_val Ã§Ä±karma: sayÄ±sal kararlÄ±lÄ±k (exp overflow Ã¶nleme)",
      "Her logit â†’ exp(logit - max) â†’ normalize",
      "Ã‡Ä±ktÄ±: toplamÄ± 1 olan olasÄ±lÄ±k daÄŸÄ±lÄ±mÄ±",
      "Value nesneleri Ã¼zerinde â†’ autograd backward Ã§alÄ±ÅŸÄ±r",
    ]
  },
  // WEEK 2 â€” Autograd Value class
  "week2_s3": {
    label: "microgpt.py â€¢ satÄ±r 47-63",
    lines: [47, 63],
    code: `class Value:
  """stores a single scalar value
     and its gradient"""

  def __init__(self, data,
               _children=(), _op=''):
    self.data = data
    self.grad = 0
    self._backward = lambda: None
    self._prev = set(_children)
    self._op = _op

  def __add__(self, other):
    other = other if isinstance(other, Value)\\
            else Value(other)
    out = Value(self.data + other.data,
                (self, other), '+')
    def _backward():
      self.grad += out.grad   # âˆ‚L/âˆ‚a += âˆ‚L/âˆ‚out
      other.grad += out.grad  # âˆ‚L/âˆ‚b += âˆ‚L/âˆ‚out
    out._backward = _backward
    return out`,
    notes: [
      "data: sayÄ±sal deÄŸer, grad: gradient (baÅŸlangÄ±Ã§ta 0)",
      "_backward: chain rule fonksiyonu (her operasyon kendini tanÄ±mlar)",
      "_prev: bu dÃ¼ÄŸÃ¼mÃ¼ oluÅŸturan Ã§ocuk dÃ¼ÄŸÃ¼mler (graf baÄŸlantÄ±sÄ±)",
      "grad += : kritik! = deÄŸil += Ã§Ã¼nkÃ¼ birden fazla yol olabilir",
      "__add__: a + b â†’ âˆ‚L/âˆ‚a = âˆ‚L/âˆ‚out, âˆ‚L/âˆ‚b = âˆ‚L/âˆ‚out",
    ]
  },
  "week2_s4": {
    label: "microgpt.py â€¢ satÄ±r 65-90",
    lines: [65, 90],
    code: `  def __mul__(self, other):
    other = other if isinstance(other, Value)\\
            else Value(other)
    out = Value(self.data * other.data,
                (self, other), '*')
    def _backward():
      self.grad += other.data * out.grad
      other.grad += self.data * out.grad
    out._backward = _backward
    return out

  def __pow__(self, other):
    out = Value(self.data**other, (self,),
                f'**{other}')
    def _backward():
      self.grad += (other * self.data**(other-1))\\
                   * out.grad
    out._backward = _backward
    return out

  def log(self):
    out = Value(math.log(self.data),
                (self,), 'log')
    def _backward():
      self.grad += (1/self.data) * out.grad
    out._backward = _backward
    return out

  def exp(self):
    out = Value(math.exp(self.data),
                (self,), 'exp')
    def _backward():
      self.grad += out.data * out.grad
    out._backward = _backward
    return out

  def relu(self):
    out = Value(0 if self.data < 0
                else self.data, (self,), 'ReLU')
    def _backward():
      self.grad += (out.data > 0) * out.grad
    out._backward = _backward
    return out`,
    notes: [
      "mul: âˆ‚(aÃ—b)/âˆ‚a = b, âˆ‚(aÃ—b)/âˆ‚b = a â†’ Ã§apraz kuralÄ±",
      "pow: âˆ‚(x^n)/âˆ‚x = nÂ·x^(n-1) â†’ power rule",
      "log: âˆ‚log(x)/âˆ‚x = 1/x â†’ cross-entropy loss'ta kullanÄ±lÄ±r",
      "exp: âˆ‚exp(x)/âˆ‚x = exp(x) â†’ softmax'ta kullanÄ±lÄ±r",
      "relu: x>0 â†’ gradient geÃ§er, x<0 â†’ gradient 0 (kapÄ± gibi)",
    ]
  },
  // WEEK 2 â€” Backward
  "week2_s6": {
    label: "microgpt.py â€¢ satÄ±r 92-103",
    lines: [92, 103],
    code: `  def backward(self):
    # topological order all children in graph
    topo = []
    visited = set()
    def build_topo(v):
      if v not in visited:
        visited.add(v)
        for child in v._prev:
          build_topo(child)
        topo.append(v)
    build_topo(self)
    # apply chain rule to get gradients
    self.grad = 1
    for v in reversed(topo):
      v._backward()`,
    notes: [
      "build_topo: DFS ile hesaplama grafÄ±nÄ± topolojik sÄ±raya dizer",
      "self.grad = 1: loss'un kendine gÃ¶re gradientÄ± = 1 (baÅŸlangÄ±Ã§)",
      "reversed(topo): Ã§Ä±ktÄ±dan giriÅŸe doÄŸru geri yayÄ±lÄ±m",
      "v._backward(): her dÃ¼ÄŸÃ¼m kendi chain rule'Ä±nÄ± uygular",
    ]
  },
  // WEEK 3 â€” Attention in gpt()
  "week3_s2": {
    label: "microgpt.py â€¢ satÄ±r 136-157",
    lines: [136, 157],
    code: `def gpt(token_id, pos_id, keys, values):
  tok_emb = state_dict['wte'][token_id]
  pos_emb = state_dict['wpe'][pos_id % block_size]
  x = [t + p for t, p in zip(tok_emb, pos_emb)]

  for li in range(n_layer):
    # 1) Multi-head attention block
    x_residual = x
    x = rmsnorm(x)
    q = linear(x, state_dict[f'layer{li}.attn_wq'])
    k = linear(x, state_dict[f'layer{li}.attn_wk'])
    val = linear(x, state_dict[f'layer{li}.attn_wv'])
    keys[li].append(k)
    values[li].append(val)
    x_attn = []
    for h in range(n_head):
      hs = h * head_dim
      q_h = q[hs:hs+head_dim]
      k_h = [ki[hs:hs+head_dim]
             for ki in keys[li]]
      v_h = [vi[hs:hs+head_dim]
             for vi in values[li]]`,
    notes: [
      "gpt(): TEK bir token adÄ±mÄ± iÅŸler (autoregressive)",
      "tok_emb + pos_emb: token ve pozisyon bilgisi birleÅŸir",
      "rmsnorm â†’ Q,K,V projeksiyonu â†’ KV cache'e ekle",
      "Her head kendi dilimini alÄ±r: q[hs:hs+head_dim]",
      "keys/values liste olarak birikir â†’ KV Cache!",
    ]
  },
  "week3_s4": {
    label: "microgpt.py â€¢ satÄ±r 158-167",
    lines: [158, 167],
    code: `      attn_logits = [
        sum(q_h[j] * k_h[t][j]
            for j in range(head_dim))
        / head_dim**0.5
        for t in range(len(k_h))
      ]
      attn_weights = softmax(attn_logits)
      head_out = [
        sum(attn_weights[t] * v_h[t][j]
            for t in range(len(v_h)))
        for j in range(head_dim)
      ]
      x_attn.extend(head_out)`,
    notes: [
      "QÂ·K dot product: her geÃ§miÅŸ tokena uyum skoru",
      "/ head_dim**0.5: scaling trick (âˆš4 = 2)",
      "softmax: skorlarÄ± olasÄ±lÄ±klara Ã§evirir",
      "V'nin aÄŸÄ±rlÄ±klÄ± toplamÄ±: dikkat edilen bilgi",
      "extend: tÃ¼m head'lerin Ã§Ä±ktÄ±larÄ± birleÅŸtirilir",
    ]
  },
  // WEEK 4 â€” MLP block & residual
  "week4_s2": {
    label: "microgpt.py â€¢ satÄ±r 130-134",
    lines: [130, 134],
    code: `def rmsnorm(x):
    ms = sum(xi * xi for xi in x) / len(x)
    scale = (ms + 1e-5) ** -0.5
    return [xi * scale for xi in x]`,
    notes: [
      "ms = ortalama kare (mean square) â†’ vektÃ¶rÃ¼n 'enerjisi'",
      "1e-5: sÄ±fÄ±ra bÃ¶lÃ¼nmeyi Ã¶nleyen kÃ¼Ã§Ã¼k sayÄ± (epsilon)",
      "scale = 1/âˆšms: her elemanÄ± bu ile Ã§arp â†’ norm â‰ˆ 1",
      "LayerNorm'dan fark: mean Ã§Ä±karma yok â†’ daha hÄ±zlÄ±",
    ]
  },
  "week4_s3": {
    label: "microgpt.py â€¢ satÄ±r 170-177",
    lines: [170, 177],
    code: `    # 2) MLP block
    x_residual = x
    x = rmsnorm(x)
    x = linear(x, state_dict[f'layer{li}.mlp_fc1'])
    x = [xi.relu() ** 2 for xi in x]  # ReLUÂ²
    x = linear(x, state_dict[f'layer{li}.mlp_fc2'])
    x = [a + b for a, b in zip(x, x_residual)]`,
    notes: [
      "x_residual = x: skip connection iÃ§in girdiyi sakla",
      "rmsnorm â†’ linear (16â†’64) â†’ ReLUÂ² â†’ linear (64â†’16)",
      "relu()**2: negatifler 0, pozitifler karesel bÃ¼yÃ¼r (sparse!)",
      "x + x_residual: residual connection â€” gradient highway",
    ]
  },
  "week4_s5": {
    label: "microgpt.py â€¢ satÄ±r 168-169, 179-180",
    lines: [168, 180],
    code: `    x = linear(x_attn,
      state_dict[f'layer{li}.attn_wo'])
    x = [a+b for a,b in zip(x, x_residual)]
    # ... (MLP block) ...
    x = [a+b for a,b in zip(x, x_residual)]

  # project to vocab (weight tying with wte)
  logits = linear(x, state_dict['wte'])
  return logits`,
    notes: [
      "Ä°ki residual: biri attention sonrasÄ±, biri MLP sonrasÄ±",
      "weight tying: wte hem giriÅŸte hem Ã§Ä±kÄ±ÅŸta kullanÄ±lÄ±r",
      "logits = son vektÃ¶rÃ¼n vocab boyutuna projeksiyonu [28]",
    ]
  },
  // WEEK 4 â€” Linear function
  "week4_s0": {
    label: "microgpt.py â€¢ satÄ±r 122-123",
    lines: [122, 123],
    code: `def linear(x, w):
    return [sum(w[o][i] * x[i]
            for i in range(len(x)))
            for o in range(len(w))]`,
    notes: [
      "Matris-vektÃ¶r Ã§arpÄ±mÄ±: y = WÂ·x",
      "Her Ã§Ä±ktÄ± elemanÄ± = aÄŸÄ±rlÄ±k satÄ±rÄ± Â· giriÅŸ vektÃ¶rÃ¼ (dot product)",
      "Attention, MLP, projeksiyon â€” HER YERDE kullanÄ±lÄ±r",
    ]
  },
  // WEEK 5 â€” Training loop
  "week5_s2": {
    label: "microgpt.py â€¢ satÄ±r 188-205",
    lines: [188, 205],
    code: `for step in range(args.num_steps):

  # Tokenize a document, crop to block_size
  doc = docs[step % len(docs)]
  tokens = [BOS] + [stoi[ch] for ch in doc] \\
           + [EOS]
  tokens = tokens[:block_size]

  # Forward pass over time dimension
  keys, values = [[] for _ in range(n_layer)],\\
                 [[] for _ in range(n_layer)]
  lossf = 0.0
  for pos_id in range(len(tokens) - 1):
    logits = gpt(tokens[pos_id], pos_id,
                 keys, values)
    probs = softmax(logits)
    loss = -probs[tokens[pos_id + 1]].log()
    loss = (1/(len(tokens)-1)) * loss
    loss.backward()
    lossf += loss.data`,
    notes: [
      "Her adÄ±mda TEK dokÃ¼man (isim) iÅŸlenir â†’ SGD",
      "tokens: [BOS, 'e', 'm', 'm', 'a', EOS] â†’ [:8] kÄ±rp",
      "Her pozisyonda: gpt() â†’ softmax â†’ loss â†’ backward",
      "-log(P(doÄŸru)): cross-entropy loss â†’ ne kadar yanlÄ±ÅŸ?",
      "backward(): hesaplama grafÄ±ndan tÃ¼m gradientler hesaplanÄ±r",
    ]
  },
  // WEEK 5 â€” Adam optimizer
  "week5_s5": {
    label: "microgpt.py â€¢ satÄ±r 183-186, 207-216",
    lines: [183, 216],
    code: `# Adam optimizer setup
learning_rate = args.learning_rate  # 0.01
beta1, beta2, eps_adam = 0.9, 0.95, 1e-8
m = [0.0] * len(params) # first moment
v = [0.0] * len(params) # second moment

  # Adam update (in training loop)
  lr_t = learning_rate * (1 - step/args.num_steps)
  for i, p in enumerate(params):
    m[i] = beta1*m[i] + (1-beta1)*p.grad
    v[i] = beta2*v[i] + (1-beta2)*p.grad**2
    m_hat = m[i] / (1 - beta1**(step+1))
    v_hat = v[i] / (1 - beta2**(step+1))
    p.data -= lr_t * m_hat / (v_hat**0.5 + eps_adam)
    p.grad = 0  # KRÄ°TÄ°K: gradient sÄ±fÄ±rla`,
    notes: [
      "m: momentum (gradient yÃ¶nÃ¼ ortalamasÄ±) â†’ dÃ¼zgÃ¼n ilerleme",
      "v: variance (gradient bÃ¼yÃ¼klÃ¼ÄŸÃ¼ ortalamasÄ±) â†’ adaptif LR",
      "bias correction: erken adÄ±mlarda m ve v kÃ¼Ã§Ã¼k â†’ dÃ¼zelt",
      "lr_t: linear decay â€” eÄŸitim ilerledikÃ§e LR azalÄ±r",
      "p.grad = 0: HER adÄ±mda sÄ±fÄ±rla yoksa gradientler birikir!",
    ]
  },
  // WEEK 6 â€” Inference
  "week6_s1": {
    label: "microgpt.py â€¢ satÄ±r 219-232",
    lines: [219, 232],
    code: `# Inference: generate 5 samples
print("\\n--- generation ---")
for sample_idx in range(5):
  keys, values = [[] for _ in range(n_layer)],\\
                 [[] for _ in range(n_layer)]
  token_id = BOS
  generated = []
  for pos_id in range(block_size):
    logits = gpt(token_id, pos_id,
                 keys, values)
    probs = softmax(logits)
    token_id = random.choices(
      range(vocab_size),
      weights=[p.data for p in probs])[0]
    if token_id == EOS:
      break
    generated.append(itos[token_id])
  print(f"sample {sample_idx}: "
        f"{''.join(generated)}")`,
    notes: [
      "EÄŸitimden farklÄ±: backward() YOK â€” sadece forward",
      "BOS ile baÅŸla â†’ her adÄ±mda bir token Ã¼ret â†’ EOS'ta dur",
      "random.choices: olasÄ±lÄ±klara gÃ¶re rastgele seÃ§im (sampling)",
      "KV cache: keys/values birikir â†’ Ã¶nceki tokenlar tekrar hesaplanmaz",
      "p.data: Value nesnesinin ham sayÄ±sÄ±nÄ± al (grad gerekmez)",
    ]
  },
  // WEEK 6 â€” Temperature (conceptual â€” real code doesn't have T)
  "week6_s2": {
    label: "microgpt.py'ye temperature ekleme",
    lines: [0, 0],
    code: `# Orijinal kodda temperature YOK â€”
# Eklemek basit:
probs = softmax(logits)  # orijinal

# Temperature eklenmiÅŸ hali:
scaled = [l / temperature for l in logits]
probs = softmax(scaled)

# T=0.5 â†’ sivri (deterministik)
# T=1.0 â†’ normal (dengeli)
# T=2.0 â†’ dÃ¼z (yaratÄ±cÄ±/rastgele)`,
    notes: [
      "Orijinal microgpt.py'de temperature parametresi yok",
      "Logit'leri T'ye bÃ¶lmek softmax daÄŸÄ±lÄ±mÄ±nÄ± kontrol eder",
      "Bu ders aracÄ±nda (Lab) temperature ayarlayabilirsiniz",
    ]
  }
};

// â”€â”€â”€ FULL CODE MAP â€” tÃ¼m microgpt.py renk kodlu â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const CODE_MAP_SECTIONS = [
  { name: lang==="tr"?"AÃ§Ä±klama & Ä°mportlar":"Description & Imports", lines: [1, 12], color: "#64748B", week: 0 },
  { name: lang==="tr"?"Hiperparametreler (CLI)":"Hyperparameters (CLI)", lines: [13, 27], color: "#0EA5E9", week: 0 },
  { name: lang==="tr"?"Dataset YÃ¼kleme":"Dataset Loading", lines: [29, 36], color: "#0EA5E9", week: 0 },
  { name: "Tokenizer", lines: [38, 44], color: "#8B5CF6", week: 1 },
  { name: lang==="tr"?"Value SÄ±nÄ±fÄ± (Autograd)":"Value Class (Autograd)", lines: [47, 105], color: "#F59E0B", week: 2 },
  { name: lang==="tr"?"Parametre BaÅŸlatma":"Parameter Init", lines: [107, 119], color: "#8B5CF6", week: 1 },
  { name: "linear() & softmax()", lines: [122, 128], color: "#10B981", week: 3 },
  { name: "rmsnorm()", lines: [130, 134], color: "#EC4899", week: 4 },
  { name: "gpt() â€” Attention", lines: [136, 167], color: "#10B981", week: 3 },
  { name: "gpt() â€” MLP & Residual", lines: [168, 180], color: "#EC4899", week: 4 },
  { name: "Adam Optimizer Setup", lines: [183, 186], color: "#EF4444", week: 5 },
  { name: lang==="tr"?"EÄŸitim DÃ¶ngÃ¼sÃ¼":"Training Loop", lines: [188, 216], color: "#EF4444", week: 5 },
  { name: "Inference & Sampling", lines: [219, 232], color: "#6366F1", week: 6 },
];

const RealCodeBlock = ({ data, weekColor }) => {
  const [expanded, setExpanded] = useState(false);
  if (!data) return null;
  return (
    <div style={{ margin: "14px 0", borderRadius: 14, overflow: "hidden", border: "1px solid rgba(245,158,11,0.2)", background: "rgba(245,158,11,0.03)" }}>
      <button onClick={() => setExpanded(!expanded)} style={{
        width: "100%", display: "flex", alignItems: "center", justifyContent: "space-between", padding: "10px 16px",
        background: "rgba(245,158,11,0.06)", border: "none", cursor: "pointer", fontFamily: "inherit"
      }}>
        <div style={{ display: "flex", alignItems: "center", gap: 8 }}>
          <span style={{ fontSize: 17 }}>ğŸ“„</span>
          <span style={{ fontSize: 14, fontWeight: 700, color: "#F59E0B", fontFamily: "'Fira Code', monospace" }}>{data.label}</span>
        </div>
        <div style={{ display: "flex", alignItems: "center", gap: 6 }}>
          <span style={{ fontSize: 12, color: "#64748B", padding: "2px 8px", borderRadius: 4, background: "rgba(255,255,255,0.05)" }}>{lang==="tr"?"GerÃ§ek Kod":"Real Code"}</span>
          <span style={{ fontSize: 15, color: "#94A3B8", transition: "transform .2s", transform: expanded ? "rotate(180deg)" : "rotate(0)" }}>â–¼</span>
        </div>
      </button>
      {expanded && (
        <div style={{ padding: "0 16px 14px" }}>
          <pre style={{ margin: "8px 0", padding: 14, borderRadius: 10, background: "#0D1117", border: "1px solid rgba(255,255,255,0.06)", overflowX: "auto", fontFamily: "'Fira Code', monospace", fontSize: 14, lineHeight: 1.6, color: "#E6EDF3", whiteSpace: "pre-wrap" }}>{data.code}</pre>
          {data.notes && (
            <div style={{ display: "flex", flexDirection: "column", gap: 4, marginTop: 6 }}>
              {data.notes.map((note, i) => (
                <div key={i} style={{ display: "flex", alignItems: "flex-start", gap: 8, fontSize: 14, color: "#94A3B8", lineHeight: 1.4 }}>
                  <span style={{ color: "#F59E0B", fontSize: 13, marginTop: 2, flexShrink: 0 }}>â–¸</span>
                  {note}
                </div>
              ))}
            </div>
          )}
        </div>
      )}
    </div>
  );
};

const CodeMapPanel = ({ onClose }) => (
  <div style={{ position: "fixed", inset: 0, background: "rgba(0,0,0,0.7)", zIndex: 100, display: "flex", justifyContent: "center", alignItems: "center", padding: 20 }} onClick={onClose}>
    <div onClick={e => e.stopPropagation()} style={{ width: "100%", maxWidth: 700, maxHeight: "90vh", background: "#0D1117", borderRadius: 20, border: "1px solid rgba(255,255,255,0.1)", overflow: "hidden", display: "flex", flexDirection: "column" }}>
      <div style={{ padding: "16px 24px", borderBottom: "1px solid rgba(255,255,255,0.06)", display: "flex", justifyContent: "space-between", alignItems: "center" }}>
        <div>
          <div style={{ fontSize: 19, fontWeight: 800, color: "#E2E8F0" }}>ğŸ—ºï¸ Kod HaritasÄ± â€” microgpt.py</div>
          <div style={{ fontSize: 14, color: "#64748B" }}>243 satÄ±r, haftalara gÃ¶re renk kodlu</div>
        </div>
        <button onClick={onClose} style={{ width: 32, height: 32, borderRadius: 8, border: "none", background: "rgba(255,255,255,0.06)", color: "#94A3B8", fontSize: 19, cursor: "pointer" }}>âœ•</button>
      </div>
      <div style={{ flex: 1, overflowY: "auto", padding: 20 }}>
        <div style={{ display: "flex", flexWrap: "wrap", gap: 6, marginBottom: 16 }}>
          {CODE_MAP_SECTIONS.map((s, i) => (
            <div key={i} style={{ display: "flex", alignItems: "center", gap: 4, padding: "3px 8px", borderRadius: 6, background: `${s.color}12`, border: `1px solid ${s.color}30` }}>
              <div style={{ width: 8, height: 8, borderRadius: 2, background: s.color }} />
              <span style={{ fontSize: 12, color: s.color, fontWeight: 600 }}>H{s.week}</span>
              <span style={{ fontSize: 12, color: "#94A3B8" }}>{s.name}</span>
            </div>
          ))}
        </div>
        <div style={{ display: "flex", flexDirection: "column", gap: 2 }}>
          {CODE_MAP_SECTIONS.map((s, i) => (
            <div key={i} style={{ borderRadius: 10, overflow: "hidden", border: `1px solid ${s.color}20` }}>
              <div style={{ padding: "6px 12px", background: `${s.color}10`, display: "flex", justifyContent: "space-between", alignItems: "center" }}>
                <span style={{ fontSize: 13, fontWeight: 700, color: s.color }}>{s.name}</span>
                <span style={{ fontSize: 12, color: "#64748B", fontFamily: "'Fira Code', monospace" }}>satÄ±r {s.lines[0]}-{s.lines[1]} â€¢ Hafta {s.week}</span>
              </div>
              <div style={{ height: Math.max(4, (s.lines[1] - s.lines[0] + 1) * 0.8), background: `${s.color}08`, borderTop: `1px solid ${s.color}10` }} />
            </div>
          ))}
        </div>
        <div style={{ marginTop: 16, padding: 14, borderRadius: 10, background: "rgba(255,255,255,0.02)", border: "1px solid rgba(255,255,255,0.05)" }}>
          <div style={{ fontSize: 14, fontWeight: 700, color: "#E2E8F0", marginBottom: 6 }}>ğŸ“Š SatÄ±r DaÄŸÄ±lÄ±mÄ±</div>
          <div style={{ display: "flex", height: 20, borderRadius: 6, overflow: "hidden", gap: 1 }}>
            {CODE_MAP_SECTIONS.map((s, i) => (
              <div key={i} style={{ flex: s.lines[1] - s.lines[0] + 1, background: s.color, minWidth: 2 }} title={`${s.name}: ${s.lines[1] - s.lines[0] + 1} satÄ±r`} />
            ))}
          </div>
          <div style={{ display: "flex", justifyContent: "space-between", marginTop: 4 }}>
            <span style={{ fontSize: 12, color: "#64748B" }}>satÄ±r 1</span>
            <span style={{ fontSize: 12, color: "#64748B" }}>satÄ±r 243</span>
          </div>
        </div>
      </div>
    </div>
  </div>
);

// â”€â”€â”€ INSTRUCTOR NOTES â€” Hoca Modu Verileri â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// â”€â”€â”€ SLIDE REFERENCES â€” Slaytâ†”Explorer KÃ¶prÃ¼ HaritasÄ± â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const EMBEDDED_SLIDES = {
  "week0_s0": [
    {
      title: "Dil Modeli Nedir?",
      desc: "Bir dil modeli, verilen bir sÃ¶zcÃ¼k dizisinden sonra hangi sÃ¶zcÃ¼ÄŸÃ¼n geleceÄŸini tahmin eden bir sistemdir. Her olasÄ± sonraki sÃ¶zcÃ¼ÄŸe bir olasÄ±lÄ±k atar ve bu olasÄ±lÄ±klarÄ± kullanarak metin Ã¼retebilir.",
      formula: "P(wâ‚™ | wâ‚, wâ‚‚, ..., wâ‚™â‚‹â‚)",
      example: { input: "BugÃ¼n hava Ã§ok ___", output: "gÃ¼zel (%40)  sÄ±cak (%25)  soÄŸuk (%15)  kÃ¶tÃ¼ (%10)  ..." },
      code: "logits = self.head(x)        # her token iÃ§in skor\nprobs = F.softmax(logits, dim=-1)  # olasÄ±lÄ±k daÄŸÄ±lÄ±mÄ±",
      keyPoint: "N-gram modeli sadece son 2-3 sÃ¶zcÃ¼ÄŸe bakar. BDM (GPT, Claude) TÃœM Ã¶nceki sÃ¶zcÃ¼klere bakar â€” bu yÃ¼zden Ã§ok daha gÃ¼Ã§lÃ¼.",
    },
    {
      title: "BDM'ler NasÄ±l Ã‡alÄ±ÅŸÄ±r?",
      desc: "BÃ¼yÃ¼k dil modelleri, muazzam miktarda metin Ã¼zerinde 'sonraki sÃ¶zcÃ¼ÄŸÃ¼ tahmin et' gÃ¶revi ile eÄŸitilir. Bu basit gÃ¶revle dil yapÄ±sÄ±nÄ±, dÃ¼nya bilgisini ve akÄ±l yÃ¼rÃ¼tmeyi Ã¶ÄŸrenirler.",
      example: { input: "The water of Walden Pond is beautifully ___", output: "blue (%32)  clear (%28)  green (%18)  cold (%8)  ..." },
      keyPoint: "EÄŸitim = sonraki sÃ¶zcÃ¼ÄŸÃ¼ tahmin et. Bu kadar basit ama bu kadar gÃ¼Ã§lÃ¼.",
    },
  ],
  "week0_s1": [
    {
      title: "Sinir AÄŸÄ± Birimi: AÄŸÄ±rlÄ±klÄ± Toplam + Aktivasyon",
      desc: "Yapay sinir aÄŸÄ±nÄ±n temel birimi Ã§ok basittir: girdilerin aÄŸÄ±rlÄ±klÄ± toplamÄ±nÄ± al, bir yanlÄ±lÄ±k (bias) ekle, sonra doÄŸrusal olmayan bir fonksiyondan geÃ§ir.",
      formula: "y = f(wâ‚xâ‚ + wâ‚‚xâ‚‚ + ... + wâ‚™xâ‚™ + b) = f(wÂ·x + b)",
      example: { input: "Girdiler: xâ‚=0.5, xâ‚‚=0.8 | AÄŸÄ±rlÄ±klar: wâ‚=0.3, wâ‚‚=0.7", output: "z = 0.3Ã—0.5 + 0.7Ã—0.8 + b = 0.71 + b â†’ y = Ïƒ(z)" },
      code: "# PyTorch'ta bir sinir birimi:\ny = torch.sigmoid(w @ x + b)",
      keyPoint: "AÄŸÄ±rlÄ±klar her girdinin ne kadar Ã¶nemli olduÄŸunu belirler. EÄŸitim = bu aÄŸÄ±rlÄ±klarÄ± ayarlamak.",
    },
  ],
  "week0_s2": [
    {
      title: "Dil Modeli: OlasÄ±lÄ±k DaÄŸÄ±lÄ±mÄ±",
      desc: "Dil modeli, Ã¶nceki sÃ¶zcÃ¼kler verildiÄŸinde sonraki sÃ¶zcÃ¼k Ã¼zerinde bir olasÄ±lÄ±k daÄŸÄ±lÄ±mÄ± verir. Bunu tekrarlayarak cÃ¼mle, paragraf, hatta kitap Ã¼retebilir.",
      formula: "P(wâ‚wâ‚‚...wâ‚™) = P(wâ‚) Ã— P(wâ‚‚|wâ‚) Ã— P(wâ‚ƒ|wâ‚wâ‚‚) Ã— ...",
      example: { input: "Ben okula ___", output: "gidiyorum (%45)  gittim (%20)  gitmek (%15)  ..." },
      code: "# microGPT Ã¼retim dÃ¶ngÃ¼sÃ¼:\nfor _ in range(max_new_tokens):\n    logits = model(context)\n    probs = F.softmax(logits[:,-1,:], dim=-1)\n    next_token = torch.multinomial(probs, 1)",
      keyPoint: "Dil modeli = koÅŸullu olasÄ±lÄ±k makinesi. Kelime kelime tahmin ederek metin Ã¼retir.",
    },
  ],
  "week0_s3": [
    {
      title: "CanlÄ± Pipeline: Girdi â†’ Ã‡Ä±ktÄ±",
      desc: "microGPT tam bir dil modeli pipeline'Ä± uygular: metin giriÅŸi â†’ tokenization â†’ embedding â†’ transformer â†’ olasÄ±lÄ±k â†’ Ã¶rnekleme â†’ Ã§Ä±ktÄ± metni.",
      example: { input: "microGPT girdi: 'Ah'", output: "Token ID: [15] â†’ Embedding â†’ Transformer â†’ 'Ahmet' (%30), 'Ahmed' (%25)..." },
      code: "# 243 satÄ±rlÄ±k tam pipeline:\nencode â†’ wte + wpe â†’ attention â†’ mlp â†’ lm_head â†’ softmax â†’ decode",
      keyPoint: "GPT-4 ile microGPT aynÄ± algoritmayÄ± kullanÄ±r. Fark sadece Ã¶lÃ§ek: 3,648 vs ~1.8 trilyon parametre.",
    },
  ],
  "week0_s4": [
    {
      title: "XOR: Tek Katman Neden Yetmez?",
      desc: "Minsky ve Papert (1969) gÃ¶sterdi ki tek katmanlÄ± aÄŸ (perceptron) XOR gibi basit problemleri bile Ã§Ã¶zemez. DoÄŸrusal olarak ayrÄ±lamayan veriler iÃ§in gizli katman gerekir.",
      formula: "XOR(0,0)=0  XOR(0,1)=1  XOR(1,0)=1  XOR(1,1)=0",
      example: { input: "AND: tek Ã§izgiyle ayrÄ±lÄ±r âœ… | XOR: tek Ã§izgiyle AYRILAMAZ âŒ", output: "Ã‡Ã¶zÃ¼m: 2 katman â†’ ilk katman ara Ã¶zellikler Ã¼retir, ikinci katman bunlarÄ± birleÅŸtirir" },
      keyPoint: "Gizli katman = temsil gÃ¼cÃ¼. Bu yÃ¼zden 'derin' Ã¶ÄŸrenme diyoruz â€” derinlik karmaÅŸÄ±k fonksiyonlarÄ± mÃ¼mkÃ¼n kÄ±lar.",
    },
  ],
  "week0_s5": [
    {
      title: "Ã–n KoÅŸullar: Python & PyTorch Temelleri",
      desc: "microGPT'yi anlamak iÃ§in temel Python ve PyTorch bilgisi yeterli. KarmaÅŸÄ±k matematik yerine, kodun her satÄ±rÄ±nÄ±n ne yaptÄ±ÄŸÄ±nÄ± sezgisel olarak kavramak Ã¶nemli.",
      example: { input: "Gereken: Python deÄŸiÅŸkenler, dÃ¶ngÃ¼ler, fonksiyonlar", output: "PyTorch: tensor, matmul, nn.Module, backward()" },
      code: "import torch\nimport torch.nn as nn\n# Bu iki import ile microGPT yazÄ±labilir",
      keyPoint: "Derin Ã¶ÄŸrenme korkutucu deÄŸil â€” microGPT'nin 243 satÄ±rÄ± bunu kanÄ±tlÄ±yor.",
    },
  ],
  "week0_s6": [
    {
      title: "BDM Metin Ãœretim DÃ¶ngÃ¼sÃ¼",
      desc: "Metin Ã¼retimi otoregresif bir dÃ¶ngÃ¼dÃ¼r: her adÄ±mda model bir token Ã¼retir, bu token girdiye eklenir ve sonraki token iÃ§in tekrar model Ã§alÄ±ÅŸtÄ±rÄ±lÄ±r.",
      example: { input: "BaÅŸlangÄ±Ã§: [BOS] 'Merhaba'", output: "AdÄ±m 1: â†’ 'ben' | AdÄ±m 2: â†’ 'Ali' | AdÄ±m 3: â†’ [EOS] | SonuÃ§: 'Merhaba ben Ali'" },
      code: "# microGPT generate() dÃ¶ngÃ¼sÃ¼:\ncontext = seed_tokens\nfor _ in range(max_tokens):\n    next_tok = model.predict(context)\n    context = torch.cat([context, next_tok])",
      keyPoint: "Ãœretim = tekrarlÄ± tahmin. Her token Ã¶nceki tÃ¼m tokenlara koÅŸullu.",
    },
  ],
  "week0_s7": [
    {
      title: "7 Parametre: microGPT Kontrol Paneli",
      desc: "microGPT'nin davranÄ±ÅŸÄ± 7 parametreyle kontrol edilir. Her birini deÄŸiÅŸtirmek modelin kapasitesini, hÄ±zÄ±nÄ± ve Ã§Ä±ktÄ± kalitesini doÄŸrudan etkiler.",
      example: { input: "vocab=27, d=16, heads=4, layers=1, block=8", output: "Toplam: 3,648 parametre â†’ CPU'da 30 saniyede eÄŸitilir" },
      code: "n_embd = 16       # embedding boyutu (d)\nn_head = 4        # dikkat baÅŸlÄ±ÄŸÄ± sayÄ±sÄ±\nn_layer = 1       # transformer katman sayÄ±sÄ±\nblock_size = 8    # baÄŸlam penceresi\nvocab_size = 27   # a-z + boÅŸluk",
      keyPoint: "GPT-4: d=12288, heads=128, layers=120+. microGPT ile AYNI yapÄ± â€” sadece sayÄ±larÄ± bÃ¼yÃ¼t!",
    },
  ],
  "week0_s8": [
    {
      title: { tr: "Kendi Verinizi Kullanma", en: "Using Your Own Data" },
      desc: "microGPT herhangi bir metin verisiyle eÄŸitilebilir. VarsayÄ±lan TÃ¼rk isimleri yerine ÅŸiir, kod veya baÅŸka bir dil kullanÄ±labilir.",
      example: { input: "Veri: 'ali\\nmehmet\\nayÅŸe\\n...' (TÃ¼rk isimleri)", output: "Model Ã¶ÄŸrenir: TÃ¼rk isim kalÄ±plarÄ±, yaygÄ±n hece yapÄ±larÄ±, isim uzunluklarÄ±" },
      keyPoint: "Veri modelin 'dÃ¼nyasÄ±'dÄ±r. Ne verirseniz onu Ã¶ÄŸrenir.",
    },
  ],
  "week0_s9": [
    {
      title: "EÄŸitim Evrimi: Rastgeleden Anlama",
      desc: "EÄŸitimin baÅŸÄ±nda model tamamen rastgele tahmin yapar. Zaman iÃ§inde Ã¶nce sÄ±k harfleri, sonra hece kalÄ±plarÄ±nÄ±, sonunda gerÃ§ek isimlere benzeyen yapÄ±larÄ± Ã¶ÄŸrenir.",
      example: { input: "AdÄ±m 0: 'xqzpwm' (rastgele) â†’ AdÄ±m 100: 'aeiou' (sesli harfler)", output: "AdÄ±m 500: 'meher' (hece yapÄ±sÄ±) â†’ AdÄ±m 1000: 'mehmet' (gerÃ§ek isim!)" },
      keyPoint: "Loss eÄŸrisi dÃ¼ÅŸerken model Ã¶ÄŸreniyor. Loss platoya ulaÅŸÄ±nca model artÄ±k iyileÅŸmiyor.",
    },
  ],
  "week0_s10": [
    {
      title: "GPT Ailesi: microGPT â†’ GPT-4",
      desc: "microGPT'den GPT-4'e giden yol, aynÄ± algoritmanÄ±n Ã¶lÃ§eklenmesidir. Daha fazla parametre + daha fazla veri + daha fazla hesaplama = daha iyi performans.",
      formula: "Loss âˆ Nâ»â°Â·â°â·â¶ Ã— Dâ»â°Â·â°â¹âµ Ã— Câ»â°Â·â°âµâ°",
      example: { input: "microGPT: d=16, 1 katman â†’ 3,648 param", output: "GPT-3: d=12288, 96 katman â†’ 175,000,000,000 param (10â¸ kat!)" },
      keyPoint: "AynÄ± algoritma, 10â¸ kat parametre farkÄ±. Ã–lÃ§ekleme yasalarÄ± bunu Ã¶ngÃ¶rÃ¼lebilir kÄ±lÄ±yor.",
    },
  ],
  "week1_s0": [
    {
      title: "SÃ¶zcÃ¼k Sayma Problemi",
      desc: "Bir cÃ¼mledeki sÃ¶zcÃ¼k sayÄ±sÄ±nÄ± belirlemek bile zordur. Noktalama sayÄ±lÄ±r mÄ±? KÄ±saltmalar? BirleÅŸik sÃ¶zcÃ¼kler? Her dil farklÄ± kurallar gerektirir.",
      example: { input: "They picnicked by the pool, then lay back on the grass.", output: "16 sÃ¶zcÃ¼k (noktalama hariÃ§) / 18 sÃ¶zcÃ¼k (noktalama dahil) â€” hangisi doÄŸru?" },
      keyPoint: "TÃ¼r (type): benzersiz sÃ¶zcÃ¼k ('the' 1 kez sayÄ±lÄ±r). Ã–rnek (token): her geÃ§iÅŸ ('the' 3 kez sayÄ±lÄ±r).",
    },
    {
      title: "BPE: Alt SÃ¶zcÃ¼k Tokenization",
      desc: "Byte Pair Encoding, sÃ¶zcÃ¼kleri daha kÃ¼Ã§Ã¼k alt birimlere ayÄ±rÄ±r. En sÄ±k komÅŸu karakter Ã§iftlerini tekrar tekrar birleÅŸtirerek bir sÃ¶zcÃ¼k daÄŸarcÄ±ÄŸÄ± oluÅŸturur.",
      formula: "Tekrarla: en sÄ±k (A,B) Ã§iftini bul â†’ 'AB' olarak birleÅŸtir â†’ k kez",
      example: { input: "'newer' â†’ BPE â†’ ['new', 'er']", output: "'lowest' â†’ ['low', 'est']   Sistem ek yapÄ±sÄ±nÄ± keÅŸfetti!" },
      code: "# BPE Ã¶ÄŸrenici pseudocode:\nvocab = tÃ¼m_karakterler\nfor i in range(k):\n    pair = en_sÄ±k_komÅŸu_Ã§ift(corpus)\n    vocab.add(merge(pair))\n    corpus = replace_all(corpus, pair)",
      keyPoint: "BPE, bilinmeyen sÃ¶zcÃ¼k sorununu Ã§Ã¶zer: her sÃ¶zcÃ¼k alt parÃ§alara ayrÄ±labilir.",
    },
  ],
  "week1_s1": [
    {
      title: "Token, Vocab, Logit â€” Temel Kavramlar",
      desc: "Token metnin en kÃ¼Ã§Ã¼k birimidir. Vocab tÃ¼m olasÄ± tokenlerin listesidir. Logit modelin her token iÃ§in Ã¼rettiÄŸi ham skordur.",
      formula: "metin â†’ tokenizer â†’ [idâ‚, idâ‚‚, ...] â†’ model â†’ logits [1Ã—|V|] â†’ softmax â†’ olasÄ±lÄ±klar",
      example: { input: "microGPT vocab: a-z + boÅŸluk = 27 token", output: "GPT-4 vocab: ~100,000 token (tiktoken cl100k_base)" },
      code: "# microGPT encode/decode:\nstoi = {ch:i for i,ch in enumerate(chars)}  # 'a'â†’0, 'b'â†’1, ...\nencode = lambda s: [stoi[c] for c in s]\ndecode = lambda l: ''.join(itos[i] for i in l)",
      keyPoint: "Vocab bÃ¼yÃ¼klÃ¼ÄŸÃ¼ = modelin 'alfabe'si. KÃ¼Ã§Ã¼k vocab â†’ uzun diziler. BÃ¼yÃ¼k vocab â†’ kÄ±sa diziler ama daha fazla parametre.",
    },
  ],
  "week1_s2": [
    {
      title: "Token Embedding: ID â†’ VektÃ¶r",
      desc: "Her token ID'si, bir embedding matrisinden karÅŸÄ±lÄ±k gelen satÄ±r vektÃ¶rÃ¼nÃ¼ seÃ§er. Bu vektÃ¶r tokenin anlamÄ±nÄ± temsil eden sayÄ±sal bir koddur.",
      formula: "x = E[token_id]    E boyutu: [|V| Ã— d]",
      example: { input: "token_id = 5 ('f'), d = 16", output: "x = E[5] = [0.12, -0.34, 0.78, ...] (16 boyutlu vektÃ¶r)" },
      code: "# microGPT embedding:\nself.wte = nn.Embedding(vocab_size, n_embd)  # [27 Ã— 16]\ntok_emb = self.wte(token_ids)  # [batch, seq_len, 16]",
      keyPoint: "Embedding = arama tablosu. EÄŸitimle bu vektÃ¶rler anlamlÄ± hale gelir: benzer tokenlar yakÄ±n vektÃ¶rler alÄ±r.",
    },
  ],
  "week1_s3": [
    {
      title: "VektÃ¶r: SayÄ± Listesi ile Anlam Temsili",
      desc: "Bir vektÃ¶r, sabit uzunlukta bir sayÄ± listesidir. SÃ¶zcÃ¼kleri vektÃ¶rlerle temsil etmek, bilgisayarÄ±n anlam Ã¼zerinde matematik yapmasÄ±nÄ± saÄŸlar.",
      formula: "king - man + woman â‰ˆ queen",
      example: { input: "kedi = [0.2, 0.8, -0.1, 0.5]", output: "kÃ¶pek = [0.3, 0.7, -0.2, 0.4]  â†’ Ã§ok yakÄ±n! (ikisi de evcil hayvan)" },
      keyPoint: "VektÃ¶r uzayÄ±nda yakÄ±n = anlamca benzer. Bu basit fikir tÃ¼m modern NLP'nin temelidir.",
    },
  ],
  "week1_s4": [
    {
      title: "Token Embedding: Tablodaki SatÄ±rÄ± SeÃ§",
      desc: "Embedding matrisi |V|Ã—d boyutlu bir tablodur. Token ID bu tablodaki satÄ±r numarasÄ±dÄ±r. Ä°leri geÃ§iÅŸte sadece bir satÄ±r seÃ§ilir â€” hesaplama Ã§ok hÄ±zlÄ±dÄ±r.",
      formula: "E âˆˆ â„^{|V|Ã—d}    x_i = E[token_i]",
      example: { input: "'merhaba' â†’ BPE â†’ [312, 4521, 89]", output: "xâ‚ = E[312], xâ‚‚ = E[4521], xâ‚ƒ = E[89]  (her biri d boyutlu)" },
      code: "# Embedding lookup = matrix indexing:\ntok_emb = self.wte(idx)  # idx: [B, T] â†’ tok_emb: [B, T, d]",
      keyPoint: "Embedding baÅŸlangÄ±Ã§ta rastgele. EÄŸitimle anlamlÄ± hale gelir â€” benzer tokenlar yakÄ±nlaÅŸÄ±r.",
    },
  ],
  "week1_s5": [
    {
      title: "Position Embedding: SÄ±ra Bilgisi",
      desc: "Dikkat mekanizmasÄ± sÄ±ra-baÄŸÄ±msÄ±zdÄ±r â€” 'Ali AyÅŸe'yi sevdi' ile 'AyÅŸe Ali'yi sevdi' aynÄ± gÃ¶rÃ¼nÃ¼r! Konum gÃ¶mmeleri her pozisyona ayrÄ± bir vektÃ¶r ekleyerek sÄ±ra bilgisi verir.",
      formula: "x_i = wte[token_i] + wpe[pozisyon_i]",
      example: { input: "'kedi uyur' â†’ token_emb: [E[kedi], E[uyur]]", output: "pos_emb: [P[0], P[1]] â†’ final: [E[kedi]+P[0], E[uyur]+P[1]]" },
      code: "self.wpe = nn.Embedding(block_size, n_embd)  # [8 Ã— 16]\npos_emb = self.wpe(torch.arange(T))  # pozisyon 0,1,2,...\nx = tok_emb + pos_emb  # toplam: token + pozisyon",
      keyPoint: "Embedding = token kimliÄŸi + pozisyon bilgisi. Ä°kisinin TOPLAMI modelin girdisidir.",
    },
  ],
  "week1_s6": [
    {
      title: "Matris Ã‡arpÄ±mÄ±: Linear Transform",
      desc: "Sinir aÄŸlarÄ±nÄ±n temel iÅŸlemi matris Ã§arpÄ±mÄ±dÄ±r. Bir vektÃ¶rÃ¼ bir matrisle Ã§arpmak, onu yeni bir uzaya yansÄ±tÄ±r (projeksiyon/dÃ¶nÃ¼ÅŸÃ¼m).",
      formula: "y = Wx + b    W: [Ã§Ä±ktÄ±_dim Ã— girdi_dim]",
      example: { input: "x = [0.5, 0.3] (2D), W = [[0.1, 0.4], [0.7, 0.2], [0.3, 0.8]] (3Ã—2)", output: "y = Wx = [0.17, 0.41, 0.39] â†’ 2D'den 3D'ye dÃ¶nÃ¼ÅŸÃ¼m!" },
      code: "# PyTorch'ta linear transform:\nself.linear = nn.Linear(n_embd, 4 * n_embd)  # d â†’ 4d\nout = self.linear(x)  # matris Ã§arpÄ±mÄ± + bias",
      keyPoint: "Matris Ã§arpÄ±mÄ± = uzay dÃ¶nÃ¼ÅŸÃ¼mÃ¼. Transformer'daki her adÄ±m bir matris Ã§arpÄ±mÄ±dÄ±r.",
    },
  ],
  "week1_s7": [
    {
      title: "Weight Tying: AynÄ± Matrisi Ä°ki Kez Kullan",
      desc: "GÃ¶mme matrisi (E) tokeni vektÃ¶re Ã§evirir. Ã‡Ã¶zme matrisi (Eáµ€) vektÃ¶rÃ¼ tekrar token skorlarÄ±na Ã§evirir. Weight tying: ikisi iÃ§in AYNI matrisi kullan!",
      formula: "Embedding: x = E[token_id]    Unembedding: logits = h Ã— Eáµ€",
      example: { input: "Vocab=27, d=16 â†’ E boyutu: [27Ã—16]", output: "Tying olmadan: 27Ã—16 + 27Ã—16 = 864 param | Tying ile: 27Ã—16 = 432 param (-%50!)" },
      code: "# microGPT weight tying:\nself.wte = nn.Embedding(V, d)      # gÃ¶mme\nself.head = nn.Linear(d, V, bias=False)  # Ã§Ã¶zme\nself.head.weight = self.wte.weight  # AYNI aÄŸÄ±rlÄ±k!",
      keyPoint: "Weight tying parametre sayÄ±sÄ±nÄ± azaltÄ±r VE performansÄ± artÄ±rÄ±r â€” embedding ve unembedding tutarlÄ± olur.",
    },
  ],
  "week1_s8": [
    {
      title: "Softmax: Skorlardan OlasÄ±lÄ±ÄŸa",
      desc: "Model her token iÃ§in bir skor (logit) Ã¼retir. Softmax bu skorlarÄ± olasÄ±lÄ±klara Ã§evirir: hepsi 0-1 arasÄ±, toplamÄ± 1.",
      formula: "softmax(záµ¢) = exp(záµ¢) / Î£â±¼ exp(zâ±¼)",
      example: { input: "Logits: [2.0, 1.0, 0.1] (3 token iÃ§in ham skorlar)", output: "Softmax: [0.659, 0.242, 0.099] â†’ toplamÄ± 1.0 âœ“" },
      code: "# microGPT'de softmax:\nlogits = self.head(x)           # [B, T, V] ham skorlar\nprobs = F.softmax(logits, dim=-1)  # [B, T, V] olasÄ±lÄ±klar\nnext_tok = torch.multinomial(probs, 1)  # Ã¶rnekle",
      keyPoint: "Softmax = sigmoidin Ã§ok sÄ±nÄ±flÄ± genellemesi. BÃ¼yÃ¼k logit â†’ yÃ¼ksek olasÄ±lÄ±k, kÃ¼Ã§Ã¼k logit â†’ dÃ¼ÅŸÃ¼k olasÄ±lÄ±k.",
    },
  ],
  "week2_s0": [
    {
      title: "TÃ¼rev Nedir? DeÄŸiÅŸimin Ã–lÃ§Ã¼sÃ¼",
      desc: "TÃ¼rev, bir fonksiyonun girdisi deÄŸiÅŸtiÄŸinde Ã§Ä±ktÄ±sÄ±nÄ±n ne kadar deÄŸiÅŸtiÄŸini sÃ¶yler. EÄŸitimde tÃ¼rev bize 'aÄŸÄ±rlÄ±ÄŸÄ± hangi yÃ¶ne deÄŸiÅŸtirmeliyim?' sorusunun cevabÄ±nÄ± verir.",
      formula: "f'(x) = lim[hâ†’0] (f(x+h) - f(x)) / h",
      example: { input: "f(x) = xÂ² â†’ f'(x) = 2x", output: "x=3'te: f'(3) = 6 â†’ 'x artarsa f(x) 6 kat hÄ±zla artar'" },
      keyPoint: "TÃ¼rev = eÄŸim = deÄŸiÅŸim oranÄ±. EÄŸitimde kayÄ±p fonksiyonunun tÃ¼revini alarak aÄŸÄ±rlÄ±klarÄ± gÃ¼ncelleriz.",
    },
  ],
  "week2_s1": [
    {
      title: "KÄ±smi TÃ¼rev ve Gradient",
      desc: "Birden fazla deÄŸiÅŸkenli fonksiyonlarda her deÄŸiÅŸkene gÃ¶re ayrÄ± tÃ¼rev alÄ±rÄ±z. TÃ¼m kÄ±smi tÃ¼revleri bir araya koyunca gradient vektÃ¶rÃ¼ elde ederiz.",
      formula: "âˆ‡L = [âˆ‚L/âˆ‚wâ‚, âˆ‚L/âˆ‚wâ‚‚, ..., âˆ‚L/âˆ‚wâ‚™]",
      example: { input: "L(wâ‚,wâ‚‚) = wâ‚Â² + 3wâ‚‚", output: "âˆ‚L/âˆ‚wâ‚ = 2wâ‚, âˆ‚L/âˆ‚wâ‚‚ = 3 â†’ âˆ‡L = [2wâ‚, 3]" },
      keyPoint: "Gradient = 'kaybÄ±n en hÄ±zlÄ± arttÄ±ÄŸÄ± yÃ¶n'. Biz TERSÄ° yÃ¶nde gideriz â†’ kayÄ±p azalÄ±r.",
    },
  ],
  "week2_s2": [
    {
      title: "Autograd: Otomatik TÃ¼rev Hesaplama",
      desc: "microGPT'deki autograd sistemi her matematiksel iÅŸlemi bir hesaplama grafiÄŸi olarak kaydeder. Backward pass sÄ±rasÄ±nda zincir kuralÄ±yla tÃ¼m tÃ¼revleri otomatik hesaplar.",
      formula: "Ä°leri: x â†’ z = Wx+b â†’ h = Ïƒ(z) â†’ L\nGeri: âˆ‚L/âˆ‚W = (âˆ‚L/âˆ‚h)(âˆ‚h/âˆ‚z)(âˆ‚z/âˆ‚W)",
      example: { input: "a = Value(2), b = Value(3), c = a * b", output: "c.backward() â†’ a.grad = 3 (âˆ‚c/âˆ‚a = b), b.grad = 2 (âˆ‚c/âˆ‚b = a)" },
      code: "# microGPT Value sÄ±nÄ±fÄ±:\nclass Value:\n    def __init__(self, data):\n        self.data = data\n        self.grad = 0\n        self._backward = lambda: None",
      keyPoint: "Autograd = elle tÃ¼rev almaya gerek yok. Kod otomatik yapÄ±yor!",
    },
  ],
  "week2_s3": [
    {
      title: "Value SÄ±nÄ±fÄ±: 4 Temel BileÅŸen",
      desc: "Value sÄ±nÄ±fÄ± autograd'Ä±n kalbidir. Her Value bir sayÄ± tutar, gradyanÄ±nÄ± biriktirir, hesaplama grafÄ±ndaki yerini bilir ve geri yayÄ±lÄ±m fonksiyonu taÅŸÄ±r.",
      example: { input: "a = Value(2), b = Value(3)", output: "c = a + b â†’ c.data=5, c._children={a,b}, c._backward: a.grad+=1, b.grad+=1" },
      code: "class Value:\n    self.data = 2.0         # ileri geÃ§iÅŸ deÄŸeri\n    self.grad = 0.0         # geri geÃ§iÅŸ gradyanÄ±\n    self._children = set()  # graf baÄŸlantÄ±larÄ±\n    self._backward = fn     # geri yayÄ±lÄ±m fonksiyonu",
      keyPoint: "Her iÅŸlem (+, Ã—, Ïƒ) grafa bir dÃ¼ÄŸÃ¼m ekler. backward() bu grafÄ± tersten yÃ¼rÃ¼r.",
    },
  ],
  "week2_s4": [
    {
      title: "OperatÃ¶r Overloading: +, Ã— Otomatik Graf",
      desc: "Python'un __add__, __mul__ gibi Ã¶zel metotlarÄ±nÄ± deÄŸiÅŸtirerek, normal aritmetik iÅŸlemlerle otomatik hesaplama grafÄ± oluÅŸtururuz.",
      example: { input: "a = Value(2); b = Value(3); c = a * b", output: "c.grad=1 â†’ a.grad += 3Ã—1 = 3, b.grad += 2Ã—1 = 2 âœ“" },
      code: "class Value:\n    def __mul__(self, other):\n        out = Value(self.data * other.data)\n        def _backward():\n            self.grad += other.data * out.grad\n            other.grad += self.data * out.grad\n        out._backward = _backward\n        return out",
      keyPoint: "Python sihri: 'a * b' yazdÄ±ÄŸÄ±nÄ±zda hem Ã§arpma hem de tÃ¼rev hesaplama kaydediliyor.",
    },
  ],
  "week2_s5": [
    {
      title: "Chain Rule: Ä°Ã§ Ä°Ã§e FonksiyonlarÄ±n TÃ¼revi",
      desc: "Zincir kuralÄ±, bileÅŸik fonksiyonlarÄ±n tÃ¼revini hesaplamanÄ±n yoludur. Backward pass tamamen zincir kuralÄ±na dayanÄ±r.",
      formula: "âˆ‚L/âˆ‚x = (âˆ‚L/âˆ‚y) Ã— (âˆ‚y/âˆ‚x) â€” 'dÄ±ÅŸtan iÃ§e, Ã§arparak ilerle'",
      example: { input: "L = (aÃ—b + c)Â² â†’ dÄ±ÅŸ: uÂ², iÃ§: aÃ—b+c", output: "âˆ‚L/âˆ‚a = 2(aÃ—b+c) Ã— b â€” dÄ±ÅŸ tÃ¼rev Ã— iÃ§ tÃ¼rev" },
      keyPoint: "Her dÃ¼ÄŸÃ¼m sadece kendi lokal tÃ¼revini bilir. Zincir kuralÄ± bunlarÄ± Ã§arparak birleÅŸtirir.",
    },
  ],
  "week2_s6": [
    {
      title: "Somut Ã–rnek: L = (a Ã— b) + c",
      desc: "Basit bir hesaplama grafÄ±nda ileri ve geri geÃ§iÅŸi adÄ±m adÄ±m izleyelim.",
      formula: "âˆ‚L/âˆ‚a = âˆ‚L/âˆ‚d Ã— âˆ‚d/âˆ‚a = 1 Ã— b = 3",
      example: { input: "a=2, b=3, c=4 â†’ d=aÃ—b=6 â†’ L=d+c=10", output: "Geri: âˆ‚L/âˆ‚L=1 â†’ âˆ‚L/âˆ‚d=1, âˆ‚L/âˆ‚c=1 â†’ âˆ‚L/âˆ‚a=b=3, âˆ‚L/âˆ‚b=a=2" },
      keyPoint: "Geri yayÄ±lÄ±m = 'kayÄ±ptaki 1 birimlik deÄŸiÅŸim, her parametreyi ne kadar etkiler?'",
    },
  ],
  "week2_s7": [
    {
      title: "Gradient ToplanmasÄ±: += Neden Kritik?",
      desc: "Bir deÄŸiÅŸken birden fazla yerde kullanÄ±lÄ±rsa, gradyanlarÄ± TOPLANMALIDIR. Bu Ã§ok Ã¶nemli bir detaydÄ±r â€” unutulursa gradyanlar kaybolur.",
      formula: "EÄŸer x, f(x) ve g(x)'te kullanÄ±lÄ±yorsa: âˆ‚L/âˆ‚x = âˆ‚L/âˆ‚f Ã— âˆ‚f/âˆ‚x + âˆ‚L/âˆ‚g Ã— âˆ‚g/âˆ‚x",
      example: { input: "a=2 â†’ b=a+a=4 (a iki kez kullanÄ±ldÄ±)", output: "âˆ‚b/âˆ‚a = 1 + 1 = 2 (toplama!) â€” a.grad += 1; a.grad += 1" },
      code: "# DOÄRU: gradyan biriktir\nself.grad += local_grad * out.grad\n# YANLIÅ: gradyan Ã¼zerine yaz\nself.grad = local_grad * out.grad  # âŒ Ã¶nceki kaybolur!",
      keyPoint: "grad += (topla), grad = (Ã¼zerine yaz) DEÄÄ°L. Bu tek karakter farkÄ± her ÅŸeyi deÄŸiÅŸtirir.",
    },
  ],
  "week2_s8": [
    {
      title: "Bizim Autograd vs PyTorch",
      desc: "microGPT'deki autograd, PyTorch'un torch.autograd modÃ¼lÃ¼nÃ¼n basitleÅŸtirilmiÅŸ versiyonudur. AynÄ± prensip: hesaplama grafÄ± + zincir kuralÄ± + backward pass.",
      example: { input: "Bizim Value: Python, CPU, eÄŸitim amaÃ§lÄ±, ~50 satÄ±r", output: "PyTorch Tensor: C++/CUDA, GPU, Ã¼retim, milyonlarca satÄ±r" },
      code: "# PyTorch eÅŸdeÄŸeri:\nx = torch.tensor(2.0, requires_grad=True)\ny = x ** 2 + 3 * x\ny.backward()\nprint(x.grad)  # 7.0 (= 2*2 + 3)",
      keyPoint: "Mekanizma aynÄ±, Ã¶lÃ§ek farklÄ±. Anlamak iÃ§in basitini yaz, kullanmak iÃ§in PyTorch kullan.",
    },
  ],
  "week3_s0": [
    {
      title: "RNN'den Attention'a: Neden Yeni Mimari?",
      desc: "RNN sÃ¶zcÃ¼kleri sÄ±rayla iÅŸler ve bilgiyi bir gizli durumda taÅŸÄ±r. Uzun cÃ¼mlelerde erken sÃ¶zcÃ¼klerin bilgisi kaybolur. Dikkat mekanizmasÄ± her sÃ¶zcÃ¼ÄŸÃ¼n doÄŸrudan her diÄŸer sÃ¶zcÃ¼ÄŸe bakmasÄ±nÄ± saÄŸlar.",
      example: { input: "RNN: 'Ali okula gitti Ã§Ã¼nkÃ¼ ___' â†’ 'Ali' bilgisi 4 adÄ±m uzakta, zayÄ±flamÄ±ÅŸ", output: "Attention: her sÃ¶zcÃ¼k doÄŸrudan 'Ali'ye bakabilir â†’ bilgi kaybÄ± yok" },
      keyPoint: "RNN = sÄ±ralÄ± boru hattÄ± (bilgi kaybolur). Attention = herkes herkesi gÃ¶rÃ¼r (bilgi korunur).",
    },
  ],
  "week3_s1": [
    {
      title: "Self-Attention: BaÄŸlamsal Anlam",
      desc: "AynÄ± sÃ¶zcÃ¼k farklÄ± cÃ¼mlelerde farklÄ± anlam taÅŸÄ±r. Self-attention, her sÃ¶zcÃ¼ÄŸÃ¼n temsilini baÄŸlamdaki diÄŸer sÃ¶zcÃ¼klerin bilgisiyle zenginleÅŸtirir.",
      example: { input: "'bank' â†’ 'river bank' (nehir kÄ±yÄ±sÄ±) vs 'bank account' (banka)", output: "Attention sonrasÄ±: 'bank' vektÃ¶rÃ¼ iki cÃ¼mlede FARKLI olur" },
      code: "# Sezgi: her token komÅŸularÄ±na sorar 'bana ne bilgi verebilirsin?'\n# ve cevaplarÄ± aÄŸÄ±rlÄ±klÄ± olarak toplar\nattention_output = weighted_sum(values, attention_weights)",
      keyPoint: "Statik embedding: 'bank' her yerde aynÄ±. Attention sonrasÄ±: baÄŸlama gÃ¶re farklÄ±laÅŸÄ±r.",
    },
  ],
  "week3_s2": [
    {
      title: "Query, Key, Value: 3 FarklÄ± Rol",
      desc: "Her token 3 farklÄ± role bÃ¼rÃ¼nÃ¼r: Query (ne arÄ±yorum?), Key (bende ne var?), Value (iÅŸte bilgim). Bu kÃ¼tÃ¼phanede kitap aramaya benzer.",
      formula: "Q = XWq    K = XWk    V = XWv",
      example: { input: "Siz (Q): 'Fizik kitabÄ± arÄ±yorum'", output: "Raf etiketleri (K): 'Fizik', 'Tarih', 'Roman' â†’ Fizik uyuÅŸur â†’ O kitabÄ±n iÃ§eriÄŸi (V) verilir" },
      code: "# microGPT Q, K, V hesaplama:\nq = x @ self.Wq  # [B, T, d] â†’ [B, T, head_dim]\nk = x @ self.Wk\nv = x @ self.Wv",
      keyPoint: "QÂ·K = 'ne kadar ilgili?' skoru. Bu skor V'lerin aÄŸÄ±rlÄ±ÄŸÄ±nÄ± belirler.",
    },
  ],
  "week3_s3": [
    {
      title: "Dikkat KalÄ±plarÄ±: Her Head Ne Ã–ÄŸrenir?",
      desc: "Multi-head attention'da her baÅŸlÄ±k farklÄ± iliÅŸki tÃ¼rlerini Ã¶ÄŸrenir. Bir baÅŸlÄ±k sÃ¶zdizimi, diÄŸeri anlam, bir diÄŸeri pozisyon iliÅŸkilerini yakalayabilir.",
      example: { input: "Head 1: 'kedi â†’ uyuyor' (Ã¶zne-yÃ¼klem)", output: "Head 2: 'bÃ¼yÃ¼k â†’ kedi' (sÄ±fat-isim) | Head 3: her token â†’ bir Ã¶nceki token (pozisyon)" },
      code: "# microGPT: 4 head, her biri d/4 = 4 boyutlu\n# Her head ayrÄ± bir 'bakÄ±ÅŸ aÃ§Ä±sÄ±'",
      keyPoint: "4 head = 4 farklÄ± bakÄ±ÅŸ aÃ§Ä±sÄ±. GPT-3'te 96 head â†’ Ã§ok zengin iliÅŸki aÄŸÄ±.",
    },
  ],
  "week3_s4": [
    {
      title: "Scaled Dot-Product: Tam Hesaplama",
      desc: "Dikkat skoru, sorgu ile anahtarÄ±n nokta Ã§arpÄ±mÄ±dÄ±r. âˆšd ile bÃ¶lme, bÃ¼yÃ¼k boyutlarda gradyanlarÄ± stabilize eder.",
      formula: "Attention(Q,K,V) = softmax(QKáµ€ / âˆšd) Ã— V",
      example: { input: "Q=[1,0], Kâ‚=[1,0], Kâ‚‚=[0,1]", output: "QÂ·Kâ‚=1 (yÃ¼ksek benzerlik), QÂ·Kâ‚‚=0 (dÃ¼ÅŸÃ¼k) â†’ Token 1'e daha Ã§ok dikkat" },
      code: "# microGPT attention:\natt = (q @ k.transpose(-2,-1)) * (1.0 / math.sqrt(k.size(-1)))\natt = att.masked_fill(self.mask[:,:,:T,:T] == 0, float('-inf'))\natt = F.softmax(att, dim=-1)\nout = att @ v  # aÄŸÄ±rlÄ±klÄ± toplam",
      keyPoint: "QKáµ€ = benzerlik matrisi [TÃ—T]. Softmax â†’ olasÄ±lÄ±k. V ile Ã§arp â†’ aÄŸÄ±rlÄ±klÄ± bilgi.",
    },
  ],
  "week3_s5": [
    {
      title: "Dot Product: Benzerlik Ã–lÃ§Ã¼mÃ¼",
      desc: "Ä°ki vektÃ¶rÃ¼n nokta Ã§arpÄ±mÄ±, onlarÄ±n ne kadar 'aynÄ± yÃ¶ne baktÄ±ÄŸÄ±nÄ±' Ã¶lÃ§er. Dikkat mekanizmasÄ±nÄ±n benzerlik hesaplamasÄ±nÄ±n temelidir.",
      formula: "aÂ·b = Î£áµ¢ aáµ¢báµ¢ = |a||b|cos(Î¸)",
      example: { input: "a=[1,0,0], b=[1,0,0] â†’ aÂ·b = 1 (aynÄ± yÃ¶n)", output: "a=[1,0,0], b=[0,1,0] â†’ aÂ·b = 0 (dik, iliÅŸkisiz)" },
      keyPoint: "Dot product > 0: benzer yÃ¶n. = 0: iliÅŸkisiz. < 0: zÄ±t yÃ¶n.",
    },
  ],
  "week3_s6": [
    {
      title: "Multi-Head & Causal Masking",
      desc: "Ã‡ok baÅŸlÄ±klÄ± dikkat: aynÄ± girdiyi farklÄ± aÃ§Ä±lardan analiz et. Causal mask: otoregresif Ã¼retimde geleceÄŸi gÃ¶rmesini engelle.",
      formula: "MultiHead = Concat(headâ‚, ..., headâ‚•) Ã— Wâ‚’\nher headáµ¢ = Attention(QWqáµ¢, KWkáµ¢, VWváµ¢)",
      example: { input: "'Ali okula gitti' â€” 'gitti' tokenÄ± iÃ§in mask:", output: "'Ali' âœ“  'okula' âœ“  'gitti' âœ“  [gelecek tokenlar] âœ— (maskelenmiÅŸ)" },
      code: "# Causal mask: Ã¼st Ã¼Ã§gen = -âˆ\nmask = torch.tril(torch.ones(T, T))  # alt Ã¼Ã§gen\natt = att.masked_fill(mask == 0, float('-inf'))\n# softmax(-âˆ) = 0 â†’ gelecek gÃ¶rÃ¼nmez",
      keyPoint: "Multi-head = paralel bakÄ±ÅŸ aÃ§Ä±larÄ±. Causal mask = 'geleceÄŸi bilemezsin' kuralÄ±.",
    },
  ],
  "week3_s7": [
    {
      title: "Attention Ã‡Ä±ktÄ±sÄ± & Projeksiyon",
      desc: "Dikkat mekanizmasÄ±nÄ±n Ã§Ä±ktÄ±sÄ±, value vektÃ¶rlerinin aÄŸÄ±rlÄ±klÄ± toplamÄ±dÄ±r. Son bir lineer projeksiyon tÃ¼m head'lerin Ã§Ä±ktÄ±larÄ±nÄ± birleÅŸtirir.",
      formula: "aáµ¢ = Î£â±¼ Î±áµ¢â±¼ Ã— vâ±¼    (Î±áµ¢â±¼ = softmax(qáµ¢Â·kâ±¼/âˆšd))",
      example: { input: "Î± = [0.7, 0.2, 0.1] (3 tokena dikkat aÄŸÄ±rlÄ±klarÄ±)", output: "Ã§Ä±ktÄ± = 0.7Ã—vâ‚ + 0.2Ã—vâ‚‚ + 0.1Ã—vâ‚ƒ â†’ baÄŸlamsal temsil" },
      code: "# microGPT: head Ã§Ä±ktÄ±larÄ± birleÅŸtirilir\nout = att @ v          # [B, T, head_dim]\nout = self.proj(out)   # [B, T, d] â†’ geri orijinal boyuta",
      keyPoint: "Dikkat = bilgi filtreleme. Her token sadece ilgili bilgiyi alÄ±r, gÃ¼rÃ¼ltÃ¼yÃ¼ gÃ¶rmezden gelir.",
    },
  ],
  "week4_s0": [
    {
      title: "Transformer BloÄŸu: BÃ¼yÃ¼k Resim",
      desc: "Bir transformer bloÄŸu 4 bileÅŸenden oluÅŸur ve bu blok N kez tekrarlanÄ±r. Her blok girdinin boyutunu deÄŸiÅŸtirmez â€” bu yÃ¼zden Ã¼st Ã¼ste yÄ±ÄŸÄ±labilir.",
      formula: "x â†’ LayerNorm â†’ Attention â†’ +x (residual) â†’ LayerNorm â†’ MLP â†’ +x (residual)",
      example: { input: "Girdi: [8 token Ã— 16 boyut] matrisi", output: "Ã‡Ä±ktÄ±: [8 token Ã— 16 boyut] â€” boyut aynÄ±! Ama her token artÄ±k baÄŸlam biliyor" },
      code: "# microGPT transformer blok:\nclass Block(nn.Module):\n    def forward(self, x):\n        x = x + self.attn(self.ln1(x))   # dikkat + residual\n        x = x + self.mlp(self.ln2(x))    # MLP + residual\n        return x",
      keyPoint: "1 blok = dikkat (tokenlar arasÄ± bilgi) + MLP (token iÃ§i dÃ¶nÃ¼ÅŸÃ¼m) + residual (bilgi korunmasÄ±).",
    },
  ],
  "week4_s1": [
    {
      title: "Transformer AdÄ±m AdÄ±m SimÃ¼lasyonu",
      desc: "Tek bir token bir transformer bloÄŸundan geÃ§erken neler olur? Normalizasyon â†’ dikkat â†’ toplama â†’ normalizasyon â†’ MLP â†’ toplama.",
      example: { input: "x = [0.5, -0.3, 0.8, ...] (normalize edilmemiÅŸ)", output: "â†’ LayerNorm â†’ Attention (diÄŸer tokenlardan bilgi) â†’ +x â†’ LayerNorm â†’ MLP â†’ +x â†’ Ã§Ä±ktÄ±" },
      code: "# AdÄ±m adÄ±m:\nx_norm = self.ln1(x)           # 1. normalize et\nattn_out = self.attn(x_norm)   # 2. dikkat hesapla\nx = x + attn_out               # 3. residual ekle\nx_norm = self.ln2(x)           # 4. tekrar normalize\nmlp_out = self.mlp(x_norm)     # 5. MLP dÃ¶nÃ¼ÅŸÃ¼mÃ¼\nx = x + mlp_out                # 6. residual ekle",
      keyPoint: "Her adÄ±mÄ±n rolÃ¼: norm=stabilize, attn=diÄŸerlerinden Ã¶ÄŸren, MLP=kendi bilgini gÃ¼ncelle, residual=eski bilgiyi koru.",
    },
  ],
  "week4_s2": [
    {
      title: "RMSNorm: VektÃ¶rÃ¼ Normalize Et",
      desc: "Layer normalization, her vektÃ¶rÃ¼ ortalama=0, standart sapma=1 olacak ÅŸekilde normalize eder. Bu, eÄŸitimi stabilize eder ve gradyan patlamasÄ±nÄ± Ã¶nler.",
      formula: "RMSNorm(x) = x / RMS(x) Ã— Î³    RMS(x) = âˆš(Î£xáµ¢Â²/d)",
      example: { input: "x = [10, -5, 3, 8] â†’ RMS = âˆš(100+25+9+64)/4 = âˆš49.5 â‰ˆ 7.0", output: "x_norm = [1.43, -0.71, 0.43, 1.14] â†’ deÄŸerler makul aralÄ±kta" },
      code: "# microGPT RMSNorm:\nclass RMSNorm(nn.Module):\n    def forward(self, x):\n        rms = torch.sqrt(torch.mean(x**2, dim=-1, keepdim=True))\n        return x / (rms + 1e-8) * self.weight",
      keyPoint: "Normalizasyon olmadan derin aÄŸlar eÄŸitilemez â€” deÄŸerler katman katman bÃ¼yÃ¼r veya kÃ¼Ã§Ã¼lÃ¼r.",
    },
  ],
  "week4_s3": [
    {
      title: "MLP Bloku: Token Ä°Ã§i DÃ¶nÃ¼ÅŸÃ¼m",
      desc: "Feed-forward aÄŸ her token iÃ§in baÄŸÄ±msÄ±z olarak Ã§alÄ±ÅŸÄ±r. Boyutu geniÅŸletir (dâ†’4d), aktivasyon uygular, tekrar daraltÄ±r (4dâ†’d).",
      formula: "MLP(x) = Wâ‚‚ Â· activation(Wâ‚ Â· x + bâ‚) + bâ‚‚",
      example: { input: "x: [16 boyut] â†’ Wâ‚: [16â†’64] geniÅŸlet â†’ GELU â†’ Wâ‚‚: [64â†’16] daralt", output: "Parametre: 16Ã—64 + 64Ã—16 = 2,048 (toplam parametrelerin bÃ¼yÃ¼k kÄ±smÄ±!)" },
      code: "# microGPT MLP:\nclass MLP(nn.Module):\n    def __init__(self, d):\n        self.fc1 = nn.Linear(d, 4*d)   # geniÅŸlet\n        self.fc2 = nn.Linear(4*d, d)   # daralt\n    def forward(self, x):\n        return self.fc2(F.gelu(self.fc1(x)))",
      keyPoint: "MLP = 'dÃ¼ÅŸÃ¼nme' katmanÄ±. Dikkat bilgiyi toplar, MLP bu bilgiyi iÅŸler ve dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r.",
    },
  ],
  "week4_s4": [
    {
      title: "Aktivasyon: DoÄŸrusallÄ±k TuzaÄŸÄ±",
      desc: "Aktivasyon fonksiyonu olmadan, kaÃ§ katman eklersen ekle, sonuÃ§ tek bir matris Ã§arpÄ±mÄ±na eÅŸdeÄŸerdir. DoÄŸrusal olmayanlÄ±k aÄŸa gerÃ§ek Ã¶ÄŸrenme gÃ¼cÃ¼ verir.",
      formula: "Wâ‚‚(Wâ‚x) = (Wâ‚‚Wâ‚)x = W'x â†’ tek katman etkisi!",
      example: { input: "ReLU(z) = max(0, z) â†’ negatifler 0 olur, pozitifler kalÄ±r", output: "GELU(z) = z Ã— Î¦(z) â†’ dÃ¼zgÃ¼n ReLU, GPT/BERT tercih eder" },
      code: "# microGPT: ReGLUÂ² kullanÄ±r\ndef relu2(x):\n    return F.relu(x) ** 2  # max(0,x)Â²",
      keyPoint: "Aktivasyon olmadan: 100 katman = 1 katman. Aktivasyon ile: her katman YENÄ° Ã¶zellikler Ã¶ÄŸrenir.",
    },
  ],
  "week4_s5": [
    {
      title: "Residual BaÄŸlantÄ±lar: Gradient Highway",
      desc: "Residual baÄŸlantÄ±, katmanÄ±n Ã§Ä±ktÄ±sÄ±nÄ± girdisiyle toplar: x + f(x). Bu, gradyanÄ±n doÄŸrudan akmasÄ±nÄ± saÄŸlar ve derin aÄŸlarÄ± eÄŸitilebilir kÄ±lar.",
      formula: "x_out = x + f(x)    (f = attention veya MLP)",
      example: { input: "Residual olmadan: x â†’ fâ‚ â†’ fâ‚‚ â†’ fâ‚ƒ (gradyan her katmanda kÃ¼Ã§Ã¼lÃ¼r)", output: "Residual ile: gradyan doÄŸrudan akar: âˆ‚x_out/âˆ‚x = 1 + âˆ‚f/âˆ‚x â†’ en az 1!" },
      code: "# microGPT residual connection:\nx = x + self.attn(self.ln1(x))  # dikkat + residual\nx = x + self.mlp(self.ln2(x))   # MLP + residual",
      keyPoint: "Residual = 'en kÃ¶tÃ¼ ihtimalle hiÃ§bir ÅŸey yapma'. Gradient highway: 96 katmanda bile gradyan kaybolmaz.",
    },
  ],
  "week4_s6": [
    {
      title: "Weight Initialization: Kritik BaÅŸlatma",
      desc: "AÄŸÄ±rlÄ±klarÄ±n baÅŸlangÄ±Ã§ deÄŸerleri eÄŸitimin baÅŸarÄ±sÄ±nÄ± belirler. Ã‡ok bÃ¼yÃ¼k â†’ gradyan patlamasÄ±. Ã‡ok kÃ¼Ã§Ã¼k â†’ gradyan sÃ¶nmesi.",
      formula: "Xavier: W ~ N(0, 1/âˆšn)    He: W ~ N(0, âˆš(2/n))",
      example: { input: "n_embd=16 â†’ std = 1/âˆš16 = 0.25", output: "AÄŸÄ±rlÄ±klar [-0.5, 0.5] civarÄ±nda baÅŸlar â€” ne Ã§ok bÃ¼yÃ¼k ne Ã§ok kÃ¼Ã§Ã¼k" },
      code: "# PyTorch varsayÄ±lan: Kaiming/He initialization\n# microGPT: nn.Linear zaten uygun init yapar\nnn.init.normal_(self.weight, std=0.02)",
      keyPoint: "Ä°yi init = eÄŸitim hÄ±zla baÅŸlar. KÃ¶tÃ¼ init = eÄŸitim hiÃ§ baÅŸlamaz veya patlar.",
    },
  ],
  "week4_s7": [
    {
      title: "RMSNorm vs LayerNorm KarÅŸÄ±laÅŸtÄ±rma",
      desc: "LayerNorm ortalamayÄ± Ã§Ä±karÄ±r ve standart sapmaya bÃ¶ler. RMSNorm sadece RMS'ye bÃ¶ler (ortalama Ã§Ä±karmaz). RMSNorm daha hÄ±zlÄ± ve modern modellerde tercih edilir.",
      formula: "LayerNorm: (x - Î¼) / Ïƒ Ã— Î³ + Î²\nRMSNorm: x / RMS(x) Ã— Î³",
      example: { input: "x = [4, 2, 6]", output: "LayerNorm: Î¼=4, Ïƒ=1.63 â†’ [-0, -1.22, 1.22]\nRMSNorm: RMS=4.32 â†’ [0.93, 0.46, 1.39]" },
      keyPoint: "RMSNorm: daha az hesaplama, benzer performans. LLaMA, GPT-4 RMSNorm kullanÄ±r.",
    },
  ],
  "week5_s0": [
    {
      title: "Optimizasyon: KaybÄ± Minimize Et",
      desc: "EÄŸitim = kayÄ±p fonksiyonunu minimize eden aÄŸÄ±rlÄ±klarÄ± bulmak. Gradient descent kaybÄ±n azaldÄ±ÄŸÄ± yÃ¶nde kÃ¼Ã§Ã¼k adÄ±mlar atar.",
      formula: "w â† w - Î· Ã— âˆ‚L/âˆ‚w    (Î· = Ã¶ÄŸrenme oranÄ±)",
      example: { input: "DaÄŸda sisli bir gece: en dik iniÅŸ yÃ¶nÃ¼nÃ¼ bul â†’ kÃ¼Ã§Ã¼k adÄ±m at â†’ tekrarla", output: "Her adÄ±mda kayÄ±p biraz azalÄ±r â†’ sonunda 'vadi' (minimum) bulunur" },
      keyPoint: "Gradyan = 'hangi yÃ¶nde tÄ±rmanÄ±rÄ±m?' bilgisi. Biz TERSÄ° yÃ¶nde yÃ¼rÃ¼rÃ¼z â†’ kayÄ±p dÃ¼ÅŸer.",
    },
  ],
  "week5_s1": [
    {
      title: "Gradient Descent: AdÄ±m AdÄ±m",
      desc: "Her eÄŸitim adÄ±mÄ±nda: ileri geÃ§iÅŸ (tahmin yap) â†’ kayÄ±p hesapla â†’ geri geÃ§iÅŸ (gradyan bul) â†’ aÄŸÄ±rlÄ±klarÄ± gÃ¼ncelle.",
      formula: "1. Å· = model(x)        # ileri geÃ§iÅŸ\n2. L = loss(Å·, y)       # kayÄ±p\n3. âˆ‚L/âˆ‚w = backward()   # gradyanlar\n4. w = w - Î· Ã— âˆ‚L/âˆ‚w    # gÃ¼ncelleme",
      example: { input: "DoÄŸru: 'e', Tahmin: P('e')=0.1 (dÃ¼ÅŸÃ¼k) â†’ Loss yÃ¼ksek", output: "Gradyan 'e' olasÄ±lÄ±ÄŸÄ±nÄ± artÄ±racak yÃ¶nÃ¼ gÃ¶sterir â†’ gÃ¼ncelleme â†’ P('e')=0.15" },
      code: "# microGPT eÄŸitim dÃ¶ngÃ¼sÃ¼:\nfor step in range(max_steps):\n    logits, loss = model(x, targets)\n    optimizer.zero_grad()  # gradyanlarÄ± sÄ±fÄ±rla\n    loss.backward()        # gradyanlarÄ± hesapla\n    optimizer.step()       # aÄŸÄ±rlÄ±klarÄ± gÃ¼ncelle",
      keyPoint: "Bu 4 satÄ±r TÃœM sinir aÄŸÄ± eÄŸitiminin Ã¶zÃ¼dÃ¼r. GPT-4 bile aynÄ± dÃ¶ngÃ¼yÃ¼ kullanÄ±r.",
    },
  ],
  "week5_s2": [
    {
      title: "EÄŸitim SimÃ¼lasyonu: LR Etkisi",
      desc: "Ã–ÄŸrenme oranÄ± (learning rate) en kritik hiperparametredir. Ã‡ok bÃ¼yÃ¼k â†’ kayÄ±p salÄ±nÄ±r/patlar. Ã‡ok kÃ¼Ã§Ã¼k â†’ Ã§ok yavaÅŸ Ã¶ÄŸrenir.",
      formula: "w_new = w_old - lr Ã— gradient",
      example: { input: "lr=0.1: bÃ¼yÃ¼k adÄ±mlar â†’ hÄ±zlÄ± ama kararsÄ±z, salÄ±nÄ±r", output: "lr=0.0001: kÃ¼Ã§Ã¼k adÄ±mlar â†’ kararlÄ± ama 10x yavaÅŸ Ã¶ÄŸrenir" },
      code: "# microGPT: Adam optimizer, lr=0.01\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-2)",
      keyPoint: "Ä°deal LR aralÄ±ÄŸÄ±: genelde 1e-4 ile 1e-2 arasÄ±. Adam optimizer LR'yi otomatik ayarlar.",
    },
  ],
  "week5_s3": [
    {
      title: "Cross-Entropy Loss: Bilgi Teorisi",
      desc: "Cross-entropy, modelin tahmin daÄŸÄ±lÄ±mÄ±nÄ±n gerÃ§ek daÄŸÄ±lÄ±mdan ne kadar uzak olduÄŸunu Ã¶lÃ§er. DoÄŸru tokena verilen olasÄ±lÄ±k ne kadar yÃ¼ksekse kayÄ±p o kadar dÃ¼ÅŸÃ¼k.",
      formula: "CE = -log P(doÄŸru_token)",
      example: { input: "DoÄŸru token: 'e'", output: "P('e')=0.9 â†’ L=-log(0.9)=0.105 (dÃ¼ÅŸÃ¼k kayÄ±p âœ…)\nP('e')=0.01 â†’ L=-log(0.01)=4.605 (yÃ¼ksek kayÄ±p âŒ)" },
      code: "# PyTorch'ta cross-entropy:\nloss = F.cross_entropy(logits.view(-1, V), targets.view(-1))\n# Ä°Ã§erde: softmax + negative log likelihood",
      keyPoint: "KayÄ±p = modelin ÅŸaÅŸkÄ±nlÄ±ÄŸÄ±nÄ±n Ã¶lÃ§Ã¼sÃ¼. DÃ¼ÅŸÃ¼k kayÄ±p = model doÄŸru tahmin ediyor.",
    },
  ],
  "week5_s4": [
    {
      title: "Logaritma: Neden -log KullanÄ±rÄ±z?",
      desc: "OlasÄ±lÄ±klar Ã§arpÄ±lÄ±r ve Ã§ok kÃ¼Ã§Ã¼k sayÄ±lar oluÅŸur (10â»Â¹â°â°â°). Log dÃ¶nÃ¼ÅŸÃ¼mÃ¼ Ã§arpmayÄ± toplamaya Ã§evirir ve sayÄ±larÄ± yÃ¶netilebilir tutar.",
      formula: "log(a Ã— b) = log(a) + log(b)    -log(1) = 0, -log(0.5) = 0.69, -log(0.01) = 4.6",
      example: { input: "P(cÃ¼mle) = 0.1 Ã— 0.2 Ã— 0.3 = 0.006 (Ã§ok kÃ¼Ã§Ã¼k!)", output: "-log: 1.0 + 0.7 + 0.5 = 2.2 (yÃ¶netilebilir sayÄ±)" },
      keyPoint: "-log(p): p=1 â†’ 0 (mÃ¼kemmel tahmin), pâ†’0 â†’ âˆ (kÃ¶tÃ¼ tahmin). Bu doÄŸal bir kayÄ±p fonksiyonu.",
    },
  ],
  "week5_s5": [
    {
      title: "Adam Optimizer: SGD'nin Evrimi",
      desc: "Adam, SGD'nin iki sorunununu Ã§Ã¶zer: momentum ile salÄ±nÄ±mÄ± azaltÄ±r, adaptif Ã¶ÄŸrenme oranÄ± ile her parametre iÃ§in ayrÄ± hÄ±z kullanÄ±r.",
      formula: "Adam: m = Î²â‚m + (1-Î²â‚)g, v = Î²â‚‚v + (1-Î²â‚‚)gÂ², w = w - Î· Ã— m/âˆšv",
      example: { input: "SGD: tÃ¼m parametreler aynÄ± hÄ±zda â†’ bazÄ±larÄ± Ã§ok hÄ±zlÄ±, bazÄ±larÄ± Ã§ok yavaÅŸ", output: "Adam: sÄ±k gÃ¼ncellenen parametreleri yavaÅŸlat, nadir gÃ¼ncellenenleri hÄ±zlandÄ±r" },
      code: "# SGD â†’ Adam evrimi:\n# SGD:  w -= lr * grad\n# +Momentum: w -= lr * running_avg(grad)\n# +Adaptive: w -= lr * running_avg(grad) / sqrt(running_avg(gradÂ²))\n# = Adam!",
      keyPoint: "Pratik: Adam (veya AdamW) neredeyse her zaman iyi Ã§alÄ±ÅŸÄ±r. microGPT dahil.",
    },
  ],
  "week5_s6": [
    {
      title: "Learning Rate Schedule & EÄŸitim DÃ¶ngÃ¼sÃ¼",
      desc: "Sabit Ã¶ÄŸrenme oranÄ± yerine, eÄŸitim boyunca LR'yi deÄŸiÅŸtirmek daha iyi sonuÃ§ verir. Warmup + cosine decay en yaygÄ±n stratejidir.",
      example: { input: "Warmup (ilk 100 adÄ±m): lr = 0 â†’ 0.01 (yavaÅŸÃ§a artÄ±r)", output: "Decay (geri kalan): lr = 0.01 â†’ 0.001 (kosinÃ¼s eÄŸrisiyle azalt)" },
      code: "# microGPT: basit sabit lr\n# GPT-3: warmup + cosine decay\nfor step in range(max_steps):\n    lr = get_lr(step)  # warmup + decay\n    for p in model.parameters():\n        p.data -= lr * p.grad",
      keyPoint: "Warmup: baÅŸta patlamamayÄ± Ã¶nler. Decay: sonda ince ayar yapar. Ä°kisi birlikte en iyi.",
    },
  ],
  "week5_s7": [
    {
      title: "Gradient SÄ±fÄ±rlama: Neden zero_grad()?",
      desc: "PyTorch gradyanlarÄ± biriktirir (toplar). Her eÄŸitim adÄ±mÄ±ndan Ã¶nce sÄ±fÄ±rlamazsak, Ã¶nceki adÄ±mlarÄ±n gradyanlarÄ± karÄ±ÅŸÄ±r.",
      formula: "YANLIÅ: grad = grad_step1 + grad_step2 + ... (birikir!)\nDOÄRU: her adÄ±mda grad = 0 â†’ sadece bu adÄ±mÄ±n gradyanÄ±",
      example: { input: "AdÄ±m 1: grad=0.5, AdÄ±m 2: grad=0.3", output: "zero_grad yok â†’ grad=0.8 (yanlÄ±ÅŸ!) | zero_grad var â†’ grad=0.3 (doÄŸru)" },
      code: "# Her adÄ±mda 3 satÄ±r:\noptimizer.zero_grad()  # 1. sÄ±fÄ±rla\nloss.backward()        # 2. hesapla\noptimizer.step()       # 3. gÃ¼ncelle",
      keyPoint: "zero_grad() unutulursa model yanlÄ±ÅŸ yÃ¶nde gÃ¼ncellenir. En sÄ±k yapÄ±lan hata!",
    },
  ],
  "week6_s0": [
    {
      title: "EÄŸitim vs Inference: Ä°ki FarklÄ± Mod",
      desc: "EÄŸitimde model tÃ¼m tokenlara paralel bakar ve kayÄ±p hesaplar. Inference'da tek tek token Ã¼retir â€” tamamen farklÄ± bir sÃ¼reÃ§.",
      example: { input: "EÄŸitim: 'Ali okula gitti' â†’ tÃ¼m tokenlar aynÄ± anda, kayÄ±p = -log P(her doÄŸru token)", output: "Inference: 'Ali' â†’ 'okula' â†’ 'gitti' â†’ ... tek tek, otoregresif" },
      code: "# EÄŸitim modu:\nmodel.train()\nlogits, loss = model(x, targets)  # paralel, kayÄ±p var\n\n# Inference modu:\nmodel.eval()\nwith torch.no_grad():  # gradyan hesaplama kapalÄ±\n    output = model.generate(prompt)  # tek tek Ã¼ret",
      keyPoint: "EÄŸitim: paralel, hÄ±zlÄ±, gradyan var. Inference: sÄ±ralÄ±, yavaÅŸ, gradyan yok.",
    },
  ],
  "week6_s1": [
    {
      title: "Autoregressive Generation: Token Token",
      desc: "Otoregresif Ã¼retim: model bir token Ã¼retir, bu token girdiye eklenir, tekrar model Ã§alÄ±ÅŸtÄ±rÄ±lÄ±r. EOS gelene kadar devam.",
      formula: "P(wâ‚...wâ‚™) = P(wâ‚) Ã— P(wâ‚‚|wâ‚) Ã— P(wâ‚ƒ|wâ‚wâ‚‚) Ã— ...",
      example: { input: "Seed: 'A' â†’ Model: 'l' (%30) â†’ 'i' (%45) â†’ ' ' (%50) â†’ [EOS]", output: "SonuÃ§: 'Ali ' â€” model bir isim Ã¼retti!" },
      code: "# microGPT generate:\ndef generate(self, idx, max_new):\n    for _ in range(max_new):\n        logits = self(idx[:, -block_size:])\n        probs = F.softmax(logits[:, -1, :], dim=-1)\n        next_id = torch.multinomial(probs, 1)\n        idx = torch.cat([idx, next_id], dim=1)\n    return idx",
      keyPoint: "Her adÄ±mda sadece SON tokenin logitleri kullanÄ±lÄ±r. Ã–nceki tokenlar baÄŸlam olarak kalÄ±r.",
    },
  ],
  "week6_s2": [
    {
      title: "Temperature & Sampling Etkisi",
      desc: "Temperature olasÄ±lÄ±k daÄŸÄ±lÄ±mÄ±nÄ± yeniden ÅŸekillendirir. DÃ¼ÅŸÃ¼k temperature = gÃ¼venli/tekrarlayÄ±cÄ±. YÃ¼ksek temperature = yaratÄ±cÄ±/riskli.",
      formula: "P(i) = exp(záµ¢/Ï„) / Î£â±¼ exp(zâ±¼/Ï„)    Ï„ = temperature",
      example: { input: "Logits: [3.0, 1.5, 0.5] â†’ Ï„=1.0: [0.73, 0.16, 0.11]", output: "Ï„=0.5: [0.91, 0.07, 0.02] (keskin) | Ï„=2.0: [0.49, 0.29, 0.22] (dÃ¼z)" },
      code: "# microGPT temperature:\nlogits = logits / temperature\nprobs = F.softmax(logits, dim=-1)\nnext_tok = torch.multinomial(probs, 1)",
      keyPoint: "Ï„â†’0: greedy (hep aynÄ± Ã§Ä±ktÄ±). Ï„=1: normal. Ï„â†’âˆ: rastgele (anlamsÄ±z Ã§Ä±ktÄ±).",
    },
  ],
  "week6_s3": [
    {
      title: "Temperature: Matematiksel Detay",
      desc: "Temperature logitleri bÃ¶lmek, softmax'Ä±n girdilerini Ã¶lÃ§ekler. KÃ¼Ã§Ã¼k Ï„ farklarÄ± bÃ¼yÃ¼tÃ¼r (keskin), bÃ¼yÃ¼k Ï„ farklarÄ± kÃ¼Ã§Ã¼ltÃ¼r (dÃ¼z).",
      formula: "Ï„=0.5: logit/0.5 â†’ farklar 2x bÃ¼yÃ¼r â†’ softmax daha keskin\nÏ„=2.0: logit/2.0 â†’ farklar yarÄ±lanÄ±r â†’ softmax daha dÃ¼z",
      example: { input: "Logits: [2, 1, 0]", output: "Ï„=0.5 â†’ [4,2,0] â†’ softmax: [0.84, 0.14, 0.02]\nÏ„=2.0 â†’ [1,0.5,0] â†’ softmax: [0.51, 0.31, 0.19]" },
      keyPoint: "Temperature kodu sadece 1 satÄ±r: logits = logits / Ï„ â€” ama etkisi dramatik.",
    },
  ],
  "week6_s4": [
    {
      title: "Sampling Stratejileri: Greedy, Top-k, Top-p",
      desc: "Greedy her zaman en olasÄ± tokeni seÃ§er. Top-k ve Top-p dÃ¼ÅŸÃ¼k olasÄ±lÄ±klÄ± tokenleri keserek hem yaratÄ±cÄ± hem de mantÄ±klÄ± Ã§Ä±ktÄ±lar saÄŸlar.",
      formula: "Top-k: en yÃ¼ksek k tokeni tut, diÄŸerlerini sÄ±fÄ±rla\nTop-p: P kÃ¼mÃ¼latif â‰¥ p olana kadar token ekle",
      example: { input: "OlasÄ±lÄ±klar: a(%40) b(%25) c(%15) d(%10) e(%5) f(%3) g(%2)", output: "Greedy: hep 'a' | Top-3: {a,b,c} arasÄ± | Top-p(0.8): {a,b,c} (kÃ¼mÃ¼latif=%80)" },
      keyPoint: "Pratikte: temperature=0.7 + top_p=0.9 kombinasyonu iyi Ã§alÄ±ÅŸÄ±r.",
    },
  ],
  "week6_s5": [
    {
      title: "KV Cache: HÄ±zlÄ± Inference",
      desc: "Her yeni token Ã¼retiminde Ã¶nceki tokenlarÄ±n K ve V vektÃ¶rlerini yeniden hesaplamak israf. KV cache bunlarÄ± bellekte saklar.",
      formula: "Naive: her adÄ±mda O(nÂ²) hesaplama\nKV Cache: Ã¶nceki K,V'leri sakla â†’ sadece yeni tokenin Q'sunu hesapla â†’ O(n)",
      example: { input: "100. token Ã¼retilirken: naive â†’ 100 token Ã— 100 token = 10,000 iÅŸlem", output: "KV cache â†’ sadece yeni Q Ã— 100 eski K = 100 iÅŸlem (100x hÄ±zlÄ±!)" },
      code: "# KV cache pseudocode:\nif cache is not None:\n    k = torch.cat([cache_k, new_k], dim=1)  # eski K + yeni K\n    v = torch.cat([cache_v, new_v], dim=1)\n    cache = (k, v)  # gÃ¼ncelle",
      keyPoint: "KV cache olmadan LLM Ã§Ä±karÄ±mÄ± pratik olarak imkansÄ±z â€” Ã§ok yavaÅŸ olur.",
    },
  ],
  "week6_s6": [
    {
      title: "Inference Pipeline: UÃ§tan Uca",
      desc: "Tam inference pipeline'Ä±: metin giriÅŸinden Ã§Ä±ktÄ± metnine kadar olan tÃ¼m adÄ±mlar.",
      formula: "Metin â†’ Tokenize â†’ Embed â†’ NÃ—[Normâ†’Attnâ†’+â†’Normâ†’MLPâ†’+] â†’ LM Head â†’ Softmax â†’ Sample â†’ Decode â†’ Metin",
      example: { input: "Girdi: 'Merhaba'", output: "â†’ [312,4521] â†’ embed â†’ transformer Ã— N â†’ logits â†’ softmax â†’ [89] â†’ 'ben' â†’ tekrarla" },
      code: "# microGPT full pipeline:\ntokens = encode('Ah')          # metin â†’ sayÄ±lar\ntensor = torch.tensor([tokens]) # tensor'a Ã§evir\noutput = model.generate(tensor, max_new_tokens=20)\nprint(decode(output[0].tolist()))  # 'Ahmet' gibi bir isim",
      keyPoint: "243 satÄ±r kodla tam pipeline: encode â†’ model â†’ decode. Her ÅŸey burada.",
    },
  ],
  "week6_s7": [
    {
      title: "microGPT vs Production GPT: KapanÄ±ÅŸ",
      desc: "microGPT ve GPT-4 aynÄ± algoritmayÄ± kullanÄ±r. Fark sadece Ã¶lÃ§ek, veri ve mÃ¼hendislik detaylarÄ±ndadÄ±r.",
      example: { input: "microGPT: 3,648 param, 27 vocab, CPU, 30 saniye eÄŸitim", output: "GPT-4: ~1.8T param, 100K vocab, 10K GPU, aylar sÃ¼ren eÄŸitim" },
      keyPoint: "AlgoritmayÄ± anladÄ±ysanÄ±z, GPT-4'Ã¼ de anladÄ±nÄ±z. Geri kalan mÃ¼hendislik detayÄ±.",
    },
  ],
  "week7_s0": [
    {
      title: "Scaling Laws: Daha BÃ¼yÃ¼k = Daha Ä°yi?",
      desc: "BDM performansÄ± 3 faktÃ¶rle Ã¼s yasasÄ± olarak Ã¶lÃ§eklenir: parametre sayÄ±sÄ±, veri miktarÄ± ve hesaplama gÃ¼cÃ¼. Bu iliÅŸki Ã¶ngÃ¶rÃ¼lebilir ve gÃ¼venilirdir.",
      formula: "L(N) âˆ Nâ»â°Â·â°â·â¶    L(D) âˆ Dâ»â°Â·â°â¹âµ    L(C) âˆ Câ»â°Â·â°âµâ°",
      example: { input: "10x parametre â†’ kayÄ±p %15 dÃ¼ÅŸer", output: "10x veri â†’ kayÄ±p %18 dÃ¼ÅŸer | 10x hesaplama â†’ kayÄ±p %11 dÃ¼ÅŸer" },
      keyPoint: "Chinchilla: N parametre iÃ§in ~20N token veri gerekir. Daha fazla parametre her zaman daha iyi DEÄÄ°L â€” dengelemek lazÄ±m.",
    },
  ],
  "week7_s1": [
    {
      title: "GPT Zaman Ã‡izelgesi: 2017 â†’ BugÃ¼n",
      desc: "Transformer mimarisinden ChatGPT'ye uzanan yolculuk sadece 5 yÄ±l sÃ¼rdÃ¼. Her yÄ±l Ã¶lÃ§ek 10x bÃ¼yÃ¼dÃ¼.",
      example: { input: "2017: Attention Is All You Need (Vaswani) â†’ Transformer doÄŸdu", output: "2018: GPT-1 (117M) â†’ 2019: GPT-2 (1.5B) â†’ 2020: GPT-3 (175B) â†’ 2022: ChatGPT â†’ 2023: GPT-4" },
      keyPoint: "5 yÄ±lda 10,000x bÃ¼yÃ¼me. Algoritma aynÄ± kaldÄ±, sadece Ã¶lÃ§ek deÄŸiÅŸti.",
    },
  ],
  "week7_s2": [
    {
      title: "DonanÄ±m: Neden GPU Gerekli?",
      desc: "Dikkat mekanizmasÄ± bÃ¼yÃ¼k matris Ã§arpÄ±mlarÄ± gerektirir. GPU binlerce Ã§ekirdeÄŸiyle bu iÅŸlemleri paralel yapabilir.",
      formula: "QKáµ€: [NÃ—d] Ã— [dÃ—N] = NÂ² Ã§arpma â†’ GPU'da paralel",
      example: { input: "CPU: 8-64 Ã§ekirdek, sÄ±ralÄ± â†’ microGPT: 30 sn", output: "GPU: 10,000+ Ã§ekirdek, paralel â†’ GPT-3: 10,000 GPU Ã— haftalarca" },
      keyPoint: "microGPT CPU'da Ã§alÄ±ÅŸÄ±r (kÃ¼Ã§Ã¼k Ã¶lÃ§ek). GerÃ§ek LLM'ler GPU/TPU kÃ¼mesi gerektirir.",
    },
  ],
  "week7_s3": [
    {
      title: "EÄŸitim Pipeline: Pre-training â†’ SFT â†’ RLHF",
      desc: "Modern BDM eÄŸitimi 3 aÅŸamalÄ±dÄ±r: Ã¶nce bÃ¼yÃ¼k veri Ã¼zerinde Ã¶n eÄŸitim, sonra kaliteli Ã¶rneklerle ince ayar, son olarak insan geri bildirimiyle hizalama.",
      example: { input: "AÅŸama 1: Web metni (terabyte'larca) â†’ sonraki token tahmini", output: "AÅŸama 2: Ä°nsan yazÄ±mÄ± soru-cevap â†’ SFT | AÅŸama 3: Hangisi daha iyi? â†’ RLHF" },
      code: "# microGPT sadece AÅŸama 1'i yapar:\n# Pre-training: isimleri tahmin et\n# AÅŸama 2-3 bÃ¼yÃ¼k modeller iÃ§in",
      keyPoint: "Pre-training = ham yetenek. SFT = 'nasÄ±l konuÅŸulur' Ã¶ÄŸretir. RLHF = zararlÄ± olmamayÄ± Ã¶ÄŸretir.",
    },
  ],
  "week7_s4": [
    {
      title: "Tokenization Evrimi",
      desc: "Karakter dÃ¼zeyinden BPE'ye, oradan SentencePiece'e: tokenization yÃ¶ntemleri dilin yapÄ±sÄ±na gÃ¶re evrildi.",
      example: { input: "Karakter: 'merhaba' = 7 token (Ã§ok uzun)", output: "BPE: 'merhaba' = 2-3 token | SÃ¶zcÃ¼k: 'merhaba' = 1 token (ama OOV sorunu)" },
      keyPoint: "BPE = altÄ±n denge. Bilinmeyen sÃ¶zcÃ¼k yok, diziler makul uzunlukta.",
    },
  ],
  "week7_s5": [
    {
      title: "Dikkat Evrimi: Vanilla â†’ Flash â†’ Sliding",
      desc: "Orijinal dikkat O(nÂ²) bellek ve hesaplama gerektirir. Modern yÃ¶ntemler bunu dramatik ÅŸekilde azaltÄ±r.",
      formula: "Vanilla: O(nÂ²) bellek | Flash: O(n) bellek, 2-4x hÄ±z | Sliding: O(nÃ—w) hesaplama",
      example: { input: "Vanilla Attention, n=4096: 4096Â² = 16M elemanlÄ± matris!", output: "Flash: aynÄ± sonuÃ§, ama bellekte 16M yerine ~4K tutar" },
      keyPoint: "Flash Attention sayesinde baÄŸlam penceresi 2K'dan 128K+'ya Ã§Ä±ktÄ±.",
    },
  ],
  "week7_s6": [
    {
      title: "AÃ§Ä±k Kaynak LLM'ler: LLaMA â†’ DeepSeek",
      desc: "2023'ten itibaren aÃ§Ä±k kaynak modeller kapalÄ± kaynak modellerle rekabet etmeye baÅŸladÄ±. Bu demokratikleÅŸme araÅŸtÄ±rmayÄ± hÄ±zlandÄ±rdÄ±.",
      example: { input: "2023: LLaMA (Meta, 7-65B) â†’ ilk gÃ¼Ã§lÃ¼ aÃ§Ä±k model", output: "2024: LLaMA-3, Mistral (7B MoE), DeepSeek (671B MoE) â†’ GPT-4 seviyesine yakÄ±n" },
      keyPoint: "AÃ§Ä±k kaynak = herkes eriÅŸebilir, geliÅŸtirebilir, denetleyebilir. AraÅŸtÄ±rma hÄ±zÄ± 10x arttÄ±.",
    },
  ],
  "week7_s7": [
    {
      title: "GÃ¼ncel Trendler: MoE, RAG, Agent",
      desc: "Modern AI 4 ana trendi takip ediyor: verimli mimariler (MoE), dÄ±ÅŸ bilgi (RAG), araÃ§ kullanma (Agent) ve Ã§oklu modal (Multimodal).",
      example: { input: "MoE: 671B parametre ama sadece 37B aktif â†’ hÄ±zlÄ± ama gÃ¼Ã§lÃ¼", output: "RAG: model bilmediÄŸini sorar â†’ halÃ¼sinasyon â†“ | Agent: model araÃ§ kullanÄ±r (web, kod, API)" },
      keyPoint: "Gelecek: daha bÃ¼yÃ¼k deÄŸil daha akÄ±llÄ± modeller. AraÃ§ kullanma + dÃ¼ÅŸÃ¼nme + dÄ±ÅŸ bilgi.",
    },
  ],
  "weekB_s0": [
    {
      title: "Attention Is All You Need â€” Neden Devrim?",
      desc: "2017 Ã¶ncesi NLP dÃ¼nyasÄ±nda RNN ve LSTM hakimdi. Google'dan 8 araÅŸtÄ±rmacÄ±, RNN'yi tamamen kaldÄ±rÄ±p sadece attention kullanan bir model Ã¶nerdi. SonuÃ§: hem daha hÄ±zlÄ± hem daha doÄŸru.",
      formula: "Attention(Q,K,V) = softmax(QKáµ€/âˆšdâ‚–)V",
      example: { input: "Bu TEK formÃ¼l tÃ¼m makaleyi Ã¶zetler", output: "QÂ·K = benzerlik skoru â†’ softmax = olasÄ±lÄ±k â†’ V ile Ã§arp = bilgi al" },
      keyPoint: "Ä°sim 'Attention Is All You Need' = sadece dikkat mekanizmasÄ± yeterli, baÅŸka hiÃ§bir ÅŸeye gerek yok."
    }
  ],
  "weekB_s1": [
    {
      title: "RNN'nin 3 BÃ¼yÃ¼k Sorunu",
      desc: "RNN sÃ¶zcÃ¼kleri birer birer iÅŸler: tâ‚ â†’ tâ‚‚ â†’ tâ‚ƒ â†’ ... Bu sÄ±ralÄ± yapÄ± 3 kritik sorun yaratÄ±r.",
      formula: "RNN: hâ‚œ = f(hâ‚œâ‚‹â‚, xâ‚œ) â€” her adÄ±m Ã¶ncekine baÄŸÄ±mlÄ± â†’ paralel yapÄ±lamaz",
      example: { input: "100 sÃ¶zcÃ¼klÃ¼k cÃ¼mle â†’ RNN: 100 sÄ±ralÄ± adÄ±m (yavaÅŸ!)", output: "Transformer: 1 paralel adÄ±m â†’ tÃ¼m sÃ¶zcÃ¼kler aynÄ± anda (hÄ±zlÄ±!)" },
      keyPoint: "1. SÄ±ralÄ± â†’ yavaÅŸ 2. Uzak sÃ¶zcÃ¼kleri unutur 3. Gradient sÃ¶nmesi. Transformer Ã¼Ã§Ã¼nÃ¼ de Ã§Ã¶zer."
    }
  ],
  "weekB_s2": [
    {
      title: "Attention: KÃ¼tÃ¼phane Analojisi",
      desc: "Bir kÃ¼tÃ¼phaneye girip 'yapay zeka kitabÄ±' arÄ±yorsunuz (Query). Her rafta etiket var (Key). Etiket sorunuzla ne kadar uyumluysa, o raftan o kadar bilgi (Value) alÄ±rsÄ±nÄ±z.",
      formula: "score(Q,K) = QÂ·K â†’ yÃ¼ksek benzerlik = daha fazla dikkat",
      example: { input: "Q: 'yapay zeka' | Kâ‚: 'fizik', Kâ‚‚: 'AI temelleri', Kâ‚ƒ: 'yemek'", output: "score: 0.1, 0.85, 0.05 â†’ Kâ‚‚'nin Value'su en Ã§ok alÄ±nÄ±r" },
      code: "# Self-attention: her token hem Q hem K hem V rolÃ¼nde\nQ = x @ Wq   # ne arÄ±yorum?\nK = x @ Wk   # bende ne var?\nV = x @ Wv   # iÅŸte bilgim",
      keyPoint: "Self-attention'da her sÃ¶zcÃ¼k hem soru sorar hem cevap verir. Bu yÃ¼zden baÄŸlam bilgisi Ã§ok zengin."
    }
  ],
  "weekB_s3": [
    {
      title: "3 Temel FormÃ¼l",
      desc: "Makalenin tÃ¼m matematiÄŸi 3 formÃ¼le sÄ±ÄŸar. Her birini kaydÄ±rÄ±cÄ±larla keÅŸfedebilirsiniz.",
      formula: "â‘  Dot Product: QÂ·K = Î£ qáµ¢Ã—káµ¢\nâ‘¡ Softmax: P(i) = eË£â± / Î£ eË£Ê²\nâ‘¢ Attention: softmax(QKáµ€/âˆšd) Ã— V",
      example: { input: "Q=[1,0,1], K=[1,1,0] â†’ QÂ·K = 1Ã—1 + 0Ã—1 + 1Ã—0 = 1", output: "âˆšd Ã¶lÃ§ekleme: d=64 ise â†’ skor/8 (gradyanlarÄ± stabilize eder)" },
      keyPoint: "Multi-head: aynÄ± girdiyi 8 farklÄ± perspektiften analiz et â†’ concat â†’ proje. Paralel Ã§alÄ±ÅŸÄ±r!"
    }
  ],
  "weekB_s4": [
    {
      title: "Encoder-Decoder Mimarisi",
      desc: "Encoder girdi cÃ¼mlesini anlar, Decoder Ã§Ä±ktÄ± cÃ¼mlesini Ã¼retir. Her biri 6 katmandan oluÅŸur. Her katmanda: Attention + FFN + Residual + LayerNorm.",
      formula: "Encoder katman: x â†’ MultiHead(x,x,x) + x â†’ FFN(.) + . â†’ Ã§Ä±ktÄ±\nDecoder: masked self-attn â†’ cross-attn(encoder) â†’ FFN",
      example: { input: "Encoder: 'I love AI' â†’ zenginleÅŸtirilmiÅŸ temsil", output: "Decoder: [BOS] â†’ 'Yapay' â†’ 'zekayÄ±' â†’ 'seviyorum' â†’ [EOS]" },
      keyPoint: "microGPT sadece Decoder kullanÄ±r (GPT tarzÄ±). BERT sadece Encoder kullanÄ±r. Orijinal Transformer ikisini birden kullanÄ±r."
    }
  ],
  "weekB_s5": [
    {
      title: "Pozisyon Kodlama: sin/cos DalgalarÄ±",
      desc: "Attention sÄ±ra bilmez: 'Ali AyÅŸe'yi sevdi' ile 'AyÅŸe Ali'yi sevdi' aynÄ± gÃ¶rÃ¼nÃ¼r. Sin/cos dalgalarÄ± her pozisyona benzersiz bir parmak izi ekler.",
      formula: "PE(pos, 2i) = sin(pos / 10000^(2i/d))\nPE(pos, 2i+1) = cos(pos / 10000^(2i/d))",
      example: { input: "Pozisyon 0: [sin(0), cos(0), sin(0), cos(0), ...]", output: "Pozisyon 5: [sin(5), cos(5), sin(5/100), cos(5/100), ...] â€” her biri benzersiz" },
      keyPoint: "Sin/cos avantajÄ±: eÄŸitimde 50 token gÃ¶rdÃ¼ ama 500 token'da da Ã§alÄ±ÅŸÄ±r (genelleme). Ã–ÄŸrenilebilir embedding bunu yapamaz."
    }
  ],
  "weekB_s6": [
    {
      title: "EÄŸitim: 8 GPU, 3.5 GÃ¼n",
      desc: "Base model (65M param): 12 saat eÄŸitim. Big model (213M param): 3.5 gÃ¼n. WMT 2014 Ä°ngilizce-Almanca ve Ä°ngilizce-FransÄ±zca Ã§eviri gÃ¶revleri.",
      formula: "lr = dâ»â°Â·âµ Ã— min(stepâ»â°Â·âµ, step Ã— warmupâ»Â¹Â·âµ)",
      example: { input: "Warmup: 4000 adÄ±m boyunca lr artÄ±r", output: "Sonra: adÄ±mâ»â°Â·âµ ile azalt. Dropout=0.1, Label smoothing Îµ=0.1" },
      keyPoint: "ENâ†’DE: 28.4 BLEU (yeni rekor!). ENâ†’FR: 41.8 BLEU (tek modelle en iyi). Ve daha az eÄŸitim sÃ¼resi!"
    }
  ],
  "weekB_s7": [
    {
      title: "Bu Makale DÃ¼nyayÄ± NasÄ±l DeÄŸiÅŸtirdi?",
      desc: "15 sayfa, 8 yazar, 90K+ atÄ±f. GPT, BERT, ChatGPT, DALL-E, AlphaFold, Copilot â€” hepsi Transformer tabanlÄ±. AI'Ä±n her alanÄ±nÄ± dÃ¶nÃ¼ÅŸtÃ¼rdÃ¼.",
      example: { input: "2017: Transformer (Ã§eviri) â†’ 2018: BERT + GPT-1", output: "2020: GPT-3 (175B) â†’ 2022: ChatGPT â†’ 2023: GPT-4 â†’ 2024: AÃ§Ä±k kaynak yarÄ±ÅŸÄ±" },
      keyPoint: "Sadece NLP deÄŸil: gÃ¶rÃ¼ntÃ¼ (ViT), protein (AlphaFold), mÃ¼zik (MusicGen), kod (Copilot), robotik..."
    }
  ],
};

const SlideRefPanel = ({ weekIdx, sectionIdx }) => {
  const key = `week${weekIdx}_s${sectionIdx}`;
  const cards = EMBEDDED_SLIDES[key];
  if (!cards || cards.length === 0) return null;
  return (
    <div style={{ marginTop: 10, marginBottom: 14 }}>
      {cards.map((card, i) => (
        <div key={i} style={{ background: "rgba(139,92,246,0.04)", border: "1px solid rgba(139,92,246,0.12)", borderRadius: 14, padding: "18px 20px", marginBottom: i < cards.length - 1 ? 14 : 0 }}>
          <div style={{ fontSize: 17, fontWeight: 700, color: "#A78BFA", marginBottom: 10, display: "flex", alignItems: "center", gap: 8 }}>
            <span style={{ width: 4, height: 20, background: "#A78BFA", borderRadius: 2, flexShrink: 0 }}></span>
            {card.title}
          </div>

          <p style={{ fontSize: 15, lineHeight: 1.75, color: "#B0B8C4", margin: "0 0 12px 0" }}>{card.desc}</p>

          {card.formula && (
            <div style={{ background: "rgba(139,92,246,0.08)", border: "1px solid rgba(139,92,246,0.15)", borderRadius: 10, padding: "10px 14px", marginBottom: 12 }}>
              <div style={{ fontSize: 11, fontWeight: 700, color: "#8B5CF6", marginBottom: 4, textTransform: "uppercase", letterSpacing: 1 }}>FormÃ¼l</div>
              <pre style={{ margin: 0, fontFamily: "'Fira Code', monospace", fontSize: 13, color: "#C4B5FD", whiteSpace: "pre-wrap", lineHeight: 1.6 }}>{card.formula}</pre>
            </div>
          )}

          {card.example && (
            <div style={{ background: "rgba(16,185,129,0.06)", border: "1px solid rgba(16,185,129,0.15)", borderRadius: 10, padding: "10px 14px", marginBottom: 12 }}>
              <div style={{ fontSize: 11, fontWeight: 700, color: "#10B981", marginBottom: 6, textTransform: "uppercase", letterSpacing: 1 }}>Ã–rnek</div>
              <div style={{ fontSize: 13, color: "#6EE7B7", lineHeight: 1.6 }}>
                <span style={{ color: "#9CA3AF" }}>Girdi: </span>{card.example.input}
              </div>
              <div style={{ fontSize: 13, color: "#A7F3D0", lineHeight: 1.6, marginTop: 4 }}>
                <span style={{ color: "#9CA3AF" }}>Ã‡Ä±ktÄ±: </span>{card.example.output}
              </div>
            </div>
          )}

          {card.code && (
            <div style={{ background: "rgba(0,0,0,0.3)", borderRadius: 10, padding: "10px 14px", marginBottom: 12, border: "1px solid rgba(255,255,255,0.06)" }}>
              <div style={{ fontSize: 11, fontWeight: 700, color: "#64748B", marginBottom: 4, textTransform: "uppercase", letterSpacing: 1 }}>microGPT Kodu</div>
              <pre style={{ margin: 0, fontFamily: "'Fira Code', monospace", fontSize: 12, color: "#E2E8F0", whiteSpace: "pre-wrap", lineHeight: 1.6 }}>{card.code}</pre>
            </div>
          )}

          {card.keyPoint && (
            <div style={{ background: "rgba(251,191,36,0.06)", borderLeft: "3px solid rgba(251,191,36,0.4)", borderRadius: "0 8px 8px 0", padding: "8px 14px" }}>
              <div style={{ fontSize: 11, fontWeight: 700, color: "#FBBF24", marginBottom: 2, textTransform: "uppercase", letterSpacing: 1 }}>Anahtar Nokta</div>
              <div style={{ fontSize: 13, color: "#FDE68A", lineHeight: 1.6 }}>{card.keyPoint}</div>
            </div>
          )}
        </div>
      ))}
    </div>
  );
};

const INSTRUCTOR_NOTES = {
  // W0
  "week0_s0": { time: 10, difficulty: 1, prep: "microGPT'yi Ã¶nceden Ã§alÄ±ÅŸtÄ±rÄ±n, 2-3 isim Ã¼retin. Ã–ÄŸrencilere canlÄ± gÃ¶sterin.", emphasize: "243 satÄ±r = gerÃ§ek GPT. AynÄ± algoritma, sadece Ã¶lÃ§ek farkÄ±.", studentQs: [
    { q: "Bu gerÃ§ek GPT mi?", a: "Evet! AynÄ± Transformer mimarisi. GPT-4 ile fark sadece parametre sayÄ±sÄ± (3,648 vs ~1.8T) ve eÄŸitim verisi." },
    { q: "Neden Python? Neden C++ deÄŸil?", a: "Okunabilirlik. AmaÃ§ Ã¶ÄŸrenmek, hÄ±z deÄŸil. Production'da PyTorch/C++ kullanÄ±lÄ±r." }
  ], cheatSheet: "microGPT: 243 satÄ±r, 3,648 param, 27 token vocab, 16-dim embedding, 4 head, 1 layer, block_size=8" },
  "week0_s1": { time: 5, difficulty: 1, prep: "Basit bir sinir aÄŸÄ± diyagramÄ± tahtaya Ã§izin (3 daire â†’ 2 daire â†’ 1 daire).", emphasize: "Sinir aÄŸÄ± = Ã§arpma + toplama. Korkutucu deÄŸil.", studentQs: [
    { q: "Biyolojik nÃ¶ronla ilgisi var mÄ±?", a: "Ä°sim oradan geliyor ama benzerlik yÃ¼zeysel. Matematiksel fonksiyon olarak dÃ¼ÅŸÃ¼nÃ¼n." }
  ], cheatSheet: "NÃ¶ron: output = activation(wâ‚xâ‚ + wâ‚‚xâ‚‚ + ... + b)" },
  "week0_s2": { time: 5, difficulty: 1, emphasize: "Dil modeli = P(sonraki token | Ã¶ncekiler). TÃ¼m ders bu TEK cÃ¼mle Ã¼zerine kurulu.", studentQs: [
    { q: "ChatGPT de aynÄ± ÅŸeyi mi yapÄ±yor?", a: "Evet! Her seferinde bir sonraki tokeni tahmin eder. 'AkÄ±llÄ±lÄ±k' Ã§ok bÃ¼yÃ¼k Ã¶lÃ§ekten geliyor." }
  ], cheatSheet: "Dil modeli: P(xâ‚œ | xâ‚, xâ‚‚, ..., xâ‚œâ‚‹â‚) â€” koÅŸullu olasÄ±lÄ±k" },
  "week0_s3": { time: 8, difficulty: 2, prep: "Pipeline diyagramÄ±nÄ± tahtaya Ã§izin. Her kutuyu renklendirin.", emphasize: "Bu pipeline W1-W6'da detaylÄ± iÅŸlenecek. Åimdi bÃ¼yÃ¼k resmi gÃ¶rsÃ¼nler.", studentQs: [
    { q: "Her adÄ±m ne kadar sÃ¼rer?", a: "microGPT'de mikrosaniyeler. GPT-4'te bir token ~50ms. Ama milyarlarca parametre Ã§arpÄ±lÄ±yor." }
  ], cheatSheet: "Pipeline: Token â†’ Embed â†’ Pos â†’ Attention â†’ MLP â†’ Softmax â†’ Sample" },
  "week0_s4": { time: 3, difficulty: 1, emphasize: "Framework'ler kara kutu, biz cam kutu yapÄ±yoruz. Analoji: araba kullanmak vs motor anlamak." },
  "week0_s5": { time: 5, difficulty: 1, prep: "Python 3.10+ ve metin editÃ¶rÃ¼ hazÄ±r olsun. CanlÄ± kurulum gÃ¶sterin.", emphasize: "GPU gerekmez. Laptop yeterli. 3 dakikada eÄŸitim biter." },
  "week0_s6": { time: 8, difficulty: 1, prep: "Terminalde python microgpt.py Ã§alÄ±ÅŸtÄ±rÄ±n. Loss dÃ¼ÅŸÃ¼ÅŸÃ¼nÃ¼ ve isim Ã¼retimini gÃ¶sterin.", emphasize: "Ä°lk Ã§alÄ±ÅŸtÄ±rma anÄ± Ã¶ÄŸrenciler iÃ§in Ã§ok motivasyonel. Hep birlikte yapÄ±n.", studentQs: [
    { q: "Neden garip isimler Ã¼retiyor?", a: "Model Ä°ngilizce isim istatistiklerini Ã¶ÄŸreniyor. GerÃ§ek olmayan ama 'Ä°ngilizce gibi duran' isimler Ã¼retiyor." }
  ] },
  "week0_s7": { time: 10, difficulty: 2, prep: "7 parametreyi deÄŸiÅŸtirerek 2-3 farklÄ± sonuÃ§ hazÄ±rlayÄ±n.", emphasize: "n_embd ve n_layer'Ä± deÄŸiÅŸtirerek loss farkÄ±nÄ± gÃ¶sterin. Ã–ÄŸrencilere de denetin.", studentQs: [
    { q: "En iyi parametreler ne?", a: "Harika soru â€” bunu sistematik olarak araÅŸtÄ±rabilirsinizacaÄŸÄ±z (NAS projesi)!" }
  ], cheatSheet: "7 param: n_embd=16, n_head=4, n_layer=1, block_size=8, batch=32, lr=0.01, steps=1000" },
  // W1
  "week1_s0": { time: 8, difficulty: 2, prep: "'emma' ismini tahtaya yazÄ±p tokenize edin: â†’ [BOS, e, m, m, a, BOS]", emphasize: "Token = modelin gÃ¶rdÃ¼ÄŸÃ¼ en kÃ¼Ã§Ã¼k birim. Karakter dÃ¼zeyinde = her harf bir token.", studentQs: [
    { q: "GPT-4 de karakter karakter mÄ± bakÄ±yor?", a: "HayÄ±r, BPE kullanÄ±yor: 'playing' â†’ ['play', 'ing']. Biz basitlik iÃ§in karakter dÃ¼zeyi kullanÄ±yoruz." },
    { q: "Neden 27 token?", a: "a-z (26) + Ã¶zel BOS/EOS tokeni (1) = 27. Ä°simler sadece kÃ¼Ã§Ã¼k harften oluÅŸuyor." }
  ], cheatSheet: "Vocab: a-z (26) + BOS (0) = 27 token. stoi: charâ†’int, itos: intâ†’char" },
  "week1_s1": { time: 5, difficulty: 2, emphasize: "Embedding = anlamsÄ±z ID'yi anlamlÄ± vektÃ¶re Ã§evirme. Tablo aramasÄ± (lookup), eÄŸitimle Ã¶ÄŸrenilir.", cheatSheet: "wte: [27 Ã— 16] matris. embed('a') = wte[1] â†’ 16-boyutlu vektÃ¶r" },
  "week1_s2": { time: 5, difficulty: 2, emphasize: "Transformer sÄ±ra bilmez! Pozisyon embedding olmadan 'abc' = 'cba'. Bu Ã§ok ÅŸaÅŸÄ±rtÄ±cÄ±.", cheatSheet: "wpe: [8 Ã— 16] matris. Toplam girdi = wte[token_id] + wpe[position]" },
  "week1_s3": { time: 5, difficulty: 3, emphasize: "Softmax = ham skorlarÄ± olasÄ±lÄ±ÄŸa Ã§evirme. Toplam her zaman 1.", studentQs: [
    { q: "Neden exp kullanÄ±yoruz?", a: "Negatif sayÄ±larÄ± pozitif yapmak + bÃ¼yÃ¼k farklarÄ± daha belirgin yapmak. exp(10)/exp(1) â‰ˆ 8100Ã—" }
  ], cheatSheet: "softmax(xáµ¢) = exp(xáµ¢) / Î£exp(xâ±¼). Max-trick: softmax(x) = softmax(x - max(x))" },
  // W2
  "week2_s0": { time: 10, difficulty: 3, prep: "Basit Ã¶rnek hazÄ±rlayÄ±n: f(x)=xÂ², df/dx=2x. x=3 â†’ f=9, df=6.", emphasize: "Autograd olmadan Ã¶ÄŸrenme yok. Bu haftanÄ±n konusu dersin TEMELÄ°.", studentQs: [
    { q: "Bunun GPT ile ne ilgisi var?", a: "GPT parametrelerini nasÄ±l gÃ¼ncelliyor? Loss â†’ gradient â†’ gÃ¼ncelleme. Bu sÃ¼recin motoru autograd." }
  ], cheatSheet: "Autograd: forward(hesapla) â†’ backward(tÃ¼rev al) â†’ gÃ¼ncelle(w -= lr * grad)" },
  "week2_s1": { time: 8, difficulty: 3, emphasize: "Her Value: data + grad + backward fonksiyonu. 3 bileÅŸen, hepsi bu.", cheatSheet: "Value(data=3.0, grad=0.0, _backward=lambda: None)" },
  "week2_s2": { time: 8, difficulty: 4, prep: "Chain rule Ã¶rneÄŸi tahtada: f(g(x)) = (3x+1)Â². df/dx = 2(3x+1)Â·3", emphasize: "Chain rule = autograd'Ä±n TEK sÄ±rrÄ±. Bunu anladÄ±klarÄ±nda geri kalanÄ± kolay.", studentQs: [
    { q: "Birden fazla girdi olunca ne olur?", a: "Partial derivative: her girdi iÃ§in ayrÄ± ayrÄ± tÃ¼rev al, diÄŸerlerini sabit tut." }
  ], cheatSheet: "Chain rule: âˆ‚L/âˆ‚x = âˆ‚L/âˆ‚y Â· âˆ‚y/âˆ‚x. Multiply: âˆ‚(aÂ·b)/âˆ‚a = b, âˆ‚(aÂ·b)/âˆ‚b = a" },
  // W3
  "week3_s0": { time: 5, difficulty: 2, emphasize: "RNN â†’ sÄ±ralÄ± darboÄŸaz. Attention â†’ paralel + uzun mesafe. 2017 devrim.", cheatSheet: "RNN: O(n) sÄ±ralÄ±. Attention: O(nÂ²) paralel â†’ GPU'da Ã§ok daha hÄ±zlÄ±" },
  "week3_s1": { time: 10, difficulty: 4, prep: "3 token Ã¶rneÄŸi hazÄ±rlayÄ±n: 'a','b','c'. Q,K,V matrislerini 2Ã—2 yapÄ±n. Elle hesaplayÄ±n.", emphasize: "Attention = her token tÃ¼m Ã¶nceki tokenlara bakÄ±p 'hangisi bana lazÄ±m?' diyor. KÃ¼tÃ¼phane analojisi.", studentQs: [
    { q: "Neden Q, K, V ayrÄ±?", a: "Q = 'ne arÄ±yorum', K = 'bende ne var', V = 'bilgim ne'. Rol ayrÄ±mÄ± â†’ esneklik." },
    { q: "Bu O(nÂ²) deÄŸil mi? YavaÅŸ olmaz mÄ±?", a: "Evet, ama GPU ile paralelize edilebilir. Ve Flash Attention gibi teknikler var (W7'de gÃ¶receÄŸiz)." }
  ], cheatSheet: "Attention(Q,K,V) = softmax(QKáµ€/âˆšd)Â·V. d=head_dim=n_embd/n_head=16/4=4" },
  "week3_s2": { time: 8, difficulty: 4, emphasize: "Scaled dot-product'Ä±n 'scaled' kÄ±smÄ± kritik. âˆšd olmadan gradientler Ã§ok bÃ¼yÃ¼k olur.", cheatSheet: "score = QÂ·Káµ€ / âˆšd_k. d_k=4 â†’ /2. BÃ¼yÃ¼k d_k â†’ kÃ¼Ã§Ã¼k gradient â†’ daha kararlÄ±" },
  // W4
  "week4_s0": { time: 8, difficulty: 3, prep: "Transformer bloÄŸu diyagramÄ± Ã§izin: Input â†’ Norm â†’ Attention â†’ +Residual â†’ Norm â†’ MLP â†’ +Residual", emphasize: "Transformer = Lego. Attention + MLP bloklarÄ±nÄ± Ã¼st Ã¼ste koy.", cheatSheet: "x = x + Attention(Norm(x)). x = x + MLP(Norm(x)). Residual connection = toplama" },
  "week4_s1": { time: 5, difficulty: 3, emphasize: "RMSNorm: x/âˆš(mean(xÂ²)+Îµ). LayerNorm'dan %30 hÄ±zlÄ±, modern standart.", cheatSheet: "RMSNorm(x) = x Â· Î³ / âˆš(mean(xÂ²) + Îµ). Î³ Ã¶ÄŸrenilebilir, Îµ=1e-5" },
  "week4_s2": { time: 8, difficulty: 3, emphasize: "MLP: geniÅŸlet â†’ aktive et â†’ daralt. 16â†’64â†’16. Token iÃ§i bilgi iÅŸleme.", cheatSheet: "MLP(x) = Wâ‚‚ Â· activation(Wâ‚ Â· x + bâ‚) + bâ‚‚. Hidden=4Ã—n_embd=64" },
  // W5
  "week5_s0": { time: 5, difficulty: 2, emphasize: "EÄŸitim = loss'u minimize et. Loss dÃ¼ÅŸÃ¼yorsa model Ã¶ÄŸreniyor.", cheatSheet: "EÄŸitim dÃ¶ngÃ¼sÃ¼: forward â†’ loss â†’ backward â†’ step â†’ zero_grad â†’ tekrarla" },
  "week5_s1": { time: 8, difficulty: 3, emphasize: "Cross-entropy: -log(P(doÄŸru)). P=1 â†’ loss=0, P=0.01 â†’ loss=4.6. Log Ã§ok sert cezalandÄ±rÄ±r.", studentQs: [
    { q: "Neden MSE deÄŸil de cross-entropy?", a: "OlasÄ±lÄ±k daÄŸÄ±lÄ±mlarÄ± iÃ§in cross-entropy daha uygun. MSE gradient'i kÃ¼Ã§Ã¼k olasÄ±lÄ±klarda Ã§ok yavaÅŸ." }
  ], cheatSheet: "CE = -log(P(doÄŸru)). Rastgele: -log(1/27)=3.33. Ä°yi model: -log(0.3)â‰ˆ1.2" },
  "week5_s2": { time: 10, difficulty: 4, prep: "2D loss landscape Ã§izimi hazÄ±rlayÄ±n (vadi + top analojisi).", emphasize: "GD: gradient'in tersi yÃ¶nÃ¼nde adÄ±m at. LR Ã§ok bÃ¼yÃ¼k â†’ patlama, Ã§ok kÃ¼Ã§Ã¼k â†’ yavaÅŸ.", cheatSheet: "w = w - lr Ã— âˆ‚L/âˆ‚w. lr=0.01. Adam: momentum + adaptive LR per parameter" },
  // W6
  "week6_s0": { time: 8, difficulty: 2, prep: "CanlÄ± demo: temperature=0.1 vs 1.0 vs 2.0 ile isim Ã¼retin.", emphasize: "Ãœretim = eÄŸitimin tersi. Forward pass + sample. Temperature ile Ã§eÅŸitlilik ayarÄ±.", studentQs: [
    { q: "Temperature neden 'sÄ±caklÄ±k' deniyor?", a: "Fizikten geliyor: yÃ¼ksek sÄ±caklÄ±k â†’ daha kaotik parÃ§acÄ±klar â†’ daha rastgele daÄŸÄ±lÄ±m." }
  ], cheatSheet: "logits/T â†’ softmax â†’ sample. T=0.1: deterministik, T=1: normal, T=2: kaotik" },
  "week6_s1": { time: 5, difficulty: 3, emphasize: "KV cache: Ã¶nceki pozisyonlarÄ± tekrar hesaplama â†’ O(n) yerine O(1) per token.", cheatSheet: "Cache K,V her pozisyonda. Yeni token: sadece 1 Q hesapla, cache'ten K,V al" },
  // W7
  "week7_s0": { time: 8, difficulty: 2, emphasize: "Scaling laws = AI'Ä±n Moore YasasÄ±. 10Ã— param â†’ belirli miktarda loss dÃ¼ÅŸÃ¼ÅŸÃ¼.", cheatSheet: "L(N) = a/N^b. Chinchilla optimal: D â‰ˆ 20N (20 token per parametre)" },
  "week7_s1": { time: 10, difficulty: 1, prep: "Timeline'Ä± ekranda gÃ¶sterip her dÃ¶nemi tek tek geÃ§in.", emphasize: "2017â†’2024: 7 yÄ±lda dÃ¼nya deÄŸiÅŸti. Transformer tek makale ile baÅŸladÄ±." },
  "week7_s3": { time: 8, difficulty: 2, emphasize: "Pre-training (%95 maliyet) â†’ SFT â†’ RLHF. RLHF akÄ±l vermez, davranÄ±ÅŸ dÃ¼zeltir.", studentQs: [
    { q: "ChatGPT neden bazen yanlÄ±ÅŸ sÃ¶ylÃ¼yor?", a: "Pre-training'de yanlÄ±ÅŸ bilgi de Ã¶ÄŸreniyor. RLHF sadece FORMAT'Ä± (kibarlÄ±k, yapÄ±) dÃ¼zeltir, BÄ°LGÄ°'yi dÃ¼zeltmez." }
  ] },
  // W8-W9
  // W0 remaining
  "week0_s8": { time: 5, difficulty: 1, prep: "Terminal aÃ§Ä±k olsun. python microgpt.py komutunu birlikte Ã§alÄ±ÅŸtÄ±rÄ±n.", emphasize: "Ä°lk Ã§alÄ±ÅŸtÄ±rma Ã¶ÄŸrenciler iÃ§in bÃ¼yÃ¼lÃ¼ an. Hep birlikte yapÄ±n!", studentQs: [
    { q: "Hata aldÄ±m?", a: "Python versiyonunu kontrol edin (3.8+). Dosya yolunu kontrol edin. En yaygÄ±n hata: yanlÄ±ÅŸ dizin." }
  ] },
  "week0_s9": { time: 10, difficulty: 2, prep: "n_embd=8 vs 32, steps=100 vs 1000 sonuÃ§larÄ±nÄ± Ã¶nceden hazÄ±rlayÄ±n.", emphasize: "Parametreleri deÄŸiÅŸtirmek = deney yapmak. Bu bilimsel sÃ¼recin baÅŸlangÄ±cÄ±.", studentQs: [
    { q: "Hangi parametre en Ã¶nemli?", a: "n_embd ve n_layer loss'a en Ã§ok etki eder. Bunu sistematik deneylerle araÅŸtÄ±rabilirsiniz." }
  ] },
  "week0_s10": { time: 5, difficulty: 1, emphasize: "TÃ¼rkÃ§e isimler, ÅŸehir adlarÄ±, kelimeler... veri deÄŸiÅŸtirmek Ã§ok kolay.", studentQs: [
    { q: "TÃ¼rkÃ§e Ã§alÄ±ÅŸÄ±r mÄ±?", a: "Evet ama TÃ¼rkÃ§e harfler (ÄŸ,Ã¼,ÅŸ,Ä±,Ã¶,Ã§) vocab'a eklenmeli. Vocab 27â†’33 olur." }
  ] },
  "week0_s11": { time: 5, difficulty: 1, emphasize: "EÄŸitim ilerledikÃ§e isimler daha gerÃ§ekÃ§i olur. Loss dÃ¼ÅŸÃ¼ÅŸÃ¼nÃ¼ gÃ¶sterin." },
  "week0_s12": { time: 5, difficulty: 1, emphasize: "microGPT â†’ GPT-4: aynÄ± algoritma, farklÄ± Ã¶lÃ§ek. Bu ders o kÃ¶prÃ¼yÃ¼ kuruyor." },
  // W1 remaining
  "week1_s4": { time: 10, difficulty: 2, prep: "Tokenizer playground'u aÃ§Ä±n. 'emma', 'michael', 'x' yazarak farklarÄ± gÃ¶sterin.", emphasize: "Ä°nteraktif deney: Ã¶ÄŸrenciler kendi isimlerini tokenize etsin." },
  "week1_s5": { time: 5, difficulty: 2, emphasize: "VektÃ¶r = yÃ¶nlÃ¼ bÃ¼yÃ¼klÃ¼k. [0.3, -0.1, 0.8] = 3 boyutlu uzayda nokta.", cheatSheet: "VektÃ¶r: v âˆˆ â„â¿. microGPT: n=16. Benzerlik: cos(a,b) = aÂ·b / (|a||b|)" },
  "week1_s6": { time: 5, difficulty: 2, emphasize: "Embedding tablosu = Ã¶ÄŸrenilebilir sÃ¶zlÃ¼k. wte[5] = 'e' harfinin vektÃ¶rÃ¼.", cheatSheet: "wte: [27Ã—16]. Lookup: embed(token_id) = wte[token_id]. EÄŸitimle gÃ¼ncellenir" },
  "week1_s7": { time: 5, difficulty: 2, emphasize: "'abc' ve 'cba' position embedding olmadan AYNI gÃ¶rÃ¼nÃ¼r. Bu Ã§ok ÅŸaÅŸÄ±rtÄ±cÄ±.", cheatSheet: "wpe: [8Ã—16]. x = wte[tok] + wpe[pos]. block_size=8 â†’ max 8 pozisyon" },
  "week1_s8": { time: 5, difficulty: 3, emphasize: "Matris Ã§arpÄ±mÄ± = embedding'den sonraki HER adÄ±mÄ±n temeli. y = Wx + b", cheatSheet: "[MÃ—K] Â· [KÃ—N] = [MÃ—N]. microGPT: [batchÃ—16] Â· [16Ã—64] = [batchÃ—64]" },
  "week1_s9": { time: 5, difficulty: 2, emphasize: "Weight tying: aynÄ± matris giriÅŸ+Ã§Ä±kÄ±ÅŸta â†’ parametre tasarrufu + tutarlÄ±lÄ±k.", cheatSheet: "logits = x @ wte.T (transpoz). 3,648 parametrenin Ã¶nemli kÄ±smÄ± wte'de" },
  "week1_s10": { time: 5, difficulty: 2, emphasize: "Softmax: ham skor â†’ olasÄ±lÄ±k. Toplam=1. exp kullanarak negatifi pozitife Ã§evirir.", cheatSheet: "softmax(xáµ¢) = exp(xáµ¢)/Î£exp(xâ±¼). Max-trick: overflow Ã¶nleme. Î£=1 her zaman" },
  // W2 remaining
  "week2_s3": { time: 5, difficulty: 3, emphasize: "KÄ±smi tÃ¼rev: birden fazla deÄŸiÅŸken olunca her birini ayrÄ± tÃ¼revle.", cheatSheet: "âˆ‚f/âˆ‚x: x'e gÃ¶re tÃ¼rev, y sabit. Gradient: âˆ‡f = [âˆ‚f/âˆ‚x, âˆ‚f/âˆ‚y, ...]" },
  "week2_s4": { time: 10, difficulty: 3, prep: "Autograd playground'u aÃ§Ä±n. Basit bir graf oluÅŸturup backward Ã§alÄ±ÅŸtÄ±rÄ±n.", emphasize: "CanlÄ± deney: Ã¶ÄŸrenciler a=2, b=3, c=a*b+a grafÄ±nÄ± oluÅŸtursun." },
  "week2_s5": { time: 5, difficulty: 3, emphasize: "Value = autograd'Ä±n atom'u. data, grad, _children, _backward.", cheatSheet: "Value(2.0).data=2.0, .grad=0.0. Backward sonrasÄ± .grad dolacak" },
  "week2_s6": { time: 5, difficulty: 3, emphasize: "__add__, __mul__ overload: a+b yazdÄ±ÄŸÄ±nÄ±zda Python otomatik graf oluÅŸturur.", cheatSheet: "a + b â†’ Value.__add__(a,b) â†’ yeni node + backward fonksiyonu kaydeder" },
  "week2_s7": { time: 8, difficulty: 4, emphasize: "Chain rule: âˆ‚L/âˆ‚x = âˆ‚L/âˆ‚y Â· âˆ‚y/âˆ‚x. TÃ¼m backward pass bu TEK kurala dayanÄ±r.", cheatSheet: "Add backward: grad += 1 Ã— out.grad. Mul backward: grad += other.data Ã— out.grad" },
  "week2_s8": { time: 5, difficulty: 3, prep: "L = (aÃ—b)+c Ã¶rneÄŸini tahtada Ã§izin, elle backward yapÄ±n.", emphasize: "Somut Ã¶rnek: a=2, b=-3, c=10. L=(2Ã—-3)+10=4. âˆ‚L/âˆ‚a=-3, âˆ‚L/âˆ‚b=2, âˆ‚L/âˆ‚c=1" },
  "week2_s9": { time: 5, difficulty: 3, emphasize: "grad += (topla), grad = (ata) DEÄÄ°L! AynÄ± deÄŸiÅŸken birden fazla yerde kullanÄ±lÄ±rsa gradientler toplanÄ±r.", studentQs: [
    { q: "Neden += kullanÄ±yoruz?", a: "y = x+x olsun. âˆ‚y/âˆ‚x = 2, ama iki ayrÄ± yoldan 1+1=2. Toplama yapmazsak 1 buluruz â€” yanlÄ±ÅŸ!" }
  ] },
  "week2_s10": { time: 5, difficulty: 2, emphasize: "Bizim Value sÄ±nÄ±fÄ± = PyTorch'un autograd'Ä±nÄ±n mini versiyonu. AynÄ± mantÄ±k, farklÄ± Ã¶lÃ§ek." },
  // W3 remaining
  "week3_s3": { time: 8, difficulty: 3, emphasize: "Her token 'soru soruyor': Ben kim olmalÄ±yÄ±m? Cevap iÃ§in tÃ¼m Ã¶nceki tokenlara bakÄ±yor.", cheatSheet: "Attention weight Î±[i][j] = token i'nin token j'ye ne kadar dikkat ettiÄŸi" },
  "week3_s4": { time: 8, difficulty: 3, prep: "KÃ¼tÃ¼phane analojisi: Q=soru, K=kitap etiketi, V=kitap iÃ§eriÄŸi. Tahtaya Ã§izin.", emphasize: "QÂ·K = uyum skoru. YÃ¼ksek skor = 'bu kitap bana lazÄ±m'. V = o kitabÄ±n bilgisi." },
  "week3_s5": { time: 10, difficulty: 3, prep: "Attention playground'u aÃ§Ä±n. 'abc' yazÄ±p head kalÄ±plarÄ±nÄ± inceleyin.", emphasize: "Her head farklÄ± kalÄ±p Ã¶ÄŸrenir: biri Ã¶nceki harfe bakar, biri sesli harflere." },
  "week3_s6": { time: 8, difficulty: 4, prep: "3 token, 2 boyutlu Q,K,V ile elle hesaplama hazÄ±rlayÄ±n.", emphasize: "Tam formÃ¼l: softmax(QKáµ€/âˆšd)Â·V. âˆšd olmazsa gradient patlar.", cheatSheet: "Q,K,V: [seqÃ—d_k]. QKáµ€: [seqÃ—seq]. softmax: satÄ±r bazlÄ±. Ã—V: [seqÃ—d_k]" },
  "week3_s7": { time: 5, difficulty: 2, emphasize: "Dot product = benzerlik Ã¶lÃ§Ã¼sÃ¼. aÂ·b bÃ¼yÃ¼k â†’ aynÄ± yÃ¶n, kÃ¼Ã§Ã¼k â†’ farklÄ± yÃ¶n.", cheatSheet: "aÂ·b = Î£aáµ¢báµ¢. Geometric: |a||b|cos(Î¸). cos(Î¸)=1: aynÄ± yÃ¶n, 0: dik, -1: ters" },
  "week3_s8": { time: 8, difficulty: 3, emphasize: "Multi-head: 4 farklÄ± bakÄ±ÅŸ aÃ§Ä±sÄ±. Causal mask: gelecek tokenlarÄ± -âˆ yaparak gizle.", cheatSheet: "n_head=4, d_k=16/4=4. Mask: attn[i][j>i] = -âˆ â†’ softmax sonrasÄ± 0" },
  "week3_s9": { time: 5, difficulty: 3, emphasize: "Head Ã§Ä±ktÄ±larÄ± concat â†’ Wo ile projeksiyon. 4Ã—4=16 boyuta geri dÃ¶n.", cheatSheet: "MultiHead = Concat(head1,...,head4) Â· Wo. Wo: [16Ã—16]" },
  // W4 remaining
  "week4_s3": { time: 10, difficulty: 3, prep: "Transformer flow viz'i aÃ§Ä±n. AdÄ±m adÄ±m geÃ§in.", emphasize: "Her adÄ±mda veri nasÄ±l deÄŸiÅŸiyor? GiriÅŸ â†’ Norm â†’ Attention â†’ +Residual â†’ Norm â†’ MLP â†’ +Residual" },
  "week4_s4": { time: 5, difficulty: 3, emphasize: "RMSNorm: mean Ã§Ä±karma yok, sadece Ã¶lÃ§ekleme. Daha hÄ±zlÄ±, modern standart.", cheatSheet: "RMSNorm(x) = xÂ·Î³/âˆš(mean(xÂ²)+Îµ). vs LayerNorm: (x-Î¼)Â·Î³/Ïƒ + Î²" },
  "week4_s5": { time: 5, difficulty: 3, emphasize: "MLP = token iÃ§i bilgi iÅŸleme. Attention token arasÄ±, MLP token iÃ§i.", cheatSheet: "MLP: 16â†’64(Ã—4)â†’16. W1:[16Ã—64], W2:[64Ã—16]. ReLUÂ²(x) = max(0,x)Â²" },
  "week4_s6": { time: 5, difficulty: 2, emphasize: "Aktivasyon olmadan derin aÄŸ = sÄ±ÄŸ aÄŸ. Non-linearity = Ã¶ÄŸrenme kapasitesi.", cheatSheet: "ReLU: max(0,x). ReLUÂ²: max(0,x)Â². GELU: xÂ·Î¦(x). Tanh: (eÂ²Ë£-1)/(eÂ²Ë£+1)" },
  "week4_s7": { time: 5, difficulty: 3, emphasize: "Residual = x + f(x). Gradient highway: derin aÄŸlarda gradient serbest akÄ±yor.", studentQs: [
    { q: "Neden sadece topluyoruz?", a: "Skip connection gradientlerin katmanlar boyunca akmasÄ±nÄ± saÄŸlar. Olmasa 10+ katmanda gradient kaybolur." }
  ] },
  "week4_s8": { time: 5, difficulty: 3, emphasize: "BaÅŸlatma kritik: sÄ±fÄ±r = Ã¶ÄŸrenmeme, bÃ¼yÃ¼k = patlama, kÃ¼Ã§Ã¼k = kaybolma.", cheatSheet: "Xavier: std=1/âˆšn. Kaiming: std=âˆš(2/n). microGPT: 0.02 std normal" },
  "week4_s9": { time: 5, difficulty: 2, emphasize: "RMSNorm vs LayerNorm: pratik fark kÃ¼Ã§Ã¼k ama hÄ±z farkÄ± %30.", cheatSheet: "LayerNorm: (x-Î¼)/ÏƒÂ·Î³+Î² (4 op). RMSNorm: x/âˆš(mean(xÂ²)+Îµ)Â·Î³ (3 op)" },
  // W5 remaining
  "week5_s3": { time: 8, difficulty: 3, prep: "Vadi + top analojisi Ã§izin. Top = model, vadi = minimum, eÄŸim = gradient.", emphasize: "GD: gradient yokuÅŸ aÅŸaÄŸÄ±yÄ± gÃ¶sterir. AdÄ±m boyutu = learning rate.", cheatSheet: "w_new = w_old - lr Ã— âˆ‚L/âˆ‚w. lr=0.01. BÃ¼yÃ¼k lr â†’ salÄ±nÄ±m, kÃ¼Ã§Ã¼k lr â†’ yavaÅŸ" },
  "week5_s4": { time: 10, difficulty: 3, prep: "Training sim'i aÃ§Ä±n. LR slider'Ä± 0.001 â†’ 0.1 arasÄ±nda gezdirin.", emphasize: "CanlÄ± deney: LR=0.001 Ã§ok yavaÅŸ, LR=0.1 patlÄ±yor, LR=0.01 ideal." },
  "week5_s5": { time: 5, difficulty: 3, emphasize: "CE = -log(P). P yÃ¼ksek â†’ loss dÃ¼ÅŸÃ¼k. P dÃ¼ÅŸÃ¼k â†’ loss Ã§ok yÃ¼ksek.", cheatSheet: "P=1: loss=0. P=0.5: loss=0.69. P=0.1: loss=2.3. P=0.01: loss=4.6" },
  "week5_s6": { time: 5, difficulty: 2, emphasize: "Log neden kullanÄ±lÄ±yor? DÃ¼ÅŸÃ¼k olasÄ±lÄ±ÄŸa Ã‡OK aÄŸÄ±r ceza verir.", cheatSheet: "-log(0.5)=0.69 ama -(1-0.5)=0.5. -log(0.01)=4.6 ama -(1-0.01)=0.99. Log daha sert" },
  "week5_s7": { time: 5, difficulty: 3, emphasize: "Adam: momentum (geÃ§miÅŸ gradientler) + adaptive (her parametre kendi lr'si).", cheatSheet: "Adam: m = Î²â‚m + (1-Î²â‚)g, v = Î²â‚‚v + (1-Î²â‚‚)gÂ². w -= lrÂ·mÌ‚/âˆšvÌ‚+Îµ. Î²â‚=0.9, Î²â‚‚=0.999" },
  "week5_s8": { time: 5, difficulty: 2, emphasize: "Cosine decay: baÅŸta bÃ¼yÃ¼k adÄ±m (keÅŸif), sonda kÃ¼Ã§Ã¼k (hassas ayar).", cheatSheet: "lr_t = lr_min + 0.5(lr_max-lr_min)(1+cos(Ï€t/T)). Warmup: ilk N adÄ±m lineer artÄ±ÅŸ" },
  "week5_s9": { time: 3, difficulty: 2, emphasize: "p.grad = 0 her adÄ±mda ÅART. Yoksa Ã¶nceki adÄ±mÄ±n gradienti birikir â†’ felaket.", studentQs: [
    { q: "Neden otomatik sÄ±fÄ±rlanmÄ±yor?", a: "Bazen kasÄ±tlÄ± olarak biriktirmek istersiniz (gradient accumulation). PyTorch da aynÄ±: optimizer.zero_grad()" }
  ] },
  // W6 remaining
  "week6_s2": { time: 5, difficulty: 2, emphasize: "EÄŸitim: forward+backward+update. Inference: sadece forward. Dropout OFF, BatchNorm fixed.", cheatSheet: "EÄŸitim: loss hesapla â†’ backprop â†’ gÃ¼ncelle. Inference: tahmin yap â†’ bitir" },
  "week6_s3": { time: 8, difficulty: 2, emphasize: "Autoregressive: BOS â†’ 'e' â†’ 'em' â†’ 'emm' â†’ 'emma' â†’ BOS. Her adÄ±m 1 token.", cheatSheet: "Loop: token = BOS. while token != BOS: logits = forward(tokens). token = sample(softmax(logits/T))" },
  "week6_s4": { time: 10, difficulty: 2, prep: "Generation playground'u aÃ§Ä±n. Temperature'Ä± deÄŸiÅŸtirerek farkÄ± gÃ¶sterin.", emphasize: "T=0.1: hep aynÄ± isimler. T=1.0: Ã§eÅŸitli. T=2.0: saÃ§ma isimler. CanlÄ± gÃ¶sterin." },
  "week6_s5": { time: 5, difficulty: 2, emphasize: "Temperature = softmax'Ä± keskinleÅŸtirme/dÃ¼zleÅŸtirme. Matematik basit: logits/T.", cheatSheet: "T<1: [0.1,0.8,0.1]â†’[0.01,0.98,0.01] (keskin). T>1: [0.1,0.8,0.1]â†’[0.2,0.6,0.2] (dÃ¼z)" },
  "week6_s6": { time: 5, difficulty: 2, emphasize: "Greedy = her zaman en yÃ¼ksek. Top-k = ilk k'dan sample. Nucleus = toplam %p'ye kadar.", cheatSheet: "Greedy: argmax. Top-k: en yÃ¼ksek k seÃ§, diÄŸerleri 0. Top-p: kÃ¼mÃ¼latif â‰¤ p olanlar" },
  "week6_s7": { time: 5, difficulty: 3, emphasize: "KV cache: tekrar hesaplama yok. Yeni token iÃ§in sadece 1 Q hesapla.", cheatSheet: "Without cache: n token â†’ O(nÂ²). With cache: n token â†’ O(n). Bellek: O(nÃ—dÃ—layers)" },
  "week6_s8": { time: 5, difficulty: 2, emphasize: "UÃ§tan uca: isim girin, her adÄ±mÄ± takip edin: token â†’ embed â†’ attend â†’ MLP â†’ softmax â†’ sample" },
  "week6_s9": { time: 5, difficulty: 1, emphasize: "microGPT vs production: aynÄ± algoritma. Fark: veri Ã¶lÃ§eÄŸi, donanÄ±m, optimizasyon, RLHF." },
  // W7 remaining
  "week7_s2": { time: 8, difficulty: 2, emphasize: "Ä°nteraktif scatter plot'u gÃ¶sterin. microGPT â†’ GPT-4 noktalarÄ±nÄ± tÄ±klayÄ±n.", cheatSheet: "microGPT: 3.6K param, lossâ‰ˆ2.0. GPT-3: 175B, lossâ‰ˆ0.5. GPT-4: ~1.8T, lossâ‰ˆ0.3" },
  "week7_s4": { time: 5, difficulty: 1, prep: "Hardware kartlarÄ±nÄ± tÄ±klayarak specs'leri gÃ¶sterin.", emphasize: "GPU 312 TFLOPS vs CPU 0.5 TFLOPS = 624Ã— hÄ±z farkÄ±. AI = paralel matris Ã§arpÄ±mÄ±.", cheatSheet: "A100: 6912 CUDA core, 312 TFLOPS, 80GB HBM3, ~$10K" },
  "week7_s5": { time: 8, difficulty: 2, emphasize: "3 aÅŸama: pre-training (%95) â†’ SFT (%3) â†’ RLHF (%2). AsÄ±l gÃ¼Ã§ pre-training'den gelir.", studentQs: [
    { q: "RLHF olmadan ChatGPT olur mu?", a: "Model bilgili ama kaba, tutarsÄ±z, bazen tehlikeli olur. RLHF 'kibarlÄ±k + gÃ¼venlik' ekler, zeka eklemez." }
  ] },
  "week7_s6": { time: 5, difficulty: 2, emphasize: "Karakterâ†’BPEâ†’SentencePieceâ†’tiktoken. Her adÄ±m daha verimli tokenization.", cheatSheet: "Karakter: 27 vocab. BPE(GPT-2): 50K. tiktoken(GPT-4): 100K. Daha bÃ¼yÃ¼k vocab = daha az token" },
  "week7_s7": { time: 5, difficulty: 3, emphasize: "Vanilla O(nÂ²) bellek â†’ Flash O(n) bellek. AynÄ± matematik, farklÄ± hesaplama sÄ±rasÄ±.", cheatSheet: "Flash Attention: IO-aware tiling. HBMâ†’SRAM blok blok. 2-4Ã— hÄ±zlanma, sonuÃ§ identik" },
  "week7_s8": { time: 5, difficulty: 1, emphasize: "Open source devrim: LLaMA 3.1 405B, DeepSeek-V3 671B MoE. GPT-4'e yakÄ±n, Ã¼cretsiz.", cheatSheet: "LLaMA: Meta, 405B. Mistral: 7-22B+MoE. DeepSeek-V3: 671B (37B active). Qwen: Alibaba. Gemma: Google" },
  "week7_s9": { time: 8, difficulty: 2, emphasize: "5 trend: MoE (verimlilik), RAG (bilgi), Agent (araÃ§), Multimodal (Ã§ok mod), Reasoning (dÃ¼ÅŸÃ¼nce zinciri).", studentQs: [
    { q: "Bunlardan hangisi en Ã¶nemli?", a: "Hepsi birbirini tamamlÄ±yor. GPT-4 = MoE + Multimodal. o1 = Reasoning. Perplexity = RAG. Claude = Agent." }
  ] },
};

// â”€â”€â”€ LESSON PLAN â€” HaftalÄ±k Ders PlanÄ± â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const LESSON_PLANS = {
  0: { title: { tr: "GiriÅŸ & CanlÄ± Demo", en: "Introduction & Live Demo" }, totalMin: 75, plan: [
    { phase: "AÃ§Ä±lÄ±ÅŸ", min: 5, desc: "Ders tanÄ±tÄ±mÄ±, beklentiler, 'GPT nedir?' tartÄ±ÅŸmasÄ±" },
    { phase: "CanlÄ± Demo", min: 15, desc: "microGPT'yi Ã§alÄ±ÅŸtÄ±rÄ±n, isim Ã¼retin, Ã¶ÄŸrencilerle birlikte deneyin" },
    { phase: "Ders AnlatÄ±mÄ±", min: 30, desc: "S0-S7: Pipeline, parametreler, vocab. Her bÃ¶lÃ¼mde viz'i gÃ¶sterin" },
    { phase: "Hands-on Lab", min: 15, desc: "Ã–ÄŸrenciler kendi bilgisayarlarÄ±nda Ã§alÄ±ÅŸtÄ±rsÄ±n, parametreleri deÄŸiÅŸtirsin" },
    { phase: "KapanÄ±ÅŸ & Quiz", min: 10, desc: "7 soruluk quiz + gelecek haftaya hazÄ±rlÄ±k" }
  ]},
  1: { title: "Tokenization & Embedding", totalMin: 75, plan: [
    { phase: "Tekrar", min: 5, desc: "GeÃ§en haftanÄ±n pipeline'Ä±nÄ± tekrar edin. 'BugÃ¼n ilk kutuyu aÃ§Ä±yoruz'" },
    { phase: "Token Demo", min: 10, desc: "'emma' â†’ [BOS,e,m,m,a,BOS] tahtada gÃ¶sterin. Tokenizer playground" },
    { phase: "Embedding Ders", min: 20, desc: "ID â†’ vektÃ¶r dÃ¶nÃ¼ÅŸÃ¼mÃ¼, position embedding, weight tying" },
    { phase: "Hands-on", min: 15, desc: "Tokenizer Playground viz ile deney. FarklÄ± isimler deneyin" },
    { phase: "Softmax + Quiz", min: 15, desc: "Softmax aÃ§Ä±klamasÄ± + 7 soruluk quiz" },
    { phase: "KapanÄ±ÅŸ", min: 10, desc: "BPE vs karakter tartÄ±ÅŸmasÄ±, gelecek hafta: autograd" }
  ]},
  2: { title: "Autograd Engine", totalMin: 75, plan: [
    { phase: "Motivasyon", min: 10, desc: "Neden tÃ¼rev lazÄ±m? Basit Ã¶rnek: f(x)=xÂ², x=3 â†’ yokuÅŸ aÅŸaÄŸÄ± gitme" },
    { phase: "Value SÄ±nÄ±fÄ±", min: 15, desc: "data + grad + backward. Tahtada elle hesaplama" },
    { phase: "Chain Rule", min: 20, desc: "EN KRÄ°TÄ°K BÃ–LÃœM. BileÅŸik fonksiyon Ã¶rneÄŸi. YavaÅŸ gidin" },
    { phase: "Autograd Playground", min: 15, desc: "Ä°nteraktif viz ile graf oluÅŸturun, backward Ã§alÄ±ÅŸtÄ±rÄ±n" },
    { phase: "DoÄŸrulama + Quiz", min: 15, desc: "PyTorch ile gradient karÅŸÄ±laÅŸtÄ±rma + quiz" }
  ]},
  3: { title: "Attention Mechanism", totalMin: 75, plan: [
    { phase: "RNN â†’ Attention", min: 10, desc: "RNN'in sÄ±ralÄ± darboÄŸazÄ±nÄ± aÃ§Ä±klayÄ±n, attention neden icat edildi" },
    { phase: "Q, K, V Sezgisel", min: 15, desc: "KÃ¼tÃ¼phane analojisi: Q=soru, K=etiket, V=kitap. Tahtada 3 token Ã¶rneÄŸi" },
    { phase: "Scaled Dot-Product", min: 15, desc: "FormÃ¼l: softmax(QKáµ€/âˆšd)Â·V. Elle hesaplama yaptÄ±rÄ±n" },
    { phase: "Multi-Head + Causal", min: 10, desc: "Neden birden fazla head? Causal mask neden gerekli?" },
    { phase: "Attention Playground", min: 15, desc: "Ä°nteraktif viz ile attention aÄŸÄ±rlÄ±klarÄ±nÄ± inceleyin" },
    { phase: "Quiz", min: 10, desc: "7 soruluk quiz" }
  ]},
  4: { title: "Transformer Block", totalMin: 75, plan: [
    { phase: "BÃ¼yÃ¼k Resim", min: 10, desc: "Transformer = Attention + MLP + Residual + Norm. Lego analojisi" },
    { phase: "RMSNorm & Residual", min: 15, desc: "Neden normalize? Neden residual connection?" },
    { phase: "MLP & Aktivasyon", min: 15, desc: "GeniÅŸlet â†’ aktive et â†’ daralt. ReLUÂ² ve GELU karÅŸÄ±laÅŸtÄ±rma" },
    { phase: "Transformer Flow Viz", min: 15, desc: "Ä°nteraktif bileÅŸen ile veri akÄ±ÅŸÄ±nÄ± takip edin" },
    { phase: "Weight Init + Quiz", min: 20, desc: "Neden baÅŸlatma Ã¶nemli? + quiz" }
  ]},
  5: { title: "Training Loop", totalMin: 75, plan: [
    { phase: "GiriÅŸ", min: 5, desc: "Ã–ÄŸrenme = loss'u minimize etme. Basit tepe/vadi analojisi" },
    { phase: "Cross-Entropy", min: 15, desc: "-log(P). Tahtada hesaplama: P=0.5 â†’ loss=0.69, P=0.01 â†’ loss=4.6" },
    { phase: "Gradient Descent", min: 15, desc: "w -= lr Ã— grad. LR etkisi: bÃ¼yÃ¼k â†’ patlama, kÃ¼Ã§Ã¼k â†’ yavaÅŸ" },
    { phase: "Adam + LR Decay", min: 10, desc: "Momentum + adaptive. Cosine decay" },
    { phase: "Training Sim", min: 15, desc: "Ä°nteraktif eÄŸitim simÃ¼lasyonu: LR slider ile canlÄ± deney" },
    { phase: "Quiz + KapanÄ±ÅŸ", min: 15, desc: "Quiz + gelecek hafta: inference" }
  ]},
  6: { title: "Inference & Generation", totalMin: 75, plan: [
    { phase: "Demo Ã–nce", min: 10, desc: "Temperature 0.1 vs 2.0 canlÄ± gÃ¶sterin. Ã–ÄŸrenciler tahmin etsin" },
    { phase: "Sampling Stratejileri", min: 15, desc: "Greedy, random, top-k. Temperature etkisi" },
    { phase: "KV Cache", min: 15, desc: "Neden cache? O(nÂ²) â†’ O(n). Bellekte ne saklanÄ±yor?" },
    { phase: "Generation Playground", min: 15, desc: "Ä°nteraktif viz ile Ã¼retim deneyleri" },
    { phase: "Quiz + YarÄ± DÃ¶nem Ã–zeti", min: 20, desc: "Quiz + W0-W6 Ã¶zet. Genel Ã¶zet" }
  ]},
  7: { title: "Modern AI Evrimi", totalMin: 75, plan: [
    { phase: "Scaling Laws", min: 10, desc: "microGPT â†’ GPT-4 grafiÄŸi. GÃ¼Ã§ yasasÄ±. Chinchilla" },
    { phase: "Timeline", min: 15, desc: "2017-2024 interaktif timeline. Her dÃ¶neme 2 dk" },
    { phase: "DonanÄ±m & Pipeline", min: 15, desc: "CPUâ†’GPUâ†’TPU. Pre-trainingâ†’SFTâ†’RLHF" },
    { phase: "Open Source & Trendler", min: 15, desc: "LLaMA, Mistral, DeepSeek. MoE, RAG, Agent" },
    { phase: "TartÄ±ÅŸma + Quiz", min: 20, desc: "AI'Ä±n geleceÄŸi tartÄ±ÅŸmasÄ± + quiz" }
  ]},
};

// â”€â”€â”€ INSTRUCTOR CHEAT SHEETS â€” Her Hafta Ä°Ã§in Kopya KaÄŸÄ±dÄ± â”€â”€â”€â”€â”€
const WEEK_CHEAT_SHEETS = {
  0: { title: "W0: GiriÅŸ Kopya KaÄŸÄ±dÄ±", formulas: ["Pipeline: Tokenâ†’Embedâ†’Posâ†’Attnâ†’MLPâ†’Softmaxâ†’Sample", "Vocab=27 (a-z + BOS), n_embd=16, n_head=4, n_layer=1", "Parametre: 3,648. Block_size=8 (context window)", "Autoregressive: P(xâ‚œ | xâ‚...xâ‚œâ‚‹â‚)"], keyPoints: ["microGPT = gerÃ§ek GPT, sadece kÃ¼Ã§Ã¼k", "243 satÄ±r, 0 baÄŸÄ±mlÄ±lÄ±k", "Ä°sim Ã¼retir, karakter karakter"] },
  1: { title: "W1: Token Kopya KaÄŸÄ±dÄ±", formulas: ["stoi: charâ†’int, itos: intâ†’char", "wte: [27Ã—16] embed matris, wpe: [8Ã—16] pos matris", "x = wte[token_id] + wpe[position]", "softmax(xáµ¢) = exp(xáµ¢) / Î£exp(xâ±¼)"], keyPoints: ["Token = modelin atom'u", "Embedding: IDâ†’vektÃ¶r (Ã¶ÄŸrenilebilir)", "Weight tying: wte giriÅŸ+Ã§Ä±kÄ±ÅŸta paylaÅŸÄ±lÄ±r"] },
  2: { title: "W2: Autograd Kopya KaÄŸÄ±dÄ±", formulas: ["Value: data + grad + _backward()", "Chain rule: âˆ‚L/âˆ‚x = âˆ‚L/âˆ‚y Â· âˆ‚y/âˆ‚x", "Add: âˆ‚(a+b)/âˆ‚a = 1", "Mul: âˆ‚(aÂ·b)/âˆ‚a = b", "Topological sort â†’ backward sÄ±ra"], keyPoints: ["Autograd = otomatik tÃ¼rev hesaplama", "Forward: graf oluÅŸtur, Backward: gradient hesapla", "Her operasyon kendi tÃ¼revini bilir"] },
  3: { title: "W3: Attention Kopya KaÄŸÄ±dÄ±", formulas: ["Attention(Q,K,V) = softmax(QKáµ€/âˆšd)Â·V", "Q = xÂ·Wq, K = xÂ·Wk, V = xÂ·Wv", "head_dim = n_embd/n_head = 16/4 = 4", "Causal mask: score[i][j>i] = -âˆ"], keyPoints: ["Q=soru, K=etiket, V=bilgi", "Multi-head: 4 farklÄ± bakÄ±ÅŸ aÃ§Ä±sÄ±", "Causal: gelecek tokenlarÄ± gÃ¶rmez"] },
  4: { title: "W4: Transformer Kopya KaÄŸÄ±dÄ±", formulas: ["x = x + Attention(Norm(x))", "x = x + MLP(Norm(x))", "RMSNorm(x) = xÂ·Î³ / âˆš(mean(xÂ²)+Îµ)", "MLP: Wâ‚‚Â·act(Wâ‚Â·x+bâ‚)+bâ‚‚, hidden=4Ã—16=64"], keyPoints: ["Residual: bilgi kaybÄ±nÄ± Ã¶nler", "Pre-norm: modern standart", "MLP: token iÃ§i bilgi iÅŸleme"] },
  5: { title: "W5: Training Kopya KaÄŸÄ±dÄ±", formulas: ["CE Loss = -log(P(doÄŸru))", "Rastgele loss = -log(1/27) = 3.33", "GD: w = w - lr Ã— âˆ‚L/âˆ‚w", "Adam: momentum + adaptive per-param"], keyPoints: ["Loss dÃ¼ÅŸÃ¼yorsa model Ã¶ÄŸreniyor", "LR Ã§ok kritik: 0.01 iyi baÅŸlangÄ±Ã§", "Her adÄ±mda grad sÄ±fÄ±rla!"] },
  6: { title: "W6: Inference Kopya KaÄŸÄ±dÄ±", formulas: ["logits/T â†’ softmax â†’ sample", "T<1: keskin, T=1: normal, T>1: dÃ¼z", "KV Cache: O(nÂ²) â†’ O(n) per token", "Top-k: sadece en yÃ¼ksek k olasÄ±lÄ±ktan seÃ§"], keyPoints: ["Ãœretim = forward + sample dÃ¶ngÃ¼sÃ¼", "Temperature = Ã§eÅŸitlilik kontrolÃ¼", "BOS ile baÅŸla, BOS gelince dur"] },
  7: { title: "W7: Evrim Kopya KaÄŸÄ±dÄ±", formulas: ["L(N) = a/N^b (scaling law)", "Chinchilla: D â‰ˆ 20N", "Flash Attn: O(nÂ²) compute, O(n) memory", "MoE: 8 expert, 2 active per token"], keyPoints: ["2017 Transformer â†’ 2024 Frontier", "Pre-trainingâ†’SFTâ†’RLHF pipeline", "Open source: LLaMA, Mistral, DeepSeek"] },
};

// â”€â”€â”€ INSTRUCTOR UI COMPONENTS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const InstructorPanel = ({ weekIdx, sectionIdx, weekColor }) => {
  const key = `week${weekIdx}_s${sectionIdx}`;
  const notes = INSTRUCTOR_NOTES[key];
  const [showQs, setShowQs] = useState(false);
  if (!notes) return null;
  return (
    <div style={{ background: "rgba(251,191,36,0.04)", border: "1px solid rgba(251,191,36,0.15)", borderRadius: 14, padding: 16, marginBottom: 12 }}>
      <div style={{ display: "flex", alignItems: "center", gap: 8, marginBottom: 10 }}>
        <span style={{ fontSize: 19 }}>ğŸ“</span>
        <span style={{ fontSize: 15, fontWeight: 700, color: "#FBBF24" }}>{lang==="tr"?"Hoca NotlarÄ±":"Instructor Notes"}</span>
        {notes.time && <span style={{ fontSize: 12, padding: "2px 8px", borderRadius: 6, background: "rgba(251,191,36,0.1)", color: "#FBBF24", marginLeft: "auto" }}>â±ï¸ {notes.time} dk</span>}
        {notes.difficulty && <span style={{ fontSize: 12, padding: "2px 8px", borderRadius: 6, background: notes.difficulty >= 4 ? "rgba(239,68,68,0.1)" : notes.difficulty >= 3 ? "rgba(251,191,36,0.1)" : "rgba(34,197,94,0.1)", color: notes.difficulty >= 4 ? "#EF4444" : notes.difficulty >= 3 ? "#FBBF24" : "#22C55E" }}>{"â­".repeat(notes.difficulty)} {lang==="tr"?"zorluk":"difficulty"}</span>}
      </div>

      {notes.prep && (
        <div style={{ fontSize: 14, color: "#FDE68A", marginBottom: 8, padding: "6px 10px", borderRadius: 8, background: "rgba(251,191,36,0.06)" }}>
          ğŸ“‹ <strong>{lang==="tr"?"HazÄ±rlÄ±k":"Prep"}:</strong> {notes.prep}
        </div>
      )}

      {notes.emphasize && (
        <div style={{ fontSize: 14, color: "#FCD34D", marginBottom: 8, padding: "6px 10px", borderRadius: 8, background: "rgba(251,191,36,0.04)" }}>
          ğŸ¯ <strong>{lang==="tr"?"Vurgula":"Emphasize"}:</strong> {notes.emphasize}
        </div>
      )}

      {notes.cheatSheet && (
        <div style={{ fontSize: 13, color: "#D1D5DB", marginBottom: 8, padding: "6px 10px", borderRadius: 8, background: "rgba(255,255,255,0.03)", fontFamily: "'Fira Code', monospace" }}>
          ğŸ“ {notes.cheatSheet}
        </div>
      )}

      {notes.studentQs && notes.studentQs.length > 0 && (
        <div>
          <button onClick={() => setShowQs(!showQs)} style={{ fontSize: 13, color: "#F59E0B", background: "none", border: "none", cursor: "pointer", fontFamily: "inherit", padding: 0, fontWeight: 600 }}>
            {showQs ? "â–¾" : "â–¸"} {lang==="tr"?`ğŸ™‹ Ã–ÄŸrenci bunu soracak (${notes.studentQs.length} soru)`:`ğŸ™‹ Students will ask (${notes.studentQs.length} questions)`}
          </button>
          {showQs && notes.studentQs.map((sq, i) => (
            <div key={i} style={{ marginTop: 6, marginLeft: 12, padding: "6px 10px", borderRadius: 8, background: "rgba(255,255,255,0.02)", borderLeft: "2px solid rgba(251,191,36,0.3)" }}>
              <div style={{ fontSize: 13, fontWeight: 600, color: "#FBBF24", marginBottom: 2 }}>â“ {sq.q}</div>
              <div style={{ fontSize: 13, color: "#94A3B8" }}>ğŸ’¬ {sq.a}</div>
            </div>
          ))}
        </div>
      )}
    </div>
  );
};

const LessonPlanPanel = ({ weekIdx }) => {
  const plan = LESSON_PLANS[weekIdx];
  const [elapsed, setElapsed] = useState(0);
  const [running, setRunning] = useState(false);
  const [currentPhase, setCurrentPhase] = useState(0);
  const timerRef = useRef(null);

  useEffect(() => {
    if (running) {
      timerRef.current = setInterval(() => setElapsed(e => e + 1), 1000);
    } else {
      clearInterval(timerRef.current);
    }
    return () => clearInterval(timerRef.current);
  }, [running]);

  if (!plan) return null;
  const elapsedMin = Math.floor(elapsed / 60);
  const elapsedSec = elapsed % 60;

  // Calculate cumulative time
  let cumulative = 0;
  const phases = plan.plan.map(p => { cumulative += p.min; return { ...p, cumEnd: cumulative }; });

  return (
    <div style={{ background: "rgba(99,102,241,0.04)", border: "1px solid rgba(99,102,241,0.15)", borderRadius: 14, padding: 16, marginBottom: 12 }}>
      <div style={{ display: "flex", alignItems: "center", gap: 8, marginBottom: 10 }}>
        <span style={{ fontSize: 19 }}>ğŸ“‹</span>
        <span style={{ fontSize: 15, fontWeight: 700, color: "#818CF8" }}>{lang==="tr"?"Ders PlanÄ±":"Lesson Plan"} â€” {typeof plan.title === "object" ? tx(plan.title, lang) : plan.title}</span>
        <span style={{ fontSize: 13, color: "#6366F1", marginLeft: "auto" }}>{plan.totalMin} {lang==="tr"?"dk toplam":"min total"}</span>
      </div>

      {/* Timer */}
      <div style={{ display: "flex", alignItems: "center", gap: 8, marginBottom: 10, padding: "8px 12px", borderRadius: 10, background: "rgba(99,102,241,0.06)" }}>
        <button onClick={() => setRunning(!running)} style={{ fontSize: 19, background: "none", border: "none", cursor: "pointer", padding: 0 }}>
          {running ? "â¸ï¸" : "â–¶ï¸"}
        </button>
        <span style={{ fontSize: 23, fontWeight: 800, color: running ? "#818CF8" : "#475569", fontFamily: "'Fira Code', monospace" }}>
          {String(elapsedMin).padStart(2,"0")}:{String(elapsedSec).padStart(2,"0")}
        </span>
        <span style={{ fontSize: 13, color: "#475569" }}>/ {plan.totalMin}:00</span>
        <button onClick={() => { setElapsed(0); setRunning(false); setCurrentPhase(0); }} style={{ fontSize: 13, color: "#6366F1", background: "rgba(99,102,241,0.1)", border: "none", borderRadius: 6, padding: "2px 8px", cursor: "pointer", marginLeft: "auto", fontFamily: "inherit" }}>{lang === "tr" ? "SÄ±fÄ±rla" : "Reset"}</button>
      </div>

      {/* Progress bar */}
      <div style={{ display: "flex", gap: 2, height: 6, borderRadius: 4, overflow: "hidden", marginBottom: 8 }}>
        {phases.map((p, i) => (
          <div key={i} style={{ flex: p.min, background: i <= currentPhase ? "#6366F1" : "rgba(99,102,241,0.15)", transition: "background .3s", cursor: "pointer", borderRadius: 2 }} onClick={() => setCurrentPhase(i)} />
        ))}
      </div>

      {/* Phase list */}
      {phases.map((p, i) => (
        <div key={i} onClick={() => setCurrentPhase(i)} style={{ display: "flex", alignItems: "center", gap: 8, padding: "5px 8px", borderRadius: 8, cursor: "pointer", marginBottom: 2,
          background: i === currentPhase ? "rgba(99,102,241,0.08)" : "transparent",
          borderLeft: i === currentPhase ? "3px solid #6366F1" : "3px solid transparent",
          opacity: i < currentPhase ? 0.5 : 1, transition: "all .2s" }}>
          <span style={{ fontSize: 12, fontWeight: 700, color: i === currentPhase ? "#818CF8" : "#475569", minWidth: 35 }}>{p.min} {lang==="tr"?"dk":"m"}</span>
          <span style={{ fontSize: 13, fontWeight: i === currentPhase ? 700 : 400, color: i === currentPhase ? "#E2E8F0" : "#94A3B8" }}>{p.phase}</span>
          <span style={{ fontSize: 12, color: "#475569", marginLeft: "auto" }}>{p.desc.substring(0, 50)}{p.desc.length > 50 ? "..." : ""}</span>
        </div>
      ))}
    </div>
  );
};

const CheatSheetPanel = ({ weekIdx }) => {
  const sheet = WEEK_CHEAT_SHEETS[weekIdx];
  if (!sheet) return null;
  return (
    <div style={{ background: "rgba(16,185,129,0.04)", border: "1px solid rgba(16,185,129,0.15)", borderRadius: 14, padding: 16, marginBottom: 12 }}>
      <div style={{ display: "flex", alignItems: "center", gap: 8, marginBottom: 10 }}>
        <span style={{ fontSize: 19 }}>ğŸ“</span>
        <span style={{ fontSize: 15, fontWeight: 700, color: "#10B981" }}>{sheet.title}</span>
      </div>
      <div style={{ marginBottom: 8 }}>
        <div style={{ fontSize: 12, color: "#6EE7B7", fontWeight: 600, marginBottom: 4 }}>{lang==="tr"?"FormÃ¼ller & SayÄ±lar":"Formulas & Numbers"}:</div>
        {sheet.formulas.map((f, i) => (
          <div key={i} style={{ fontSize: 13, color: "#D1D5DB", padding: "2px 0", fontFamily: "'Fira Code', monospace" }}>â†’ {f}</div>
        ))}
      </div>
      <div>
        <div style={{ fontSize: 12, color: "#6EE7B7", fontWeight: 600, marginBottom: 4 }}>{lang==="tr"?"Kilit Noktalar":"Key Points"}:</div>
        {sheet.keyPoints.map((kp, i) => (
          <div key={i} style={{ fontSize: 13, color: "#94A3B8", padding: "2px 0" }}>âœ“ {kp}</div>
        ))}
      </div>
    </div>
  );
};

const SECTION_EXTRAS = {
  "week0_s0": {
    why: "Bu dersin amacÄ± GPT'nin 'bÃ¼yÃ¼lÃ¼' gÃ¶rÃ¼nen davranÄ±ÅŸlarÄ±nÄ±n arkasÄ±ndaki matematiÄŸi anlamanÄ±zdÄ±r. ChatGPT kullandÄ±ÄŸÄ±nÄ±zda 'nasÄ±l yapÄ±yor?' diye merak ettiyseniz, bu ders tam size gÃ¶re."
  },
  "week0_s1": {
    why: "Yapay sinir aÄŸlarÄ±nÄ± anlamak ZORUNLU Ã§Ã¼nkÃ¼ GPT bir sinir aÄŸÄ±dÄ±r. Ama korkacak bir ÅŸey yok â€” Ã§arpma ve toplama biliyorsanÄ±z sinir aÄŸÄ±nÄ± anlayabilirsiniz.",
    analogy: { title: "Excel FormÃ¼lÃ¼ Benzetmesi", emoji: "ğŸ“Š", text: "Bir Excel sayfasÄ± dÃ¼ÅŸÃ¼nÃ¼n: A1 hÃ¼cresine girdi yazÄ±yorsunuz, B1 hÃ¼cresinde =A1*0.5+0.3 formÃ¼lÃ¼ var, C1'de sonucu gÃ¶rÃ¼yorsunuz. Sinir aÄŸÄ± tam olarak bu â€” ama binlerce hÃ¼cre ve formÃ¼l. 'EÄŸitim' = Excel'in 0.5 ve 0.3 gibi katsayÄ±larÄ± otomatik bulmasÄ±. Veriyi gÃ¶steriyorsunuz, formÃ¼l kendini ayarlÄ±yor." },
    concrete: { title: "Somut Ev FiyatÄ± Ã–rneÄŸi", content: "Girdi: alan=120mÂ², oda=3\nModel: fiyat = wâ‚Ã—120 + wâ‚‚Ã—3 + b\n\nBaÅŸlangÄ±Ã§ (rastgele): wâ‚=0.001, wâ‚‚=0.5, b=0\nâ†’ fiyat = 0.12 + 1.5 + 0 = 1.62 TL (!)\n\n100 adÄ±m eÄŸitim sonrasÄ±: wâ‚=5000, wâ‚‚=20000, b=50000\nâ†’ fiyat = 600K + 60K + 50K = 710K TL âœ“" }
  },
  "week0_s2": {
    analogy: { title: "CÃ¼mle Tamamlama Oyunu", emoji: "ğŸ¯", text: "Dil modeli, arkadaÅŸlarÄ±nÄ±zla oynadÄ±ÄŸÄ±nÄ±z 'cÃ¼mleyi tamamla' oyununa benzer. Biri 'dÃ¼n okula gi...' deyince siz otomatik olarak 'ttim' veya 'deceÄŸim' gibi devamlar dÃ¼ÅŸÃ¼nÃ¼rsÃ¼nÃ¼z. Beyniniz binlerce cÃ¼mle duyduÄŸu iÃ§in 'olasÄ± devamlarÄ±' tahmin edebilir. GPT aynÄ± ÅŸeyi yapar â€” milyarlarca metin okumuÅŸ ve kalÄ±plarÄ± Ã¶ÄŸrenmiÅŸtir." },
    why: "Dil modeli kavramÄ± bu dersin TEMELÄ°DÄ°R. TÃ¼m haftalarda Ã¶ÄŸreneceÄŸiniz her ÅŸey â€” embedding, attention, training â€” 'sonraki tokeni tahmin et' gÃ¶revine hizmet eder."
  },
  "week0_s3": {
    bridge: { from: "Sinir aÄŸÄ± ve dil modeli kavramlarÄ±nÄ± Ã¶ÄŸrendik", to: "Åimdi somut olarak bu kodun ne yaptÄ±ÄŸÄ±nÄ± gÃ¶relim â€” 5 adÄ±mlÄ±k pipeline" },
    concrete: { title: "Loss = 3.33 ne anlama geliyor?", content: "28 token arasÄ±ndan rastgele seÃ§im: P(doÄŸru) = 1/28\nLoss = -log(1/28) = log(28) â‰ˆ 3.33\n\nBu 'en kÃ¶tÃ¼' durum. EÄŸitimle:\nâ†’ P(doÄŸru) = 1/7 olursa: loss = log(7) â‰ˆ 1.95\nâ†’ Yani model rastgeleden 4Ã— daha iyi!" }
  },
  "week0_s4": {
    analogy: { title: "Araba Mekanik vs SÃ¼rÃ¼cÃ¼", emoji: "ğŸ”§", text: "PyTorch kullanmak = araba kullanmak. microgpt.py okumak = motorun nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± anlamak. Ä°yi bir sÃ¼rÃ¼cÃ¼ iÃ§in motor bilgisi ÅŸart deÄŸil â€” ama Ä°YÄ° BÄ°R MÃœHENDÄ°S olmak istiyorsanÄ±z, motorun iÃ§ini bilmelisiniz. Bu ders sizi mÃ¼hendis yapÄ±yor." },
    concrete: { title: "PyTorch vs microgpt.py", content: "PyTorch'ta 3 satÄ±r:\nloss = criterion(output, target)\nloss.backward()\noptimizer.step()\n\nmicrogpt.py'de aynÄ± iÅŸlem 30+ satÄ±r.\nAma her satÄ±r OKUNABILIR ve ANLAÅILIR.\nPyTorch'un arkasÄ±nda ~2M satÄ±r C++/CUDA var." }
  },
  "week0_s7": {
    tryIt: "params",
    why: "Bu 7 parametre modelin 'DNA'sÄ±dÄ±r. DeÄŸiÅŸtirdiÄŸinizde model tamamen farklÄ± davranÄ±r. Deney yaparak Ã¶ÄŸrenin!",
    analogy: { title: "Araba Kontrol Paneli", emoji: "ğŸ›ï¸", text: "n_embd = motor hacmi (bÃ¼yÃ¼k = gÃ¼Ã§lÃ¼ ama pahalÄ±). n_layer = vites sayÄ±sÄ± (Ã§ok = hassas kontrol). n_head = ayna sayÄ±sÄ± (Ã§ok = daha geniÅŸ gÃ¶rÃ¼ÅŸ). block_size = yakÄ±t deposu (bÃ¼yÃ¼k = uzun yol). learning_rate = gaz pedalÄ± hassasiyeti (Ã§ok = tehlikeli). num_steps = yol mesafesi. seed = baÅŸlangÄ±Ã§ noktasÄ±." }
  },
  "week0_s10": {
    analogy: { title: "Bisikletten Uzay MekiÄŸine", emoji: "ğŸš€", text: "microGPT bir bisiklet â€” pedal, direksiyon, fren hepsi var. GPT-4 bir uzay mekiÄŸi â€” aynÄ± fizik kurallarÄ± (Newton) ama milyonlarca kat daha karmaÅŸÄ±k mÃ¼hendislik. Bu derste bisikleti parÃ§alayÄ±p anlayacaksÄ±nÄ±z. Sonra mekiÄŸin %90'Ä±nÄ± da anlamÄ±ÅŸ olacaksÄ±nÄ±z." },
    concrete: { title: "Ã–lÃ§ek KarÅŸÄ±laÅŸtÄ±rmasÄ±", content: "microGPT:  3,648 parametre (~15 KB bellek)\nGPT-2:     1.5 milyar parametre (~6 GB)\nGPT-3:     175 milyar parametre (~700 GB)\nGPT-4:     ~1+ trilyon parametre (~4 TB)\n\nOran: GPT-4 / microGPT â‰ˆ 300,000,000Ã—\nAma temel algoritma AYNI." }
  },
  "week1_s0": {
    why: "Bilgisayar sadece sayÄ±larÄ± iÅŸleyebilir. 'Merhaba' yazdÄ±ÄŸÄ±nÄ±zda ekranda harf gÃ¶rÃ¼rsÃ¼nÃ¼z ama bilgisayar iÃ§inde hepsi sayÄ±dÄ±r. Dil modelinin metni anlamasÄ± iÃ§in Ã¶nce onu sayÄ±lara Ã§evirmeliyiz â€” tokenization tam olarak budur.",
    bridge: { from: "GeÃ§en hafta GPT'nin ne yaptÄ±ÄŸÄ±nÄ± gÃ¶rdÃ¼k: isim alÄ±r, yeni isim Ã¼retir.", to: "Åimdi 'ismi alÄ±r' kÄ±smÄ±na odaklanÄ±yoruz. Model bir ismi nasÄ±l 'gÃ¶rÃ¼yor'? Cevap: tokenization." }
  },
  "week1_s2": {
    tryIt: "tokenizer"
  },
  "week1_s3": {
    why: "Token ID'leri (0, 1, 2...) modele 'a yakÄ±n mÄ± b'ye?' gibi iliÅŸkileri sÃ¶yleyemez. ID=5 ile ID=6 yan yana ama 'e' ile 'f' birbirine yakÄ±n deÄŸil! Embedding her harfi Ã§ok boyutlu bir uzaya yerleÅŸtirerek bu sorunu Ã§Ã¶zer.",
    analogy: { title: "Rehber Kitap Adresi", emoji: "ğŸ“", text: "DÃ¼ÅŸÃ¼nÃ¼n ki her karakter bir ÅŸehir. Token ID = posta kodu (sadece numara). Embedding = GPS koordinatÄ± (enlem, boylam + irtifa). Posta kodlarÄ± sÄ±ralÄ± ama coÄŸrafi yakÄ±nlÄ±ÄŸÄ± gÃ¶stermez: Ä°stanbul=34, KÄ±rklareli=39 â†’ yakÄ±n ama kodlarÄ± uzak! GPS koordinatlarÄ± ise gerÃ§ek mesafeyi verir. Embedding tÄ±pkÄ± GPS gibi, harflerin 'anlam uzayÄ±ndaki' gerÃ§ek konumunu verir." },
    tryIt: "embedding"
  },
  "week1_s5": {
    tryIt: "softmax"
  },
  "week2_s0": {
    why: "5.000 parametrenin her birinin loss'a etkisini bilmemiz lazÄ±m. Tek tek deneyerek bulmak (x'i 0.001 artÄ±r, loss ne oldu?) 5.000 ayrÄ± forward pass demek. Autograd bunu TEK backward pass ile yapÄ±yor â€” hepsi bedava!",
    bridge: { from: "GeÃ§en hafta modeli kurduk: embedding â†’ attention â†’ MLP â†’ Ã§Ä±ktÄ±. Ama bu model henÃ¼z 'cahil' â€” rastgele aÄŸÄ±rlÄ±klarla saÃ§ma tahminler yapÄ±yor.", to: "Åimdi 'nasÄ±l Ã¶ÄŸrenir?' sorusuna geÃ§iyoruz. Cevap: gradient hesaplama (bu hafta) + parametre gÃ¼ncelleme (gelecek hafta)." },
    analogy: { title: "KÃ¶r DaÄŸcÄ±", emoji: "ğŸ”ï¸", text: "Bir daÄŸda gÃ¶zÃ¼nÃ¼z baÄŸlÄ± duruyorsunuz ve en alÃ§ak noktaya inmeniz gerekiyor. Elinizle zemini yokluyorsunuz: 'saÄŸa mÄ± eÄŸimli, sola mÄ±?' TÃ¼rev tam olarak bu: 'bu yÃ¶nde ilerlersem yokuÅŸ aÅŸaÄŸÄ± mÄ±, yukarÄ± mÄ± giderim?' Gradient ise tÃ¼m yÃ¶nlerdeki eÄŸimleri birden sÃ¶yler: 'kuzeybatÄ±ya doÄŸru en dik iniÅŸ var.'" }
  },
  "week2_s3": {
    stepByStep: {
      title: "L = (a Ã— b) + c Hesaplama GrafÄ±",
      steps: [
        { label: "DeÄŸerleri kur", calc: "a = 2, b = 3, c = 1", note: "Bu deÄŸerler modelin parametreleri gibi dÃ¼ÅŸÃ¼nÃ¼n" },
        { label: "Ä°leri: d = a Ã— b", calc: "d = 2 Ã— 3 = 6", note: "Ã‡arpma operatÃ¶rÃ¼ â€” local_grads = (b=3, a=2)" },
        { label: "Ä°leri: L = d + c", calc: "L = 6 + 1 = 7", note: "Toplama operatÃ¶rÃ¼ â€” local_grads = (1, 1)" },
        { label: "Geri: âˆ‚L/âˆ‚L = 1", calc: "L.grad = 1", note: "BaÅŸlangÄ±Ã§ noktasÄ±: loss'un kendine gÃ¶re tÃ¼revi her zaman 1" },
        { label: "Geri: âˆ‚L/âˆ‚d", calc: "d.grad += 1 Ã— 1 = 1", note: "Toplama â†’ local_grad=1, L.grad=1 â†’ chain rule: 1Ã—1" },
        { label: "Geri: âˆ‚L/âˆ‚c", calc: "c.grad += 1 Ã— 1 = 1", note: "Toplama â†’ local_grad=1, L.grad=1 â†’ chain rule: 1Ã—1" },
        { label: "Geri: âˆ‚L/âˆ‚a", calc: "a.grad += b Ã— d.grad = 3 Ã— 1 = 3", note: "Ã‡arpma â†’ local_grad=b=3, d.grad=1 â†’ chain rule: 3Ã—1" },
        { label: "Geri: âˆ‚L/âˆ‚b", calc: "b.grad += a Ã— d.grad = 2 Ã— 1 = 2", note: "Ã‡arpma â†’ local_grad=a=2, d.grad=1 â†’ chain rule: 2Ã—1" },
        { label: "DoÄŸrulama âœ“", calc: "âˆ‚L/âˆ‚a = b = 3 âœ“, âˆ‚L/âˆ‚b = a = 2 âœ“", note: "L = ab+c â†’ âˆ‚L/âˆ‚a = b, âˆ‚L/âˆ‚b = a â€” eliyle aynÄ± sonuÃ§!" }
      ]
    }
  },
  "week3_s0": {
    bridge: { from: "Autograd ile gradient hesaplamayÄ± Ã¶ÄŸrendik. Bu sayede modelin parametrelerini gÃ¼ncelleyebiliriz.", to: "Ama modelin iÃ§inde ne oluyor? Token'lar birbirleriyle nasÄ±l 'konuÅŸuyor'? Ä°ÅŸte attention mekanizmasÄ± â€” Transformer'Ä±n kalbi!" }
  },
  "week3_s1": {
    analogy: { title: "ToplantÄ±da Not Alma", emoji: "ğŸ“‹", text: "Bir toplantÄ±dasÄ±nÄ±z ve not alÄ±yorsunuz. 5 kiÅŸi konuÅŸtu. Son konuÅŸmacÄ± siz ve Ã¶nceki konuÅŸmacÄ±larÄ±n sÃ¶ylediklerini Ã¶zetlemeniz gerekiyor. Herkesi eÅŸit dinlemezsiniz: CEO'nun sÃ¶zlerine %40, projenin lideri %30, diÄŸerleri %10'ar dikkat edersiniz. Self-attention tam olarak bunu yapar: her token, Ã¶nceki tokenlardan ne kadar 'bilgi alacaÄŸÄ±na' dinamik olarak karar verir." }
  },
  "week3_s2": {
    analogy: { title: "KÃ¼tÃ¼phane Arama", emoji: "ğŸ“š", text: "Bir kÃ¼tÃ¼phanedesiniz: Query = aradÄ±ÄŸÄ±nÄ±z konu ('yapay zeka tarihi'). Key = kitap kapaÄŸÄ±ndaki baÅŸlÄ±klar. QÂ·K = baÅŸlÄ±kla aranÄ±zÄ±n uyumu (yÃ¼ksek = ilgili kitap). Value = kitabÄ±n iÃ§eriÄŸi. Uyum yÃ¼ksekse o kitaptan Ã§ok alÄ±ntÄ± yaparsÄ±nÄ±z. DÃ¼ÅŸÃ¼kse geÃ§ersiniz. Attention aynÄ± ÅŸekilde Ã§alÄ±ÅŸÄ±r!" },
    tryIt: "dotProduct"
  },
  "week4_s0": {
    bridge: { from: "Self-attention ile tokenlar arasÄ± iletiÅŸimi Ã¶ÄŸrendik. Ama tek attention yeterli mi?", to: "HayÄ±r! Attention'dan sonra her token kendi baÅŸÄ±na bir 'dÃ¼ÅŸÃ¼nme' aÅŸamasÄ±ndan geÃ§er: MLP bloÄŸu. AyrÄ±ca normalizasyon ve residual baÄŸlantÄ±lar eÄŸitimi kararlÄ± kÄ±lar. Ä°ÅŸte tam Transformer mimarisi!" }
  },
  "week5_s0": {
    bridge: { from: "Model mimarisini tamamladÄ±k: Embedding â†’ Attention â†’ MLP â†’ Ã‡Ä±ktÄ±.", to: "Åimdi en kritik soru: bu model nasÄ±l Ã¶ÄŸrenir? Cevap: Forward â†’ Loss â†’ Backward â†’ Update dÃ¶ngÃ¼sÃ¼. Bu hafta dÃ¶ngÃ¼nÃ¼n her aÅŸamasÄ±nÄ± detaylÄ±ca gÃ¶receÄŸiz." },
    tryIt: "gradient"
  },
  "week5_s2": {
    stepByStep: {
      title: "Cross-Entropy Loss Hesaplama",
      steps: [
        { label: "Girdi", calc: "tokens = [BOS, h, e, l, l, o]", note: "'hello' kelimesini tokenize ettik" },
        { label: "Pozisyon 0: BOSâ†’h tahmin", calc: "P('h') = 0.04 (model henÃ¼z cahil)", note: "1/27 â‰ˆ 0.037 rastgele tahmine yakÄ±n" },
        { label: "Loss hesapla", calc: "Lâ‚€ = -log(0.04) = 3.22", note: "DÃ¼ÅŸÃ¼k olasÄ±lÄ±k â†’ yÃ¼ksek loss (ceza)" },
        { label: "Pozisyon 1: hâ†’e tahmin", calc: "P('e') = 0.08", note: "Biraz daha iyi ama hala dÃ¼ÅŸÃ¼k" },
        { label: "Loss hesapla", calc: "Lâ‚ = -log(0.08) = 2.53", note: "Daha iyi olasÄ±lÄ±k â†’ daha dÃ¼ÅŸÃ¼k loss" },
        { label: "Ortalama al", calc: "Loss = (3.22 + 2.53 + ...) / 5", note: "TÃ¼m pozisyonlarÄ±n ortalamasÄ± = modelin genel baÅŸarÄ±sÄ±" },
        { label: "KarÅŸÄ±laÅŸtÄ±r", calc: "Rastgele: 3.33 | EÄŸitilmiÅŸ: ~2.0", note: "Loss dÃ¼ÅŸtÃ¼ = model Ã¶ÄŸreniyor! ğŸ‰" }
      ]
    }
  },
  "week6_s2": {
    tryIt: "softmax"
  },
  "week7_s0": {
    why: "Scaling laws'u anlamak 'Ã¶lÃ§ek artÄ±rma' kararlarÄ±nÄ±n arkasÄ±ndaki bilimi gÃ¶sterir. Neden 1T parametre? Ã‡Ã¼nkÃ¼ matematik Ã¶yle diyor.",
    analogy: { title: "Fabrika Ãœretim HattÄ±", emoji: "ğŸ­", text: "Bir fabrikada Ã¼retim hattÄ±nÄ± 2Ã— bÃ¼yÃ¼tÃ¼nce Ã¼retim tam 2Ã— artmaz â€” ama gÃ¼Ã§ yasasÄ±yla artar. AI'da da aynÄ±: 10Ã— parametre â†’ ~3Ã— iyileÅŸme. Getiri azalan ama hala deÄŸerli." }
  },
  "week7_s1": {
    bridge: { from: "Scaling laws'u Ã¶ÄŸrendik", to: "Åimdi bu yasalarÄ±n somut tarihÃ§esini gÃ¶relim â€” 2017'den bugÃ¼ne" },
    concrete: { title: "Maliyet Evrimi", content: "2017 Transformer: ~$10K\n2018 GPT-1: ~$50K\n2020 GPT-3: ~$5M\n2023 GPT-4: ~$100M+\n2024 Frontier: ~$200M+\n\n7 yÄ±lda 20,000Ã— maliyet artÄ±ÅŸÄ±\nAma performans 100Ã— iyileÅŸme" }
  },
  "week7_s3": {
    analogy: { title: "Ã‡Ä±rak â†’ Kalfa â†’ Usta", emoji: "ğŸ“", text: "Pre-training = Ã§Ä±raklÄ±k (her ÅŸeyi gÃ¶zlemle). SFT = kalfalÄ±k (ustadan soru-cevap Ã¶ÄŸren). RLHF = ustalÄ±k (mÃ¼ÅŸteri memnuniyetine gÃ¶re ince ayar). Her aÅŸama bir Ã¶ncekinin Ã¼stÃ¼ne inÅŸa edilir." }
  },
};

// â”€â”€â”€ QUIZ DATA â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const QUIZZES = {
  0: [
    { q: "microGPT kaÃ§ satÄ±r koddan oluÅŸur?", opts: ["243", "24300", "2430", "43"], ans: 0, explain: "Karpathy'nin saf Python implementasyonu tam 243 satÄ±r â€” hiÃ§bir dÄ±ÅŸ kÃ¼tÃ¼phane kullanmadan." },
    { q: "Bu model ne tÃ¼r bir gÃ¶rev yapÄ±yor?", opts: ["Ã‡eviri", "Karakter dÃ¼zeyinde isim Ã¼retme", "Ses tanÄ±ma", "GÃ¶rÃ¼ntÃ¼ sÄ±nÄ±flandÄ±rma"], ans: 1, explain: "32K Ä°ngilizce isim Ã¼zerinde eÄŸitilmiÅŸ karakter dÃ¼zeyinde dil modeli. Yeni, var olmayan isimler Ã¼retir." },
    { q: "GPT 'autoregressive' ne demek?", opts: ["Sadece Ã¶nceki tokenlara bakarak sÄ±rayla tahmin yapar", "TÃ¼m cÃ¼mleyi bir kerede Ã¼retir", "Paralel tÃ¼m tokenlara bakar", "Rastgele tokenlar seÃ§er"], ans: 0, explain: "Autoregressive = her adÄ±mda kendi Ã¼rettiÄŸi Ã§Ä±ktÄ±yÄ± girdi olarak kullanarak sÄ±rayla ilerler. GeleceÄŸi gÃ¶rmez." },
    { q: "microGPT kaÃ§ parametre iÃ§erir?", opts: ["1 milyon", "1 milyar", "243", "3,648"], ans: 3, explain: "3,648 Ã¶ÄŸrenilebilir parametre. GPT-4'Ã¼n 1 trilyonun Ã¼zerinde parametresi var â€” aynÄ± algoritma, farklÄ± Ã¶lÃ§ek." },
    { q: "Forward pass ne yapar?", opts: ["Girdi â†’ model â†’ Ã§Ä±ktÄ± (tahmin) hesaplar", "Veri yÃ¼kler", "Gradient hesaplar", "Parametreleri gÃ¼nceller"], ans: 0, explain: "Forward pass: girdi token'Ä± modelden geÃ§irip 27 token Ã¼zerinde olasÄ±lÄ±k daÄŸÄ±lÄ±mÄ± (logits) Ã¼retir." },
    { q: "Bu kodda vocab (kelime daÄŸarcÄ±ÄŸÄ±) boyutu kaÃ§tÄ±r?", opts: ["27", "16", "8", "256"], ans: 0, explain: "a-z (26 harf) + BOS/EOS (1 Ã¶zel token) = 27 token. Karakter dÃ¼zeyinde tokenization." },
    { q: "Neden PyTorch yerine sÄ±fÄ±rdan yazÄ±lmÄ±ÅŸ?", opts: ["Fark yok", "PyTorch pahalÄ±", "PyTorch yavaÅŸ", "Her satÄ±rÄ± ANLAYARAK Ã¶ÄŸrenmek â€” kara kutu olmasÄ±n"], ans: 3, explain: "PyTorch'ta 3 satÄ±rda yazÄ±lan ÅŸey burada 30+ satÄ±r. Ama her satÄ±r okunabilir ve anlaÅŸÄ±lÄ±r â€” Ã¶ÄŸrenme amaÃ§lÄ±." },
  ],
  1: [
    { q: "Tokenization ne iÅŸe yarar?", opts: ["YazÄ±m hatalarÄ±nÄ± dÃ¼zeltir", "Metni sÄ±kÄ±ÅŸtÄ±rÄ±r", "Metni sayÄ±sal ID dizisine Ã§evirir", "Metni renklendirir"], ans: 2, explain: "Bilgisayar metin iÅŸleyemez. Tokenization metni modelin anlayacaÄŸÄ± sayÄ±lara Ã§evirir." },
    { q: "Embedding nedir?", opts: ["Dosya sÄ±kÄ±ÅŸtÄ±rma", "Veri tabanÄ± sorgusu", "Åifreleme yÃ¶ntemi", "Token ID'yi Ã§ok boyutlu vektÃ¶re dÃ¶nÃ¼ÅŸtÃ¼rme"], ans: 3, explain: "Embedding, bir ID'yi (Ã¶r: 5) anlamlÄ± bir vektÃ¶re (Ã¶r: [0.2, -0.1, 0.5, ...]) dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r. Benzer tokenlar yakÄ±n vektÃ¶rlere sahip olur." },
    { q: "BOS token ne iÅŸe yarar?", opts: ["BoÅŸluk karakteridir", "Dizinin baÅŸlangÄ±cÄ±nÄ±/sonunu iÅŸaret eder", "En sÄ±k harfi temsil eder", "HatayÄ± gÃ¶sterir"], ans: 1, explain: "BOS (Beginning of Sequence) modele 'yeni dizi baÅŸlÄ±yor' ve 'dizi bitti' sinyali verir." },
    { q: "Weight tying ne demek?", opts: ["GiriÅŸ ve Ã§Ä±kÄ±ÅŸ embedding matrisini paylaÅŸma", "EÄŸitimi durdurma", "Ä°ki modeli birleÅŸtirme", "AÄŸÄ±rlÄ±klarÄ± sÄ±fÄ±rlama"], ans: 0, explain: "AynÄ± wte matrisi hem tokenâ†’vektÃ¶r (giriÅŸ) hem vektÃ¶râ†’logit (Ã§Ä±kÄ±ÅŸ) iÃ§in kullanÄ±lÄ±r â†’ parametre tasarrufu." },
    { q: "'emma' tokenize edilirse kaÃ§ eÄŸitim Ã§ifti oluÅŸur?", opts: ["5", "3", "6", "4"], ans: 0, explain: "BOSâ†’e, eâ†’m, mâ†’m, mâ†’a, aâ†’BOS = 5 Ã§ift. Kural: harf sayÄ±sÄ± + 1 (BOSâ†’ilk harf) = eÄŸitim Ã§ifti." },
    { q: "Position embedding olmadan 'abc' ve 'cba' farkÄ± ne olur?", opts: ["Sadece son harf farklÄ±", "Sadece ilk harf farklÄ±", "Model ikisini AYNI gÃ¶rÃ¼r", "Model farklÄ± iÅŸler"], ans: 2, explain: "Transformer yapÄ±sal olarak sÄ±ra bilgisi iÃ§ermez. Position embedding olmadan token sÄ±rasÄ± kaybolur!" },
    { q: "Softmax Ã§Ä±ktÄ±larÄ±nÄ±n toplamÄ± kaÃ§tÄ±r?", opts: ["1", "DeÄŸiÅŸir", "0", "0.5"], ans: 0, explain: "Softmax her zaman toplam=1 olan olasÄ±lÄ±k daÄŸÄ±lÄ±mÄ± Ã¼retir. P(i) = exp(xi)/Î£exp(xj), tÃ¼m P'ler toplamÄ± 1." },
  ],
  2: [
    { q: "TÃ¼rev (gradient) modele ne sÃ¶yler?", opts: ["KaÃ§ parametre var", "Modelin doÄŸruluÄŸu", "Her parametreyi hangi yÃ¶nde deÄŸiÅŸtirince loss azalÄ±r", "EÄŸitim ne kadar sÃ¼rer"], ans: 2, explain: "âˆ‚L/âˆ‚w = 'w'yi biraz artÄ±rÄ±rsam loss ne kadar deÄŸiÅŸir?' Negatif yÃ¶nde gÃ¼ncelleme yaparak loss azaltÄ±lÄ±r." },
    { q: "grad += kullanmak neden kritik? (= yerine)", opts: ["Python kuralÄ±", "Birden fazla yoldan gelen gradientler toplanmalÄ±", "Daha hÄ±zlÄ±", "Bellek tasarrufu"], ans: 1, explain: "Bir parametre birden fazla yoldan loss'u etkileyebilir (Ã¶r: weight tying). TÃ¼m yollarÄ±n gradientleri toplanmalÄ±dÄ±r." },
    { q: "Topological sort backward pass'te neden gerekli?", opts: ["DÃ¼ÄŸÃ¼mlerin doÄŸru baÄŸÄ±mlÄ±lÄ±k sÄ±rasÄ±nda iÅŸlenmesi iÃ§in", "HÄ±z optimizasyonu", "Alfabetik sÄ±ralama iÃ§in", "Bellek yÃ¶netimi"], ans: 0, explain: "Chain rule'Ä±n doÄŸru Ã§alÄ±ÅŸmasÄ± iÃ§in bir dÃ¼ÄŸÃ¼mÃ¼n gradientini hesaplamadan Ã¶nce onu kullanan tÃ¼m dÃ¼ÄŸÃ¼mler hesaplanmÄ±ÅŸ olmalÄ±." },
    { q: "L = aÃ—b ise âˆ‚L/âˆ‚a kaÃ§tÄ±r?", opts: ["aÃ—b", "1", "b", "a"], ans: 2, explain: "Ã‡arpmanÄ±n yerel tÃ¼revi: âˆ‚(aÃ—b)/âˆ‚a = b (diÄŸer girdiyi sabit tut, a katsayÄ±sÄ± = b). Oyun alanÄ±nda deneyin!" },
    { q: "Backward pass neden loss dÃ¼ÄŸÃ¼mÃ¼nden (L) baÅŸlar?", opts: ["âˆ‚L/âˆ‚L = 1 olduÄŸu iÃ§in â€” chain rule'un baÅŸlangÄ±Ã§ noktasÄ±", "Rastgele seÃ§im", "Alfabetik sÄ±ra", "En bÃ¼yÃ¼k deÄŸer olduÄŸu iÃ§in"], ans: 0, explain: "âˆ‚L/âˆ‚L = 1 (bir ÅŸeyin kendisine gÃ¶re tÃ¼revi = 1). Bu '1' chain rule ile Ã§arpÄ±larak tÃ¼m dÃ¼ÄŸÃ¼mlere yayÄ±lÄ±r." },
    { q: "ReLU(x) fonksiyonunun x=-3'teki gradient'i kaÃ§tÄ±r?", opts: ["3", "-3", "1", "0"], ans: 3, explain: "ReLU(x) = max(0,x). x<0 ise Ã§Ä±ktÄ±=0 ve gradient=0 (nÃ¶ron 'Ã¶lÃ¼'). x>0 ise gradient=1 (geÃ§ir). -3<0 â†’ 0." },
    { q: "Bu koddaki Value sÄ±nÄ±fÄ± ile PyTorch Tensor farkÄ± nedir?", opts: ["FarklÄ± algoritma", "Value skaler, Tensor N-boyutlu â€” ama aynÄ± gradient deÄŸerleri", "Value daha hÄ±zlÄ±", "PyTorch daha doÄŸru"], ans: 1, explain: "Ä°kisi de aynÄ± autograd algoritmasÄ±nÄ± Ã§alÄ±ÅŸtÄ±rÄ±r. Fark: Value tek sayÄ±yla, Tensor milyonlarca sayÄ±yla paralel (GPU) Ã§alÄ±ÅŸÄ±r." },
  ],
  3: [
    { q: "Self-attention'da QÂ·K ne anlama gelir?", opts: ["Veri sÄ±kÄ±ÅŸtÄ±rma", "Ä°ki token arasÄ±ndaki uyum/benzerlik skoru", "Parametre sayÄ±sÄ±", "Loss deÄŸeri"], ans: 1, explain: "Query (ne arÄ±yorum?) ile Key (bende ne var?) arasÄ±ndaki dot product = uyum skoru. YÃ¼ksek skor â†’ daha Ã§ok dikkat." },
    { q: "Neden âˆšd_head'e bÃ¶lÃ¼yoruz?", opts: ["Boyut artÄ±nca dot product bÃ¼yÃ¼r â†’ softmax Ã§ok sivri â†’ gradient kaybolur", "Bellekte yer aÃ§mak iÃ§in", "HÄ±z iÃ§in", "Estetik sebep"], ans: 0, explain: "Scaling trick: d bÃ¼yÃ¼dÃ¼kÃ§e dot product bÃ¼yÃ¼r, softmax daÄŸÄ±lÄ±mÄ± sivri (spike) yapar, gradient kaybolur. âˆšd ile normalleÅŸtirme bunu Ã¶nler." },
    { q: "Multi-head attention neden kullanÄ±lÄ±r?", opts: ["Sadece gelenek", "Her head farklÄ± iliÅŸki kalÄ±plarÄ± Ã¶ÄŸrenebilir", "Parametre azaltma", "HÄ±z artÄ±ÅŸÄ±"], ans: 1, explain: "Her head baÄŸÄ±msÄ±z attention hesabÄ± yapar: biri sesli-sessiz uyumunu, diÄŸeri pozisyon yakÄ±nlÄ±ÄŸÄ±nÄ± Ã¶ÄŸrenebilir. Zenginlik saÄŸlar." },
    { q: "Causal masking ne saÄŸlar?", opts: ["Daha iyi doÄŸruluk", "HÄ±z artÄ±ÅŸÄ±", "Bellek tasarrufu", "Her token sadece Ã–NCEKÄ° tokenlara bakabilir â€” geleceÄŸi gÃ¶remez"], ans: 3, explain: "GPT causal modeldir: eÄŸitimde 'kopya Ã§ekmeyi' Ã¶nlemek iÃ§in gelecek tokenlar maskelenir. Bu kodda KV cache doÄŸal mask saÄŸlar." },
    { q: "Bu kodda head_dim kaÃ§tÄ±r?", opts: ["8", "16", "4", "1"], ans: 2, explain: "16 boyutlu embedding Ã· 4 head = 4 boyut/head. Her head 4-boyutlu Q,K,V vektÃ¶rleri ile Ã§alÄ±ÅŸÄ±r." },
    { q: "Q, K, V'nin rolleri nedir?", opts: ["Q=ne arÄ±yorum, K=bende ne var, V=bilgi iÃ§eriÄŸi", "Hepsi aynÄ± iÅŸi yapar", "Q=hÄ±z, K=yÃ¶n, V=uzaklÄ±k", "Q=girdi, K=Ã§Ä±ktÄ±, V=hata"], ans: 0, explain: "QÂ·K = uyum skoru belirler, yÃ¼ksek uyumlu token'Ä±n V'si (bilgi iÃ§eriÄŸi) daha Ã§ok alÄ±nÄ±r." },
    { q: "Attention aÄŸÄ±rlÄ±klarÄ±nÄ±n toplamÄ± kaÃ§tÄ±r?", opts: ["DeÄŸiÅŸir", "Head sayÄ±sÄ±", "1", "0"], ans: 2, explain: "Softmax'Ä±n Ã§Ä±ktÄ±larÄ± her zaman toplam=1 olur. Bu, bir olasÄ±lÄ±k daÄŸÄ±lÄ±mÄ± oluÅŸturur â€” hangi token'a ne kadar dikkat?" },
  ],
  4: [
    { q: "RMSNorm, LayerNorm'dan farkÄ± nedir?", opts: ["SonuÃ§lar farklÄ±", "Daha fazla parametre", "Ortalama Ã§Ä±karmaz, sadece RMS ile normalize eder â†’ ~%30 hÄ±zlÄ±", "Daha yavaÅŸ"], ans: 2, explain: "RMSNorm, mean Ã§Ä±karma adÄ±mÄ±nÄ± atlar â†’ daha az hesaplama, eÅŸdeÄŸer kalite. Modern LLM'lerin (LLaMA, Mistral) standardÄ±." },
    { q: "Residual connection (x + f(x)) neden ÅŸart?", opts: ["Kod basitliÄŸi", "Parametre azaltÄ±r", "Sadece GPT'de var", "Gradient doÄŸrudan giriÅŸe akabilir, derin aÄŸlarÄ± eÄŸitilebilir kÄ±lar"], ans: 3, explain: "+x terimi gradient'e 'kestirme yol' aÃ§ar: âˆ‚L/âˆ‚x = âˆ‚L/âˆ‚out Ã— (âˆ‚f/âˆ‚x + 1). +1 = gradient highway." },
    { q: "MLP'de ReLUÂ² neden ~%40 nÃ¶ronu 'Ã¶ldÃ¼rÃ¼r'?", opts: ["Bozuk baÅŸlatma", "Negatif deÄŸerler sÄ±fÄ±ra dÃ¼ÅŸer (sparse), bu verimlilik ve genelleme artÄ±rÄ±r", "Bug", "Rastgele olur"], ans: 1, explain: "ReLUÂ²: max(0,x)Â². Negatifler=0 â†’ sparse aktivasyon. Bu, modelin bilgiyi yoÄŸunlaÅŸtÄ±rmasÄ±na ve genellemesine yardÄ±mcÄ± olur." },
    { q: "Transformer bloÄŸundaki 2 ana bileÅŸen nedir?", opts: ["RNN + CNN", "Self-Attention + MLP (Feed-Forward)", "Encoder + Decoder", "Softmax + Loss"], ans: 1, explain: "Her Transformer katmanÄ±: Attention (tokenlar arasÄ± bilgi akÄ±ÅŸÄ±) + MLP (token iÃ§i dÃ¶nÃ¼ÅŸÃ¼m). Ä°kisi de residual ile sarmalanÄ±r." },
    { q: "Pre-norm ve post-norm farkÄ± nedir?", opts: ["Ä°kisi de aynÄ±", "Post-norm daha modern", "Pre-norm daha yavaÅŸ", "Pre-norm: norm â†’ block â†’ +res (daha kararlÄ± eÄŸitim)"], ans: 3, explain: "Pre-norm (bu kod): norm Ã–NCE uygulanÄ±r â†’ gradient akÄ±ÅŸÄ± daha iyi â†’ kararlÄ± eÄŸitim. GPT-2 post-norm, modern modeller pre-norm." },
    { q: "Aktivasyon fonksiyonu olmadan derin aÄŸ ne olur?", opts: ["Daha hÄ±zlÄ± olur", "Daha az parametre olur", "Tek bir matris Ã§arpÄ±mÄ±na eÅŸdeÄŸer olur â€” katmanlar anlamsÄ±z", "Normal Ã§alÄ±ÅŸÄ±r"], ans: 2, explain: "Wâ‚ƒÃ—Wâ‚‚Ã—Wâ‚Ã—x = WÃ—x. Non-linearity olmadan kaÃ§ katman olursa olsun tek lineer dÃ¶nÃ¼ÅŸÃ¼m â€” Ã¶ÄŸrenme kapasitesi Ã§ok sÄ±nÄ±rlÄ±." },
    { q: "Wo ve fc2 neden sÄ±fÄ±ra yakÄ±n baÅŸlatÄ±lÄ±r?", opts: ["Bellek tasarrufu", "Daha hÄ±zlÄ± yakÄ±nsama", "Rastgele seÃ§im", "BaÅŸta residual block â‰ˆ identity â†’ kararlÄ± eÄŸitim baÅŸlangÄ±cÄ±"], ans: 3, explain: "Woâ‰ˆ0 â†’ attention Ã§Ä±ktÄ±sÄ±â‰ˆ0 â†’ x + 0 = x (identity). Model yavaÅŸ yavaÅŸ block katkÄ±sÄ±nÄ± artÄ±rmayÄ± Ã¶ÄŸrenir." },
  ],
  5: [
    { q: "Cross-entropy loss = -log(P(doÄŸru)). P=1/27 ise loss kaÃ§?", opts: ["~3.33", "1.0", "27", "0"], ans: 0, explain: "-log(1/27) = log(27) â‰ˆ 3.30. Bu, rastgele tahmin eden modelin loss'udur. EÄŸitimle bu deÄŸer dÃ¼ÅŸer." },
    { q: "Learning rate Ã§ok bÃ¼yÃ¼kse ne olur?", opts: ["HiÃ§bir etkisi yok", "Daha hÄ±zlÄ± Ã¶ÄŸrenir", "Daha iyi geneller", "Minimum etrafÄ±nda salÄ±nÄ±r veya patlar (diverge)"], ans: 3, explain: "BÃ¼yÃ¼k LR â†’ bÃ¼yÃ¼k adÄ±m â†’ minimumu atlar â†’ loss yÃ¼kselir â†’ model 'patlar'. KÃ¼Ã§Ã¼k LR gÃ¼venli ama yavaÅŸ." },
    { q: "Adam optimizer'da momentum ne iÅŸe yarar?", opts: ["HÄ±z artÄ±ÅŸÄ±", "Loss hesabÄ±", "Bellek tasarrufu", "Ã–nceki gradientleri hatÄ±rlayarak salÄ±nÄ±mÄ± azaltÄ±r"], ans: 3, explain: "Momentum = gradient yÃ¶nÃ¼nÃ¼n hareketli ortalamasÄ±. GÃ¼rÃ¼ltÃ¼lÃ¼ gradientleri dÃ¼zleÅŸtirir, kararlÄ± ilerlemedir." },
    { q: "EÄŸitim dÃ¶ngÃ¼sÃ¼nÃ¼n doÄŸru sÄ±rasÄ± hangisidir?", opts: ["Loss â†’ Backward â†’ Forward", "Backward â†’ Forward â†’ GÃ¼ncelle", "Forward â†’ Loss â†’ Backward â†’ GÃ¼ncelle â†’ Grad sÄ±fÄ±rla", "GÃ¼ncelle â†’ Forward â†’ Loss"], ans: 2, explain: "Forward pass (tahmin) â†’ loss hesapla â†’ backward pass (gradient) â†’ optimizer gÃ¼ncelle â†’ gradient sÄ±fÄ±rla â†’ tekrarla." },
    { q: "Neden -log(p) kullanÄ±lÄ±r, neden sadece (1-p) deÄŸil?", opts: ["DÃ¼ÅŸÃ¼k olasÄ±lÄ±ÄŸa Ã‡OK aÄŸÄ±r ceza verir, bilgi teorisi ile uyumlu", "Geleneksel", "Daha hÄ±zlÄ± hesaplanÄ±r", "Fark yok"], ans: 0, explain: "-log(0.01) = 4.6 ama 1-0.01 = 0.99. Log, dÃ¼ÅŸÃ¼k olasÄ±lÄ±klara Ã§ok daha aÄŸÄ±r ceza verir â†’ model kesin yanlÄ±ÅŸlardan kaÃ§Ä±nÄ±r." },
    { q: "Linear decay'de step=500 (toplam 1000) ise lr_t ne olur? (lr=0.01)", opts: ["0", "0.001", "0.005", "0.01"], ans: 2, explain: "lr_t = 0.01 Ã— (1 - 500/1000) = 0.01 Ã— 0.5 = 0.005. YarÄ±da yarÄ± hÄ±z â€” minimum'a yaklaÅŸtÄ±kÃ§a daha kÃ¼Ã§Ã¼k adÄ±mlar." },
    { q: "Gradient sÄ±fÄ±rlanmazsa ne olur?", opts: ["Daha iyi geneller", "HiÃ§bir etki yok", "Daha hÄ±zlÄ± Ã¶ÄŸrenir", "Gradient birikir â†’ sÃ¼rekli bÃ¼yÃ¼r â†’ model patlar"], ans: 3, explain: "+= ile gradient birikir: 0.5 â†’ 0.8 â†’ 1.5 â†’ ... â†’ âˆ. Her adÄ±mda p.grad = 0 yapÄ±lmalÄ±!" },
  ],
  6: [
    { q: "Inference'da backward pass yapÄ±lÄ±r mÄ±?", opts: ["HayÄ±r â€” sadece forward pass yeterli", "Evet, her zaman", "Sadece ilk adÄ±mda", "Opsiyonel"], ans: 0, explain: "Inference'da parametre gÃ¼ncellemesi yok â†’ gradient gerekmez â†’ backward pass yok â†’ daha hÄ±zlÄ±, daha az bellek." },
    { q: "Temperature=0.1 ile Ã¼retim nasÄ±l olur?", opts: ["Tamamen rastgele", "Neredeyse deterministik â€” hep en olasÄ± token seÃ§ilir", "Ã‡ok yaratÄ±cÄ±", "Model Ã§Ã¶ker"], ans: 1, explain: "DÃ¼ÅŸÃ¼k T â†’ logitler/T bÃ¼yÃ¼r â†’ softmax Ã§ok sivri â†’ en yÃ¼ksek olasÄ±lÄ±klÄ± token neredeyse %100 alÄ±r. Tekrarlara dÃ¼ÅŸer." },
    { q: "KV Cache ne saÄŸlar?", opts: ["Daha fazla parametre", "Daha iyi sonuÃ§", "Ã–nceki tokenlarÄ± yeniden hesaplamadan saklar â†’ O(nÂ²)â†’O(n)", "SÄ±kÄ±ÅŸtÄ±rma"], ans: 2, explain: "Her yeni token iÃ§in sadece 1 K,V hesaplanÄ±r, Ã¶ncekiler cache'ten okunur. Zaman: O(nÂ²) â†’ O(n)." },
    { q: "Autoregressive Ã¼retim neden sÄ±ralÄ± Ã§alÄ±ÅŸÄ±r?", opts: ["Bellek yetersizliÄŸi", "Her token Ã¶nceki token'a baÄŸlÄ±dÄ±r â€” paralel Ã¼retilemez", "GPU yetersizliÄŸi", "TasarÄ±m hatasÄ±"], ans: 1, explain: "pos=3'Ã¼ Ã¼retmek iÃ§in pos=2'nin Ã§Ä±ktÄ±sÄ± gerekir. Bu nedenle her token sÄ±rayla Ã¼retilmeli â€” paralellik mÃ¼mkÃ¼n deÄŸil." },
    { q: "Temperature=2.0 ile Ã¼retim nasÄ±l olur?", opts: ["Ã‡ok yaratÄ±cÄ± â€” dÃ¼ÅŸÃ¼k olasÄ±lÄ±klÄ± tokenlar da seÃ§ilir", "Her zaman aynÄ± isim", "Model Ã§Ã¶ker", "Sessiz kalÄ±r"], ans: 0, explain: "YÃ¼ksek T â†’ logitler kÃ¼Ã§Ã¼lÃ¼r â†’ softmax dÃ¼zleÅŸir â†’ tÃ¼m tokenlar yakÄ±n olasÄ±lÄ±kla â†’ kaotik, anlamsÄ±z sonuÃ§lar." },
    { q: "Ãœretim ne zaman durur?", opts: ["Loss sÄ±fÄ±r olunca", "KullanÄ±cÄ± durdurna kadar", "8 harf Ã¼retince", "BOS/EOS token Ã¼retilince veya max uzunluÄŸa ulaÅŸÄ±nca"], ans: 3, explain: "Ä°ki duruÅŸ koÅŸulu: BOS token Ã¼retilirse DUR (model 'bitti' diyor) veya block_size=8'e ulaÅŸÄ±lÄ±rsa DUR (max uzunluk)." },
    { q: "Bu kod ile GPT-4 arasÄ±ndaki TEK fark nedir?", opts: ["FarklÄ± matematik", "FarklÄ± algoritma", "Sadece Ã¶lÃ§ek ve mÃ¼hendislik â€” temel matematik aynÄ±", "FarklÄ± programlama dili"], ans: 2, explain: "Birebir aynÄ± algoritma! Fark: 3,648 vs 1T+ parametre, CPU vs 10K+ GPU, dakikalar vs aylar. Matematik = aynÄ±." },
  ],
  7: [
    { q: "Scaling laws ne der?", opts: ["Parametre/veri artÄ±nca loss gÃ¼Ã§ yasasÄ±yla dÃ¼ÅŸer", "KÃ¼Ã§Ã¼k model her zaman yeterli", "Ã–lÃ§ek Ã¶nemsiz", "BÃ¼yÃ¼k model her zaman kÃ¶tÃ¼"], ans: 0, explain: "Kaplanick et al.: loss âˆ 1/N^Î±. Daha fazla parametre VE veri â†’ daha dÃ¼ÅŸÃ¼k loss. GÃ¼Ã§ yasasÄ± iliÅŸkisi." },
    { q: "Pre-training â†’ SFT â†’ RLHF sÄ±ralamasÄ±nÄ±n amacÄ± nedir?", opts: ["Ham gÃ¼Ã§ â†’ yetenek â†’ iyi davranÄ±ÅŸ (hizalama)", "HÄ±z artÄ±ÅŸÄ±", "Maliyet azaltma", "Sadece gelenek"], ans: 0, explain: "Pre-training: genel bilgi Ã¶ÄŸren. SFT: assistant gibi davran. RLHF: zararsÄ±z ve yararlÄ± ol. Her aÅŸama bir katman ekler." },
    { q: "BPE tokenization'Ä±n karakter dÃ¼zeyine avantajÄ± nedir?", opts: ["AynÄ± metin daha az token â†’ daha uzun context", "Daha yavaÅŸ", "Daha basit", "Fark yok"], ans: 0, explain: "'playing' karakter: 7 token, BPE: 2 token. AynÄ± context window'a 3Ã— daha fazla metin sÄ±ÄŸar â†’ daha iyi anlama." },
    { q: "Flash Attention neyi deÄŸiÅŸtirir?", opts: ["Matematik formÃ¼lÃ¼nÃ¼", "Bellek eriÅŸim dÃ¼zenini â€” sonuÃ§ aynÄ±, 2-4Ã— hÄ±zlÄ±", "Attention'Ä± kaldÄ±rÄ±r", "Parametre sayÄ±sÄ±nÄ±"], ans: 1, explain: "AynÄ± softmax(QKáµ€/âˆšd)V hesabÄ±! Fark: GPU bellek hiyerarÅŸisine uygun tiling â†’ IO darboÄŸazÄ± Ã§Ã¶zÃ¼lÃ¼r â†’ 2-4Ã— hÄ±z." },
    { q: "MoE (Mixture of Experts) nasÄ±l verimlilik saÄŸlar?", opts: ["TÃ¼m parametreleri kullanÄ±r", "Her token sadece 2/8 uzmanÄ± aktive eder â†’ az hesaplama", "Attention'Ä± kaldÄ±rÄ±r", "Parametre azaltÄ±r"], ans: 1, explain: "GPT-4 ~1.8T toplam parametre ama her token sadece ~280B aktif parametre kullanÄ±r. BÃ¼yÃ¼k kapasite, verimli Ã§alÄ±ÅŸma." },
    { q: "GPU neden AI eÄŸitiminde CPU'dan Ã§ok daha iyi?", opts: ["Daha az enerji", "Binlerce paralel Ã§ekirdek matris Ã§arpÄ±mÄ±nÄ± aynÄ± anda yapar", "Daha ucuz", "Daha basit mimari"], ans: 1, explain: "LLM = devasa matris Ã§arpÄ±mlarÄ±. GPU 6,912 CUDA Ã§ekirdeÄŸi ile bunlarÄ± paralel yapar. CPU 8-16 Ã§ekirdek ile sÄ±ralÄ±." },
    { q: "microGPT ile GPT-4'Ã¼n ortak noktasÄ± nedir?", opts: ["Parametre sayÄ±sÄ±", "DonanÄ±m", "Temel Transformer algoritmasÄ±: embedding + attention + MLP + softmax", "EÄŸitim verisi"], ans: 2, explain: "Ä°kisi de aynÄ± matematik: token embed â†’ multi-head attention â†’ MLP â†’ softmax â†’ next-token prediction. Fark = Ã¶lÃ§ek." },
  ],
  8: [
    { q: "BPE'de en sÄ±k komÅŸu Ã§ifti birleÅŸtirmenin bilgi-teorik gerekÃ§esi nedir?", opts: ["HÄ±z artÄ±ÅŸÄ±", "Estetik sebep", "Bellek tasarrufu", "Entropy azaltma: sÄ±k Ã§iftleri tek sembolle kodlamak toplam bit sayÄ±sÄ±nÄ± dÃ¼ÅŸÃ¼rÃ¼r"], ans: 3, explain: "Shannon'Ä±n kaynak kodlama teoremi: sÄ±k semboller kÄ±sa kod â†’ ortalama uzunluk â‰ˆ H(X). BPE buna yaklaÅŸÄ±r." },
    { q: "Hessian matrisi eÄŸitimde ne bilgi verir?", opts: ["Parametre uzayÄ±ndaki eÄŸrilik â€” minimum'un keskin mi dÃ¼z mÃ¼ olduÄŸunu gÃ¶sterir", "Gradient yÃ¶nÃ¼", "Parametre sayÄ±sÄ±", "Loss deÄŸeri"], ans: 0, explain: "Hessian eigenvalue'larÄ±: bÃ¼yÃ¼k = keskin minimum (genelleme kÃ¶tÃ¼), kÃ¼Ã§Ã¼k = dÃ¼z (iyi genelleme). Newton yÃ¶ntemi Hessian kullanÄ±r." },
    { q: "Attention head pruning'de Taylor expansion skoru neyi Ã¶lÃ§er?", opts: ["Head'in kaldÄ±rÄ±lmasÄ±nÄ±n loss'a etkisini birinci derece yaklaÅŸÄ±mla tahmin eder", "Head renkliliÄŸini", "Head boyutunu", "Head hÄ±zÄ±nÄ±"], ans: 0, explain: "I(h) = |Î±_h Â· âˆ‚L/âˆ‚Î±_h| â‰ˆ Î”L (head kaldÄ±rÄ±ldÄ±ÄŸÄ±nda loss deÄŸiÅŸimi). DÃ¼ÅŸÃ¼k skor = gereksiz head." },
    { q: "Embedding isotropy neden Ã¶nemlidir?", opts: ["HÄ±z artÄ±ÅŸÄ±", "Anisotropik uzayda tokenlar dar bir koniye sÄ±kÄ±ÅŸÄ±r â†’ benzerlik Ã¶lÃ§Ã¼mleri anlamsÄ±zlaÅŸÄ±r", "GÃ¶rsel gÃ¼zellik", "Bellek tasarrufu"], ans: 1, explain: "TÃ¼m vektÃ¶rler aynÄ± yÃ¶ne bakÄ±yorsa cosine similarity hep yÃ¼ksek â†’ ayÄ±rt edicilik kaybolur. Ä°yi embedding isotropik." },
    { q: "Float16'da softmax overflow'u nasÄ±l Ã¶nlenir?", opts: ["max-trick: softmax(x) = softmax(x - max(x)) ile numerik kararlÄ±lÄ±k saÄŸlanÄ±r", "Float64 kullanÄ±lÄ±r", "Softmax kullanÄ±lmaz", "Ã–nlenemez"], ans: 0, explain: "exp(100) = overflow ama exp(100-100)=exp(0)=1. max Ã§Ä±karma matematiÄŸi deÄŸiÅŸtirmez, numerik kararlÄ±lÄ±k saÄŸlar." },
    { q: "Akademik raporda 'Related Work' bÃ¶lÃ¼mÃ¼ neden zorunludur?", opts: ["Sayfa doldurmak", "Ã‡alÄ±ÅŸmanÄ±zÄ± mevcut literatÃ¼re konumlandÄ±rÄ±r ve katkÄ±nÄ±zÄ±n orijinalliÄŸini gÃ¶sterir", "Referans sayÄ±sÄ±nÄ± artÄ±rmak", "Gelenek"], ans: 1, explain: "Related work: 'daha Ã¶nce ne yapÄ±ldÄ±, benim farkÄ±m ne?' sorusuna cevap verir. Akademik katkÄ±nÄ±n temeli." },
    { q: "KontrollÃ¼ deneyde 'kontrol deÄŸiÅŸkeni' ne demektir?", opts: ["En Ã¶nemli parametre", "Deneyde sabit tutulan deÄŸiÅŸken â€” sadece bir ÅŸeyi deÄŸiÅŸtirerek etkisini Ã¶lÃ§", "Rastgele seÃ§ilen deÄŸer", "SonuÃ§ deÄŸiÅŸkeni"], ans: 1, explain: "Ã–rnek: BPE vs Unigram karÅŸÄ±laÅŸtÄ±rmasÄ±nda vocab boyutu, veri seti, model mimarisi SABÄ°T. Sadece tokenizer DEÄÄ°ÅÄ°R." },
  ],
  9: [
    { q: "Neural Architecture Search'te Pareto frontÄ± ne gÃ¶sterir?", opts: ["En kÃ¶tÃ¼ modeller", "Rastgele noktalar", "Loss vs parametre trade-off'unda optimal noktalarÄ± â€” birini iyileÅŸtirmeden diÄŸeri kÃ¶tÃ¼leÅŸmez", "En iyi model"], ans: 2, explain: "Pareto-optimal: A noktasÄ±ndan B'ye geÃ§ince ya loss artar ya parametre. Ä°kisi birden azalmaz. TasarÄ±m kararÄ± gerektirir." },
    { q: "Knowledge distillation'da temperature T_distill neden yÃ¼ksek tutulur?", opts: ["HÄ±z iÃ§in", "Bellek tasarrufu", "Soft targets daha bilgi iÃ§erir: dÃ¼ÅŸÃ¼k olasÄ±lÄ±klÄ± sÄ±nÄ±flar arasÄ±ndaki iliÅŸkileri de aktarÄ±r", "Rastgele seÃ§im"], ans: 2, explain: "T=1: [0.9, 0.05, 0.05] â†’ sadece 'doÄŸru cevap'. T=5: [0.4, 0.35, 0.25] â†’ 'yanlÄ±ÅŸlar arasÄ±ndaki benzerlik' bilgisi de aktarÄ±lÄ±r." },
    { q: "RoPE neden context genellemede learned PE'den Ã¼stÃ¼ndÃ¼r?", opts: ["Daha hÄ±zlÄ±", "GÃ¶receli pozisyon bilgisi: eÄŸitim uzunluÄŸu Ã¶tesinde de Ã§alÄ±ÅŸÄ±r Ã§Ã¼nkÃ¼ fark tabanlÄ±", "Daha az parametre", "Daha basit"], ans: 1, explain: "Learned PE: pos=8'i hiÃ§ gÃ¶rmedi â†’ bilinmeyen vektÃ¶r. RoPE: pos(i)-pos(j) farkÄ± Ã¶nemli â†’ uzun context'e geneller." },
    { q: "Sparse attention'da %50 sparsity ne kadar FLOPs tasarrufu saÄŸlar?", opts: ["Tasarruf yok", "%90", "%10", "Teorik %50, pratikte %30-40 (overhead nedeniyle)"], ans: 3, explain: "%50 token atlanÄ±r â†’ QK^T'nin yarÄ±sÄ± hesaplanmaz. Ama maskeleme + indexing overhead'i tam %50'ye ulaÅŸmayÄ± engeller." },
    { q: "Grokking fenomeni nedir?", opts: ["Overfitting", "Underfitting", "HÄ±zlÄ± Ã¶ÄŸrenme", "EÄŸitim lossâ‰ˆ0 olduktan Ã‡OK sonra aniden test loss'un da dÃ¼ÅŸmesi â€” gecikmeli genelleme"], ans: 3, explain: "KÃ¼Ã§Ã¼k veri + uzun eÄŸitim: model Ã¶nce ezberler (trainâ†“, testâ†’), sonra aniden geneller (testâ†“). Neden olduÄŸu hala araÅŸtÄ±rÄ±lÄ±yor." },
    { q: "Loss landscape'te 'flat minimum' neden tercih edilir?", opts: ["KÃ¼Ã§Ã¼k parametre pertÃ¼rbasyon'a karÅŸÄ± dayanÄ±klÄ± â†’ daha iyi genelleme", "Daha dÃ¼ÅŸÃ¼k loss", "Daha hÄ±zlÄ± eÄŸitim", "Daha az parametre"], ans: 0, explain: "Sharp minimum: kÃ¼Ã§Ã¼k w deÄŸiÅŸimi â†’ bÃ¼yÃ¼k loss artÄ±ÅŸÄ± (kÄ±rÄ±lgan). Flat: wÂ±Îµ â†’ loss stabil. Test veri daÄŸÄ±lÄ±m kaymasÄ±na dayanÄ±klÄ±." },
    { q: "Ablation study nedir ve neden YL projelerinde zorunludur?", opts: ["Hepsini ekle", "Kodu sil", "Her bileÅŸeni tek tek Ã§Ä±kararak bireysel katkÄ±sÄ±nÄ± Ã¶lÃ§ â€” bilimsel yÃ¶ntemin temelidir", "En iyi sonucu bul"], ans: 2, explain: "4 Ã¶zellik eklediniz, toplam %15 iyileÅŸme. Hangisi ne kadar katkÄ± yaptÄ±? Ablation olmadan bunu BÄ°LEMEZSÄ°NÄ°Z." },
  ]
};
const COMMON_MISTAKES = {
  0: [
    { mistake: "\"GPT sadece bÃ¼yÃ¼k ÅŸirketler yapabilir\"", truth: "Bu 243 satÄ±rlÄ±k kod AYNI algoritmayÄ± Ã§alÄ±ÅŸtÄ±rÄ±r. Fark sadece Ã¶lÃ§ek ve donanÄ±mdÄ±r." },
    { mistake: "\"Derin Ã¶ÄŸrenme Ã§ok matematik gerektirir\"", truth: "Temel 4 iÅŸlem + tÃ¼rev yeterli. Bu derste gÃ¶receÄŸiniz gibi her adÄ±m basit aritmetik." },
  ],
  1: [
    { mistake: "\"Embedding rastgele sayÄ±lardÄ±r, anlamsÄ±z\"", truth: "BaÅŸta rastgele ama eÄŸitimle anlam kazanÄ±r. Benzer tokenlar yakÄ±n vektÃ¶rlere sahip olur." },
    { mistake: "\"Token ID sÄ±rasÄ± Ã¶nemli (a=0, b=1 â†’ a ve b yakÄ±n)\"", truth: "ID sÄ±rasÄ± anlam taÅŸÄ±maz! Embedding zaten iliÅŸkileri Ã¶ÄŸrenir. ID sadece indeks." },
    { mistake: "\"BOS ve EOS farklÄ± tokenlar\"", truth: "Bu kodda ikisi de aynÄ± token (ID=26). BaÄŸlam farkÄ±nÄ± model Ã¶ÄŸrenir." },
  ],
  2: [
    { mistake: "\"grad = (eÅŸittir) yeterli, += gerekmiyor\"", truth: "KRÄ°TÄ°K HATA! Bir parametre birden fazla yoldan loss'u etkiliyorsa (weight tying gibi) gradientler TOPLANMALI." },
    { mistake: "\"Her adÄ±mda gradient sÄ±fÄ±rlamak gereksiz\"", truth: "SÄ±fÄ±rlanmazsa gradientler birikir â†’ model patlar. p.grad = 0 her adÄ±mda ÅART." },
    { mistake: "\"Backward'da dÃ¼ÄŸÃ¼m sÄ±rasÄ± Ã¶nemli deÄŸil\"", truth: "YanlÄ±ÅŸ sÄ±rada gradient hesaplarsanÄ±z chain rule bozulur. Topological sort zorunlu." },
  ],
  3: [
    { mistake: "\"Q, K, V hep aynÄ± â€” neden 3 ayrÄ± matris?\"", truth: "Her biri farklÄ± rol: Q=ne arÄ±yorum, K=bende ne var, V=bilgi iÃ§eriÄŸi. FarklÄ± projeksiyon farklÄ± Ã¶ÄŸrenme." },
    { mistake: "\"Scaling (Ã·âˆšd) sadece optimizasyon tricki\"", truth: "HayÄ±r, kritik! Onsuz bÃ¼yÃ¼k boyutlarda softmax spike yapÄ±p gradient kaybolur â€” model Ã¶ÄŸrenemez." },
  ],
  4: [
    { mistake: "\"Normalizasyon olmazsa da eÄŸitilir\"", truth: "Derin aÄŸlarda aktivasyonlar katman katman patlar veya kaybolur. Norm olmadan 2+ katmanlÄ± model eÄŸitilemez." },
    { mistake: "\"Residual sadece derin aÄŸlar iÃ§in lazÄ±m\"", truth: "Tek katmanlÄ± bu kodda bile residual, kararlÄ± eÄŸitim ve identity baÅŸlatma saÄŸlar." },
  ],
  5: [
    { mistake: "\"Loss her adÄ±mda dÃ¼ÅŸmeli\"", truth: "Stochastic eÄŸitimde (tek Ã¶rnek/adÄ±m) loss salÄ±nÄ±r, bu NORMAL. Trend dÃ¼ÅŸÃ¼yorsa model Ã¶ÄŸreniyor." },
    { mistake: "\"Learning rate yÃ¼ksekse daha hÄ±zlÄ± Ã¶ÄŸrenir\"", truth: "Belirli bir noktadan sonra LR artÄ±ÅŸÄ± â†’ patlama â†’ loss NaN olur. Ä°yi LR = denge." },
  ],
  6: [
    { mistake: "\"Temperature=0 en iyi sonuÃ§ verir\"", truth: "Tâ‰ˆ0 deterministik â†’ Ã§eÅŸitlilik yok, tekrarlara dÃ¼ÅŸer. Ä°yi Ã¼retim iÃ§in T=0.7-1.0 dengeli." },
    { mistake: "\"Model her Ã§alÄ±ÅŸmada aynÄ± sonuÃ§ vermeli\"", truth: "Sampling stokastik â†’ farklÄ± rastgele tohum = farklÄ± sonuÃ§. Bu, Ã¶zellik, hata deÄŸil." },
  ],
  7: [
    { mistake: "\"GPT-4 tamamen farklÄ± bir teknoloji\"", truth: "AynÄ± Transformer temeli! Fark sadece Ã¶lÃ§ek (parametre, veri, donanÄ±m) ve mÃ¼hendislik optimizasyonlarÄ±." },
    { mistake: "\"AÃ§Ä±k kaynak modeller zayÄ±f\"", truth: "LLaMA 3.1 405B, DeepSeek-V3 birÃ§ok gÃ¶revde GPT-4'e yakÄ±n veya eÅŸit performans gÃ¶steriyor." },
    { mistake: "\"RLHF modeli akÄ±llÄ± yapar\"", truth: "RLHF hizalama (gÃ¼venlik, yararlÄ±lÄ±k) saÄŸlar â€” temel yetenek pre-training'den gelir." },
  ],
  8: [
    { mistake: "\"Projeyi son gÃ¼ne bÄ±rakÄ±rÄ±m\"", truth: "Kod yazmak kolay, DEBUG etmek zor. Ä°lk hafta Ã§alÄ±ÅŸan bir ÅŸey olsun, ikinci hafta geliÅŸtirin." },
    { mistake: "\"ChatGPT ile tÃ¼m kodu yazarÄ±m, teslim ederim\"", truth: "Her satÄ±rÄ± aÃ§Ä±klayabilmelisiniz. Oral sÄ±navda 'bunu AI yazdÄ±' = sÄ±fÄ±r puan." },
  ],
  9: [
    { mistake: "\"En karmaÅŸÄ±k projeyi seÃ§meliyim\"", truth: "En Ã‡OK Ã–ÄRENECEÄÄ°NÄ°Z projeyi seÃ§in. Basit ama iyi anlaÅŸÄ±lmÄ±ÅŸ > karmaÅŸÄ±k ama yarÄ±m." },
    { mistake: "\"Rapor opsiyoneldir\"", truth: "Final'de analiz ve yorumlama %25 puan. Kod Ã§alÄ±ÅŸsa bile raporsuz tam not alamazsÄ±nÄ±z." },
  ]
};

// â”€â”€â”€ GLOSSARY (SÃ–ZLÃœK) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const GLOSSARY = [
  { term: "Autograd", def: {tr:"Hesaplama grafÄ± Ã¼zerinde otomatik tÃ¼rev alma sistemi. Her operasyonun yerel tÃ¼revini bilerek chain rule ile geri yayÄ±lÄ±m yapar.",en:"Automatic differentiation system on computation graphs. Performs backpropagation via chain rule knowing each operation's local derivative."}, cat: "temel", week: 2 },
  { term: "Autoregressive", def: {tr:"Her adÄ±mda kendi Ã§Ä±ktÄ±sÄ±nÄ± girdi olarak kullanan Ã¼retim yÃ¶ntemi. GPT autoregressive: Ã¶nceki tokenlara bakarak sonraki tokeni tahmin eder.",en:"Generation method that uses its own output as input at each step. GPT is autoregressive: predicts next token by looking at previous tokens."}, cat: "model", week: 0 },
  { term: "Attention", def: {tr:"Her tokenÄ±n diÄŸer tokenlara dinamik aÄŸÄ±rlÄ±klarla 'dikkat etme' mekanizmasÄ±. FormÃ¼l: softmax(QÂ·Káµ€/âˆšd)Â·V",en:"Mechanism for each token to 'attend' to others with dynamic weights. Formula: softmax(QÂ·Káµ€/âˆšd)Â·V"}, cat: "mimari", week: 3 },
  { term: "Backward Pass", def: {tr:"Loss'tan parametrelere doÄŸru gradient hesaplama sÃ¼reci. Chain rule ile her dÃ¼ÄŸÃ¼mÃ¼n gradientini hesaplar.",en:"Process of computing gradients from loss to parameters. Computes each node's gradient via chain rule."}, cat: "temel", week: 2 },
  { term: "BOS/EOS", def: {tr:"Beginning/End of Sequence. Dizinin baÅŸÄ±nÄ± ve sonunu iÅŸaret eden Ã¶zel token.",en:"Beginning/End of Sequence. Special token marking start and end of a sequence."}, cat: "veri", week: 1 },
  { term: "Causal Mask", def: {tr:"Her tokenÄ±n sadece Ã¶nceki tokenlara bakabilmesini saÄŸlayan maskeleme. GPT'nin 'kopya Ã§ekmesini' engeller.",en:"Masking that ensures each token can only look at previous tokens. Prevents GPT from 'cheating'."}, cat: "mimari", week: 3 },
  { term: "Chain Rule", def: {tr:"BileÅŸik fonksiyonlarÄ±n tÃ¼rev kuralÄ±: f(g(x))' = f'(g(x)) Ã— g'(x). Autograd'Ä±n temelindeki matematik.",en:"Derivative rule for composite functions: f(g(x))' = f'(g(x)) Ã— g'(x). The math behind autograd."}, cat: "temel", week: 2 },
  { term: "Cross-Entropy Loss", def: {tr:"L = -log(P(doÄŸru_token)). Modelin tahmin kalitesini Ã¶lÃ§en kayÄ±p fonksiyonu. DÃ¼ÅŸÃ¼k loss = iyi model.",en:"L = -log(P(correct_token)). Loss function measuring prediction quality. Low loss = good model."}, cat: "eÄŸitim", week: 5 },
  { term: "Dot Product", def: {tr:"Ä°ki vektÃ¶rÃ¼n element-wise Ã§arpÄ±mlarÄ±nÄ±n toplamÄ±: aÂ·b = Î£ aáµ¢báµ¢. Benzerlik Ã¶lÃ§Ã¼sÃ¼ olarak kullanÄ±lÄ±r.",en:"Sum of element-wise products of two vectors: aÂ·b = Î£ aáµ¢báµ¢. Used as a similarity measure."}, cat: "temel", week: 3 },
  { term: "Embedding", def: {tr:"Token ID'yi Ã§ok boyutlu sÃ¼rekli vektÃ¶re dÃ¶nÃ¼ÅŸtÃ¼ren Ã¶ÄŸrenilebilir tablo. Bu kodda 28Ã—16 matris.",en:"Learnable lookup table converting token IDs to multi-dimensional continuous vectors. In this code: 28Ã—16 matrix."}, cat: "mimari", week: 1 },
  { term: "Forward Pass", def: {tr:"Girdi â†’ model katmanlarÄ± â†’ Ã§Ä±ktÄ± (logits) hesaplama sÃ¼reci. Ä°leri yÃ¶nde data akÄ±ÅŸÄ±.",en:"Process of computing input â†’ model layers â†’ output (logits). Forward data flow."}, cat: "temel", week: 0 },
  { term: "Loss", def: {tr:"Modelin tahmin kalitesini Ã¶lÃ§en hata fonksiyonu. DÃ¼ÅŸÃ¼k loss = iyi tahmin. microGPT baÅŸlangÄ±Ã§: 3.33, eÄŸitim sonrasÄ±: ~2.0.",en:"Error function measuring prediction quality. Low loss = good prediction. microGPT start: 3.33, after training: ~2.0."}, cat: "temel", week: 0 },
  { term: "Parametre", def: {tr:"Modelin Ã¶ÄŸrenilebilir sayÄ±sal deÄŸerleri (aÄŸÄ±rlÄ±klar). microGPT: 3,648 parametre, GPT-4: ~1T+.",en:"Model's learnable numerical values (weights). microGPT: 3,648 parameters, GPT-4: ~1T+."}, cat: "temel", week: 0 },
  { term: "Hyperparametre", def: {tr:"EÄŸitim Ã¶ncesi sabitlenen tasarÄ±m kararlarÄ±: n_embd, n_layer, learning_rate vb. EÄŸitimle deÄŸiÅŸmez.",en:"Design decisions fixed before training: n_embd, n_layer, learning_rate etc. Not changed during training."}, cat: "temel", week: 0 },
  { term: "Pipeline", def: {tr:"Veriyi adÄ±m adÄ±m iÅŸleyen sÄ±ralÄ± sÃ¼reÃ§. GPT: tokenize â†’ embed â†’ attend â†’ MLP â†’ predict.",en:"Sequential process that processes data step by step. GPT: tokenize â†’ embed â†’ attend â†’ MLP â†’ predict."}, cat: "temel", week: 0 },
  { term: "Gradient", def: {tr:"TÃ¼m kÄ±smi tÃ¼revlerin vektÃ¶rÃ¼: âˆ‡f = [âˆ‚f/âˆ‚wâ‚, âˆ‚f/âˆ‚wâ‚‚, ...]. Parametrelerin gÃ¼ncelleme yÃ¶nÃ¼nÃ¼ gÃ¶sterir.",en:"Vector of all partial derivatives: âˆ‡f = [âˆ‚f/âˆ‚wâ‚, âˆ‚f/âˆ‚wâ‚‚, ...]. Shows parameter update direction."}, cat: "temel", week: 2 },
  { term: "Gradient Descent", def: {tr:"Parametreleri gradient'in ters yÃ¶nÃ¼nde gÃ¼ncelleyerek loss'u minimize etme: w -= lr Ã— âˆ‚L/âˆ‚w",en:"Minimizing loss by updating parameters in the opposite direction of gradient: w -= lr Ã— âˆ‚L/âˆ‚w"}, cat: "eÄŸitim", week: 5 },
  { term: "KV Cache", def: {tr:"Ã–nceki pozisyonlarÄ±n Key ve Value vektÃ¶rlerini saklayarak tekrar hesaplamayÄ± Ã¶nleyen optimizasyon.",en:"Optimization that stores previous positions' Key and Value vectors to avoid recomputation."}, cat: "mimari", week: 6 },
  { term: "Learning Rate", def: {tr:"Parametre gÃ¼ncelleme adÄ±m boyutu. Ã‡ok bÃ¼yÃ¼k â†’ patlama, Ã§ok kÃ¼Ã§Ã¼k â†’ yavaÅŸ Ã¶ÄŸrenme.",en:"Parameter update step size. Too large â†’ explosion, too small â†’ slow learning."}, cat: "eÄŸitim", week: 5 },
  { term: "Logits", def: {tr:"Modelin son katman ham Ã§Ä±ktÄ± skorlarÄ±. Softmax'tan geÃ§irilmeden Ã¶nceki deÄŸerler.",en:"Model's raw output scores from the last layer. Values before softmax."}, cat: "model", week: 1 },
  { term: "MLP (Feed-Forward)", def: {tr:"Her tokena baÄŸÄ±msÄ±z uygulanan geniÅŸletâ†’aktive etâ†’daralt aÄŸÄ±. Bu kodda: 16â†’64â†’16.",en:"Expandâ†’activateâ†’compress network applied independently to each token. In this code: 16â†’64â†’16."}, cat: "mimari", week: 4 },
  { term: "Multi-Head Attention", def: {tr:"Embedding'i birden fazla head'e bÃ¶lÃ¼p her birinde baÄŸÄ±msÄ±z attention hesaplama. FarklÄ± kalÄ±plar Ã¶ÄŸrenir.",en:"Splitting embedding into multiple heads with independent attention computation. Learns different patterns."}, cat: "mimari", week: 3 },
  { term: "ReLUÂ²", def: {tr:"Aktivasyon fonksiyonu: max(0,x)Â². Negatifler sÄ±fÄ±r olur, pozitifler karesel bÃ¼yÃ¼r â†’ sparse temsil.",en:"Activation function: max(0,x)Â². Negatives become zero, positives grow quadratically â†’ sparse representation."}, cat: "mimari", week: 4 },
  { term: "Residual Connection", def: {tr:"x = f(x) + x_skip. Girdiyi Ã§Ä±ktÄ±ya ekleyerek gradient akÄ±ÅŸÄ±na kestirme yol saÄŸlar.",en:"x = f(x) + x_skip. Provides gradient shortcut by adding input to output."}, cat: "mimari", week: 4 },
  { term: "RMSNorm", def: {tr:"x / âˆš(mean(xÂ²) + Îµ). LayerNorm'un hÄ±zlÄ± versiyonu â€” ortalama Ã§Ä±karma adÄ±mÄ± yok.",en:"x / âˆš(mean(xÂ²) + Îµ). Fast version of LayerNorm â€” no mean subtraction step."}, cat: "mimari", week: 4 },
  { term: "Sampling", def: {tr:"OlasÄ±lÄ±k daÄŸÄ±lÄ±mÄ±ndan rastgele token seÃ§me. Temperature ile kontrol edilir.",en:"Randomly selecting a token from probability distribution. Controlled by temperature."}, cat: "model", week: 6 },
  { term: "Softmax", def: {tr:"Ham skorlarÄ± olasÄ±lÄ±k daÄŸÄ±lÄ±mÄ±na Ã§evirir: P(i) = exp(xáµ¢)/Î£exp(xâ±¼). Toplam her zaman 1.",en:"Converts raw scores to probability distribution: P(i) = exp(xáµ¢)/Î£exp(xâ±¼). Sum always equals 1."}, cat: "temel", week: 1 },
  { term: "Temperature", def: {tr:"Softmax'Ä±n sivriliÄŸini kontrol eden parametre. T<1 â†’ deterministik, T>1 â†’ rastgele.",en:"Parameter controlling softmax sharpness. T<1 â†’ deterministic, T>1 â†’ random."}, cat: "model", week: 6 },
  { term: "Token", def: {tr:"Modelin iÅŸlediÄŸi en kÃ¼Ã§Ã¼k birim. Bu kodda her karakter (a-z + BOS) bir token.",en:"Smallest unit the model processes. In this code each character (a-z + BOS) is a token."}, cat: "veri", week: 1 },
  { term: "Topological Sort", def: {tr:"DAG'da dÃ¼ÄŸÃ¼mleri baÄŸÄ±mlÄ±lÄ±k sÄ±rasÄ±na dizen algoritma. Backward pass'te doÄŸru gradient sÄ±rasÄ±nÄ± saÄŸlar.",en:"Algorithm that orders DAG nodes by dependency. Ensures correct gradient order in backward pass."}, cat: "temel", week: 2 },
  { term: "Transformer", def: {tr:"Attention + MLP + Norm + Residual'dan oluÅŸan mimari. 2017'de tanÄ±tÄ±ldÄ±, tÃ¼m modern LLM'lerin temeli.",en:"Architecture composed of Attention + MLP + Norm + Residual. Introduced in 2017, foundation of all modern LLMs."}, cat: "mimari", week: 4 },
  { term: "Weight Tying", def: {tr:"GiriÅŸ embedding matrisi (wte) ile Ã§Ä±kÄ±ÅŸ projeksiyon matrisinin paylaÅŸÄ±lmasÄ±. Parametre tasarrufu saÄŸlar.",en:"Sharing input embedding matrix (wte) with output projection matrix. Saves parameters."}, cat: "mimari", week: 1 },
  { term: "Scaling Laws", def: {tr:"Model boyutu, veri ve hesaplama artÄ±nca loss'un gÃ¼Ã§ yasasÄ±yla dÃ¼ÅŸtÃ¼ÄŸÃ¼nÃ¼ gÃ¶steren ampirik yasalar (Kaplanick 2020).",en:"Empirical laws showing loss decreases as a power law with model size, data, and compute (Kaplan 2020)."}, cat: "evrim", week: 7 },
  { term: "BPE", def: {tr:"Byte Pair Encoding: En sÄ±k karakter Ã§iftlerini birleÅŸtirerek alt-kelime token'larÄ± oluÅŸturan tokenization algoritmasÄ±.",en:"Byte Pair Encoding: Tokenization algorithm creating subword tokens by merging the most frequent character pairs."}, cat: "evrim", week: 7 },
  { term: "RLHF", def: {tr:"Reinforcement Learning from Human Feedback: Ä°nsan tercihleri ile modeli 'iyi davranÄ±ÅŸa' hizalama yÃ¶ntemi.",en:"Reinforcement Learning from Human Feedback: Method for aligning the model to 'good behavior' using human preferences."}, cat: "evrim", week: 7 },
  { term: "SFT", def: {tr:"Supervised Fine-Tuning: Ä°nsan yazÄ±mÄ± soru-cevap Ã§iftleri ile modeli assistant formatÄ±na dÃ¶nÃ¼ÅŸtÃ¼rme.",en:"Supervised Fine-Tuning: Converting the model to assistant format using human-written Q&A pairs."}, cat: "evrim", week: 7 },
  { term: "MoE", def: {tr:"Mixture of Experts: Birden fazla uzman aÄŸ, her token sadece birkaÃ§Ä±nÄ± aktive eder â†’ verimli bÃ¼yÃ¼k model.",en:"Mixture of Experts: Multiple expert networks, each token activates only a few â†’ efficient large model."}, cat: "evrim", week: 7 },
  { term: "Flash Attention", def: {tr:"IO-aware tiling ile standart attention'Ä± 2-4Ã— hÄ±zlandÄ±ran algoritma. Matematik aynÄ±, bellek eriÅŸimi farklÄ±.",en:"Algorithm that speeds up standard attention 2-4Ã— via IO-aware tiling. Same math, different memory access."}, cat: "evrim", week: 7 },
  { term: "RAG", def: {tr:"Retrieval-Augmented Generation: DÄ±ÅŸ bilgi tabanÄ±ndan ilgili dokÃ¼manlarÄ± Ã§ekip yanÄ±ta ekleyen yÃ¶ntem.",en:"Retrieval-Augmented Generation: Method that retrieves relevant documents from external knowledge base and adds to response."}, cat: "evrim", week: 7 },
  { term: "Ablation Study", def: {tr:"Her bileÅŸeni tek tek Ã§Ä±kararak bireysel katkÄ±sÄ±nÄ± Ã¶lÃ§en deneysel yÃ¶ntem. YL araÅŸtÄ±rmanÄ±n temel aracÄ±.",en:"Experimental method measuring individual contribution by removing each component. A fundamental research tool."}, cat: "araÅŸtÄ±rma", week: 8 },
  { term: "Hessian", def: {tr:"Ä°kinci tÃ¼rev matrisi. Loss landscape'Ä±n eÄŸriliÄŸini gÃ¶sterir. Newton yÃ¶ntemi Hessian kullanÄ±r.",en:"Second derivative matrix. Shows the curvature of the loss landscape. Newton's method uses the Hessian."}, cat: "araÅŸtÄ±rma", week: 8 },
  { term: "Isotropy", def: {tr:"Embedding vektÃ¶rlerinin uzayda eÅŸit daÄŸÄ±lÄ±mÄ±. Anisotropik = dar koniye sÄ±kÄ±ÅŸmÄ±ÅŸ = kÃ¶tÃ¼.",en:"Equal distribution of embedding vectors in space. Anisotropic = squeezed into narrow cone = bad."}, cat: "araÅŸtÄ±rma", week: 8 },
  { term: "Head Pruning", def: {tr:"Gereksiz attention head'lerini kaldÄ±rma. Taylor expansion ile importance skoru hesaplanÄ±r.",en:"Removing unnecessary attention heads. Importance score computed via Taylor expansion."}, cat: "araÅŸtÄ±rma", week: 8 },
  { term: "Entropy", def: {tr:"H(X) = -Î£p(x)log(p(x)). Belirsizlik Ã¶lÃ§Ã¼sÃ¼. Tokenizer deÄŸerlendirmede kullanÄ±lÄ±r.",en:"H(X) = -Î£p(x)log(p(x)). Measure of uncertainty. Used in tokenizer evaluation."}, cat: "araÅŸtÄ±rma", week: 8 },
  { term: "Pareto Front", def: {tr:"Ã‡ok amaÃ§lÄ± optimizasyonda optimal noktalar kÃ¼mesi. Birini iyileÅŸtirmeden diÄŸeri kÃ¶tÃ¼leÅŸmez.",en:"Set of optimal points in multi-objective optimization. Can't improve one without worsening another."}, cat: "araÅŸtÄ±rma", week: 9 },
  { term: "Knowledge Distillation", def: {tr:"BÃ¼yÃ¼k teacher modelin bilgisini kÃ¼Ã§Ã¼k student modele aktarma. Soft targets ile sÄ±nÄ±flar arasÄ± iliÅŸki aktarÄ±lÄ±r.",en:"Transferring knowledge from large teacher model to small student model. Inter-class relationships transferred via soft targets."}, cat: "araÅŸtÄ±rma", week: 9 },
  { term: "Grokking", def: {tr:"EÄŸitim lossâ‰ˆ0 olduktan Ã§ok sonra test loss'un aniden dÃ¼ÅŸmesi. Gecikmeli genelleme fenomeni.",en:"Test loss suddenly dropping long after training lossâ‰ˆ0. A delayed generalization phenomenon."}, cat: "araÅŸtÄ±rma", week: 9 },
  { term: "RoPE", def: {tr:"Rotary Position Embedding. Q,K vektÃ¶rlerini pozisyona gÃ¶re dÃ¶ndÃ¼rerek gÃ¶receli pozisyon bilgisi saÄŸlar.",en:"Rotary Position Embedding. Provides relative position info by rotating Q,K vectors based on position."}, cat: "araÅŸtÄ±rma", week: 9 },
  { term: "NAS", def: {tr:"Neural Architecture Search. Otomatik mimari arama: arama uzayÄ± + strateji (random/Bayesian) + deÄŸerlendirme.",en:"Neural Architecture Search. Automatic architecture search: search space + strategy (random/Bayesian) + evaluation."}, cat: "araÅŸtÄ±rma", week: 9 },
];

// â”€â”€â”€ COMPARISON TABLES â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const COMPARISONS = {
  "model_scale": {
    title: {tr:"Model Ã–lÃ§ek KarÅŸÄ±laÅŸtÄ±rma",en:"Model Scale Comparison"},
    headers: ["", "microGPT", "GPT-1", "GPT-2", "GPT-3", "GPT-4"],
    rows: [
      ["Parametre", "3,648", "117M", "1.5B", "175B", "~1T+"],
      [lang==="tr"?"Katman":"Layers", "1", "12", "48", "96", "?"],
      ["Embedding", "16", "768", "1600", "12288", "?"],
      ["Context", "8", "512", "1024", "2048", "128K"],
      ["Vocab", "28", "~40K", "~50K", "~50K", "~100K"],
      [lang === "tr" ? lang === "tr" ? "YÄ±l" : "Year" : "Year", "2024", "2018", "2019", "2020", "2023"],
    ],
    note: {tr:"Algoritma aynÄ± â€” fark sadece Ã¶lÃ§ek ve mÃ¼hendislik.",en:"Same algorithm â€” difference is only scale and engineering."}
  },
  "norm_compare": {
    title: {tr:"Normalizasyon YÃ¶ntemleri",en:"Normalization Methods"},
    headers: ["", "BatchNorm", "LayerNorm", "RMSNorm â˜…"],
    rows: [
      ["FormÃ¼l", "x-Î¼_batch/Ïƒ_batch", "(x-Î¼)/Ïƒ + Î³,Î²", "x/âˆš(mean(xÂ²)+Îµ)"],
      [lang==="tr"?"Ä°ÅŸlem sayÄ±sÄ±":"Operations", "5", "4", "2"],
      [lang==="tr"?"Ã–ÄŸr. parametre":"Learn. params", "2 (Î³,Î²)", "2 (Î³,Î²)", "1 (Î³)"],
      [lang==="tr"?"Batch baÄŸÄ±mlÄ±":"Batch dependent", "Evet", "HayÄ±r", "HayÄ±r"],
      [lang === "tr" ? "HÄ±z" : "Speed", lang==="tr"?"Orta":"Medium", lang==="tr"?"Orta":"Medium", lang==="tr"?"~%30 hÄ±zlÄ±":"~30% faster"],
      [lang==="tr"?"Kullanan":"Used by", "ResNet", "GPT-2", "LLaMA, Mistral"],
    ],
    note: {tr:"â˜… = bu kodda kullanÄ±lan. Modern LLM standardÄ±.",en:"â˜… = used in this code. Modern LLM standard."}
  },
  "optimizer_compare": {
    title: {tr:"Optimizer KarÅŸÄ±laÅŸtÄ±rma",en:"Optimizer Comparison"},
    headers: ["", "SGD", "Momentum", "Adam â˜…"],
    rows: [
      [lang==="tr"?"GÃ¼ncelleme":"Update", "w -= lrÂ·g", "m = Î²m + g", "m + v adaptif"],
      ["Adaptif LR", "âŒ", "âŒ", "âœ…"],
      ["Momentum", "âŒ", "âœ…", "âœ…"],
      [lang==="tr"?"Bellek (param baÅŸÄ±)":"Memory (per param)", "0", "+1 buffer", "+2 buffer"],
      [lang==="tr"?"Avantaj":"Advantage", lang==="tr"?"Basit":"Simple", lang==="tr"?"DÃ¼zgÃ¼n ilerle":"Smooth progress", lang==="tr"?"Her param. kendi LR":"Per-param LR"],
      [lang==="tr"?"NLP'de tercih":"NLP preference", lang==="tr"?"Nadir":"Rare", lang==="tr"?"Nadir":"Rare", lang==="tr"?"Standart":"Standard"],
    ],
    note: {tr:"â˜… = bu kodda kullanÄ±lan. NLP'de Adam (veya AdamW) baskÄ±n.",en:"â˜… = used in this code. Adam (or AdamW) dominant in NLP."}
  },
  "activation_compare": {
    title: {tr:"Aktivasyon FonksiyonlarÄ±",en:"Activation Functions"},
    headers: ["", "ReLU", "ReLUÂ² â˜…", "GELU", "SwiGLU"],
    rows: [
      ["FormÃ¼l", "max(0,x)", "max(0,x)Â²", "xÂ·Î¦(x)", "gateÂ·xW"],
      ["f(-1)", "0", "0", "-0.16", "-"],
      ["f(0.5)", "0.5", "0.25", "0.35", "-"],
      ["f(2)", "2", "4", "1.95", "-"],
      ["Sparsity", lang==="tr"?"Orta":"Medium", lang==="tr"?"YÃ¼ksek":"High", lang==="tr"?"DÃ¼ÅŸÃ¼k":"Low", lang==="tr"?"Orta":"Medium"],
      [lang==="tr"?"Kullanan":"Used by", lang==="tr"?"Klasik":"Classic", "microGPT", "GPT-2", "LLaMA"],
    ],
    note: {tr:"â˜… = bu kodda. ReLUÂ² kÃ¼Ã§Ã¼kleri kÃ¼Ã§Ã¼ltÃ¼r, bÃ¼yÃ¼kleri bÃ¼yÃ¼tÃ¼r â†’ seÃ§ici.",en:"â˜… = in this code. ReLUÂ² shrinks small values, amplifies large ones â†’ selective."}
  }
};

// â”€â”€â”€ RESOURCES (KAYNAKLAR) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const RESOURCES = {
  0: [
    { title: "Karpathy â€” microGPT Gist", url: "https://gist.github.com/karpathy/8627fe009c40f57531cb18360106ce95", type: "kod" },
    { title: "Karpathy â€” Let's build GPT from scratch", url: "https://www.youtube.com/watch?v=kCc8FmEb1nY", type: "video" },
    { title: "Karpathy â€” makemore serisi", url: "https://www.youtube.com/playlist?list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ", type: "video" },
  ],
  1: [
    { title: "3Blue1Brown â€” Word Embeddings", url: "https://www.youtube.com/watch?v=wjZofJX0v4M", type: "video" },
    { title: "Jay Alammar â€” The Illustrated Word2Vec", url: "https://jalammar.github.io/illustrated-word2vec/", type: "blog" },
    { title: "HuggingFace â€” Tokenizer Docs", url: "https://huggingface.co/docs/tokenizers", type: "docs" },
  ],
  2: [
    { title: "Karpathy â€” micrograd (autograd sÄ±fÄ±rdan)", url: "https://github.com/karpathy/micrograd", type: "kod" },
    { title: "3Blue1Brown â€” Backpropagation", url: "https://www.youtube.com/watch?v=Ilg3gGewQ5U", type: "video" },
    { title: "Calculus on Computational Graphs", url: "https://colah.github.io/posts/2015-08-Backprop/", type: "blog" },
  ],
  3: [
    { title: "Jay Alammar â€” The Illustrated Transformer", url: "https://jalammar.github.io/illustrated-transformer/", type: "blog" },
    { title: "3Blue1Brown â€” Attention in Transformers", url: "https://www.youtube.com/watch?v=eMlx5fFNoYc", type: "video" },
    { title: "Attention Is All You Need (orijinal paper)", url: "https://arxiv.org/abs/1706.03762", type: "paper" },
  ],
  4: [
    { title: "RMSNorm Paper", url: "https://arxiv.org/abs/1910.07467", type: "paper" },
    { title: "Deep Residual Learning (ResNet paper)", url: "https://arxiv.org/abs/1512.03385", type: "paper" },
  ],
  5: [
    { title: "Karpathy â€” A Recipe for Training NNs", url: "https://karpathy.github.io/2019/04/25/recipe/", type: "blog" },
    { title: "Adam Paper", url: "https://arxiv.org/abs/1412.6980", type: "paper" },
  ],
  6: [
    { title: "HuggingFace â€” Text Generation Strategies", url: "https://huggingface.co/blog/how-to-generate", type: "blog" },
    { title: "The Illustrated GPT-2", url: "https://jalammar.github.io/illustrated-gpt2/", type: "blog" },
  ]
};

// â”€â”€â”€ NEW UI COMPONENTS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

const QuizWidget = ({ questions, weekColor }) => {
  const [current, setCurrent] = useState(0);
  const [selected, setSelected] = useState(-1);
  const [showResult, setShowResult] = useState(false);
  const [score, setScore] = useState(0);
  const [finished, setFinished] = useState(false);
  const q = questions[current];

  const handleSelect = (idx) => {
    if (showResult) return;
    setSelected(idx);
    setShowResult(true);
    if (idx === q.ans) setScore(s => s + 1);
  };
  const handleNext = () => {
    if (current < questions.length - 1) {
      setCurrent(c => c + 1);
      setSelected(-1);
      setShowResult(false);
    } else {
      setFinished(true);
    }
  };
  const handleReset = () => { setCurrent(0); setSelected(-1); setShowResult(false); setScore(0); setFinished(false); };

  if (finished) return (
    <div style={{ margin: "18px 0", padding: 24, borderRadius: 16, background: "rgba(16,185,129,0.06)", border: "1px solid rgba(16,185,129,0.2)", textAlign: "center" }}>
      <div style={{ fontSize: 38, marginBottom: 8 }}>ğŸ‰</div>
      <div style={{ fontSize: 21, fontWeight: 800, color: "#10B981", marginBottom: 4 }}>{score}/{questions.length} DoÄŸru!</div>
      <div style={{ fontSize: 16, color: "#94A3B8", marginBottom: 12 }}>
        {score === questions.length ? "MÃ¼kemmel! Tam puan!" : score >= questions.length * 0.7 ? "Harika! Ä°yi anlamÄ±ÅŸsÄ±n." : "Tekrar gÃ¶zden geÃ§irmeni Ã¶neririm."}
      </div>
      <button onClick={handleReset} style={{ padding: "8px 20px", borderRadius: 10, border: "none", background: weekColor, color: "#fff", fontSize: 15, fontWeight: 700, cursor: "pointer", fontFamily: "inherit" }}>Tekrar Dene</button>
    </div>
  );

  return (
    <div style={{ margin: "18px 0", padding: 20, borderRadius: 16, background: "rgba(99,102,241,0.04)", border: "1px solid rgba(99,102,241,0.15)" }}>
      <div style={{ display: "flex", justifyContent: "space-between", alignItems: "center", marginBottom: 12 }}>
        <div style={{ display: "flex", alignItems: "center", gap: 8 }}>
          <span style={{ fontSize: 19 }}>ğŸ§ª</span>
          <span style={{ fontSize: 15, fontWeight: 700, color: "#6366F1", textTransform: "uppercase", letterSpacing: ".06em" }}>Mini Quiz</span>
        </div>
        <span style={{ fontSize: 13, color: "#64748B" }}>{current + 1}/{questions.length} â€¢ Skor: {score}</span>
      </div>
      <div style={{ fontSize: 17, fontWeight: 600, color: "#E2E8F0", marginBottom: 14, lineHeight: 1.6 }}>{q.q}</div>
      <div style={{ display: "flex", flexDirection: "column", gap: 6, marginBottom: 12 }}>
        {q.opts.map((opt, i) => {
          const isCorrect = i === q.ans;
          const isSelected = i === selected;
          let bg = "rgba(255,255,255,0.03)";
          let border = "1px solid rgba(255,255,255,0.06)";
          let color = "#CBD5E1";
          if (showResult && isCorrect) { bg = "rgba(16,185,129,0.15)"; border = "1px solid rgba(16,185,129,0.4)"; color = "#10B981"; }
          if (showResult && isSelected && !isCorrect) { bg = "rgba(239,68,68,0.1)"; border = "1px solid rgba(239,68,68,0.3)"; color = "#EF4444"; }
          return (
            <button key={i} onClick={() => handleSelect(i)} style={{
              padding: "10px 14px", borderRadius: 10, border, background: bg, color, fontSize: 15,
              textAlign: "left", cursor: showResult ? "default" : "pointer", fontFamily: "inherit", transition: "all .2s",
              display: "flex", alignItems: "center", gap: 10
            }}>
              <div style={{ width: 22, height: 22, borderRadius: 6, background: showResult && isCorrect ? "#10B981" : showResult && isSelected ? "#EF4444" : "rgba(255,255,255,0.06)", display: "flex", alignItems: "center", justifyContent: "center", fontSize: 13, fontWeight: 700, color: showResult ? "#fff" : "#64748B", flexShrink: 0 }}>
                {showResult && isCorrect ? "âœ“" : showResult && isSelected ? "âœ—" : String.fromCharCode(65 + i)}
              </div>
              {opt}
            </button>
          );
        })}
      </div>
      {showResult && (
        <div style={{ padding: "10px 14px", borderRadius: 10, background: selected === q.ans ? "rgba(16,185,129,0.08)" : "rgba(239,68,68,0.06)", marginBottom: 10 }}>
          <div style={{ fontSize: 14, fontWeight: 600, color: selected === q.ans ? "#10B981" : "#EF4444", marginBottom: 4 }}>{selected === q.ans ? "âœ“ DoÄŸru!" : "âœ— YanlÄ±ÅŸ"}</div>
          <div style={{ fontSize: 14, color: "#94A3B8", lineHeight: 1.5 }}>{q.explain}</div>
        </div>
      )}
      {showResult && (
        <button onClick={handleNext} style={{ padding: "8px 20px", borderRadius: 10, border: "none", background: weekColor, color: "#fff", fontSize: 15, fontWeight: 700, cursor: "pointer", fontFamily: "inherit" }}>
          {current < questions.length - 1 ? (lang === "tr" ? "Sonraki Soru â†’" : "Next Question â†’") : (lang === "tr" ? "SonuÃ§larÄ± GÃ¶r" : "See Results")}
        </button>
      )}
    </div>
  );
};

const MistakesList = ({ mistakes, weekColor }) => (
  <div style={{ margin: "18px 0", padding: 18, borderRadius: 14, background: "rgba(239,68,68,0.04)", border: "1px solid rgba(239,68,68,0.12)" }}>
    <div style={{ display: "flex", alignItems: "center", gap: 8, marginBottom: 12 }}>
      <span style={{ fontSize: 19 }}>âš ï¸</span>
      <span style={{ fontSize: 15, fontWeight: 700, color: "#EF4444", textTransform: "uppercase", letterSpacing: ".06em" }}>YaygÄ±n YanlÄ±ÅŸlar</span>
    </div>
    <div style={{ display: "flex", flexDirection: "column", gap: 8 }}>
      {mistakes.map((m, i) => (
        <div key={i} style={{ padding: "10px 14px", borderRadius: 10, background: "rgba(0,0,0,0.15)" }}>
          <div style={{ fontSize: 15, color: "#EF4444", fontWeight: 600, marginBottom: 4, textDecoration: "line-through", textDecorationColor: "rgba(239,68,68,0.4)" }}>{m.mistake}</div>
          <div style={{ fontSize: 15, color: "#10B981", lineHeight: 1.5 }}>âœ“ {m.truth}</div>
        </div>
      ))}
    </div>
  </div>
);

const ComparisonTableWidget = ({ data }) => (
  <div style={{ margin: "14px 0", padding: 16, borderRadius: 14, background: "rgba(14,165,233,0.04)", border: "1px solid rgba(14,165,233,0.12)", overflowX: "auto" }}>
    <div style={{ fontSize: 15, fontWeight: 700, color: "#0EA5E9", marginBottom: 10 }}>ğŸ“Š {tx(data.title, lang)}</div>
    <table style={{ width: "100%", borderCollapse: "collapse", fontSize: 14 }}>
      <thead>
        <tr>{data.headers.map((h, i) => (
          <th key={i} style={{ padding: "6px 10px", textAlign: i === 0 ? "left" : "center", color: "#94A3B8", fontWeight: 600, borderBottom: "1px solid rgba(255,255,255,0.06)", fontSize: 13, whiteSpace: "nowrap" }}>{h}</th>
        ))}</tr>
      </thead>
      <tbody>
        {data.rows.map((row, r) => (
          <tr key={r}>
            {row.map((cell, c) => (
              <td key={c} style={{ padding: "6px 10px", textAlign: c === 0 ? "left" : "center", color: c === 0 ? "#94A3B8" : "#E2E8F0", fontFamily: c > 0 ? "'Fira Code', monospace" : "inherit", borderBottom: "1px solid rgba(255,255,255,0.03)", fontWeight: c === 0 ? 600 : 400, fontSize: 13 }}>{cell}</td>
            ))}
          </tr>
        ))}
      </tbody>
    </table>
    {data.note && <div style={{ marginTop: 8, fontSize: 13, color: "#64748B", fontStyle: "italic" }}>{tx(data.note, lang)}</div>}
  </div>
);

const ResourceLinks = ({ resources }) => {
  const typeIcons = { video: "ğŸ¬", blog: "ğŸ“", kod: "ğŸ’»", docs: "ğŸ“–", paper: "ğŸ“„" };
  const typeColors = { video: "#EF4444", blog: "#0EA5E9", kod: "#10B981", docs: "#8B5CF6", paper: "#F59E0B" };
  return (
    <div style={{ margin: "14px 0", padding: 16, borderRadius: 14, background: "rgba(139,92,246,0.04)", border: "1px solid rgba(139,92,246,0.12)" }}>
      <div style={{ display: "flex", alignItems: "center", gap: 8, marginBottom: 10 }}>
        <span style={{ fontSize: 17 }}>ğŸ”—</span>
        <span style={{ fontSize: 14, fontWeight: 700, color: "#8B5CF6", textTransform: "uppercase", letterSpacing: ".06em" }}>Daha Fazla Ã–ÄŸren</span>
      </div>
      <div style={{ display: "flex", flexDirection: "column", gap: 6 }}>
        {resources.map((r, i) => (
          <a key={i} href={r.url} target="_blank" rel="noopener noreferrer" style={{ display: "flex", alignItems: "center", gap: 10, padding: "8px 12px", borderRadius: 8, background: "rgba(0,0,0,0.15)", textDecoration: "none", transition: "all .2s" }}
            onMouseEnter={e => e.currentTarget.style.background = "rgba(0,0,0,0.25)"}
            onMouseLeave={e => e.currentTarget.style.background = "rgba(0,0,0,0.15)"}>
            <span style={{ fontSize: 17 }}>{typeIcons[r.type]}</span>
            <span style={{ fontSize: 14, color: "#E2E8F0", fontWeight: 500, flex: 1 }}>{r.title}</span>
            <span style={{ fontSize: 12, padding: "2px 8px", borderRadius: 4, background: `${typeColors[r.type]}15`, color: typeColors[r.type], fontWeight: 600, textTransform: "uppercase" }}>{r.type}</span>
          </a>
        ))}
      </div>
    </div>
  );
};

const GlossaryPanel = ({ searchTerm, setSearchTerm, onClose }) => {
  const filtered = GLOSSARY.filter(g =>
    g.term.toLowerCase().includes(searchTerm.toLowerCase()) ||
    tx(g.def, lang).toLowerCase().includes(searchTerm.toLowerCase())
  );
  const catColors = { temel: "#F59E0B", mimari: "#10B981", eÄŸitim: "#EF4444", model: "#0EA5E9", veri: "#8B5CF6" };
  return (
    <div style={{ position: "fixed", top: 0, right: 0, width: 380, height: "100vh", background: "#0D1117", borderLeft: "1px solid rgba(255,255,255,0.08)", zIndex: 100, display: "flex", flexDirection: "column", boxShadow: "-8px 0 32px rgba(0,0,0,0.4)" }}>
      <div style={{ padding: "16px 20px", borderBottom: "1px solid rgba(255,255,255,0.06)", display: "flex", alignItems: "center", justifyContent: "space-between" }}>
        <div style={{ display: "flex", alignItems: "center", gap: 8 }}>
          <span style={{ fontSize: 21 }}>ğŸ“–</span>
          <span style={{ fontSize: 17, fontWeight: 700, color: "#E2E8F0" }}>{lang==="tr"?"Kavram SÃ¶zlÃ¼ÄŸÃ¼":"Concept Glossary"}</span>
          <span style={{ fontSize: 13, color: "#64748B" }}>{lang==="tr"?`(${GLOSSARY.length} terim)`:`(${GLOSSARY.length} terms)`}</span>
        </div>
        <button onClick={onClose} style={{ width: 28, height: 28, borderRadius: 8, border: "none", background: "rgba(255,255,255,0.06)", color: "#94A3B8", fontSize: 17, cursor: "pointer", display: "flex", alignItems: "center", justifyContent: "center" }}>âœ•</button>
      </div>
      <div style={{ padding: "10px 20px" }}>
        <input
          type="text" value={searchTerm} onChange={e => setSearchTerm(e.target.value)}
          placeholder=lang === "tr" ? "Kavram ara... (Ã¶r: embedding, gradient)" : "Search concepts... (e.g. embedding, gradient)"
          style={{ width: "100%", padding: "8px 12px", borderRadius: 8, border: "1px solid rgba(255,255,255,0.1)", background: "rgba(255,255,255,0.03)", color: "#E2E8F0", fontSize: 15, outline: "none", fontFamily: "inherit" }}
        />
      </div>
      <div style={{ flex: 1, overflowY: "auto", padding: "0 20px 20px" }}>
        {filtered.length === 0 && <div style={{ textAlign: "center", color: "#475569", fontSize: 15, marginTop: 30 }}>{lang==="tr"?"SonuÃ§ bulunamadÄ±.":"No results found."}</div>}
        {filtered.map((g, i) => (
          <div key={i} style={{ padding: "12px 14px", borderRadius: 10, background: "rgba(255,255,255,0.02)", border: "1px solid rgba(255,255,255,0.04)", marginBottom: 6 }}>
            <div style={{ display: "flex", alignItems: "center", gap: 8, marginBottom: 4 }}>
              <span style={{ fontSize: 16, fontWeight: 700, color: "#E2E8F0" }}>{g.term}</span>
              <span style={{ fontSize: 11, padding: "2px 6px", borderRadius: 4, background: `${catColors[g.cat]}15`, color: catColors[g.cat], fontWeight: 600, textTransform: "uppercase" }}>{g.cat}</span>
              <span style={{ fontSize: 11, color: "#475569" }}>{lang==="tr"?"Hafta":"Week"} {g.week}</span>
            </div>
            <div style={{ fontSize: 14, color: "#94A3B8", lineHeight: 1.5 }}>{tx(g.def, lang)}</div>
          </div>
        ))}
      </div>
    </div>
  );
};

const ProgressSidebar = ({ weekIdx, completedSections }) => {
  return WEEKS.map((w, wi) => {
    const total = w.sections.length;
    const done = (completedSections[wi] || []).length;
    const pct = total > 0 ? (done / total) * 100 : 0;
    return (
      <div key={wi} style={{ height: 3, background: "rgba(255,255,255,0.04)", borderRadius: 2, marginTop: 4, overflow: "hidden" }}>
        <div style={{ height: "100%", width: `${pct}%`, background: w.color, borderRadius: 2, transition: "width .5s" }} />
      </div>
    );
  });
};

// â”€â”€â”€ NEW ANIMATED VIZ COMPONENTS FOR WEEK 0 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

const TrainingEvolutionViz = () => {
  const [epoch, setEpoch] = useState(0);
  const [playing, setPlaying] = useState(false);
  const stages = [
    { step: 1, loss: 3.33, names: ["xqwpzml","jivrty","bnkcfe"], label: lang === "tr" ? "Rastgele BaÅŸlangÄ±Ã§" : "Random Start", color: "#EF4444",
      learned: "HiÃ§bir ÅŸey â€” tÃ¼m aÄŸÄ±rlÄ±klar rastgele. 27 tokendan uniform Ã¶rnekleme: P(her token) â‰ˆ 1/27 = 3.7%",
      insight: "BaÅŸlangÄ±Ã§ loss = -log(1/27) = 3.33 â†’ model tamamen ÅŸaÅŸkÄ±n, her token eÅŸit olasÄ±" },
    { step: 10, loss: 3.10, names: ["llmyi","aeonnt","ukssde"], label: lang === "tr" ? "Harf FrekanslarÄ±" : "Letter Frequencies", color: "#EF4444",
      learned: "SÄ±k harfler keÅŸfedildi: 'a', 'e', 'i' daha olasÄ± hale geldi. Nadir harfler ('q','x','z') azaldÄ±.",
      insight: "Model henÃ¼z sÄ±ra bilmiyor ama Ä°ngilizce'de hangi harfler yaygÄ±n bilmeye baÅŸladÄ±" },
    { step: 50, loss: 2.80, names: ["torena","gnaria","melon"], label: lang === "tr" ? "Sesli-ÃœnsÃ¼z KalÄ±bÄ±" : "Vowel-Consonant Pattern", color: "#F59E0B",
      learned: "ÃœnsÃ¼z+sesli alternasyonu Ã¶ÄŸrenildi: 'to-re-na'. Ã‡ift Ã¼nsÃ¼z ('gn') hÃ¢lÃ¢ sorunlu.",
      insight: "Dikkat mekanizmasÄ± Ã§alÄ±ÅŸmaya baÅŸladÄ± â€” bir Ã¶nceki harfe bakarak sonraki tÃ¼rÃ¼ tahmin ediyor" },
    { step: 100, loss: 2.50, names: ["toman","sariel","jenna"], label: lang === "tr" ? "Ä°sim YapÄ±sÄ±" : "Name Structure", color: "#F59E0B",
      learned: "Ä°sim uzunluklarÄ± doÄŸallaÅŸtÄ± (4-6 harf). '-el', '-an', '-na' gibi yaygÄ±n sonekler Ã¶ÄŸrenildi.",
      insight: "EOS tahmini iyileÅŸti â€” model ne zaman durmasÄ± gerektiÄŸini biliyor" },
    { step: 200, loss: 2.30, names: ["marin","della","kiran"], label: lang === "tr" ? "GerÃ§ekÃ§i Ä°simler" : "Realistic Names", color: "#10B981",
      learned: "'della', 'kiran' gerÃ§ek isimlere Ã§ok benzer. Ã‡ift harf kalÄ±plarÄ± ('ll','nn') doÄŸru kullanÄ±lÄ±yor.",
      insight: "Model Ä°ngilizce isim fonotaktiÄŸini Ã¶ÄŸrendi â€” hangi harf kombinasyonlarÄ± 'isim gibi' hissettiriyor" },
    { step: 500, loss: 2.10, names: ["kamrin","jede","quila"], label: lang === "tr" ? "YaratÄ±cÄ± Ãœretim" : "Creative Generation", color: "#10B981",
      learned: "Veride olmayan AMA yapÄ±ya uyan isimler: 'kamrin', 'quila'. Model genelleme yapÄ±yor!",
      insight: "Overfitting yok â€” model ezberlemiyor, KURAL Ã¶ÄŸreniyor. Bu generalization'Ä±n Ã¶zÃ¼" },
    { step: 1000, loss: 2.00, names: ["ellora","bryn","asha"], label: "Tam Model", color: "#0EA5E9",
      learned: "'asha' (SanskritÃ§e), 'bryn' (Galce), 'ellora' (Ä°talyan) â€” farklÄ± kÃ¼ltÃ¼rel kalÄ±plar bile Ã¶ÄŸrenildi.",
      insight: "3,648 parametre ile bu kadar zengin kalÄ±p Ã¶ÄŸrenmek â†’ Ã¶lÃ§eklemenin gÃ¼cÃ¼nÃ¼ hayal edin (175B parametre!)" },
  ];
  const s = stages[epoch];
  useEffect(() => {
    if (!playing) return;
    const t = setInterval(() => setEpoch(e => { if (e >= stages.length - 1) { setPlaying(false); return e; } return e + 1; }), 2000);
    return () => clearInterval(t);
  }, [playing]);
  return (<VizBox title={lang === "tr" ? "EÄŸitim Evrimi â€” Model NasÄ±l Ã–ÄŸreniyor?" : "Training Evolution â€” How Does the Model Learn?"} color="#10B981">
    <div style={{fontSize:13,color:"#94A3B8",marginBottom:8}}>{lang === "tr" ? "â–¶ butonuna basÄ±n ve modelin adÄ±m adÄ±m Ã¶ÄŸrenme sÃ¼recini izleyin. KaydÄ±rÄ±cÄ±yla istediÄŸiniz aÅŸamaya atlayÄ±n." : "Press â–¶ and watch the model learn step by step. Use the slider to jump to any stage."}</div>
    <div style={{display:"flex",gap:16,flexWrap:"wrap"}}>
      <div style={{flex:1,minWidth:220}}>
        <div style={{fontSize:13,color:"#94A3B8",marginBottom:6}}>{lang === "tr" ? "Loss EÄŸrisi" : "Loss Curve"}</div>
        <svg viewBox="0 0 200 80" style={{width:"100%",height:100}}>
          <line x1="20" y1="5" x2="20" y2="70" stroke="#1E293B" strokeWidth="0.5"/>
          <line x1="20" y1="70" x2="195" y2="70" stroke="#1E293B" strokeWidth="0.5"/>
          <text x="5" y="12" fill="#64748B" fontSize="5">3.3</text>
          <text x="5" y="70" fill="#64748B" fontSize="5">2.0</text>
          {stages.map((st, i) => {
            const x = 20 + (i / (stages.length - 1)) * 170;
            const y = ((3.33 - st.loss) / 1.33) * 60;
            return (<g key={i}>
              {i > 0 && <line x1={20+((i-1)/(stages.length-1))*170} y1={70-((3.33-stages[i-1].loss)/1.33)*60} x2={x} y2={70-y} stroke={i<=epoch?st.color:"#1E293B30"} strokeWidth={i<=epoch?1.5:0.5} style={{transition:"all .5s"}}/>}
              <circle cx={x} cy={70-y} r={i===epoch?4:2.5} fill={i<=epoch?st.color:"#1E293B"} stroke={st.color} strokeWidth={i===epoch?1.5:0.5} style={{transition:"all .5s"}}/>
            </g>);
          })}
        </svg>
      </div>
      <div style={{flex:1,minWidth:240}}>
        <div style={{padding:14,borderRadius:12,background:`${s.color}10`,border:`1.5px solid ${s.color}30`,transition:"all .4s"}}>
          <div style={{display:"flex",justifyContent:"space-between",alignItems:"center",marginBottom:6}}>
            <span style={{fontSize:13,color:"#64748B"}}>AdÄ±m {s.step}</span>
            <span style={{fontSize:23,fontWeight:800,color:s.color,fontFamily:"'Fira Code',monospace"}}>{s.loss.toFixed(2)}</span>
          </div>
          <div style={{fontSize:14,fontWeight:700,color:s.color,marginBottom:8}}>{s.label}</div>
          <div style={{display:"flex",gap:6,justifyContent:"center",marginBottom:10}}>
            {s.names.map((n,i) => (<div key={i} style={{padding:"4px 10px",borderRadius:6,background:"rgba(0,0,0,0.2)",fontSize:16,fontFamily:"'Fira Code',monospace",fontWeight:700,color:"#E2E8F0"}}>{n}</div>))}
          </div>
          <div style={{padding:"8px 10px",borderRadius:8,background:"rgba(139,92,246,.06)",marginBottom:6}}>
            <div style={{fontSize:11,color:"#A78BFA",fontWeight:700,marginBottom:2}}>{lang === "tr" ? "NE Ã–ÄRENDÄ°?" : "WHAT DID IT LEARN?"}</div>
            <div style={{fontSize:13,color:"#C4B5FD",lineHeight:1.5}}>{s.learned}</div>
          </div>
          <div style={{padding:"6px 10px",borderRadius:8,background:"rgba(251,191,36,.05)",borderLeft:"3px solid rgba(251,191,36,.3)"}}>
            <div style={{fontSize:12,color:"#FBBF24",lineHeight:1.5}}>{s.insight}</div>
          </div>
        </div>
        <div style={{display:"flex",gap:6,marginTop:8,justifyContent:"center",alignItems:"center"}}>
          <button onClick={()=>{setEpoch(0);setPlaying(true);}} style={{padding:"6px 16px",borderRadius:8,border:"none",background:"#10B981",color:"#fff",fontSize:14,fontWeight:700,cursor:"pointer",fontFamily:"inherit"}}>{lang === "tr" ? "â–¶ BaÅŸlat" : "â–¶ Start"}</button>
          <button onClick={()=>setPlaying(false)} style={{padding:"6px 12px",borderRadius:8,border:"1px solid rgba(255,255,255,.1)",background:"transparent",color:"#94A3B8",fontSize:14,cursor:"pointer",fontFamily:"inherit"}}>â¸</button>
          <input type="range" min={0} max={stages.length-1} value={epoch} onChange={e=>{setPlaying(false);setEpoch(+e.target.value);}} style={{flex:1,accentColor:"#10B981"}}/>
        </div>
      </div>
    </div>
  </VizBox>);
};

const GPTScaleTowerViz = () => {
  const [hov, setHov] = useState(0);
  const models = [
    {name:"microGPT",params:3648,layers:1,embd:16,ctx:8,year:"2024",color:"#0EA5E9",h:8,
     can:"TÃ¼rk ismi Ã¼retebilir (5-6 harf). Fonotaktik kalÄ±plarÄ± Ã¶ÄŸrenir.",
     cant:"CÃ¼mle kuramaz. Anlam bilmez. Sadece harf kalÄ±plarÄ±."},
    {name:"GPT-1",params:117e6,layers:12,embd:768,ctx:512,year:"2018",color:"#8B5CF6",h:30,
     can:"Basit cÃ¼mleler kurabilir. Metin sÄ±nÄ±flandÄ±rma yapabilir.",
     cant:"Uzun mantÄ±k zincirleri kuramaz. SÄ±kÃ§a Ã§eliÅŸir."},
    {name:"GPT-2",params:1.5e9,layers:48,embd:1600,ctx:1024,year:"2019",color:"#10B981",h:50,
     can:"TutarlÄ± paragraflar yazabilir. Basit soru-cevap yapabilir.",
     cant:"Matematiksel akÄ±l yÃ¼rÃ¼tme zayÄ±f. HalÃ¼sinasyon yaygÄ±n."},
    {name:"GPT-3",params:175e9,layers:96,embd:12288,ctx:2048,year:"2020",color:"#F59E0B",h:75,
     can:"Few-shot Ã¶ÄŸrenme: birkaÃ§ Ã¶rnekle yeni gÃ¶revler yapabilir. Kod yazabilir.",
     cant:"GÃ¼venilir deÄŸil. GÃ¼ncel bilgi yok. Uzun baÄŸlam sÄ±nÄ±rlÄ±."},
    {name:"GPT-4",params:1e12,layers:120,embd:16384,ctx:131072,year:"2023",color:"#EF4444",h:95,
     can:"TÄ±p sÄ±navÄ±nÄ± geÃ§er. Kod debug eder. 128K baÄŸlam. GÃ¶rÃ¼ntÃ¼ anlayabilir.",
     cant:"Tam gÃ¼venilir deÄŸil. Hesaplama pahalÄ±. EÄŸitim maliyeti ~$100M+."},
  ];
  const fmtP = p => p<1e6?`${(p/1e3).toFixed(1)}K`:p<1e9?`${(p/1e6).toFixed(0)}M`:p<1e12?`${(p/1e9).toFixed(0)}B`:`~${(p/1e12).toFixed(0)}T+`;
  const m = models[hov];
  return (<VizBox title={lang === "tr" ? "GPT Ailesi â€” Ã–lÃ§ek Kulesi" : "GPT Family â€” Scale Tower"} color="#6366F1">
    <div style={{fontSize:13,color:"#94A3B8",marginBottom:10}}>Her sÃ¼tunun Ã¼zerine gelin â€” o modelin yeteneklerini ve sÄ±nÄ±rlarÄ±nÄ± gÃ¶rÃ¼n.</div>
    <div style={{display:"flex",gap:8,alignItems:"flex-end",justifyContent:"center",height:130,marginBottom:10}}>
      {models.map((md,i) => (
        <div key={i} onMouseEnter={()=>setHov(i)} onClick={()=>setHov(i)} style={{display:"flex",flexDirection:"column",alignItems:"center",gap:4,cursor:"pointer",transform:hov===i?"scale(1.08)":"scale(1)",transition:"all .3s"}}>
          <div style={{fontSize:12,fontWeight:700,color:md.color,textAlign:"center"}}>{md.name}</div>
          <div style={{width:40+i*12,height:md.h+(hov===i?8:0),borderRadius:"8px 8px 0 0",background:`linear-gradient(180deg,${md.color}40,${md.color}15)`,border:`1.5px solid ${md.color}50`,borderBottom:"none",display:"flex",alignItems:"center",justifyContent:"center",transition:"all .4s"}}>
            <span style={{fontSize:13,fontWeight:800,color:md.color,fontFamily:"'Fira Code',monospace"}}>{fmtP(md.params)}</span>
          </div>
        </div>
      ))}
    </div>
    <div style={{padding:12,borderRadius:12,background:`${m.color}08`,border:`1.5px solid ${m.color}20`,transition:"all .3s"}}>
      <div style={{display:"flex",justifyContent:"space-between",alignItems:"center",marginBottom:8}}>
        <span style={{fontSize:18,fontWeight:800,color:m.color}}>{m.name}</span>
        <span style={{fontSize:13,color:"#64748B"}}>{m.year}</span>
      </div>
      <div style={{display:"grid",gridTemplateColumns:"repeat(3,1fr)",gap:8,marginBottom:10}}>
        {[{l:"Katman",v:m.layers},{l:"Embedding",v:m.embd.toLocaleString()},{l:"Context",v:m.ctx.toLocaleString()}].map((item,i)=>(
          <div key={i} style={{textAlign:"center",padding:"4px 0",borderRadius:6,background:"rgba(0,0,0,.2)"}}>
            <div style={{fontSize:17,fontWeight:800,color:m.color,fontFamily:"'Fira Code',monospace"}}>{item.v}</div>
            <div style={{fontSize:11,color:"#64748B"}}>{item.l}</div>
          </div>
        ))}
      </div>
      <div style={{display:"flex",gap:8,flexWrap:"wrap"}}>
        <div style={{flex:1,minWidth:160,padding:"8px 10px",borderRadius:8,background:"rgba(16,185,129,.06)"}}>
          <div style={{fontSize:11,color:"#10B981",fontWeight:700,marginBottom:2}}>{lang === "tr" ? "âœ… YAPABÄ°LÄ°R" : "âœ… CAN DO"}</div>
          <div style={{fontSize:12,color:"#A7F3D0",lineHeight:1.5}}>{m.can}</div>
        </div>
        <div style={{flex:1,minWidth:160,padding:"8px 10px",borderRadius:8,background:"rgba(239,68,68,.06)"}}>
          <div style={{fontSize:11,color:"#EF4444",fontWeight:700,marginBottom:2}}>âŒ YAPAMAZ</div>
          <div style={{fontSize:12,color:"#FCA5A5",lineHeight:1.5}}>{m.cant}</div>
        </div>
      </div>
    </div>
    <div style={{marginTop:8,padding:"6px 12px",borderRadius:8,background:"rgba(14,165,233,.06)",textAlign:"center"}}><span style={{fontSize:13,color:"#0EA5E9"}}>Algoritma aynÄ± â€” fark sadece Ã¶lÃ§ek. Bu kodu anlarsanÄ±z GPT-4'Ã¼ de anlarsÄ±nÄ±z.</span></div>
  </VizBox>);
};

const FrameworkCompareViz = () => {
  const [showInner, setShowInner] = useState(false);
  const [highlight, setHighlight] = useState(-1);
  const mappings = [
    {fw:"loss = criterion(out, target)",mc:"CE = -log(P(target))",color:"#EF4444",desc:"Cross-entropy kaybÄ± hesapla: model doÄŸru tokene ne kadar olasÄ±lÄ±k verdi?"},
    {fw:"loss.backward()",mc:"topo sort â†’ chain rule â†’ grad +=",color:"#F59E0B",desc:"Hesaplama grafÄ±nÄ± tersten yÃ¼rÃ¼, her parametre iÃ§in gradyan hesapla (3,648 deÄŸer)"},
    {fw:"optimizer.step()",mc:"w -= lr Ã— mÌ‚/(âˆšvÌ‚+Îµ); grad=0",color:"#10B981",desc:"Adam: momentum + adaptif lr ile aÄŸÄ±rlÄ±klarÄ± gÃ¼ncelle, sonra gradyanlarÄ± sÄ±fÄ±rla"},
  ];
  return (<VizBox title={lang === "tr" ? "SÄ±fÄ±rdan vs Framework â€” Ne Gizleniyor?" : "From Scratch vs Framework â€” What\'s Hidden?"} color="#F59E0B">
    <div style={{fontSize:13,color:"#94A3B8",marginBottom:10,lineHeight:1.6}}>
      PyTorch bu 3 satÄ±rÄ±n arkasÄ±nda <strong style={{color:"#F59E0B"}}>yÃ¼zlerce satÄ±r</strong> kod gizler. microGPT'de her satÄ±rÄ± kendiniz yazÄ±yorsunuz â€” bÃ¶ylece gerÃ§ekten anlÄ±yorsunuz.
    </div>
    <div style={{display:"flex",gap:12,flexWrap:"wrap"}}>
      <div style={{flex:1,minWidth:200}}>
        <div style={{fontSize:14,fontWeight:700,color:"#8B5CF6",marginBottom:6}}>ğŸ­ PyTorch (3 satÄ±r)</div>
        <div style={{padding:10,borderRadius:10,background:"#0D1117"}}>
          {mappings.map((m,i)=>(<div key={i} onMouseEnter={()=>setHighlight(i)} onMouseLeave={()=>setHighlight(-1)} style={{padding:"6px 8px",borderRadius:6,marginBottom:2,cursor:"pointer",fontFamily:"'Fira Code',monospace",fontSize:14,lineHeight:1.8,color:m.color,background:highlight===i?`${m.color}15`:"transparent",transition:"background .2s"}}>{m.fw}</div>))}
        </div>
      </div>
      <div style={{flex:1,minWidth:200}}>
        <div style={{fontSize:14,fontWeight:700,color:"#10B981",marginBottom:6}}>ğŸ”¬ microGPT (aÃ§Ä±k kod)</div>
        <div style={{padding:10,borderRadius:10,background:"#0D1117"}}>
          {mappings.map((m,i)=>(<div key={i} onMouseEnter={()=>setHighlight(i)} onMouseLeave={()=>setHighlight(-1)} style={{padding:"6px 8px",borderRadius:6,marginBottom:2,cursor:"pointer",fontFamily:"'Fira Code',monospace",fontSize:13,lineHeight:1.8,color:"#E2E8F0",background:highlight===i?`${m.color}15`:"transparent",transition:"background .2s"}}>{m.mc}</div>))}
        </div>
      </div>
    </div>
    {highlight >= 0 && (
      <div style={{marginTop:8,padding:"8px 14px",borderRadius:10,background:`${mappings[highlight].color}08`,border:`1.5px solid ${mappings[highlight].color}25`,transition:"all .3s"}}>
        <div style={{fontSize:13,color:mappings[highlight].color,lineHeight:1.6}}><strong>{mappings[highlight].fw}</strong> â†’ {mappings[highlight].desc}</div>
      </div>
    )}
    <button onClick={()=>setShowInner(!showInner)} style={{marginTop:8,padding:"6px 14px",borderRadius:8,border:"1px solid rgba(245,158,11,.3)",background:"rgba(245,158,11,.06)",color:"#F59E0B",fontSize:13,fontWeight:600,cursor:"pointer",fontFamily:"inherit",width:"100%"}}>
      {showInner?lang === "tr" ? "â–² DetaylarÄ± gizle" : "â–² Hide details":lang === "tr" ? "â–¼ loss.backward() arkasÄ±nda ne var? (tÄ±kla)" : "â–¼ What is behind loss.backward()? (click)"}
    </button>
    {showInner && (
      <div style={{marginTop:6,padding:10,borderRadius:8,background:"rgba(239,68,68,.04)",border:"1px solid rgba(239,68,68,.1)",fontSize:12,color:"#94A3B8",lineHeight:1.6}}>
        <div style={{color:"#EF4444",fontWeight:700,marginBottom:4}}>loss.backward() â€” 5 adÄ±m:</div>
        <div style={{paddingLeft:12}}>â‘  Hesaplama grafÄ±nÄ± topolojik sÄ±rala<br/>â‘¡ Son dÃ¼ÄŸÃ¼mden baÅŸla (loss.grad = 1)<br/>â‘¢ Her dÃ¼ÄŸÃ¼mde lokal tÃ¼rev Ã— yukarÄ±dan gelen grad (chain rule)<br/>â‘£ Birden fazla yol varsa: grad += (topla, Ã¼zerine yazma!)<br/>â‘¤ TÃ¼m yapraklar (parametreler) artÄ±k gradyanlarÄ±na sahip</div><br/>
        <div style={{color:"#10B981",fontWeight:700,marginBottom:4}}>optimizer.step() â€” Adam (6 adÄ±m):</div>
        <div style={{paddingLeft:12}}>â‘  m = Î²â‚Ã—m + (1-Î²â‚)Ã—grad (momentum gÃ¼ncelle)<br/>â‘¡ v = Î²â‚‚Ã—v + (1-Î²â‚‚)Ã—gradÂ² (variance gÃ¼ncelle)<br/>â‘¢ mÌ‚ = m/(1-Î²â‚áµ—) (bias correction)<br/>â‘£ vÌ‚ = v/(1-Î²â‚‚áµ—) (bias correction)<br/>â‘¤ w -= lr Ã— mÌ‚/(âˆšvÌ‚ + Îµ) (parametre gÃ¼ncelle)<br/>â‘¥ grad = 0 (sÄ±fÄ±rla â€” bir sonraki adÄ±m iÃ§in)</div>
      </div>
    )}
  </VizBox>);
};

const LivePipelineViz = () => {
  const [stage, setStage] = useState(0);
  const [auto, setAuto] = useState(false);
  const pipe = [
    {icon:"ğŸ“„",label:"emma",sub:lang==="tr"?"DokÃ¼man":"Document",color:"#0EA5E9",
     detail:lang==="tr"?"EÄŸitim verisinden bir isim seÃ§ildi":"A name was selected from training data",
     dataIn:"input.txt satÄ±r 42",dataOut:'"emma"',
     explain:lang==="tr"?"32K isimden oluÅŸan dosyadan bir satÄ±r okunur. Her isim bir eÄŸitim Ã¶rneÄŸidir.":"A line is read from a file of 32K names. Each name is a training example."},
    {icon:"ğŸ”¤",label:"[26,4,12,12,0,26]",sub:"Tokenize",color:"#8B5CF6",
     detail:lang==="tr"?"Her karakter bir sayÄ±ya dÃ¶nÃ¼ÅŸÃ¼r":"Each character becomes a number",
     dataIn:'"emma"',dataOut:"[BOS=26, e=4, m=12, m=12, a=0, EOS=26]",
     explain:lang==="tr"?"Karakter tablosundan bakÄ±lÄ±r: aâ†’0, bâ†’1, ..., zâ†’25, BOS/EOSâ†’26. BaÅŸa ve sona BOS eklenir.":"Looked up from character table: aâ†’0, bâ†’1, ..., zâ†’25, BOS/EOSâ†’26. BOS added to start and end."},
    {icon:"ğŸ“Š",label:"[0.02, -0.1, 0.3, ...]",sub:"Embedding",color:"#0EA5E9",
     detail:lang==="tr"?"Her ID bir 16 boyutlu vektÃ¶re dÃ¶nÃ¼ÅŸÃ¼r":"Each ID becomes a 16-dimensional vector",
     dataIn:"token_id = 4 (e), pozisyon = 1",dataOut:"x = wte[4] + wpe[1] = 16 boyutlu vektÃ¶r",
     explain:lang==="tr"?"Embedding tablosu: [27Ã—16] matristen 4. satÄ±r seÃ§ilir. Pozisyon tablosu: [8Ã—16]'dan 1. satÄ±r eklenir. Toplam = tokenin kimliÄŸi + konumu.":"Embedding table: row 4 selected from [27Ã—16] matrix. Position table: row 1 from [8Ã—16] added. Total = token identity + position."},
    {icon:"ğŸ”",label:"QÂ·Káµ€/âˆš4 â†’ softmax â†’ V",sub:"Attention",color:"#10B981",
     detail:lang==="tr"?"Her token diÄŸer tokenlara 'sorar': bana ne bilgi verebilirsin?":"Each token 'asks' other tokens: what info can you give me?",
     dataIn:"xâ‚, xâ‚‚, ..., xâ‚† (her biri 16d)",dataOut:"4 head Ã— dikkat aÄŸÄ±rlÄ±klarÄ± â†’ zenginleÅŸtirilmiÅŸ vektÃ¶rler",
     explain:lang==="tr"?"Her token Q (sorgu), K (anahtar), V (deÄŸer) rollerini alÄ±r. QÂ·K benzerlik skoru verir. YÃ¼ksek benzerlik = daha fazla dikkat. V'lerin aÄŸÄ±rlÄ±klÄ± toplamÄ± Ã§Ä±ktÄ± olur.":"Each token takes Q (query), K (key), V (value) roles. QÂ·K gives similarity score. High similarity = more attention. Weighted sum of V's becomes output."},
    {icon:"ğŸ§®",label:"16 â†’ 64 â†’ 16",sub:"MLP",color:"#EC4899",
     detail:lang==="tr"?"Her token baÄŸÄ±msÄ±z olarak geniÅŸlet â†’ aktive et â†’ daralt":"Each token independently: expand â†’ activate â†’ compress",
     dataIn:"attention Ã§Ä±ktÄ±sÄ± [16d]",dataOut:"fc1: 16â†’64, ReLUÂ², fc2: 64â†’16 â†’ [16d]",
     explain:lang==="tr"?"Attention bilgiyi toplar, MLP bu bilgiyi iÅŸler. GeniÅŸletme (64d) daha zengin temsil saÄŸlar. ReLUÂ² aktivasyonu doÄŸrusal olmayanlÄ±k ekler.":"Attention gathers info, MLP processes it. Expansion (64d) enables richer representation. ReLUÂ² activation adds non-linearity."},
    {icon:"ğŸ“ˆ",label:"P(a)=0.30, P(e)=0.12, ...",sub:"Softmax",color:"#F59E0B",
     detail:lang==="tr"?"28 token Ã¼zerinde olasÄ±lÄ±k daÄŸÄ±lÄ±mÄ±":"Probability distribution over 28 tokens",
     dataIn:"logits = lm_head(x) â†’ [28 skor]",dataOut:"softmax â†’ P(a)=0.30, P(m)=0.12, P(e)=0.08, ...",
     explain:lang==="tr"?"Son vektÃ¶r [16d] Ã§Ã¶zme matrisiyle [16Ã—28] Ã§arpÄ±lÄ±r â†’ her token iÃ§in bir skor. Softmax bu skorlarÄ± olasÄ±lÄ±klara Ã§evirir (toplam=1).":"Final vector [16d] multiplied by decode matrix [16Ã—28] â†’ a score for each token. Softmax converts scores to probabilities (sum=1)."},
    {icon:"ğŸ“‰",label:"Loss = -log(0.12) = 2.12",sub:lang==="tr"?"Loss Hesaplama":"Loss Computation",color:"#EF4444",
     detail:lang==="tr"?"Model 'm' iÃ§in dÃ¼ÅŸÃ¼k olasÄ±lÄ±k verdi â†’ kayÄ±p yÃ¼ksek":"Model gave low probability for 'm' â†’ high loss",
     dataIn:"Hedef: 'm', Model tahmini: P('m') = 0.12",dataOut:"CE = -log(0.12) = 2.12",
     explain:lang==="tr"?"DoÄŸru cevaba verilen olasÄ±lÄ±k ne kadar dÃ¼ÅŸÃ¼kse kayÄ±p o kadar yÃ¼ksek. P=1.0 â†’ loss=0 (mÃ¼kemmel). P=0.01 â†’ loss=4.6 (Ã§ok kÃ¶tÃ¼). AmaÃ§: bu kaybÄ± minimize etmek.":"The lower the probability given to the correct answer, the higher the loss. P=1.0 â†’ loss=0 (perfect). P=0.01 â†’ loss=4.6 (very bad). Goal: minimize this loss."},
    {icon:"â›“ï¸",label:"âˆ‚L/âˆ‚w iÃ§in her parametre",sub:"Backward Pass",color:"#F59E0B",
     detail:lang==="tr"?"Zincir kuralÄ±yla 3,648 gradyan hesaplanÄ±r":"3,648 gradients computed via chain rule",
     dataIn:"Loss = 2.12",dataOut:"grad(wte), grad(wpe), grad(Wq), grad(Wk), ... toplam 3,648 gradyan",
     explain:lang==="tr"?"KayÄ±p son katmandan geriye doÄŸru yayÄ±lÄ±r. Her parametre iÃ§in 'bu parametreyi deÄŸiÅŸtirmek kaybÄ± ne kadar deÄŸiÅŸtirir?' sorusu cevaplanÄ±r. Bu = gradient.":"Loss propagates backwards from the last layer. For each parameter: 'how much does changing this parameter change the loss?' This answer = gradient."},
    {icon:"ğŸ”§",label:"w -= 0.01 Ã— grad",sub:"Adam Update",color:"#10B981",
     detail:lang==="tr"?"Her parametre gradient yÃ¶nÃ¼nde kÃ¼Ã§Ã¼k bir adÄ±m atar":"Each parameter takes a small step in the gradient direction",
     dataIn:"w_old, grad, momentum, variance",dataOut:"w_new = w_old - lr Ã— mÌ‚/(âˆšvÌ‚+Îµ)",
     explain:lang==="tr"?"Adam optimizer: momentum (yÃ¶n) + adaptif lr (hÄ±z) birleÅŸtirir. Her parametre ayrÄ± hÄ±zda gÃ¼ncellenir. Son adÄ±m: grad = 0 (bir sonraki adÄ±m iÃ§in sÄ±fÄ±rla).":"Adam optimizer: combines momentum (direction) + adaptive lr (speed). Each parameter updates at its own rate. Final step: grad = 0 (reset for next step)."},
  ];
  useEffect(() => {
    if (!auto) return;
    const t = setInterval(() => setStage(s => { if (s >= pipe.length-1) { setAuto(false); return 0; } return s+1; }), 2200);
    return () => clearInterval(t);
  }, [auto]);
  const p = pipe[stage];
  return (<VizBox title={lang === "tr" ? "CanlÄ± Pipeline â€” Bir EÄŸitim AdÄ±mÄ± (emma)" : "Live Pipeline â€” One Training Step (emma)"} color="#0EA5E9">
    <div style={{fontSize:13,color:"#94A3B8",marginBottom:8,lineHeight:1.6}}>
      {lang==="tr"?<><strong style={{color:"#0EA5E9"}}>'emma'</strong> isminin model iÃ§indeki 9 aÅŸamalÄ± yolculuÄŸu. Her kutuya tÄ±klayarak o adÄ±mda verinin nasÄ±l dÃ¶nÃ¼ÅŸtÃ¼ÄŸÃ¼nÃ¼ gÃ¶rÃ¼n.</>:<>The 9-stage journey of <strong style={{color:"#0EA5E9"}}>'emma'</strong> through the model. Click each box to see how data transforms at each step.</>}
    </div>
    <div style={{display:"flex",gap:3,flexWrap:"wrap",justifyContent:"center",marginBottom:10}}>
      {pipe.map((s,i) => (
        <div key={i} onClick={()=>{setAuto(false);setStage(i);}} style={{
          display:"flex",flexDirection:"column",alignItems:"center",gap:2,padding:"6px 5px",borderRadius:8,minWidth:48,cursor:"pointer",
          background:i===stage?`${s.color}20`:i<stage?`${s.color}08`:"transparent",
          border:`1.5px solid ${i===stage?s.color:i<stage?`${s.color}30`:"rgba(255,255,255,0.04)"}`,
          transform:i===stage?"scale(1.1)":"scale(1)",transition:"all .3s",opacity:i<=stage?1:0.3
        }}>
          <span style={{fontSize:17}}>{s.icon}</span>
          <span style={{fontSize:10,fontWeight:700,color:i===stage?s.color:"#64748B",textAlign:"center"}}>{s.sub}</span>
        </div>
      ))}
    </div>
    <div style={{padding:14,borderRadius:12,background:`${p.color}08`,border:`1.5px solid ${p.color}25`,transition:"all .3s"}}>
      <div style={{fontSize:16,fontWeight:800,color:p.color,marginBottom:4}}>{p.icon} {stage+1}/9 â€” {p.sub}</div>
      <div style={{fontSize:14,color:"#94A3B8",marginBottom:10}}>{p.detail}</div>

      <div style={{display:"flex",gap:8,marginBottom:10,flexWrap:"wrap"}}>
        <div style={{flex:1,minWidth:160,padding:"8px 12px",borderRadius:8,background:"rgba(14,165,233,.06)",border:"1px solid rgba(14,165,233,.15)"}}>
          <div style={{fontSize:11,color:"#0EA5E9",fontWeight:700,marginBottom:2}}>{lang === "tr" ? "GÄ°RDÄ°" : "INPUT"}</div>
          <div style={{fontSize:13,fontFamily:"'Fira Code',monospace",color:"#E2E8F0",lineHeight:1.5}}>{p.dataIn}</div>
        </div>
        <div style={{display:"flex",alignItems:"center",fontSize:17,color:"#64748B"}}>â†’</div>
        <div style={{flex:1,minWidth:160,padding:"8px 12px",borderRadius:8,background:"rgba(16,185,129,.06)",border:"1px solid rgba(16,185,129,.15)"}}>
          <div style={{fontSize:11,color:"#10B981",fontWeight:700,marginBottom:2}}>{lang === "tr" ? "Ã‡IKTI" : "OUTPUT"}</div>
          <div style={{fontSize:13,fontFamily:"'Fira Code',monospace",color:"#E2E8F0",lineHeight:1.5}}>{p.dataOut}</div>
        </div>
      </div>

      <div style={{padding:"8px 12px",borderRadius:8,background:"rgba(251,191,36,.05)",borderLeft:"3px solid rgba(251,191,36,.3)"}}>
        <div style={{fontSize:11,color:"#FBBF24",fontWeight:700,marginBottom:2}}>{lang==="tr"?"NE OLUYOR?":"WHAT'S HAPPENING?"}</div>
        <div style={{fontSize:13,color:"#FDE68A",lineHeight:1.6}}>{p.explain}</div>
      </div>
    </div>
    <div style={{display:"flex",gap:6,marginTop:8,justifyContent:"center"}}>
      <button onClick={()=>{setStage(0);setAuto(true);}} style={{padding:"5px 14px",borderRadius:8,border:"none",background:"#0EA5E9",color:"#fff",fontSize:14,fontWeight:700,cursor:"pointer",fontFamily:"inherit"}}>{lang === "tr" ? "â–¶ Animasyon" : "â–¶ Animate"}</button>
      <button onClick={()=>setStage(s=>Math.max(0,s-1))} style={{padding:"5px 10px",borderRadius:8,border:"1px solid rgba(255,255,255,.1)",background:"transparent",color:"#94A3B8",fontSize:14,cursor:"pointer",fontFamily:"inherit"}}>â†</button>
      <button onClick={()=>setStage(s=>Math.min(pipe.length-1,s+1))} style={{padding:"5px 10px",borderRadius:8,border:"1px solid rgba(255,255,255,.1)",background:"transparent",color:"#94A3B8",fontSize:14,cursor:"pointer",fontFamily:"inherit"}}>â†’</button>
    </div>
  </VizBox>);
};

// â”€â”€â”€ RICH INTERACTIVE VIZ: TOKENIZER PLAYGROUND â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const TokenizerPlaygroundViz = () => {
  const [input, setInput] = useState("emma");
  const [animStep, setAnimStep] = useState(-1);
  const [auto, setAuto] = useState(false);
  const vocab = {a:0,b:1,c:2,d:3,e:4,f:5,g:6,h:7,i:8,j:9,k:10,l:11,m:12,n:13,o:14,p:15,q:16,r:17,s:18,t:19,u:20,v:21,w:22,x:23,y:24,z:25};
  const BOS = 26;
  const chars = input.toLowerCase().split("").filter(c => vocab[c] !== undefined);
  const ids = [BOS, ...chars.map(c => vocab[c]), BOS];
  const labels = ["BOS", ...chars, "BOS"];
  const pairs = ids.slice(0, -1).map((id, i) => ({ input: labels[i], target: labels[i + 1], inId: id, outId: ids[i + 1] }));

  // Animation stages: 0=chars, 1=ids, 2=addBOS, 3=pairs
  useEffect(() => {
    if (!auto) return;
    const t = setInterval(() => setAnimStep(s => { if (s >= 3) { setAuto(false); return 3; } return s + 1; }), 900);
    return () => clearInterval(t);
  }, [auto]);

  const stageLabels = [lang === "tr" ? "â‘  Karakterlere ayÄ±r" : "â‘  Split into characters", lang === "tr" ? "â‘¡ ID'lere Ã§evir" : "â‘¡ Convert to IDs", lang === "tr" ? "â‘¢ BOS ekle" : "â‘¢ Add BOS", lang === "tr" ? "â‘£ EÄŸitim Ã§iftleri oluÅŸtur" : "â‘£ Create training pairs"];
  const stageColors = ["#8B5CF6", "#0EA5E9", "#F59E0B", "#10B981"];

  return (<VizBox title={lang === "tr" ? "Tokenizer Oyun AlanÄ± â€” Kendi Kelimeni Dene" : "Tokenizer Playground â€” Try Your Own Words"} color="#8B5CF6">
    <div style={{display:"flex",gap:8,alignItems:"center",marginBottom:10,flexWrap:"wrap"}}>
      <input type="text" value={input} onChange={e=>{setInput(e.target.value.slice(0,10));setAnimStep(-1);}} maxLength={10} placeholder={lang === "tr" ? "isim yazÄ±n..." : "type a name..."} style={{padding:"7px 14px",borderRadius:10,background:"#0D1117",border:"1.5px solid rgba(139,92,246,.3)",color:"#E2E8F0",fontFamily:"'Fira Code',monospace",fontSize: 18,width:130,outline:"none"}}/>
      <button onClick={()=>{setAnimStep(0);setAuto(true);}} style={{padding:"7px 16px",borderRadius:10,border:"none",background:"#8B5CF6",color:"#fff",fontSize: 14,fontWeight:700,cursor:"pointer",fontFamily:"inherit"}}>{lang === "tr" ? "â–¶ Tokenize Et" : "â–¶ Tokenize"}</button>
      <button onClick={()=>{setAnimStep(-1);setAuto(false);}} style={{padding:"7px 12px",borderRadius:10,border:"1px solid rgba(255,255,255,.1)",background:"transparent",color:"#94A3B8",fontSize: 14,cursor:"pointer",fontFamily:"inherit"}}>â†º</button>
    </div>

    {/* Pipeline stages */}
    <div style={{display:"flex",gap:4,marginBottom:12}}>
      {stageLabels.map((l,i) => (
        <div key={i} style={{flex:1,padding:"5px 6px",borderRadius:8,fontSize: 12,fontWeight:700,textAlign:"center",
          background:i<=animStep?`${stageColors[i]}15`:"transparent",color:i<=animStep?stageColors[i]:"#334155",
          border:`1.5px solid ${i===animStep?stageColors[i]:i<animStep?`${stageColors[i]}30`:"rgba(255,255,255,.04)"}`,
          transform:i===animStep?"scale(1.04)":"scale(1)",transition:"all .3s"}}>{l}</div>
      ))}
    </div>

    {/* Stage 0+: Character strip */}
    {animStep >= 0 && (<div style={{marginBottom:8,opacity:1,transition:"opacity .4s"}}>
      <div style={{fontSize: 12,color:"#8B5CF6",fontWeight:700,marginBottom:4}}>Karakterler:</div>
      <div style={{display:"flex",gap:3,flexWrap:"wrap"}}>
        {chars.map((c,i) => (
          <div key={i} style={{width:32,height:36,borderRadius:8,display:"flex",flexDirection:"column",alignItems:"center",justifyContent:"center",
            background:"rgba(139,92,246,.08)",border:"1.5px solid rgba(139,92,246,.25)",transition:"all .3s"}}>
            <span style={{fontSize: 19,fontWeight:800,fontFamily:"'Fira Code',monospace",color:"#8B5CF6"}}>{c}</span>
          </div>
        ))}
      </div>
    </div>)}

    {/* Stage 1+: ID mapping */}
    {animStep >= 1 && (<div style={{marginBottom:8}}>
      <div style={{fontSize: 12,color:"#0EA5E9",fontWeight:700,marginBottom:4}}>Token ID'ler:</div>
      <div style={{display:"flex",gap:3,flexWrap:"wrap"}}>
        {chars.map((c,i) => (
          <div key={i} style={{display:"flex",flexDirection:"column",alignItems:"center",gap:1}}>
            <span style={{fontSize: 14,fontFamily:"'Fira Code',monospace",color:"#8B5CF6"}}>{c}</span>
            <span style={{fontSize: 11,color:"#64748B"}}>â†“</span>
            <div style={{padding:"3px 8px",borderRadius:6,background:"rgba(14,165,233,.1)",border:"1px solid rgba(14,165,233,.2)",fontSize: 15,fontFamily:"'Fira Code',monospace",color:"#0EA5E9",fontWeight:700}}>{vocab[c]}</div>
          </div>
        ))}
      </div>
    </div>)}

    {/* Stage 2+: Full token sequence with BOS */}
    {animStep >= 2 && (<div style={{marginBottom:8}}>
      <div style={{fontSize: 12,color:"#F59E0B",fontWeight:700,marginBottom:4}}>Tam dizi (BOS dahil):</div>
      <div style={{display:"flex",gap:3,flexWrap:"wrap"}}>
        {labels.map((l,i) => {
          const isBos = l === "BOS";
          return (<div key={i} style={{display:"flex",flexDirection:"column",alignItems:"center",gap:2,padding:"6px 8px",borderRadius:8,
            background:isBos?"rgba(245,158,11,.1)":"rgba(139,92,246,.05)",border:`1.5px solid ${isBos?"rgba(245,158,11,.3)":"rgba(139,92,246,.15)"}`,
            transition:"all .3s"}}>
            <span style={{fontSize: 16,fontWeight:800,fontFamily:"'Fira Code',monospace",color:isBos?"#F59E0B":"#8B5CF6"}}>{l}</span>
            <span style={{fontSize: 12,fontFamily:"'Fira Code',monospace",color:"#64748B"}}>{ids[i]}</span>
          </div>);
        })}
      </div>
      <div style={{fontSize: 12,fontFamily:"'Fira Code',monospace",color:"#64748B",marginTop:4}}>
        [{ids.join(", ")}]
      </div>
    </div>)}

    {/* Stage 3: Training pairs */}
    {animStep >= 3 && (<div>
      <div style={{fontSize: 12,color:"#10B981",fontWeight:700,marginBottom:4}}>{lang === "tr" ? `EÄŸitim Ã§iftleri (${pairs.length} adet):` : `Training pairs (${pairs.length}):` }</div>
      <div style={{display:"flex",gap:4,flexWrap:"wrap"}}>
        {pairs.map((p,i) => (
          <div key={i} style={{padding:"5px 10px",borderRadius:8,background:"rgba(16,185,129,.06)",border:"1px solid rgba(16,185,129,.15)",display:"flex",alignItems:"center",gap:4,transition:"all .3s"}}>
            <span style={{fontSize: 14,fontFamily:"'Fira Code',monospace",color:"#0EA5E9",fontWeight:700}}>{p.input}</span>
            <span style={{fontSize: 13,color:"#475569"}}>â†’</span>
            <span style={{fontSize: 14,fontFamily:"'Fira Code',monospace",color:"#10B981",fontWeight:700}}>{p.target}</span>
          </div>
        ))}
      </div>
      <div style={{marginTop:8,padding:"8px 12px",borderRadius:8,background:"rgba(245,158,11,.04)",border:"1px solid rgba(245,158,11,.12)",fontSize: 13,color:"#F59E0B"}}>
        ğŸ’¡ {chars.length} harf â†’ {ids.length} token â†’ {pairs.length} eÄŸitim Ã§ifti. 32K isim Ã— ~6 harf = ~192K Ã§ift!
      </div>
    </div>)}

    {animStep < 0 && (<div style={{padding:16,textAlign:"center",color:"#475569",fontSize: 14}}>
      {lang === "tr" ? "â˜ï¸ Bir isim yazÄ±p â–¶ Tokenize Et butonuna basÄ±n" : "â˜ï¸ Type a name and press â–¶ Tokenize"}
    </div>)}
  </VizBox>);
};

// â”€â”€â”€ RICH INTERACTIVE VIZ: AUTOGRAD PLAYGROUND â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const AutogradPlaygroundViz = () => {
  const [a, setA] = useState(2);
  const [b, setB] = useState(3);
  const [c, setC] = useState(1);
  const [step, setStep] = useState(-1);
  const [auto, setAuto] = useState(false);

  const d = a * b;
  const L = d + c;
  const grads = [
    { node: "L", val: L, grad: 1, explain: lang === "tr" ? "âˆ‚L/âˆ‚L = 1 (baÅŸlangÄ±Ã§)" : "âˆ‚L/âˆ‚L = 1 (start)", color: "#EF4444" },
    { node: "d", val: d, grad: 1, explain: lang === "tr" ? "âˆ‚L/âˆ‚d = 1 (toplama: geÃ§ir)" : "âˆ‚L/âˆ‚d = 1 (addition: pass through)", color: "#F59E0B" },
    { node: "c", val: c, grad: 1, explain: lang === "tr" ? "âˆ‚L/âˆ‚c = 1 (toplama: geÃ§ir)" : "âˆ‚L/âˆ‚c = 1 (addition: pass through)", color: "#10B981" },
    { node: "a", val: a, grad: b, explain: `âˆ‚L/âˆ‚a = b = ${b} ${lang === "tr" ? "(Ã§arpma: diÄŸer girdi)" : "(multiply: other input)"}`, color: "#0EA5E9" },
    { node: "b", val: b, grad: a, explain: `âˆ‚L/âˆ‚b = a = ${a} ${lang === "tr" ? "(Ã§arpma: diÄŸer girdi)" : "(multiply: other input)"}`, color: "#8B5CF6" },
  ];

  useEffect(() => {
    if (!auto) return;
    const t = setInterval(() => setStep(s => { if (s >= 4) { setAuto(false); return 4; } return s + 1; }), 1000);
    return () => clearInterval(t);
  }, [auto]);

  const nodeGrad = (name) => {
    const idx = grads.findIndex(g => g.node === name);
    return idx !== -1 && idx <= step ? grads[idx].grad : null;
  };
  const nodeActive = (name) => {
    const idx = grads.findIndex(g => g.node === name);
    return idx !== -1 && idx <= step;
  };

  const nodes = [
    { l: "a", v: a, x: 20, y: 18, c: "#0EA5E9" },
    { l: "b", v: b, x: 20, y: 54, c: "#8B5CF6" },
    { l: "d=aÃ—b", v: d, x: 100, y: 36, c: "#F59E0B" },
    { l: "c", v: c, x: 100, y: 66, c: "#10B981" },
    { l: "L=d+c", v: L, x: 180, y: 48, c: "#EF4444" },
  ];

  return (<VizBox title={lang === "tr" ? "Autograd Oyun AlanÄ± â€” DeÄŸerleri DeÄŸiÅŸtir, Gradientleri Ä°zle" : "Autograd Playground â€” Change Values, Watch Gradients"} color="#F59E0B">
    <div style={{display:"flex",gap:16,flexWrap:"wrap"}}>
      <div style={{flex:1,minWidth:230}}>
        {/* Sliders */}
        <div style={{display:"flex",gap:8,marginBottom:12}}>
          {[{l:"a",v:a,s:setA,c:"#0EA5E9"},{l:"b",v:b,s:setB,c:"#8B5CF6"},{l:"c",v:c,s:setC,c:"#10B981"}].map((p,i)=>(
            <div key={i} style={{flex:1}}>
              <div style={{display:"flex",justifyContent:"space-between",fontSize: 13,marginBottom:2}}>
                <span style={{color:p.c,fontWeight:800}}>{p.l}</span>
                <span style={{fontFamily:"'Fira Code',monospace",color:"#E2E8F0",fontWeight:700}}>{p.v}</span>
              </div>
              <input type="range" min={-5} max={5} value={p.v} onChange={e=>{p.s(+e.target.value);setStep(-1);setAuto(false);}} style={{width:"100%",accentColor:p.c}}/>
            </div>
          ))}
        </div>

        {/* Computation Graph SVG */}
        <svg viewBox="0 0 210 82" style={{width:"100%",height:120,background:"rgba(0,0,0,.15)",borderRadius:10,padding:4}}>
          {/* Edges */}
          {[[20,18,100,36,"#0EA5E960"],[20,54,100,36,"#8B5CF660"],[100,36,180,48,"#F59E0B60"],[100,66,180,48,"#10B98160"]].map(([x1,y1,x2,y2,col],i)=>(
            <line key={i} x1={x1} y1={y1} x2={x2} y2={y2} stroke={col} strokeWidth="1.5" strokeDasharray={step >= 0 ? "none" : "4,3"}/>
          ))}
          {/* Op labels */}
          <text x="58" y="30" fill="#F59E0B" fontSize="6" fontWeight="700" textAnchor="middle">Ã—</text>
          <text x="142" y="48" fill="#EF4444" fontSize="6" fontWeight="700" textAnchor="middle">+</text>

          {/* Backward arrows (animated) */}
          {step >= 0 && <line x1="175" y1="52" x2="110" y2="40" stroke="#EF444480" strokeWidth="1" markerEnd="url(#arrowR)" strokeDasharray="3,2"/>}
          {step >= 1 && <line x1="175" y1="52" x2="110" y2="66" stroke="#EF444480" strokeWidth="1" strokeDasharray="3,2"/>}
          {step >= 3 && <line x1="95" y1="40" x2="28" y2="22" stroke="#EF444480" strokeWidth="1" strokeDasharray="3,2"/>}
          {step >= 4 && <line x1="95" y1="40" x2="28" y2="54" stroke="#EF444480" strokeWidth="1" strokeDasharray="3,2"/>}

          {/* Nodes */}
          {nodes.map((n,i)=>{
            const g = nodeGrad(n.l.split("=")[0]);
            const active = nodeActive(n.l.split("=")[0]);
            return (<g key={i}>
              <ellipse cx={n.x} cy={n.y} rx={n.l.length>2?20:14} ry="11" fill={active?`${n.c}25`:"#0D111780"} stroke={n.c} strokeWidth={active?2:1} style={{transition:"all .4s"}}/>
              <text x={n.x} y={n.y+1} fill={n.c} fontSize="5.5" fontWeight="800" textAnchor="middle">{n.l}={n.v}</text>
              {g !== null && (<>
                <rect x={n.x-14} y={n.y+11} width="28" height="12" rx="3" fill="#EF4444" opacity="0.9"/>
                <text x={n.x} y={n.y+19} fill="#fff" fontSize="5" fontWeight="700" textAnchor="middle">grad={g}</text>
              </>)}
            </g>);
          })}
        </svg>

        {/* Controls */}
        <div style={{display:"flex",gap:6,marginTop:8}}>
          <button onClick={()=>{setStep(0);setAuto(true);}} style={{flex:1,padding:"6px 14px",borderRadius:10,border:"none",background:"#F59E0B",color:"#fff",fontSize: 14,fontWeight:700,cursor:"pointer",fontFamily:"inherit"}}>{lang === "tr" ? "â–¶ Backward" : "â–¶ Backward"}</button>
          <button onClick={()=>setStep(s=>Math.max(-1,s-1))} style={{padding:"6px 10px",borderRadius:10,border:"1px solid rgba(255,255,255,.1)",background:"transparent",color:"#94A3B8",fontSize: 14,cursor:"pointer",fontFamily:"inherit"}}>â†</button>
          <button onClick={()=>setStep(s=>Math.min(4,s+1))} style={{padding:"6px 10px",borderRadius:10,border:"1px solid rgba(255,255,255,.1)",background:"transparent",color:"#94A3B8",fontSize: 14,cursor:"pointer",fontFamily:"inherit"}}>â†’</button>
          <button onClick={()=>{setStep(-1);setAuto(false);}} style={{padding:"6px 10px",borderRadius:10,border:"1px solid rgba(255,255,255,.1)",background:"transparent",color:"#94A3B8",fontSize: 14,cursor:"pointer",fontFamily:"inherit"}}>â†º</button>
        </div>
      </div>

      {/* Backward steps panel */}
      <div style={{flex:1,minWidth:200}}>
        <div style={{fontSize: 13,fontWeight:700,color:"#EF4444",marginBottom:8,display:"flex",alignItems:"center",gap:4}}>
          <span>â†</span> Backward adÄ±mlarÄ±
        </div>
        {grads.map((g,i)=>(
          <div key={i} style={{padding:"7px 10px",borderRadius:8,marginBottom:4,
            background:i<=step?`${g.color}10`:"transparent",
            border:`1.5px solid ${i===step?g.color:i<step?`${g.color}25`:"rgba(255,255,255,.03)"}`,
            opacity:i<=step?1:0.25,transition:"all .4s",
            transform:i===step?"scale(1.02)":"scale(1)"}}>
            <div style={{display:"flex",justifyContent:"space-between",alignItems:"center"}}>
              <span style={{fontSize: 14,fontFamily:"'Fira Code',monospace",color:i===step?g.color:"#94A3B8",fontWeight:i===step?800:400}}>{g.explain}</span>
              {i<=step && <span style={{fontSize: 13,fontFamily:"'Fira Code',monospace",color:"#EF4444",fontWeight:700}}>={g.grad}</span>}
            </div>
          </div>
        ))}

        {step >= 4 && (<div style={{marginTop:8,padding:"8px 12px",borderRadius:8,background:"rgba(16,185,129,.06)",border:"1px solid rgba(16,185,129,.15)",fontSize: 13,color:"#10B981"}}>
          âœ… DoÄŸrulama: âˆ‚L/âˆ‚a = b = {b}, âˆ‚L/âˆ‚b = a = {a}. KaydÄ±rÄ±cÄ±larÄ± deÄŸiÅŸtirip tekrar deneyin!
        </div>)}

        {step < 0 && (<div style={{padding:"12px 8px",textAlign:"center",color:"#475569",fontSize: 13}}>
          â˜ï¸ KaydÄ±rÄ±cÄ±larla a, b, c deÄŸerlerini ayarlayÄ±n, sonra â–¶ Backward'a basÄ±n
        </div>)}
      </div>
    </div>
  </VizBox>);
};

// â”€â”€â”€ RICH INTERACTIVE VIZ: ATTENTION PLAYGROUND (W3) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const AttentionPlaygroundViz = () => {
  const toks = ["B","a","n","a","n","a"];
  const [selRow, setSelRow] = useState(3);
  const [activeHead, setActiveHead] = useState(0);
  const headColors = ["#0EA5E9","#10B981","#F59E0B","#EC4899"];
  const headLabels = [lang === "tr" ? "Sesli-sessiz uyumu" : "Vowel-consonant harmony",lang === "tr" ? "Pozisyon yakÄ±nlÄ±ÄŸÄ±" : "Position proximity",lang === "tr" ? "Tekrar kalÄ±bÄ±" : "Repetition pattern",lang === "tr" ? "Genel baÄŸlam" : "General context"];
  // Simulated attention patterns per head
  const patterns = useMemo(() => [
    // Head 0: vowel-consonant
    toks.map((_,r) => toks.map((_,c) => c<=r ? (("aeiou".includes(toks[c].toLowerCase()) !== "aeiou".includes(toks[r].toLowerCase())) ? 0.35 : 0.08) + Math.random()*0.05 : 0)),
    // Head 1: positional proximity
    toks.map((_,r) => toks.map((_,c) => c<=r ? Math.max(0.02, 0.4 - Math.abs(r-c)*0.1) + Math.random()*0.03 : 0)),
    // Head 2: repeat pattern
    toks.map((_,r) => toks.map((_,c) => c<=r ? (toks[c]===toks[r] ? 0.45 : 0.05) + Math.random()*0.04 : 0)),
    // Head 3: uniform-ish
    toks.map((_,r) => toks.map((_,c) => c<=r ? 0.15 + Math.random()*0.1 : 0)),
  ], []);
  const norm = (row) => { const s=row.reduce((a,b)=>a+b,0)||1; return row.map(v=>v/s); };

  const weights = patterns[activeHead].map(norm);

  return (<VizBox title={lang === "tr" ? "Attention Oyun AlanÄ± â€” Her Head Neye BakÄ±yor?" : "Attention Playground â€” What Does Each Head See?"} color="#10B981">
    <div style={{display:"flex",gap:14,flexWrap:"wrap"}}>
      <div style={{minWidth:220}}>
        <div style={{fontSize: 12,color:"#64748B",marginBottom:4}}>{lang === "tr" ? "Head seÃ§in â€” her head farklÄ± kalÄ±p Ã¶ÄŸrenir:</div>
        <div style={{display:"flex",gap:3,marginBottom:8}}>
          {[0,1,2,3].map(h=>(
            <button key={h} onClick={()=>setActiveHead(h)} style={{flex:1,padding:"5px 4px",borderRadius:8,border:`1.5px solid ${activeHead===h?headColors[h]:`${headColors[h]}30`}`,background:activeHead===h?`${headColors[h]}15`:"transparent",color:activeHead===h?headColors[h]:"#64748B",fontSize: 11,fontWeight:700,cursor:"pointer",fontFamily:"inherit",lineHeight:1.3,textAlign:"center"}}>
              H{h}<br/><span style={{fontSize: 10,fontWeight:400}}>{headLabels[h]}</span>
            </button>
          ))}
        </div>
        {/* Attention matrix */}
        <div style={{display:"flex",marginLeft:20}}>{toks.map((t,i)=>(<div key={i} style={{width:28,textAlign:"center",fontSize: 13,color:"#64748B",fontFamily:"'Fira Code',monospace"}}>{t}</div>))}</div>
        {toks.map((t,r)=>(
          <div key={r} style={{display:"flex",alignItems:"center",cursor:"pointer"}} onClick={()=>setSelRow(r)}>
            <div style={{width:18,fontSize: 13,color:selRow===r?headColors[activeHead]:"#64748B",fontFamily:"'Fira Code',monospace",fontWeight:selRow===r?800:400}}>{t}</div>
            {toks.map((_,c)=>{const masked=c>r;const w=!masked?weights[r][c]:0;return(
              <div key={c} style={{width:26,height:24,margin:1,borderRadius:4,display:"flex",alignItems:"center",justifyContent:"center",fontSize: 10,fontFamily:"'Fira Code',monospace",
                background:masked?"rgba(255,255,255,.01)":`${headColors[activeHead]}${Math.round(Math.min(200,w*250)).toString(16).padStart(2,"0")}`,
                color:masked?"#1E293B":w>0.2?"#fff":`${headColors[activeHead]}99`,
                border:selRow===r&&!masked?`1.5px solid ${headColors[activeHead]}`:"1px solid transparent",transition:"all .3s"
              }}>{masked?"âœ—":(w*100).toFixed(0)}</div>
            );})}
          </div>
        ))}
        <div style={{marginTop:4,fontSize: 11,color:"#475569"}}>{lang === "tr" ? "âœ— = causal mask (geleceÄŸi gÃ¶remez)" : "âœ— = causal mask (cannot see future)"}</div>
      </div>
      <div style={{flex:1,minWidth:180}}>
        <div style={{padding:10,borderRadius:10,background:`${headColors[activeHead]}08`,border:`1px solid ${headColors[activeHead]}20`}}>
          <div style={{fontSize: 13,color:headColors[activeHead],fontWeight:700,marginBottom:6}}>'{toks[selRow]}' (pos {selRow}) â†’ dikkat daÄŸÄ±lÄ±mÄ±:</div>
          {toks.slice(0,selRow+1).map((t,i)=>(
            <div key={i} style={{display:"flex",alignItems:"center",gap:5,marginBottom:3}}>
              <span style={{width:12,fontSize: 14,fontFamily:"'Fira Code',monospace",color:"#94A3B8",fontWeight:700}}>{t}</span>
              <div style={{flex:1,height:10,background:"rgba(255,255,255,.03)",borderRadius:5,overflow:"hidden"}}>
                <div style={{height:"100%",width:`${weights[selRow][i]*100}%`,borderRadius:5,background:headColors[activeHead],transition:"width .3s"}}/>
              </div>
              <span style={{width:28,fontSize: 12,fontFamily:"'Fira Code',monospace",color:"#E2E8F0",textAlign:"right"}}>{(weights[selRow][i]*100).toFixed(0)}%</span>
            </div>
          ))}
        </div>
        <div style={{marginTop:8,padding:"7px 10px",borderRadius:8,background:"rgba(245,158,11,.04)",border:"1px solid rgba(245,158,11,.12)",fontSize: 12,color:"#F59E0B"}}>
          ğŸ’¡ SatÄ±ra tÄ±klayÄ±n â†’ dikkat daÄŸÄ±lÄ±mÄ± deÄŸiÅŸir. Head deÄŸiÅŸtirin â†’ farklÄ± kalÄ±plar!
        </div>
        <div style={{marginTop:6,fontSize: 12,color:"#64748B"}}>
          FormÃ¼l: softmax(QÂ·Káµ€ / âˆš{4}) Ã— V
        </div>
      </div>
    </div>
  </VizBox>);
};

// â”€â”€â”€ RICH INTERACTIVE VIZ: TRANSFORMER BLOCK FLOW (W4) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const TransformerBlockFlowViz = () => {
  const [step, setStep] = useState(-1);
  const [auto, setAuto] = useState(false);
  const stages = [
    {l:lang === "tr" ? "x girdi" : "x input",sub:"[16]",c:"#0EA5E9",icon:"ğŸ“¥",d:lang === "tr" ? "Embedding katmanÄ±ndan gelen 16-boyutlu vektÃ¶r" : "16-dimensional vector from embedding layer"},
    {l:"RMSNormâ‚",sub:"x/âˆšrms",c:"#F59E0B",icon:"ğŸ“",d:lang === "tr" ? "Normalize et â†’ kararlÄ± eÄŸitim" : "Normalize â†’ stable training"},
    {l:"Self-Attn",sub:"QÂ·Káµ€/âˆšdÂ·V",c:"#10B981",icon:"ğŸ”",d:lang === "tr" ? "4 head Ã— 4 dim â†’ hangi tokenlara dikkat?" : "4 heads Ã— 4 dim â†’ which tokens to attend?"},
    {l:"+Residualâ‚",sub:"attn+x",c:"#EF4444",icon:"â•",d:lang === "tr" ? "Orijinal girdiyi geri ekle â†’ gradient highway" : "Add original input back â†’ gradient highway"},
    {l:"RMSNormâ‚‚",sub:"x/âˆšrms",c:"#F59E0B",icon:"ğŸ“",d:lang === "tr" ? "MLP Ã¶ncesi tekrar normalize" : "Re-normalize before MLP"},
    {l:"MLP",sub:"16â†’64â†’16",c:"#EC4899",icon:"ğŸ§®",d:"fc1(geniÅŸlet) â†’ ReLUÂ²(aktive) â†’ fc2(daralt)"},
    {l:"+Residualâ‚‚",sub:"mlp+x",c:"#EF4444",icon:"â•",d:lang === "tr" ? "Tekrar residual â†’ bilgi kaybÄ±nÄ± Ã¶nle" : "Residual again â†’ prevent info loss"},
    {l:lang === "tr" ? "x Ã§Ä±ktÄ±" : "x output",sub:"[16]",c:"#6366F1",icon:"ğŸ“¤",d:lang === "tr" ? "ZenginleÅŸmiÅŸ vektÃ¶r â†’ LM head veya sonraki katman" : "Enriched vector â†’ LM head or next layer"},
  ];

  useEffect(() => {
    if (!auto) return;
    const t = setInterval(() => setStep(s => { if (s >= stages.length-1) { setAuto(false); return s; } return s+1; }), 700);
    return () => clearInterval(t);
  }, [auto]);

  return (<VizBox title={lang === "tr" ? "Transformer BloÄŸu â€” AdÄ±m AdÄ±m AkÄ±ÅŸ SimÃ¼lasyonu" : "Transformer Block â€” Step-by-Step Flow Simulation"} color="#EC4899">
    {/* Stage boxes */}
    <div style={{display:"flex",gap:2,flexWrap:"wrap",justifyContent:"center",marginBottom:10}}>
      {stages.map((st,i)=>{
        const active = i===step;
        const past = i<step;
        return (<div key={i} onClick={()=>{setAuto(false);setStep(i);}} style={{
          display:"flex",flexDirection:"column",alignItems:"center",gap:1,padding:"5px 4px",borderRadius:8,minWidth:48,cursor:"pointer",
          background:active?`${st.c}20`:past?`${st.c}08`:"transparent",
          border:`1.5px solid ${active?st.c:past?`${st.c}30`:"rgba(255,255,255,.04)"}`,
          transform:active?"scale(1.08)":"scale(1)",transition:"all .3s",opacity:step<0?0.5:i<=step?1:0.25
        }}>
          <span style={{fontSize: 16}}>{st.icon}</span>
          <span style={{fontSize: 10,fontWeight:700,color:active?st.c:"#64748B",textAlign:"center",lineHeight:1.2}}>{st.l}</span>
        </div>);
      })}
    </div>

    {/* Flow arrows SVG */}
    <svg viewBox="0 0 320 16" style={{width:"100%",height:16,marginBottom:6}}>
      {stages.slice(0,-1).map((_,i) => {
        const x = 20 + i * (280/(stages.length-1));
        const x2 = 20 + (i+1) * (280/(stages.length-1));
        return <line key={i} x1={x+12} y1="8" x2={x2-8} y2="8" stroke={i<step?stages[i+1].c:"#1E293B"} strokeWidth="1.5" strokeDasharray={i<step?"":"3,3"} style={{transition:"stroke .3s"}}/>;
      })}
    </svg>

    {/* Detail panel */}
    {step >= 0 ? (
      <div style={{padding:14,borderRadius:12,background:`${stages[step].c}08`,border:`1.5px solid ${stages[step].c}25`,textAlign:"center",transition:"all .3s"}}>
        <div style={{fontSize: 12,color:"#64748B"}}>{lang === "tr" ? "AdÄ±m" : "Step"} {step+1}/{stages.length}</div>
        <div style={{fontSize: 21,fontWeight:800,fontFamily:"'Fira Code',monospace",color:stages[step].c,marginTop:2}}>{stages[step].l} â†’ {stages[step].sub}</div>
        <div style={{fontSize: 14,color:"#94A3B8",marginTop:4}}>{stages[step].d}</div>
      </div>
    ) : (
      <div style={{padding:14,textAlign:"center",color:"#475569",fontSize: 14}}>{lang === "tr" ? "â˜ï¸ â–¶ AkÄ±ÅŸ butonuna basÄ±n veya kutulara tÄ±klayÄ±n" : "â˜ï¸ Press â–¶ Flow or click the boxes"}</div>
    )}

    <div style={{display:"flex",gap:6,marginTop:8,justifyContent:"center"}}>
      <button onClick={()=>{setStep(0);setAuto(true);}} style={{padding:"6px 16px",borderRadius:10,border:"none",background:"#EC4899",color:"#fff",fontSize: 14,fontWeight:700,cursor:"pointer",fontFamily:"inherit"}}>{lang === "tr" ? "â–¶ AkÄ±ÅŸ" : "â–¶ Flow"}</button>
      <button onClick={()=>setStep(s=>Math.max(-1,s-1))} style={{padding:"6px 10px",borderRadius:10,border:"1px solid rgba(255,255,255,.1)",background:"transparent",color:"#94A3B8",fontSize: 14,cursor:"pointer",fontFamily:"inherit"}}>â†</button>
      <button onClick={()=>setStep(s=>Math.min(stages.length-1,s+1))} style={{padding:"6px 10px",borderRadius:10,border:"1px solid rgba(255,255,255,.1)",background:"transparent",color:"#94A3B8",fontSize: 14,cursor:"pointer",fontFamily:"inherit"}}>â†’</button>
      <button onClick={()=>{setStep(-1);setAuto(false);}} style={{padding:"6px 10px",borderRadius:10,border:"1px solid rgba(255,255,255,.1)",background:"transparent",color:"#94A3B8",fontSize: 14,cursor:"pointer",fontFamily:"inherit"}}>â†º</button>
    </div>
  </VizBox>);
};

// â”€â”€â”€ RICH INTERACTIVE VIZ: TRAINING SIMULATOR (W5) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const TrainingSimViz = () => {
  const [lr, setLr] = useState(0.01);
  const [epoch, setEpoch] = useState(0);
  const [running, setRunning] = useState(false);
  const [losses, setLosses] = useState([3.33]);
  const maxSteps = 40;

  useEffect(() => {
    if (!running) return;
    const t = setInterval(() => {
      setEpoch(s => {
        if (s >= maxSteps) { setRunning(false); return maxSteps; }
        setLosses(prev => {
          const last = prev[prev.length - 1];
          const good = lr >= 0.005 && lr <= 0.05;
          const tooHigh = lr > 0.05;
          const noise = (Math.random()-0.5)*0.3;
          let delta;
          if (tooHigh) delta = noise + (Math.random()>0.4 ? 0.08 : -0.02);
          else if (good) delta = -0.035 - Math.random()*0.02 + noise*0.15;
          else delta = -0.008 - Math.random()*0.005 + noise*0.1;
          return [...prev, Math.max(1.6, Math.min(4.5, last + delta))];
        });
        return s + 1;
      });
    }, 150);
    return () => clearInterval(t);
  }, [running, lr]);

  const reset = () => { setEpoch(0); setLosses([3.33]); setRunning(false); };
  const lastLoss = losses[losses.length - 1];
  const lossColor = lastLoss > 3.0 ? "#EF4444" : lastLoss > 2.3 ? "#F59E0B" : "#10B981";
  const lrZone = lr > 0.05 ? (lang === "tr" ? "âš ï¸ Ã‡ok yÃ¼ksek â€” patlama riski!" : "âš ï¸ Too high â€” explosion risk!") : lr < 0.005 ? (lang === "tr" ? "ğŸŒ Ã‡ok dÃ¼ÅŸÃ¼k â€” yavaÅŸ Ã¶ÄŸrenme" : "ğŸŒ Too low â€” slow learning") : (lang === "tr" ? "âœ… Ä°yi bÃ¶lge" : "âœ… Good range");

  return (<VizBox title={lang === "tr" ? "EÄŸitim SimÃ¼lasyonu â€” Learning Rate Etkisini Dene" : "Training Simulator â€” Try Learning Rate Effects"} color="#EF4444">
    <div style={{display:"flex",gap:16,flexWrap:"wrap"}}>
      <div style={{flex:1,minWidth:230}}>
        <div style={{display:"flex",justifyContent:"space-between",marginBottom:3}}>
          <span style={{fontSize: 13,color:"#F59E0B",fontWeight:700}}>learning_rate</span>
          <span style={{fontSize: 16,fontFamily:"'Fira Code',monospace",color:"#E2E8F0",fontWeight:800}}>{lr.toFixed(3)}</span>
        </div>
        <input type="range" min={0.001} max={0.1} step={0.001} value={lr} onChange={e=>{setLr(+parseFloat(e.target.value).toFixed(3));reset();}} style={{width:"100%",accentColor:"#F59E0B",marginBottom:2}}/>
        <div style={{fontSize: 12,color:lr>0.05?"#EF4444":lr<0.005?"#64748B":"#10B981",marginBottom:8}}>{lrZone}</div>

        {/* Loss curve */}
        <div style={{position:"relative",background:"rgba(0,0,0,.2)",borderRadius:8,padding:"4px 4px 0 4px"}}>
          <svg viewBox="0 0 200 55" style={{width:"100%",height:75}}>
            <text x="2" y="8" fill="#64748B" fontSize="4">4.0</text>
            <text x="2" y="28" fill="#64748B" fontSize="4">3.0</text>
            <text x="2" y="50" fill="#64748B" fontSize="4">2.0</text>
            <line x1="14" y1="5" x2="14" y2="52" stroke="#ffffff08" strokeWidth=".5"/>
            {losses.map((l, i) => {
              if (i === 0) return null;
              const x1 = 14 + ((i-1)/maxSteps)*183;
              const x2 = 14 + (i/maxSteps)*183;
              const y1 = 52 - ((losses[i-1]-1.5)/3.0)*47;
              const y2 = 52 - ((l-1.5)/3.0)*47;
              return <line key={i} x1={x1} y1={Math.max(3,Math.min(52,y1))} x2={x2} y2={Math.max(3,Math.min(52,y2))} stroke={lossColor} strokeWidth="1.2"/>;
            })}
          </svg>
        </div>
      </div>

      <div style={{flex:1,minWidth:160}}>
        <div style={{display:"flex",gap:8,marginBottom:10}}>
          <div style={{flex:1,padding:10,borderRadius:10,background:`${lossColor}10`,textAlign:"center"}}>
            <div style={{fontSize: 11,color:"#64748B"}}>Loss</div>
            <div style={{fontSize: 23,fontWeight:800,fontFamily:"'Fira Code',monospace",color:lossColor}}>{lastLoss.toFixed(2)}</div>
          </div>
          <div style={{flex:1,padding:10,borderRadius:10,background:"rgba(255,255,255,.02)",textAlign:"center"}}>
            <div style={{fontSize: 11,color:"#64748B"}}>{lang === "tr" ? "AdÄ±m" : "Step"}</div>
            <div style={{fontSize: 23,fontWeight:800,fontFamily:"'Fira Code',monospace",color:"#0EA5E9"}}>{epoch}/{maxSteps}</div>
          </div>
        </div>

        {epoch >= maxSteps && (<div style={{padding:"8px 10px",borderRadius:8,fontSize: 13,marginBottom:8,
          background:lastLoss<2.5?"rgba(16,185,129,.08)":"rgba(239,68,68,.08)",
          color:lastLoss<2.5?"#10B981":"#EF4444",border:`1px solid ${lastLoss<2.5?"rgba(16,185,129,.2)":"rgba(239,68,68,.2)"}`}}>
          {lastLoss<2.5 ? `âœ… Ä°yi eÄŸitim! Loss ${(3.33-lastLoss).toFixed(1)} dÃ¼ÅŸtÃ¼.` : `âš ï¸ Loss yeterince dÃ¼ÅŸmedi. LR'Ä± ayarlayÄ±p tekrar deneyin.`}
        </div>)}

        <div style={{display:"flex",gap:6}}>
          <button onClick={()=>{reset();setTimeout(()=>setRunning(true),50);}} style={{flex:1,padding:"7px 14px",borderRadius:10,border:"none",background:"#EF4444",color:"#fff",fontSize: 14,fontWeight:700,cursor:"pointer",fontFamily:"inherit"}}>{lang === "tr" ? "â–¶ EÄŸit" : "â–¶ Train"}</button>
          <button onClick={()=>setRunning(false)} style={{padding:"7px 10px",borderRadius:10,border:"1px solid rgba(255,255,255,.1)",background:"transparent",color:"#94A3B8",fontSize: 14,cursor:"pointer",fontFamily:"inherit"}}>â¸</button>
          <button onClick={reset} style={{padding:"7px 10px",borderRadius:10,border:"1px solid rgba(255,255,255,.1)",background:"transparent",color:"#94A3B8",fontSize: 14,cursor:"pointer",fontFamily:"inherit"}}>â†º</button>
        </div>
        <div style={{marginTop:8,fontSize: 12,color:"#64748B"}}>ğŸ’¡ LR'Ä± deÄŸiÅŸtirip tekrar eÄŸitin â€” etkiyi gÃ¶zlemleyin!</div>
      </div>
    </div>
  </VizBox>);
};

// â”€â”€â”€ RICH INTERACTIVE VIZ: GENERATION PLAYGROUND (W6) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const GenerationPlaygroundViz = () => {
  const [temp, setTemp] = useState(0.8);
  const [step, setStep] = useState(-1);
  const [auto, setAuto] = useState(false);
  const nameMap = {
    0.2:{steps:["k","a","r","e","n"],label:lang === "tr" ? "Deterministik â€” her zaman aynÄ±" : "Deterministic â€” always the same",color:"#0EA5E9"},
    0.5:{steps:["k","a","m","i","l"],label:lang === "tr" ? "Dengeli â€” gerÃ§ekÃ§i ve Ã§eÅŸitli" : "Balanced â€” realistic and varied",color:"#10B981"},
    0.8:{steps:["k","e","l","a","n","i"],label:lang === "tr" ? "YaratÄ±cÄ± â€” yeni kalÄ±plar" : "Creative â€” new patterns",color:"#10B981"},
    1.2:{steps:["k","z","u","o","p"],label:lang === "tr" ? "Kaotik â€” Ã§ok rastgele" : "Chaotic â€” very random",color:"#EF4444"},
  };
  const tKey = temp<=0.3?0.2:temp<=0.6?0.5:temp<=1.0?0.8:1.2;
  const gen = nameMap[tKey];

  useEffect(() => {
    if (!auto) return;
    const t = setInterval(() => setStep(s => { if (s >= gen.steps.length-1) { setAuto(false); return s; } return s+1; }), 500);
    return () => clearInterval(t);
  }, [auto, gen.steps.length]);

  // Simulated probability bars per step
  const probBars = gen.steps.map((ch, i) => {
    const others = "abcdefghijklmnopqrstuvwxyz".split("").filter(c => c !== ch).slice(0,3);
    const mainP = tKey <= 0.5 ? 0.45 + Math.random()*0.15 : tKey <= 1.0 ? 0.20+Math.random()*0.1 : 0.08+Math.random()*0.05;
    return [{ch,p:mainP,win:true}, ...others.map(c=>({ch:c,p:(1-mainP)/3+Math.random()*0.02,win:false}))];
  });

  return (<VizBox title={lang === "tr" ? "Ãœretim Oyun AlanÄ± â€” Temperature ile Ä°sim Ãœret" : "Generation Playground â€” Generate Names with Temperature"} color="#6366F1">
    <div style={{display:"flex",gap:16,flexWrap:"wrap"}}>
      <div style={{flex:1,minWidth:220}}>
        <div style={{display:"flex",justifyContent:"space-between",marginBottom:3}}>
          <span style={{fontSize: 13,color:"#6366F1",fontWeight:700}}>Temperature</span>
          <span style={{fontSize: 17,fontFamily:"'Fira Code',monospace",color:"#E2E8F0",fontWeight:800}}>{temp.toFixed(1)}</span>
        </div>
        <input type="range" min={0.1} max={1.5} step={0.1} value={temp} onChange={e=>{setTemp(+e.target.value);setStep(-1);setAuto(false);}} style={{width:"100%",accentColor:"#6366F1",marginBottom:2}}/>
        <div style={{display:"flex",justifyContent:"space-between",fontSize: 10,color:"#64748B",marginBottom:8}}>
          <span>{lang === "tr" ? "0.1 (sivri)" : "0.1 (sharp)"}</span><span>{lang === "tr" ? "0.8 (dengeli)" : "0.8 (balanced)"}</span><span>{lang === "tr" ? "1.5 (dÃ¼z)" : "1.5 (flat)"}</span>
        </div>

        {/* Distribution shape */}
        <div style={{padding:8,borderRadius:8,background:"rgba(255,255,255,.02)",marginBottom:8}}>
          <div style={{fontSize: 11,color:"#64748B",marginBottom:3}}>{lang === "tr" ? "Softmax daÄŸÄ±lÄ±m ÅŸekli:" : "Softmax distribution shape:"}</div>
          <div style={{display:"flex",gap:1,alignItems:"flex-end",height:28}}>
            {Array.from({length:20},(_,i) => {
              const spread = temp * 3;
              const h = Math.exp(-((i-5)**2)/(2*spread*spread))*26;
              return <div key={i} style={{flex:1,height:Math.max(1,h),background:"#6366F1",borderRadius:"2px 2px 0 0",opacity:0.4+h/50,transition:"height .3s"}}/>;
            })}
          </div>
        </div>

        <div style={{padding:"6px 10px",borderRadius:8,background:`${gen.color}08`,border:`1px solid ${gen.color}20`,fontSize: 13,color:gen.color,marginBottom:6}}>
          {gen.label}
        </div>
      </div>

      <div style={{flex:1,minWidth:200}}>
        {/* Generated name display */}
        <div style={{fontSize: 12,color:"#64748B",marginBottom:4}}>{lang === "tr" ? "Ãœretilen isim (BOS ile baÅŸla):" : "Generated name (start with BOS):"}</div>
        <div style={{display:"flex",gap:3,flexWrap:"wrap",marginBottom:8}}>
          <div style={{width:28,height:32,borderRadius:6,display:"flex",alignItems:"center",justifyContent:"center",fontSize: 11,fontWeight:700,color:"#F59E0B",background:"rgba(245,158,11,.08)",border:"1px solid rgba(245,158,11,.2)"}}>BOS</div>
          {gen.steps.map((ch,i) => (
            <div key={i} style={{
              width:28,height:32,borderRadius:6,display:"flex",alignItems:"center",justifyContent:"center",
              fontSize: 18,fontWeight:800,fontFamily:"'Fira Code',monospace",
              color:i<=step?"#E2E8F0":"#1E293B",
              background:i<=step?"rgba(99,102,241,.12)":"rgba(255,255,255,.02)",
              border:`1.5px solid ${i===step?"#6366F1":i<step?"rgba(99,102,241,.25)":"rgba(255,255,255,.04)"}`,
              transform:i===step?"scale(1.1)":"scale(1)",transition:"all .3s"
            }}>{i<=step?ch:"?"}</div>
          ))}
        </div>

        {/* Probability bars for current step */}
        {step >= 0 && step < probBars.length && (
          <div style={{marginBottom:8}}>
            <div style={{fontSize: 11,color:"#64748B",marginBottom:3}}>AdÄ±m {step+1} olasÄ±lÄ±klar:</div>
            {probBars[step].map((b,i)=>(
              <div key={i} style={{display:"flex",alignItems:"center",gap:4,marginBottom:2}}>
                <span style={{width:10,fontSize: 13,fontFamily:"'Fira Code',monospace",color:b.win?"#10B981":"#94A3B8",fontWeight:b.win?800:400}}>{b.ch}</span>
                <div style={{flex:1,height:8,background:"rgba(255,255,255,.03)",borderRadius:4,overflow:"hidden"}}>
                  <div style={{height:"100%",width:`${b.p*100}%`,borderRadius:4,background:b.win?"#10B981":"#334155",transition:"width .3s"}}/>
                </div>
                <span style={{width:26,fontSize: 11,fontFamily:"'Fira Code',monospace",color:"#64748B",textAlign:"right"}}>{(b.p*100).toFixed(0)}%</span>
              </div>
            ))}
          </div>
        )}

        <div style={{display:"flex",gap:6}}>
          <button onClick={()=>{setStep(0);setAuto(true);}} style={{flex:1,padding:"6px 14px",borderRadius:10,border:"none",background:"#6366F1",color:"#fff",fontSize: 14,fontWeight:700,cursor:"pointer",fontFamily:"inherit"}}>{lang === "tr" ? "â–¶ Ãœret" : "â–¶ Generate"}</button>
          <button onClick={()=>{setStep(-1);setAuto(false);}} style={{padding:"6px 10px",borderRadius:10,border:"1px solid rgba(255,255,255,.1)",background:"transparent",color:"#94A3B8",fontSize: 14,cursor:"pointer",fontFamily:"inherit"}}>â†º</button>
        </div>
      </div>
    </div>
  </VizBox>);
};

// â”€â”€â”€ WEEK 7 VIZ: SCALING LAWS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const ScalingLawsViz = () => {
  const [hover, setHover] = useState(-1);
  const models = [
    {name:"microGPT",params:"3.6K",tokens:"192K",loss:2.0,year:2024,x:5,y:72,c:"#F59E0B",r:4},
    {name:"GPT-1",params:"117M",tokens:"4.6B",loss:1.1,year:2018,x:22,y:58,c:"#0EA5E9",r:5},
    {name:"GPT-2",params:"1.5B",tokens:"40B",loss:0.8,year:2019,x:38,y:47,c:"#8B5CF6",r:6},
    {name:"GPT-3",params:"175B",tokens:"300B",loss:0.5,year:2020,x:55,y:34,c:"#10B981",r:7},
    {name:"Chinchilla",params:"70B",tokens:"1.4T",loss:0.4,year:2022,x:62,y:28,c:"#EC4899",r:6},
    {name:"LLaMA-2",params:"70B",tokens:"2T",loss:0.35,year:2023,x:70,y:24,c:"#EF4444",r:6},
    {name:"GPT-4",params:"~1.8T",tokens:"~13T",loss:0.2,year:2023,x:85,y:14,c:"#6366F1",r:8},
  ];
  return (<VizBox title={lang === "tr" ? "Scaling Laws â€” BÃ¼yÃ¼klÃ¼k vs Performans" : "Scaling Laws â€” Size vs Performance"} color="#14B8A6">
    <svg viewBox="0 0 100 85" style={{width:"100%",height:160,background:"rgba(0,0,0,.15)",borderRadius:10}}>
      <text x="50" y="82" fill="#64748B" fontSize="3" textAnchor="middle">{lang === "tr" ? "Parametre sayÄ±sÄ± â†’" : "Parameter count â†’"}</text>
      <text x="2" y="45" fill="#64748B" fontSize="3" transform="rotate(-90,2,45)">{lang === "tr" ? "â† Loss (dÃ¼ÅŸÃ¼k=iyi)" : "â† Loss (lower=better)"}</text>
      {/* Trend line */}
      <polyline points={models.map(m=>`${m.x},${m.y}`).join(" ")} fill="none" stroke="#14B8A640" strokeWidth="1" strokeDasharray="3,2"/>
      {models.map((m,i)=>(
        <g key={i} onMouseEnter={()=>setHover(i)} onMouseLeave={()=>setHover(-1)} style={{cursor:"pointer"}}>
          <circle cx={m.x} cy={m.y} r={hover===i?m.r*1.4:m.r} fill={`${m.c}${hover===i?"":"90"}`} stroke={m.c} strokeWidth={hover===i?1.5:0.5} style={{transition:"all .2s"}}/>
          <text x={m.x} y={m.y-m.r-2} fill={m.c} fontSize="3" fontWeight="700" textAnchor="middle">{m.name}</text>
        </g>
      ))}
    </svg>
    {hover >= 0 && (
      <div style={{padding:"8px 12px",borderRadius:8,background:`${models[hover].c}10`,border:`1px solid ${models[hover].c}25`,fontSize: 13,color:"#E2E8F0",marginTop:4}}>
        <strong style={{color:models[hover].c}}>{models[hover].name}</strong> ({models[hover].year}): {models[hover].params} parametre, {models[hover].tokens} token ile eÄŸitildi. Loss â‰ˆ {models[hover].loss}
      </div>
    )}
    {hover < 0 && <div style={{fontSize: 12,color:"#475569",textAlign:"center",marginTop:4}}>ğŸ’¡ Modellerin Ã¼zerine gelin â†’ detay gÃ¶rÃ¼n</div>}
  </VizBox>);
};

// â”€â”€â”€ WEEK 7 VIZ: EVOLUTION TIMELINE â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const EvolutionTimelineViz = () => {
  const [sel, setSel] = useState(0);
  const eras = [
    {year:"2017",name:"Transformer",icon:"ğŸ“„",c:"#0EA5E9",desc:"'Attention Is All You Need' â€” RNN'yi Ã¶ldÃ¼ren paper",detail:"Vaswani et al. Encoder-decoder, 65M param. Ã‡eviri gÃ¶revi. Self-attention + feed-forward = yeter!",cost:"~$10K"},
    {year:"2018",name:"GPT-1",icon:"ğŸŒ±",c:"#10B981",desc:"Ä°lk decoder-only language model",detail:"117M param, BookCorpus (4.6B token). Tek yÃ¶nlÃ¼ attention. Fine-tuning ile Ã§eÅŸitli gÃ¶revler.",cost:"~$50K"},
    {year:"2019",name:"GPT-2",icon:"ğŸ“ˆ",c:"#8B5CF6",desc:"'Too dangerous to release' â€” 1.5B parametre",detail:"WebText (40B token). Zero-shot yetenekler! Makale yazma, kod Ã¼retme baÅŸlangÄ±cÄ±.",cost:"~$250K"},
    {year:"2020",name:"GPT-3",icon:"ğŸš€",c:"#F59E0B",desc:"175B parametre â€” few-shot learning devrimi",detail:"300B token, 96 katman, 96 head. In-context learning keÅŸfi. API olarak sunuldu.",cost:"~$5M"},
    {year:"2022",name:"ChatGPT",icon:"ğŸ’¬",c:"#EF4444",desc:"RLHF ile hizalanmÄ±ÅŸ GPT-3.5 â€” dÃ¼nyayÄ± deÄŸiÅŸtirdi",detail:"InstructGPT + RLHF + SFT. 2 ayda 100M kullanÄ±cÄ±! Dialog formatÄ±, gÃ¼venlik filtreleri.",cost:"~$10M"},
    {year:"2023",name:"GPT-4 / LLaMA",icon:"ğŸŒ",c:"#6366F1",desc:"Multimodal + aÃ§Ä±k kaynak patlamasÄ±",detail:"GPT-4: ~1.8T MoE, gÃ¶rÃ¼ntÃ¼ girdi. LLaMA: aÃ§Ä±k aÄŸÄ±rlÄ±klar â†’ araÅŸtÄ±rma devrimi. Mistral, Qwen.",cost:"$100M+"},
    {year:"2024+",name:"Frontier",icon:"âš¡",c:"#14B8A6",desc:"Agent, MoE, uzun context, multimodal, reasoning",detail:"Claude 3.5, Gemini 1.5 (1M context), DeepSeek-V3 (MoE), o1 (reasoning). AÃ§Ä±k kaynak = GPT-4 seviyesi.",cost:"$200M+"},
  ];

  return (<VizBox title={lang === "tr" ? "Evrim Zaman Ã‡izelgesi â€” Transformer'dan GÃ¼nÃ¼mÃ¼ze" : "Evolution Timeline â€” From Transformer to Today"} color="#14B8A6">
    <div style={{display:"flex",gap:2,marginBottom:10,overflowX:"auto",paddingBottom:4}}>
      {eras.map((e,i)=>(
        <button key={i} onClick={()=>setSel(i)} style={{
          flex:"0 0 auto",padding:"5px 8px",borderRadius:8,border:`1.5px solid ${sel===i?e.c:`${e.c}30`}`,
          background:sel===i?`${e.c}15`:"transparent",cursor:"pointer",fontFamily:"inherit",
          display:"flex",flexDirection:"column",alignItems:"center",gap:1,minWidth:46,transition:"all .3s",
          transform:sel===i?"scale(1.05)":"scale(1)"
        }}>
          <span style={{fontSize: 17}}>{e.icon}</span>
          <span style={{fontSize: 10,fontWeight:700,color:sel===i?e.c:"#64748B"}}>{e.year}</span>
        </button>
      ))}
    </div>

    {/* Timeline bar */}
    <div style={{position:"relative",height:6,background:"rgba(255,255,255,.03)",borderRadius:3,marginBottom:10}}>
      <div style={{position:"absolute",left:0,top:0,height:6,borderRadius:3,width:`${(sel/(eras.length-1))*100}%`,background:eras[sel].c,transition:"all .4s"}}/>
      {eras.map((_,i)=>(
        <div key={i} style={{position:"absolute",left:`${(i/(eras.length-1))*100}%`,top:-1,width:8,height:8,borderRadius:4,
          background:i<=sel?eras[i].c:"#1E293B",border:`2px solid ${i===sel?eras[i].c:"#334155"}`,
          transform:"translateX(-4px)",transition:"all .3s",cursor:"pointer"}} onClick={()=>setSel(i)}/>
      ))}
    </div>

    {/* Detail card */}
    <div style={{padding:14,borderRadius:12,background:`${eras[sel].c}08`,border:`1.5px solid ${eras[sel].c}25`,transition:"all .3s"}}>
      <div style={{display:"flex",justifyContent:"space-between",alignItems:"center",marginBottom:6}}>
        <div>
          <span style={{fontSize: 21,marginRight:6}}>{eras[sel].icon}</span>
          <span style={{fontSize: 18,fontWeight:800,color:eras[sel].c}}>{eras[sel].name}</span>
          <span style={{fontSize: 13,color:"#64748B",marginLeft:6}}>({eras[sel].year})</span>
        </div>
        <span style={{fontSize: 12,padding:"3px 8px",borderRadius:6,background:`${eras[sel].c}15`,color:eras[sel].c,fontWeight:700}}>~{eras[sel].cost}</span>
      </div>
      <div style={{fontSize: 15,color:"#E2E8F0",fontWeight:600,marginBottom:4}}>{eras[sel].desc}</div>
      <div style={{fontSize: 13,color:"#94A3B8",lineHeight:1.5}}>{eras[sel].detail}</div>
    </div>
    <div style={{marginTop:6,fontSize: 11,color:"#475569",textAlign:"center"}}>{lang === "tr" ? "â† â†’ tÄ±klayarak zaman Ã§izelgesinde gezinin" : "â† â†’ click to navigate the timeline"}</div>
  </VizBox>);
};

// â”€â”€â”€ WEEK 7 VIZ: HARDWARE EVOLUTION â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const HardwareEvolutionViz = () => {
  const [sel, setSel] = useState(1);
  const hw = [
    {name:"CPU",icon:"ğŸ–¥ï¸",c:"#64748B",cores:"8-16",speed:"~0.5 TFLOPS",mem:"64GB DDR5",cost:"$500",note:"SÄ±ralÄ± iÅŸlem, genel amaÃ§lÄ±. microGPT burada Ã§alÄ±ÅŸÄ±r."},
    {name:"GPU (A100)",icon:"ğŸ®",c:"#10B981",cores:"6,912 CUDA",speed:"312 TFLOPS",mem:"80GB HBM3",cost:"$10K",note:"Paralel matris Ã§arpÄ±mÄ±. LLM eÄŸitiminin standardÄ±."},
    {name:"TPU v5",icon:"ğŸ§ ",c:"#0EA5E9",cores:lang === "tr" ? "Ã–zel MXU" : "Custom MXU",speed:"459 TFLOPS",mem:"16GB HBM",cost:"Cloud only",note:"Google'Ä±n Ã¶zel AI Ã§ipi. Gemini burada eÄŸitildi."},
    {name:"Groq LPU",icon:"âš¡",c:"#F59E0B",cores:lang === "tr" ? "Ã–zel TSP" : "Custom TSP",speed:"750 TFLOPS",mem:"230MB SRAM",cost:"Cloud only",note:"Ultra-dÃ¼ÅŸÃ¼k latency inference. Derleyici tabanlÄ± â€” GPU'dan 10Ã— hÄ±zlÄ± inference."},
  ];
  return (<VizBox title={lang === "tr" ? "DonanÄ±m Evrimi â€” CPU'dan AI Ã‡iplerine" : "Hardware Evolution â€” From CPUs to AI Chips"} color="#14B8A6">
    <div style={{display:"flex",gap:4,marginBottom:10}}>
      {hw.map((h,i)=>(
        <button key={i} onClick={()=>setSel(i)} style={{flex:1,padding:"8px 4px",borderRadius:10,border:`1.5px solid ${sel===i?h.c:`${h.c}30`}`,
          background:sel===i?`${h.c}12`:"transparent",cursor:"pointer",fontFamily:"inherit",textAlign:"center",transition:"all .3s"}}>
          <div style={{fontSize: 23}}>{h.icon}</div>
          <div style={{fontSize: 11,fontWeight:700,color:sel===i?h.c:"#64748B"}}>{h.name}</div>
        </button>
      ))}
    </div>
    <div style={{display:"grid",gridTemplateColumns:"1fr 1fr",gap:6,marginBottom:6}}>
      {[[lang === "tr" ? "Ã‡ekirdek" : "Cores",hw[sel].cores],[lang === "tr" ? "HÄ±z" : "Speed",hw[sel].speed],[lang === "tr" ? "Bellek" : "Memory",hw[sel].mem],[lang === "tr" ? "Fiyat" : "Price",hw[sel].cost]].map(([l,v],i)=>(
        <div key={i} style={{padding:"6px 10px",borderRadius:8,background:"rgba(255,255,255,.02)"}}>
          <div style={{fontSize: 11,color:"#64748B"}}>{l}</div>
          <div style={{fontSize: 15,fontWeight:700,fontFamily:"'Fira Code',monospace",color:hw[sel].c}}>{v}</div>
        </div>
      ))}
    </div>
    <div style={{fontSize: 13,color:"#94A3B8",padding:"6px 10px",borderRadius:8,background:`${hw[sel].c}06`}}>{hw[sel].note}</div>
  </VizBox>);
};

// â”€â”€â”€ WEEK 7 VIZ: TRAINING PIPELINE â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const TrainingPipelineViz = () => {
  const [step, setStep] = useState(0);
  const stages = [
    {name:"Pre-training",icon:"ğŸ“š",c:"#0EA5E9",sub:"Next-token prediction",desc:"Ä°nternet-Ã¶lÃ§eÄŸinde metin. microGPT'de Ã¶ÄŸrendiÄŸiniz TEMELDEKÄ° adÄ±m â€” milyarlarca token, haftalarca GPU.",data:"Trilyon token",cost:"%95 bÃ¼tÃ§e"},
    {name:"SFT",icon:"ğŸ‘¨â€ğŸ«",c:"#10B981",sub:"Supervised Fine-tuning",desc:"Ä°nsan yazÄ±mÄ± soru-cevap Ã§iftleri ile fine-tune. Model 'assistant' gibi davranmayÄ± Ã¶ÄŸrenir.",data:"~100K Ã¶rnek",cost:"%3 bÃ¼tÃ§e"},
    {name:"RLHF / DPO",icon:"ğŸ‘",c:"#EC4899",sub:lang === "tr" ? "Ä°nsan Hizalama" : "Human Alignment",desc:"Ä°nsan tercihleri: 'A yanÄ±tÄ± mÄ± B mi daha iyi?' Reward model eÄŸitimi + PPO/DPO ile gÃ¼ncelleme.",data:"~50K tercih",cost:"%2 bÃ¼tÃ§e"},
  ];
  return (<VizBox title={lang === "tr" ? "Modern EÄŸitim Pipeline'Ä± â€” 3 AÅŸama" : "Modern Training Pipeline â€” 3 Stages"} color="#14B8A6">
    <div style={{display:"flex",gap:6,marginBottom:10}}>
      {stages.map((s,i)=>(
        <div key={i} onClick={()=>setStep(i)} style={{flex:1,padding:"10px 6px",borderRadius:10,cursor:"pointer",textAlign:"center",
          border:`1.5px solid ${step===i?s.c:`${s.c}25`}`,background:step===i?`${s.c}12`:"transparent",transition:"all .3s",
          transform:step===i?"scale(1.03)":"scale(1)"}}>
          <div style={{fontSize: 25}}>{s.icon}</div>
          <div style={{fontSize: 12,fontWeight:700,color:step===i?s.c:"#64748B"}}>{s.name}</div>
          <div style={{fontSize: 10,color:"#475569"}}>{s.sub}</div>
        </div>
      ))}
    </div>
    <div style={{display:"flex",gap:4,marginBottom:6}}>
      {stages.map((_,i)=>(<div key={i} style={{flex:1,height:4,borderRadius:2,background:i<=step?stages[i].c:"#1E293B",transition:"all .3s"}}/>))}
    </div>
    <div style={{padding:10,borderRadius:10,background:`${stages[step].c}08`,border:`1px solid ${stages[step].c}20`}}>
      <div style={{fontSize: 14,color:"#E2E8F0",marginBottom:4}}>{stages[step].desc}</div>
      <div style={{display:"flex",gap:8,fontSize: 12}}>
        <span style={{color:stages[step].c}}>ğŸ“Š {stages[step].data}</span>
        <span style={{color:"#64748B"}}>ğŸ’° {stages[step].cost}</span>
      </div>
    </div>
  </VizBox>);
};

// â”€â”€â”€ WEEK 7 VIZ: TOKEN EVOLUTION â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const TokenEvolutionViz = () => {
  const [sel, setSel] = useState(0);
  const methods = [
    {name:"Karakter (microGPT)",c:"#F59E0B",vocab:"27",example:"'playing' â†’ p,l,a,y,i,n,g (7 token)",pro:"Basit, hiÃ§ OOV yok",con:"Ã‡ok uzun diziler, anlam yok"},
    {name:"BPE (GPT-2/3)",c:"#8B5CF6",vocab:"50,257",example:"'playing' â†’ play + ing (2 token)",pro:"Dengeli, alt-kelime semantiÄŸi",con:"Tokenizer eÄŸitimi gerekli"},
    {name:"SentencePiece (LLaMA)",c:"#10B981",vocab:"32,000",example:"'playing' â†’ â–play + ing (2 token)",pro:"Unicode-aware, dil baÄŸÄ±msÄ±z",con:"Daha yavaÅŸ tokenization"},
    {name:"tiktoken (GPT-4)",c:"#6366F1",vocab:"100,277",example:"'playing' â†’ playing (1 token!)",pro:"Ã‡ok verimli, bÃ¼yÃ¼k vocab",con:"Bellek kullanÄ±mÄ± yÃ¼ksek"},
  ];
  return (<VizBox title="Tokenization Evrimi â€” Karakterden BPE'ye" color="#14B8A6">
    <div style={{display:"flex",gap:3,marginBottom:8}}>
      {methods.map((m,i)=>(
        <button key={i} onClick={()=>setSel(i)} style={{flex:1,padding:"5px 4px",borderRadius:8,border:`1.5px solid ${sel===i?m.c:`${m.c}25`}`,
          background:sel===i?`${m.c}12`:"transparent",color:sel===i?m.c:"#64748B",fontSize: 10,fontWeight:700,cursor:"pointer",fontFamily:"inherit",textAlign:"center",transition:"all .3s"}}>
          {m.name}
        </button>
      ))}
    </div>
    <div style={{padding:10,borderRadius:10,background:`${methods[sel].c}08`,border:`1px solid ${methods[sel].c}20`}}>
      <div style={{fontSize: 14,fontFamily:"'Fira Code',monospace",color:methods[sel].c,marginBottom:4}}>{methods[sel].example}</div>
      <div style={{fontSize: 13,color:"#94A3B8",marginBottom:2}}>Vocab: <strong style={{color:"#E2E8F0"}}>{methods[sel].vocab}</strong> token</div>
      <div style={{fontSize: 12,color:"#10B981"}}>âœ… {methods[sel].pro}</div>
      <div style={{fontSize: 12,color:"#EF4444"}}>âš ï¸ {methods[sel].con}</div>
    </div>
  </VizBox>);
};

// â”€â”€â”€ WEEK 7 VIZ: ATTENTION EVOLUTION â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const AttentionEvolutionViz = () => {
  const [sel, setSel] = useState(0);
  const variants = [
    {name:"Vanilla (Bu kod)",c:"#F59E0B",complexity:"O(nÂ²)",mem:"O(nÂ²)",desc:"Her token tÃ¼m Ã¶nceki tokenlara bakar. Basit ama nÂ² bellek."},
    {name:"Multi-Query (2019)",c:"#0EA5E9",complexity:"O(nÂ²)",mem:"O(nÂ²/h)",desc:"K,V tek kopya, Q head baÅŸÄ±na. KV cache %4Ã—â†“. PaLM, Falcon."},
    {name:"Flash Attention (2022)",c:"#10B981",complexity:"O(nÂ²)",mem:"O(n)",desc:"AynÄ± matematik, farklÄ± bellek eriÅŸim dÃ¼zeni. IO-aware tiling â†’ 2-4Ã— hÄ±zlÄ±!"},
    {name:"Sliding Window (Mistral)",c:"#EC4899",complexity:"O(nÃ—w)",mem:"O(w)",desc:"Sabit pencere (w=4096). Ã–tesini katman katman gÃ¶rebilir â†’ âˆ teorik context."},
  ];
  return (<VizBox title="Attention Evrimi â€” Vanilla'dan Flash'a" color="#14B8A6">
    <div style={{display:"flex",gap:3,marginBottom:8}}>
      {variants.map((v,i)=>(
        <button key={i} onClick={()=>setSel(i)} style={{flex:1,padding:"5px 4px",borderRadius:8,border:`1.5px solid ${sel===i?v.c:`${v.c}25`}`,
          background:sel===i?`${v.c}12`:"transparent",color:sel===i?v.c:"#64748B",fontSize: 10,fontWeight:700,cursor:"pointer",fontFamily:"inherit",textAlign:"center",transition:"all .3s"}}>
          {v.name}
        </button>
      ))}
    </div>
    <div style={{padding:10,borderRadius:10,background:`${variants[sel].c}08`,border:`1px solid ${variants[sel].c}20`}}>
      <div style={{display:"flex",gap:12,marginBottom:4}}>
        <span style={{fontSize: 13,color:"#64748B"}}>Hesaplama: <strong style={{color:variants[sel].c}}>{variants[sel].complexity}</strong></span>
        <span style={{fontSize: 13,color:"#64748B"}}>Bellek: <strong style={{color:variants[sel].c}}>{variants[sel].mem}</strong></span>
      </div>
      <div style={{fontSize: 13,color:"#94A3B8"}}>{variants[sel].desc}</div>
    </div>
  </VizBox>);
};

// â”€â”€â”€ WEEK 7 VIZ: OPENSOURCE MAP â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const OpensourceMapViz = () => {
  const [sel, setSel] = useState(-1);
  const models = [
    {name:"LLaMA 3.1",org:"Meta",params:"405B",c:"#0EA5E9",desc:"AÃ§Ä±k aÄŸÄ±rlÄ±k devrimi. 128K context. AraÅŸtÄ±rma patlamasÄ±nÄ± tetikledi."},
    {name:"Mistral",org:"Mistral AI",params:"7-22B",c:"#F59E0B",desc:"KÃ¼Ã§Ã¼k ama gÃ¼Ã§lÃ¼. Sliding window attention. MoE (Mixtral 8Ã—22B)."},
    {name:"DeepSeek-V3",org:"DeepSeek",params:"671B MoE",c:"#10B981",desc:"Aktif: 37B. Ãœcretsiz API. Ã‡in'den aÃ§Ä±k kaynak lider."},
    {name:"Qwen 2.5",org:"Alibaba",params:"72B",c:"#EC4899",desc:"Ã‡ok dilli. Kod, matematik, reasoning odaklÄ±. Coder varyantÄ± Ã§ok gÃ¼Ã§lÃ¼."},
    {name:"Gemma 2",org:"Google",params:"27B",c:"#8B5CF6",desc:"KÃ¼Ã§Ã¼k, verimli. Knowledge distillation ile eÄŸitilmiÅŸ."},
  ];
  return (<VizBox title={lang === "tr" ? "AÃ§Ä±k Kaynak Modeller â€” 2024 HaritasÄ±" : "Open Source Models â€” 2024 Map"} color="#14B8A6">
    <div style={{display:"flex",gap:4,flexWrap:"wrap",marginBottom:8}}>
      {models.map((m,i)=>(
        <button key={i} onClick={()=>setSel(sel===i?-1:i)} style={{padding:"6px 10px",borderRadius:10,border:`1.5px solid ${sel===i?m.c:`${m.c}25`}`,
          background:sel===i?`${m.c}12`:"transparent",cursor:"pointer",fontFamily:"inherit",transition:"all .3s"}}>
          <div style={{fontSize: 13,fontWeight:700,color:sel===i?m.c:"#94A3B8"}}>{m.name}</div>
          <div style={{fontSize: 10,color:"#475569"}}>{m.org} â€¢ {m.params}</div>
        </button>
      ))}
    </div>
    {sel >= 0 ? (
      <div style={{padding:10,borderRadius:10,background:`${models[sel].c}08`,border:`1px solid ${models[sel].c}20`,fontSize: 13,color:"#94A3B8"}}>{models[sel].desc}</div>
    ) : (
      <div style={{fontSize: 12,color:"#475569",textAlign:"center",padding:8}}>ğŸ’¡ Bir modele tÄ±klayÄ±n â†’ detay gÃ¶rÃ¼n</div>
    )}
  </VizBox>);
};

// â”€â”€â”€ WEEK 7 VIZ: TRENDS RADAR â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const TrendsRadarViz = () => {
  const [sel, setSel] = useState(0);
  const trends = [
    {name:"MoE",icon:"ğŸ§©",c:"#F59E0B",desc:"Mixture of Experts: 8 uzman aÄŸ, her token sadece 2'sini aktive eder. Toplam parametre Ã§ok ama aktif parametre az â†’ verimli. GPT-4, Mixtral, DeepSeek-V3."},
    {name:"RAG",icon:"ğŸ“š",c:"#0EA5E9",desc:"Retrieval-Augmented Generation: Model dÄ±ÅŸ bilgi tabanÄ±ndan (dokÃ¼manlar, web) ilgili bilgiyi Ã§ekip yanÄ±ta ekler. HalÃ¼sinasyonu azaltÄ±r, gÃ¼ncel bilgi saÄŸlar."},
    {name:"Agent",icon:"ğŸ¤–",c:"#10B981",desc:"AI Agent: Model araÃ§ kullanÄ±r â€” kod Ã§alÄ±ÅŸtÄ±rma, web arama, API Ã§aÄŸrÄ±larÄ±. ReAct, function calling, tool use. Claude, GPT-4 ile entegre."},
    {name:"Multimodal",icon:"ğŸ¨",c:"#EC4899",desc:"Metin + gÃ¶rÃ¼ntÃ¼ + ses + video. GPT-4V, Gemini, Claude 3: gÃ¶rÃ¼ntÃ¼ anlama. Sora: video Ã¼retimi. Whisper: sesâ†’metin."},
    {name:"Reasoning",icon:"ğŸ§ ",c:"#6366F1",desc:"Chain-of-thought, o1/o3: dÃ¼ÅŸÃ¼nme zinciri ile karmaÅŸÄ±k problemleri adÄ±m adÄ±m Ã§Ã¶zme. Matematik, kod, mantÄ±k gÃ¶revlerinde bÃ¼yÃ¼k sÄ±Ã§rama."},
  ];
  return (<VizBox title={lang === "tr" ? "GÃ¼ncel Trendler â€” AI Nereye Gidiyor?" : "Current Trends â€” Where is AI Headed?"} color="#14B8A6">
    <div style={{display:"flex",gap:4,marginBottom:10}}>
      {trends.map((t,i)=>(
        <button key={i} onClick={()=>setSel(i)} style={{flex:1,padding:"8px 4px",borderRadius:10,
          border:`1.5px solid ${sel===i?t.c:`${t.c}25`}`,background:sel===i?`${t.c}12`:"transparent",
          cursor:"pointer",fontFamily:"inherit",textAlign:"center",transition:"all .3s"}}>
          <div style={{fontSize: 21}}>{t.icon}</div>
          <div style={{fontSize: 11,fontWeight:700,color:sel===i?t.c:"#64748B"}}>{t.name}</div>
        </button>
      ))}
    </div>
    <div style={{padding:12,borderRadius:10,background:`${trends[sel].c}08`,border:`1px solid ${trends[sel].c}20`,transition:"all .3s"}}>
      <div style={{fontSize: 14,color:"#E2E8F0",lineHeight:1.6}}>{trends[sel].desc}</div>
    </div>
  </VizBox>);
};


const ConceptMapViz = () => {
  const nodes = [
    { id: "data", l: "Veri (names.txt)", x: 50, y: 20, c: "#0EA5E9", w: 0 },
    { id: "tok", l: "Tokenization", x: 50, y: 55, c: "#8B5CF6", w: 1 },
    { id: "emb", l: "Embedding", x: 20, y: 90, c: "#0EA5E9", w: 1 },
    { id: "pos", l: "Pos Embedding", x: 80, y: 90, c: "#8B5CF6", w: 1 },
    { id: "norm", l: "RMSNorm", x: 50, y: 125, c: "#F59E0B", w: 4 },
    { id: "attn", l: "Self-Attention", x: 25, y: 160, c: "#10B981", w: 3 },
    { id: "mlp", l: "MLP (FFN)", x: 75, y: 160, c: "#EC4899", w: 4 },
    { id: "res", l: "Residual", x: 50, y: 195, c: "#F59E0B", w: 4 },
    { id: "logit", l: "Logits â†’ Softmax", x: 50, y: 230, c: "#EF4444", w: 6 },
    { id: "loss", l: "Cross-Entropy Loss", x: 20, y: 265, c: "#EF4444", w: 5 },
    { id: "grad", l: "Autograd (Backward)", x: 50, y: 300, c: "#F59E0B", w: 2 },
    { id: "adam", l: "Adam Optimizer", x: 80, y: 265, c: "#EC4899", w: 5 },
    { id: "samp", l: "Sampling", x: 80, y: 230, c: "#6366F1", w: 6 },
  ];
  const edges = [
    ["data", "tok"], ["tok", "emb"], ["tok", "pos"], ["emb", "norm"], ["pos", "norm"],
    ["norm", "attn"], ["norm", "mlp"], ["attn", "res"], ["mlp", "res"],
    ["res", "logit"], ["logit", "loss"], ["loss", "grad"], ["grad", "adam"],
    ["logit", "samp"],
  ];
  const nMap = Object.fromEntries(nodes.map(n => [n.id, n]));
  return (
    <div style={{ margin: "14px 0", padding: 16, borderRadius: 14, background: "rgba(255,255,255,0.02)", border: "1px solid rgba(255,255,255,0.06)" }}>
      <div style={{ display: "flex", alignItems: "center", gap: 8, marginBottom: 10 }}>
        <span style={{ fontSize: 19 }}>ğŸ—ºï¸</span>
        <span style={{ fontSize: 15, fontWeight: 700, color: "#0EA5E9", textTransform: "uppercase", letterSpacing: ".06em" }}>Kavram HaritasÄ± â€” TÃ¼m BileÅŸenler</span>
      </div>
      <svg viewBox="0 0 100 320" style={{ width: "100%", maxWidth: 500, margin: "0 auto", display: "block" }}>
        {edges.map(([a, b], i) => {
          const from = nMap[a], to = nMap[b];
          return <line key={i} x1={from.x} y1={from.y + 8} x2={to.x} y2={to.y - 8} stroke="rgba(255,255,255,0.08)" strokeWidth="0.5" />;
        })}
        {nodes.map((n) => (
          <g key={n.id}>
            <rect x={n.x - 18} y={n.y - 8} width={36} height={16} rx="4" fill={`${n.c}15`} stroke={`${n.c}40`} strokeWidth="0.5" />
            <text x={n.x} y={n.y + 1} textAnchor="middle" fill={n.c} fontSize="3.5" fontWeight="600">{n.l}</text>
            <text x={n.x} y={n.y + 6} textAnchor="middle" fill="#475569" fontSize="2.2">H{n.w}</text>
          </g>
        ))}
      </svg>
      <div style={{ marginTop: 8, textAlign: "center", fontSize: 12, color: "#64748B" }}>Her kutu bir kavram, H# = Ã¶ÄŸrenilen hafta. Oklar veri akÄ±ÅŸÄ±nÄ± gÃ¶sterir.</div>
    </div>
  );
};



// â•â•â• TRANSFORMER PAPER â€” RICH INTERACTIVE COMPONENTS (from transformer_explorer.jsx) â•â•â•

// TE UI Primitives
const TEBox = ({ children, style }) => (
  <div style={{ background: "rgba(0,0,0,0.25)", borderRadius: 16, padding: 20, marginBottom: 16, ...style }}>{children}</div>
);
const TELabel = ({ color, children }) => (
  <div style={{ fontSize: 13, color, fontWeight: 700, marginBottom: 12, textTransform: "uppercase", letterSpacing: "0.1em" }}>{children}</div>
);
const TEInfoBox = ({ color, icon, title, children }) => (
  <div style={{ background: `${color}10`, border: `1px solid ${color}30`, borderRadius: 14, padding: "14px 18px", marginBottom: 16, display: "flex", alignItems: "flex-start", gap: 12 }}>
    <span style={{ fontSize: 24, flexShrink: 0, marginTop: 2 }}>{icon}</span>
    <div><div style={{ fontSize: 15, fontWeight: 700, color, marginBottom: 4 }}>{title}</div><div style={{ fontSize: 14, lineHeight: 1.7, color: "#CBD5E1" }}>{children}</div></div>
  </div>
);
const TEAnalojiBox = ({ emoji, title, children }) => (
  <div style={{ background: "linear-gradient(135deg, rgba(99,102,241,0.08), rgba(236,72,153,0.08))", border: "1px solid rgba(99,102,241,0.2)", borderRadius: 14, padding: "16px 18px", marginBottom: 14 }}>
    <div style={{ fontSize: 15, fontWeight: 700, color: "#A78BFA", marginBottom: 6 }}>{emoji} {title}</div>
    <div style={{ fontSize: 14, lineHeight: 1.7, color: "#CBD5E1" }}>{children}</div>
  </div>
);
const TESlider = ({ label, value, onChange, min, max, step, color }) => (
  <div style={{ display: "flex", alignItems: "center", gap: 10, marginBottom: 8 }}>
    <span style={{ fontSize: 13, color: "#94A3B8", minWidth: 55, whiteSpace: "nowrap" }}>{label}</span>
    <input type="range" min={min} max={max} step={step} value={value} onChange={e => onChange(+e.target.value)} style={{ flex: 1 }} />
    <span style={{ fontSize: 15, fontWeight: 800, color, minWidth: 44, textAlign: "right", fontFamily: "'Fira Code', monospace" }}>
      {typeof value === "number" ? (Number.isInteger(value) ? value : value.toFixed(1)) : value}
    </span>
  </div>
);
const TENum = ({ v, color = "#E2E8F0", size = 16 }) => (
  <span style={{ fontFamily: "'Fira Code', monospace", fontSize: size, fontWeight: 700, color }}>
    {typeof v === "number" ? (Math.abs(v) < 0.005 ? "0.00" : v.toFixed(2)) : v}
  </span>
);
const TEStepBadge = ({ n, active, color, onClick }) => (
  <button onClick={onClick} style={{
    width: 32, height: 32, borderRadius: 8, display: "flex", alignItems: "center", justifyContent: "center",
    fontSize: 14, fontWeight: 800, border: active ? `2px solid ${color}` : "2px solid rgba(255,255,255,0.06)",
    background: active ? `${color}20` : "transparent", color: active ? color : "#475569",
    cursor: "pointer", transition: "all .2s", fontFamily: "inherit"
  }}>{n}</button>
);

// â•â•â• STEP-BY-STEP SOFTMAX (Rich) â•â•â•
const TESoftmax = () => {
  const [vals, setVals] = useState([2.0, 1.0, 0.5, -1.0]);
  const [step, setStep] = useState(0);
  const labels = [lang === "tr" ? "kedi" : "cat", lang === "tr" ? "kÃ¶pek" : "dog", "kuÅŸ", "balÄ±k"];
  const emojis = ["ğŸ±", "ğŸ•", "ğŸ¦", "ğŸŸ"];
  const colors = ["#0EA5E9", "#10B981", "#F59E0B", "#EC4899"];

  const maxV = Math.max(...vals);
  const shifted = vals.map(v => v - maxV);
  const exps = shifted.map(v => Math.exp(v));
  const sumExp = exps.reduce((a, b) => a + b, 0);
  const probs = exps.map(v => v / sumExp);

  const stepsData = [
    { title: "Ham Skorlar (Logits)", desc: "Model her kelime iÃ§in bir skor Ã¼retir. YÃ¼ksek skor = model o kelimeden daha emin.", color: "#0EA5E9" },
    { title: "GÃ¼venlik: max Ã§Ä±kar", desc: `En bÃ¼yÃ¼k deÄŸer: ${maxV.toFixed(1)}. TÃ¼m deÄŸerlerden bunu Ã§Ä±karÄ±yoruz. Bu sayÄ±lar Ã§ok bÃ¼yÃ¼rse e^x PATLAYACAKTI! Bu trick bunu Ã¶nler. SonuÃ§ deÄŸiÅŸmez!`, color: "#8B5CF6" },
    { title: "e Ã¼zeri x (Ã¼stel)", desc: "Her deÄŸerin e^x'ini alÄ±yoruz. Bu negatif sayÄ±larÄ± pozitife Ã§evirir ve bÃ¼yÃ¼k farklarÄ± DAHA bÃ¼yÃ¼k farklara dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r.", color: "#F59E0B" },
    { title: "Toplam hesapla", desc: `TÃ¼m e^x deÄŸerlerini topluyoruz: ${sumExp.toFixed(3)}. Bu bÃ¶len olacak. BÃ¶ylece sonuÃ§lar 0-1 arasÄ±na sÄ±kÄ±ÅŸacak.`, color: "#EF4444" },
    { title: "BÃ¶l â†’ OlasÄ±lÄ±k!", desc: "Her e^x deÄŸerini toplama bÃ¶lÃ¼yoruz. SonuÃ§: 0-1 arasÄ± olasÄ±lÄ±klar ve toplamlarÄ± tam 1!", color: "#10B981" },
  ];

  return (
    <TEBox>
      <TELabel color="#8B5CF6">{"ğŸ§® Ä°nteraktif Softmax â€” AdÄ±m AdÄ±m Hesaplama"}</TELabel>

      <div style={{ marginBottom: 16, padding: "12px 16px", borderRadius: 12, background: "rgba(255,255,255,0.02)", border: "1px solid rgba(255,255,255,0.06)" }}>
        <div style={{ fontSize: 12, color: "#64748B", marginBottom: 8 }}>{"â¬‡ï¸ KaydÄ±rÄ±cÄ±larÄ± hareket ettir â€” tÃ¼m hesaplama canlÄ± gÃ¼ncellenir!"}</div>
        {vals.map((v, i) => (
          <TESlider key={i} label={`${emojis[i]} ${labels[i]}:`} value={v} min={-3} max={5} step={0.1} color={colors[i]}
            onChange={nv => { const nvals = [...vals]; nvals[i] = nv; setVals(nvals); }} />
        ))}
      </div>

      <div style={{ display: "flex", gap: 6, marginBottom: 14, justifyContent: "center" }}>
        {stepsData.map((s, i) => (
          <TEStepBadge key={i} n={i + 1} active={step === i} color={s.color} onClick={() => setStep(i)} />
        ))}
      </div>

      <div style={{ padding: "14px 18px", borderRadius: 12, background: `${stepsData[step].color}0A`, border: `1px solid ${stepsData[step].color}25`, marginBottom: 16 }}>
        <div style={{ fontSize: 16, fontWeight: 800, color: stepsData[step].color, marginBottom: 4 }}>
          AdÄ±m {step + 1}: {stepsData[step].title}
        </div>
        <div style={{ fontSize: 14, color: "#CBD5E1", lineHeight: 1.7 }}>{stepsData[step].desc}</div>
      </div>

      <div style={{ overflowX: "auto" }}>
        <table style={{ width: "100%", borderCollapse: "collapse", fontSize: 14 }}>
          <thead>
            <tr>
              <th style={{ padding: "8px 10px", textAlign: "left", color: "#64748B", fontSize: 11, borderBottom: "1px solid rgba(255,255,255,0.08)" }}>Kelime</th>
              <th style={{ padding: "8px 10px", textAlign: "center", color: step >= 0 ? "#0EA5E9" : "#1E293B", fontSize: 11, borderBottom: "1px solid rgba(255,255,255,0.08)", transition: "color .3s" }}>{"â‘  Skor"}</th>
              <th style={{ padding: "8px 10px", textAlign: "center", color: step >= 1 ? "#8B5CF6" : "#1E293B", fontSize: 11, borderBottom: "1px solid rgba(255,255,255,0.08)", transition: "color .3s" }}>{"â‘¡ -max"}</th>
              <th style={{ padding: "8px 10px", textAlign: "center", color: step >= 2 ? "#F59E0B" : "#1E293B", fontSize: 11, borderBottom: "1px solid rgba(255,255,255,0.08)", transition: "color .3s" }}>{"â‘¢ e^x"}</th>
              <th style={{ padding: "8px 10px", textAlign: "center", color: step >= 3 ? "#EF4444" : "#1E293B", fontSize: 11, borderBottom: "1px solid rgba(255,255,255,0.08)", transition: "color .3s" }}>{"â‘£ /toplam"}</th>
              <th style={{ padding: "8px 10px", textAlign: "center", color: step >= 4 ? "#10B981" : "#1E293B", fontSize: 11, borderBottom: "1px solid rgba(255,255,255,0.08)", transition: "color .3s" }}>{"â‘¤ OlasÄ±lÄ±k"}</th>
            </tr>
          </thead>
          <tbody>
            {labels.map((l, i) => (
              <tr key={i} style={{ background: step >= 4 && probs[i] === Math.max(...probs) ? "rgba(16,185,129,0.06)" : "transparent" }}>
                <td style={{ padding: "10px", fontWeight: 700, color: colors[i], borderBottom: "1px solid rgba(255,255,255,0.04)" }}>
                  {emojis[i]} {l}
                </td>
                <td style={{ padding: "10px", textAlign: "center", borderBottom: "1px solid rgba(255,255,255,0.04)", opacity: step >= 0 ? 1 : 0.12, transition: "opacity .4s" }}>
                  <TENum v={vals[i]} color="#0EA5E9" />
                </td>
                <td style={{ padding: "10px", textAlign: "center", borderBottom: "1px solid rgba(255,255,255,0.04)", opacity: step >= 1 ? 1 : 0.12, transition: "opacity .4s" }}>
                  <TENum v={shifted[i]} color="#8B5CF6" />
                </td>
                <td style={{ padding: "10px", textAlign: "center", borderBottom: "1px solid rgba(255,255,255,0.04)", opacity: step >= 2 ? 1 : 0.12, transition: "opacity .4s" }}>
                  <TENum v={exps[i]} color="#F59E0B" />
                </td>
                <td style={{ padding: "10px", textAlign: "center", borderBottom: "1px solid rgba(255,255,255,0.04)", opacity: step >= 3 ? 1 : 0.12, transition: "opacity .4s" }}>
                  <span style={{ fontFamily: "'Fira Code', monospace", fontSize: 12, color: "#EF4444" }}>/{sumExp.toFixed(2)}</span>
                </td>
                <td style={{ padding: "10px", textAlign: "center", borderBottom: "1px solid rgba(255,255,255,0.04)", opacity: step >= 4 ? 1 : 0.12, transition: "opacity .4s" }}>
                  <TENum v={probs[i]} color="#10B981" />
                  <span style={{ fontSize: 11, color: "#64748B", marginLeft: 4 }}>({(probs[i] * 100).toFixed(1)}%)</span>
                </td>
              </tr>
            ))}
          </tbody>
        </table>
      </div>

      {step >= 4 && (
        <div style={{ display: "flex", gap: 10, alignItems: "flex-end", justifyContent: "center", height: 110, marginTop: 16, padding: "0 20px" }}>
          {labels.map((l, i) => (
            <div key={i} style={{ display: "flex", flexDirection: "column", alignItems: "center", gap: 4, flex: 1 }}>
              <div style={{ fontSize: 13, fontWeight: 700, color: "#E2E8F0" }}>{(probs[i] * 100).toFixed(1)}%</div>
              <div style={{
                width: "100%", maxWidth: 60, height: Math.max(4, probs[i] * 90), borderRadius: 8,
                background: `linear-gradient(180deg, ${colors[i]}, ${colors[i]}80)`,
                transition: "height 0.5s cubic-bezier(.4,0,.2,1)"
              }} />
              <div style={{ fontSize: 12, color: "#94A3B8" }}>{emojis[i]} {l}</div>
            </div>
          ))}
        </div>
      )}

      <div style={{ marginTop: 16, padding: "12px 16px", borderRadius: 10, background: "rgba(139,92,246,0.06)", border: "1px solid rgba(139,92,246,0.15)", textAlign: "center" }}>
        <div style={{ fontSize: 11, color: "#8B5CF6", fontWeight: 700, marginBottom: 4, textTransform: "uppercase", letterSpacing: "0.1em" }}>{"FormÃ¼l"}</div>
        <div style={{ fontSize: 18, fontWeight: 700, color: "#E2E8F0", fontFamily: "'Georgia', serif" }}>
          {"softmax(x"}<sub>{"i"}</sub>{") = e"}<sup>{"(x"}<sub>{"i"}</sub>{" - max)"}</sup>{" / Î£ e"}<sup>{"(x"}<sub>{"j"}</sub>{" - max)"}</sup>
        </div>
      </div>
    </TEBox>
  );
};

// â•â•â• DOT PRODUCT with sliders (Rich â€” 4D) â•â•â•
const TEDotProduct = () => {
  const [q, setQ] = useState([0.5, 0.8, -0.3, 0.6]);
  const [k, setK] = useState([0.7, 0.5, 0.2, -0.4]);
  const colors = ["#0EA5E9", "#10B981", "#F59E0B", "#EC4899"];

  const products = q.map((v, i) => v * k[i]);
  const result = products.reduce((a, b) => a + b, 0);

  return (
    <TEBox>
      <TELabel color="#0EA5E9">{"ğŸ® Ä°nteraktif Dot Product (Nokta Ã‡arpÄ±mÄ±)"}</TELabel>

      <div style={{ display: "grid", gridTemplateColumns: "1fr 1fr", gap: 16, marginBottom: 16 }}>
        <div style={{ padding: 14, borderRadius: 12, background: "rgba(14,165,233,0.06)", border: "1px solid rgba(14,165,233,0.15)" }}>
          <div style={{ fontSize: 13, fontWeight: 700, color: "#0EA5E9", marginBottom: 8 }}>{"ğŸ” Query (Q) â€” Ne arÄ±yorum?"}</div>
          {q.map((v, i) => (
            <TESlider key={i} label={`q${i}:`} value={v} min={-2} max={2} step={0.1} color="#0EA5E9"
              onChange={nv => { const nq = [...q]; nq[i] = nv; setQ(nq); }} />
          ))}
        </div>
        <div style={{ padding: 14, borderRadius: 12, background: "rgba(16,185,129,0.06)", border: "1px solid rgba(16,185,129,0.15)" }}>
          <div style={{ fontSize: 13, fontWeight: 700, color: "#10B981", marginBottom: 8 }}>{"ğŸ—ï¸ Key (K) â€” Bende ne var?"}</div>
          {k.map((v, i) => (
            <TESlider key={i} label={`k${i}:`} value={v} min={-2} max={2} step={0.1} color="#10B981"
              onChange={nv => { const nk = [...k]; nk[i] = nv; setK(nk); }} />
          ))}
        </div>
      </div>

      <div style={{ padding: 16, borderRadius: 12, background: "rgba(0,0,0,0.2)", border: "1px solid rgba(255,255,255,0.06)", marginBottom: 14 }}>
        <div style={{ fontSize: 12, color: "#64748B", marginBottom: 10 }}>{"Hesaplama: her elemanÄ± Ã§arp, sonra topla"}</div>
        <div style={{ display: "flex", flexWrap: "wrap", gap: 8, justifyContent: "center", alignItems: "center" }}>
          {q.map((v, i) => (
            <React.Fragment key={i}>
              {i > 0 && <span style={{ fontSize: 18, color: "#475569", fontWeight: 800 }}>+</span>}
              <div style={{ padding: "8px 12px", borderRadius: 10, background: `${colors[i]}10`, border: `1px solid ${colors[i]}25`, textAlign: "center" }}>
                <div style={{ display: "flex", alignItems: "center", gap: 4, justifyContent: "center" }}>
                  <TENum v={v} color="#0EA5E9" size={14} />
                  <span style={{ color: "#475569", fontSize: 12 }}>{"Ã—"}</span>
                  <TENum v={k[i]} color="#10B981" size={14} />
                </div>
                <div style={{ fontSize: 10, color: "#64748B", marginTop: 2 }}>{"= "}<TENum v={products[i]} color={colors[i]} size={12} /></div>
              </div>
            </React.Fragment>
          ))}
          <span style={{ fontSize: 22, color: "#475569", fontWeight: 800, margin: "0 6px" }}>=</span>
          <div style={{
            padding: "12px 20px", borderRadius: 12, textAlign: "center",
            background: result > 0 ? "rgba(16,185,129,0.12)" : result < 0 ? "rgba(239,68,68,0.12)" : "rgba(255,255,255,0.05)",
            border: `2px solid ${result > 0 ? "#10B981" : result < 0 ? "#EF4444" : "#475569"}40`,
            transition: "all .3s"
          }}>
            <TENum v={result} color={result > 0 ? "#10B981" : result < 0 ? "#EF4444" : "#94A3B8"} size={24} />
            <div style={{ fontSize: 11, color: "#94A3B8", marginTop: 2 }}>
              {result > 1 ? "ğŸ”¥ Ã‡ok benzer!" : result > 0.3 ? "ğŸ‘ Benzer" : result > -0.3 ? "ğŸ˜ NÃ¶tr" : "ğŸ‘ FarklÄ±"}
            </div>
          </div>
        </div>
      </div>

      <div style={{ display: "flex", gap: 12, justifyContent: "center" }}>
        {[
          { range: [-4, -0.5], label: "ZÄ±t yÃ¶n", emoji: "ğŸ”´", desc: "Dikkat ETME" },
          { range: [-0.5, 0.5], label: "NÃ¶tr", emoji: "âšª", desc: "Ä°lgisiz" },
          { range: [0.5, 4], label: "AynÄ± yÃ¶n", emoji: "ğŸŸ¢", desc: "DÄ°KKAT ET!" },
        ].map((r, i) => (
          <div key={i} style={{
            flex: 1, padding: "10px 8px", borderRadius: 10, textAlign: "center",
            background: result >= r.range[0] && result < r.range[1] ? "rgba(255,255,255,0.06)" : "transparent",
            border: result >= r.range[0] && result < r.range[1] ? "1px solid rgba(255,255,255,0.12)" : "1px solid transparent",
            transition: "all .3s"
          }}>
            <div style={{ fontSize: 20 }}>{r.emoji}</div>
            <div style={{ fontSize: 12, fontWeight: 700, color: "#CBD5E1" }}>{r.label}</div>
            <div style={{ fontSize: 10, color: "#64748B" }}>{r.desc}</div>
          </div>
        ))}
      </div>
    </TEBox>
  );
};

// â•â•â• FULL ATTENTION PIPELINE (New â€” didn't exist before) â•â•â•
const TEScaledAttentionPipeline = () => {
  const [step, setStep] = useState(0);
  const [dk, setDk] = useState(64);

  const rawScores = [1.2, 3.8, 0.5];
  const tokens = ["Ben", "okula", "gittim"];
  const sqrtDk = Math.sqrt(dk);
  const scaled = rawScores.map(s => s / sqrtDk);
  const probs = softmaxArr(scaled);
  const values = [[0.3, 0.7], [0.9, 0.1], [0.5, 0.5]];
  const output = values[0].map((_, d) => probs.reduce((s, p, t) => s + p * values[t][d], 0));

  const stepsInfo = [
    { title: "QÂ·K Ã‡arpÄ±mÄ±", color: "#0EA5E9", desc: `"Ben" kelimesinin Query'si ile her kelimenin Key'i Ã§arpÄ±lÄ±r.` },
    { title: "Ã· âˆšd Scaling", color: "#8B5CF6", desc: `d_k = ${dk} â†’ âˆš${dk} = ${sqrtDk.toFixed(1)}. BÃ¼yÃ¼k boyutlarda dot product Ã§ok bÃ¼yÃ¼k olur â†’ softmax patlar!` },
    { title: "Softmax", color: "#10B981", desc: "Skorlar 0-1 arasÄ± olasÄ±lÄ±ÄŸa dÃ¶nÃ¼ÅŸÃ¼r. Toplam = 1." },
    { title: "Ã— Value", color: "#EC4899", desc: "Her kelimenin Value vektÃ¶rÃ¼, kendi olasÄ±lÄ±ÄŸÄ± ile Ã§arpÄ±lÄ±p toplanÄ±r." },
  ];

  return (
    <TEBox>
      <TELabel color="#EC4899">{"ğŸ”¬ Tam Attention Pipeline â€” AdÄ±m adÄ±m hesapla"}</TELabel>

      <div style={{ display: "flex", gap: 0, marginBottom: 16, background: "rgba(255,255,255,0.02)", borderRadius: 12, overflow: "hidden", border: "1px solid rgba(255,255,255,0.06)" }}>
        {stepsInfo.map((s, i) => (
          <button key={i} onClick={() => setStep(i)} style={{
            flex: 1, padding: "12px 8px", border: "none", cursor: "pointer",
            background: step === i ? `${s.color}12` : "transparent",
            borderBottom: step === i ? `3px solid ${s.color}` : "3px solid transparent",
            color: step === i ? s.color : "#475569", fontSize: 12, fontWeight: 700,
            transition: "all .2s", fontFamily: "inherit"
          }}>
            {s.title}
          </button>
        ))}
      </div>

      <div style={{ padding: "16px 18px", borderRadius: 14, background: `${stepsInfo[step].color}06`, border: `1px solid ${stepsInfo[step].color}20`, marginBottom: 14 }}>
        <div style={{ fontSize: 17, fontWeight: 800, color: stepsInfo[step].color, marginBottom: 6 }}>
          {"AdÄ±m "}{step + 1}{": "}{stepsInfo[step].title}
        </div>
        <div style={{ fontSize: 14, color: "#CBD5E1", lineHeight: 1.7, marginBottom: 14 }}>{stepsInfo[step].desc}</div>

        {step === 0 && (
          <div style={{ display: "flex", gap: 10, justifyContent: "center", flexWrap: "wrap" }}>
            {tokens.map((t, i) => (
              <div key={i} style={{ padding: "14px 18px", borderRadius: 12, background: `rgba(14,165,233,${0.05 + rawScores[i] / 5 * 0.15})`, border: "1px solid rgba(14,165,233,0.2)", textAlign: "center", minWidth: 100 }}>
                <div style={{ fontSize: 13, color: "#94A3B8", marginBottom: 4 }}>{"QÂ·K(\""}{t}{"\")"}</div>
                <TENum v={rawScores[i]} color="#0EA5E9" size={24} />
              </div>
            ))}
          </div>
        )}

        {step === 1 && (
          <div>
            <TESlider label="d_k:" value={dk} min={4} max={512} step={4} color="#8B5CF6" onChange={setDk} />
            <div style={{ display: "flex", gap: 10, justifyContent: "center", flexWrap: "wrap", marginTop: 12 }}>
              {tokens.map((t, i) => (
                <div key={i} style={{ padding: "14px 18px", borderRadius: 12, background: "rgba(139,92,246,0.06)", border: "1px solid rgba(139,92,246,0.2)", textAlign: "center", minWidth: 130 }}>
                  <div style={{ fontSize: 12, color: "#94A3B8", marginBottom: 4 }}>{rawScores[i].toFixed(1)}{" Ã· "}{sqrtDk.toFixed(1)}</div>
                  <TENum v={scaled[i]} color="#8B5CF6" size={22} />
                  <div style={{ fontSize: 11, color: "#64748B", marginTop: 2 }}>{t}</div>
                </div>
              ))}
            </div>
            <div style={{ marginTop: 12, padding: "10px 14px", borderRadius: 10, background: "rgba(139,92,246,0.06)", fontSize: 13, color: "#A78BFA", textAlign: "center" }}>
              {"ğŸ’¡ d_k kaydÄ±rÄ±cÄ±yÄ± deÄŸiÅŸtir â€” bÃ¼yÃ¼k d_k â†’ daha kÃ¼Ã§Ã¼k skorlar â†’ softmax daha dÃ¼zgÃ¼n daÄŸÄ±lÄ±r"}
            </div>
          </div>
        )}

        {step === 2 && (
          <div style={{ display: "flex", gap: 10, alignItems: "flex-end", justifyContent: "center", height: 140 }}>
            {tokens.map((t, i) => (
              <div key={i} style={{ display: "flex", flexDirection: "column", alignItems: "center", gap: 4, minWidth: 80 }}>
                <div style={{ fontSize: 14, fontWeight: 700, color: "#10B981" }}>{(probs[i] * 100).toFixed(1)}%</div>
                <div style={{
                  width: 60, height: Math.max(6, probs[i] * 120), borderRadius: 8,
                  background: "linear-gradient(180deg, #10B981, #059669)",
                  transition: "height .5s ease"
                }} />
                <div style={{ fontSize: 13, fontWeight: 600, color: "#CBD5E1" }}>{t}</div>
                <div style={{ fontSize: 11, color: "#64748B" }}>{"skor: "}{scaled[i].toFixed(2)}</div>
              </div>
            ))}
          </div>
        )}

        {step === 3 && (
          <div>
            <div style={{ display: "flex", gap: 8, justifyContent: "center", marginBottom: 14, flexWrap: "wrap" }}>
              {tokens.map((t, i) => (
                <div key={i} style={{
                  padding: "10px 14px", borderRadius: 10,
                  background: "rgba(236,72,153,0.06)", border: "1px solid rgba(236,72,153,0.2)",
                  textAlign: "center", opacity: 0.4 + probs[i] * 1.5
                }}>
                  <div style={{ fontSize: 12, color: "#94A3B8" }}>{(probs[i] * 100).toFixed(0)}{"% Ã— V(\""}{t}{"\")"}</div>
                  <div style={{ fontSize: 13, fontFamily: "'Fira Code', monospace", color: "#EC4899", marginTop: 4 }}>
                    {probs[i].toFixed(2)}{" Ã— ["}{values[i].join(", ")}{"]"}
                  </div>
                </div>
              ))}
            </div>
            <div style={{ textAlign: "center", padding: "14px 18px", borderRadius: 12, background: "rgba(236,72,153,0.1)", border: "2px solid rgba(236,72,153,0.3)" }}>
              <div style={{ fontSize: 13, color: "#94A3B8", marginBottom: 4 }}>{"SonuÃ§ vektÃ¶r:"}</div>
              <div style={{ fontSize: 22, fontWeight: 800, color: "#EC4899", fontFamily: "'Fira Code', monospace" }}>
                [{output.map(v => v.toFixed(3)).join(", ")}]
              </div>
            </div>
          </div>
        )}
      </div>

      <div style={{ textAlign: "center", padding: "10px 14px", borderRadius: 10, background: "rgba(0,0,0,0.2)", fontSize: 16, fontWeight: 700, color: "#94A3B8", fontFamily: "'Georgia', serif" }}>
        {"Attention(Q,K,V) = "}<span style={{ color: "#10B981" }}>softmax</span>{"("}<span style={{ color: "#0EA5E9" }}>{"QÂ·K"}<sup>T</sup></span>{" / "}<span style={{ color: "#8B5CF6" }}>{"âˆšd"}<sub>k</sub></span>{") Â· "}<span style={{ color: "#EC4899" }}>V</span>
      </div>
    </TEBox>
  );
};

// â•â•â• MULTI-HEAD ATTENTION (Rich â€” 8 heads) â•â•â•
const TEMultiHead = () => {
  const [activeHead, setActiveHead] = useState(0);
  const [showMerge, setShowMerge] = useState(false);
  const headColors = ["#0EA5E9", "#10B981", "#F59E0B", "#EC4899", "#8B5CF6", "#EF4444", "#14B8A6", "#6366F1"];
  const headJobs = [
    { name: "Ã–zne-fiil iliÅŸkisi", emoji: "ğŸ‘¤", example: "'Kedi' â†’ 'kovaladÄ±'ya dikkat" },
    { name: "SÄ±fat-isim baÄŸÄ±", emoji: "ğŸ¨", example: "'BÃ¼yÃ¼k' â†’ 'ev'e dikkat" },
    { name: "Zaman ifadeleri", emoji: "â°", example: "'YarÄ±n' â†’ 'gidecek'e dikkat" },
    { name: "YakÄ±nlÄ±k iliÅŸkisi", emoji: "ğŸ“", example: "Yan yana kelimelere dikkat" },
    { name: "Zamir Ã§Ã¶zÃ¼mleme", emoji: "ğŸ”—", example: "'O' â†’ 'Ali'ye dikkat" },
    { name: "CÃ¼mle yapÄ±sÄ±", emoji: "ğŸ—ï¸", example: "Noktalama ve baÄŸlaÃ§ dikkat" },
    { name: "Edat baÄŸlantÄ±larÄ±", emoji: "ğŸ“", example: "'ile' â†’ baÄŸladÄ±ÄŸÄ± kelimelere" },
    { name: lang === "tr" ? "Genel baÄŸlam" : "General context", emoji: "ğŸŒ", example: "Uzak mesafe baÄŸÄ±mlÄ±lÄ±klar" },
  ];

  return (
    <TEBox>
      <TELabel color="#EC4899">{"ğŸ§© Multi-Head Attention â€” 8 Paralel Dikkat"}</TELabel>

      <div style={{ marginBottom: 16, padding: 14, borderRadius: 12, background: "rgba(0,0,0,0.2)" }}>
        <div style={{ fontSize: 12, color: "#64748B", marginBottom: 8, textAlign: "center" }}>{"512 boyutlu vektÃ¶r â†’ 8 head Ã— 64 boyut"}</div>
        <div style={{ display: "flex", gap: 2, borderRadius: 8, overflow: "hidden" }}>
          {Array.from({ length: 8 }, (_, i) => (
            <button key={i} onClick={() => { setActiveHead(i); setShowMerge(false); }} style={{
              flex: 1, height: 40, border: "none", cursor: "pointer",
              background: activeHead === i ? headColors[i] : `${headColors[i]}30`,
              display: "flex", alignItems: "center", justifyContent: "center",
              fontSize: 11, fontWeight: 800, color: activeHead === i ? "#fff" : headColors[i],
              transition: "all .2s", fontFamily: "inherit"
            }}>
              H{i + 1}
            </button>
          ))}
        </div>
        <div style={{ display: "flex", justifyContent: "space-between", marginTop: 4, fontSize: 9, color: "#475569" }}>
          <span>[0]</span><span>[63]</span><span>[127]</span><span>[191]</span><span>[255]</span><span>[319]</span><span>[383]</span><span>[447]</span><span>[511]</span>
        </div>
      </div>

      <div style={{ padding: 18, borderRadius: 14, marginBottom: 14, background: `${headColors[activeHead]}0A`, border: `1px solid ${headColors[activeHead]}25`, transition: "all .3s" }}>
        <div style={{ display: "flex", alignItems: "center", gap: 12, marginBottom: 10 }}>
          <div style={{ width: 48, height: 48, borderRadius: 12, background: headColors[activeHead], display: "flex", alignItems: "center", justifyContent: "center", fontSize: 24 }}>
            {headJobs[activeHead].emoji}
          </div>
          <div>
            <div style={{ fontSize: 18, fontWeight: 800, color: headColors[activeHead] }}>{"Head "}{activeHead + 1}{": "}{headJobs[activeHead].name}</div>
            <div style={{ fontSize: 13, color: "#94A3B8" }}>{"Boyut dilimi: ["}{activeHead * 64}{":"}{(activeHead + 1) * 64}{"]"}</div>
          </div>
        </div>
        <div style={{ fontSize: 14, color: "#CBD5E1", lineHeight: 1.7 }}>{"Ã–rnek: "}{headJobs[activeHead].example}</div>
        <div style={{ marginTop: 10, padding: "10px 14px", borderRadius: 8, background: "rgba(0,0,0,0.2)", fontFamily: "'Fira Code', monospace", fontSize: 12, color: "#94A3B8" }}>
          {"q_h = Q["}{activeHead * 64}{":"}{(activeHead + 1) * 64}{"] â†’ 64 boyut"}<br />
          {"k_h = K["}{activeHead * 64}{":"}{(activeHead + 1) * 64}{"] â†’ 64 boyut"}<br />
          {"head"}{activeHead + 1}{" = Attention(q_h, k_h, v_h)"}
        </div>
      </div>

      <button onClick={() => setShowMerge(!showMerge)} style={{
        width: "100%", padding: "12px 20px", borderRadius: 12, border: showMerge ? "none" : "1px solid rgba(255,255,255,0.08)",
        background: showMerge ? "linear-gradient(135deg, #EC4899, #8B5CF6)" : "rgba(255,255,255,0.04)",
        color: "#fff", fontSize: 14, fontWeight: 700, cursor: "pointer", fontFamily: "inherit", transition: "all .3s"
      }}>
        {showMerge ? "âœ… BirleÅŸtirme (Concat + W_O)" : "ğŸ”€ BirleÅŸtirme adÄ±mÄ±nÄ± gÃ¶ster â†’"}
      </button>
      {showMerge && (
        <div style={{ marginTop: 12, padding: 16, borderRadius: 14, background: "rgba(139,92,246,0.06)", border: "1px solid rgba(139,92,246,0.15)", textAlign: "center" }}>
          <div style={{ fontSize: 14, color: "#A78BFA", marginBottom: 8 }}>{"8 head birleÅŸtirilir (concat) ve W_O matrisi ile projekte edilir:"}</div>
          <div style={{ fontSize: 16, fontWeight: 700, color: "#E2E8F0", fontFamily: "'Georgia', serif" }}>
            {"MultiHead = Concat(H"}<sub>1</sub>{",...,H"}<sub>8</sub>{") Â· W"}<sup>O</sup>
          </div>
          <div style={{ display: "flex", gap: 2, marginTop: 12, borderRadius: 8, overflow: "hidden" }}>
            {headColors.map((c, i) => (
              <div key={i} style={{ flex: 1, height: 24, background: c, display: "flex", alignItems: "center", justifyContent: "center", fontSize: 9, color: "#fff", fontWeight: 800 }}>64</div>
            ))}
          </div>
          <div style={{ fontSize: 11, color: "#64748B", marginTop: 4 }}>{"8 Ã— 64 = 512 â†’ W_O [512Ã—512] â†’ 512 boyut"}</div>
        </div>
      )}
    </TEBox>
  );
};

// â•â•â• POSITIONAL ENCODING WAVES (Rich â€” with heatmap) â•â•â•
const TEPosEncoding = () => {
  const [pos, setPos] = useState(3);
  const [dim, setDim] = useState(0);
  const totalDims = 8;
  const maxPos = 20;

  const getVal = (p, d) => {
    const i = Math.floor(d / 2);
    const angle = p / Math.pow(10000, (2 * i) / 512);
    return d % 2 === 0 ? Math.sin(angle) : Math.cos(angle);
  };

  const heatmap = useMemo(() => {
    return Array.from({ length: maxPos }, (_, p) =>
      Array.from({ length: totalDims }, (_, d) => getVal(p, d))
    );
  }, []);

  return (
    <TEBox>
      <TELabel color="#14B8A6">{"ğŸŒŠ Positional Encoding â€” Ä°nteraktif Dalga"}</TELabel>

      <div style={{ display: "grid", gridTemplateColumns: "1fr 1fr", gap: 16, marginBottom: 16 }}>
        <TESlider label="Pozisyon:" value={pos} min={0} max={maxPos - 1} step={1} color="#14B8A6" onChange={setPos} />
        <TESlider label="Boyut:" value={dim} min={0} max={totalDims - 1} step={1} color="#EC4899" onChange={setDim} />
      </div>

      <div style={{ textAlign: "center", marginBottom: 16, padding: "14px 18px", borderRadius: 12, background: "rgba(20,184,166,0.08)", border: "1px solid rgba(20,184,166,0.2)" }}>
        <div style={{ fontSize: 13, color: "#94A3B8", marginBottom: 4 }}>
          {"PE(pos="}{pos}{", dim="}{dim}{") = "}{dim % 2 === 0 ? "sin" : "cos"}{"("}{pos}{" / 10000^("}{2 * Math.floor(dim / 2)}{"/512))"}
        </div>
        <div style={{ fontSize: 28, fontWeight: 800, color: "#14B8A6", fontFamily: "'Fira Code', monospace" }}>
          {getVal(pos, dim).toFixed(4)}
        </div>
      </div>

      <div style={{ overflowX: "auto", marginBottom: 12 }}>
        <div style={{ fontSize: 12, color: "#64748B", marginBottom: 6 }}>{"IsÄ± haritasÄ±: satÄ±r=pozisyon, sÃ¼tun=boyut (seÃ§ili hÃ¼creye tÄ±kla)"}</div>
        <div style={{ display: "flex", gap: 1, marginLeft: 30, marginBottom: 2 }}>
          {Array.from({ length: totalDims }, (_, d) => (
            <div key={d} style={{ width: 40, textAlign: "center", fontSize: 9, color: dim === d ? "#EC4899" : "#475569", fontWeight: dim === d ? 800 : 400 }}>d{d}</div>
          ))}
        </div>
        {Array.from({ length: Math.min(maxPos, 14) }, (_, p) => (
          <div key={p} style={{ display: "flex", alignItems: "center", gap: 1 }}>
            <div style={{ width: 28, textAlign: "right", fontSize: 10, color: pos === p ? "#14B8A6" : "#475569", fontWeight: pos === p ? 800 : 400, paddingRight: 4 }}>{p}</div>
            {Array.from({ length: totalDims }, (_, d) => {
              const val = heatmap[p][d];
              const isSelected = p === pos && d === dim;
              const hue = val > 0 ? 160 : 0;
              const intensity = Math.abs(val);
              return (
                <div key={d} onClick={() => { setPos(p); setDim(d); }} style={{
                  width: 40, height: 24, borderRadius: 3, cursor: "pointer",
                  background: `hsla(${hue}, 70%, 45%, ${0.15 + intensity * 0.65})`,
                  border: isSelected ? "2px solid #fff" : "1px solid rgba(255,255,255,0.03)",
                  display: "flex", alignItems: "center", justifyContent: "center",
                  fontSize: 9, color: isSelected ? "#fff" : "transparent", fontWeight: 700,
                  transition: "all .15s"
                }}>
                  {isSelected ? val.toFixed(2) : ""}
                </div>
              );
            })}
          </div>
        ))}
      </div>

      <div style={{ padding: 14, borderRadius: 12, background: "rgba(0,0,0,0.2)", marginBottom: 12 }}>
        <div style={{ fontSize: 12, color: "#94A3B8", marginBottom: 8 }}>{"Boyut "}{dim}{" iÃ§in dalga (seÃ§ili pozisyon: "}{pos}{")"}</div>
        <div style={{ display: "flex", alignItems: "center", gap: 1, height: 50 }}>
          {Array.from({ length: maxPos }, (_, p) => {
            const val = heatmap[p][dim];
            const h = Math.abs(val) * 22;
            return (
              <div key={p} onClick={() => setPos(p)} style={{
                flex: 1, height: 50, cursor: "pointer", position: "relative"
              }}>
                <div style={{
                  width: "100%", height: h, borderRadius: 2,
                  background: p === pos ? "#14B8A6" : val > 0 ? "rgba(16,185,129,0.4)" : "rgba(239,68,68,0.4)",
                  position: "absolute", top: val > 0 ? 25 - h : 25,
                  transition: "all .15s"
                }} />
              </div>
            );
          })}
        </div>
      </div>

      <div style={{ fontSize: 12, color: "#64748B", textAlign: "center" }}>
        {"ğŸŸ¢ pozitif | ğŸ”´ negatif â€” dÃ¼ÅŸÃ¼k boyutlar hÄ±zlÄ±, yÃ¼ksek boyutlar yavaÅŸ deÄŸiÅŸir"}
      </div>
    </TEBox>
  );
};

// â•â•â• ATTENTION WORD INTERACTION (Rich â€” 6 words) â•â•â•
const TEAttentionDemo = () => {
  const [selected, setSelected] = useState(0);
  const words = ["Kedi", "sÃ¼t", "iÃ§ti", "Ã§Ã¼nkÃ¼", "o", "aÃ§Ä±kmÄ±ÅŸtÄ±"];
  const weights = [
    [0.40, 0.15, 0.10, 0.05, 0.05, 0.25],
    [0.20, 0.35, 0.10, 0.05, 0.10, 0.20],
    [0.30, 0.25, 0.20, 0.05, 0.05, 0.15],
    [0.10, 0.05, 0.15, 0.40, 0.10, 0.20],
    [0.50, 0.05, 0.05, 0.10, 0.15, 0.15],
    [0.35, 0.10, 0.15, 0.10, 0.10, 0.20],
  ];
  const colors = ["#0EA5E9", "#10B981", "#F59E0B", "#94A3B8", "#EC4899", "#8B5CF6"];

  return (
    <TEBox>
      <TELabel color="#10B981">{"ğŸ® Kelimeye tÄ±kla â€” hangi kelimelere dikkat ettiÄŸini gÃ¶r!"}</TELabel>
      <div style={{ display: "flex", gap: 6, justifyContent: "center", marginBottom: 16, flexWrap: "wrap" }}>
        {words.map((w, i) => (
          <button key={i} onClick={() => setSelected(i)} style={{
            padding: "10px 16px", borderRadius: 10,
            border: selected === i ? `2px solid ${colors[i]}` : "2px solid rgba(255,255,255,0.08)",
            background: selected === i ? `${colors[i]}15` : "rgba(255,255,255,0.02)",
            color: selected === i ? colors[i] : "#CBD5E1",
            fontSize: 16, fontWeight: 700, cursor: "pointer", transition: "all .2s",
            transform: selected === i ? "scale(1.1)" : "scale(1)", fontFamily: "inherit"
          }}>
            {w}
          </button>
        ))}
      </div>
      <div style={{ display: "flex", gap: 8, alignItems: "flex-end", justifyContent: "center", height: 130 }}>
        {words.map((w, i) => {
          const weight = weights[selected][i];
          return (
            <div key={i} style={{ display: "flex", flexDirection: "column", alignItems: "center", gap: 4, flex: 1 }}>
              <div style={{ fontSize: 13, fontWeight: 700, color: "#E2E8F0" }}>{(weight * 100).toFixed(0)}%</div>
              <div style={{
                width: "80%", maxWidth: 50, height: Math.max(6, weight * 110), borderRadius: 8,
                background: i === selected ? `linear-gradient(180deg, ${colors[i]}, ${colors[i]}80)` : "linear-gradient(180deg, rgba(148,163,184,0.6), rgba(148,163,184,0.3))",
                transition: "height .5s ease"
              }} />
              <div style={{ fontSize: 12, fontWeight: i === selected ? 800 : 500, color: i === selected ? colors[i] : "#94A3B8" }}>{w}</div>
            </div>
          );
        })}
      </div>
      {selected === 4 && (
        <div style={{ marginTop: 14, padding: "12px 16px", borderRadius: 10, background: "rgba(236,72,153,0.08)", border: "1px solid rgba(236,72,153,0.15)", fontSize: 13, color: "#F472B6", textAlign: "center" }}>
          {"ğŸ’¡ \"o\" kelimesi \"Kedi\"ye %50 dikkat ediyor â€” zamir Ã§Ã¶zÃ¼mleme! Bu, makalenin Figure 4'Ã¼ndeki davranÄ±ÅŸla aynÄ±."}
        </div>
      )}
    </TEBox>
  );
};

// â•â•â• CAUSAL MASK (Rich â€” with hover) â•â•â•
const TECausalMask = () => {
  const tokens = ["Ben", "okula", "bugÃ¼n", "gittim", "."];
  const [hoverCell, setHoverCell] = useState(null);

  return (
    <TEBox>
      <TELabel color="#F59E0B">{"ğŸ­ Causal Mask â€” HÃ¼crelere tÄ±kla!"}</TELabel>
      <div style={{ display: "flex", justifyContent: "center" }}>
        <div>
          <div style={{ display: "flex", marginLeft: 70 }}>
            {tokens.map((t, i) => (
              <div key={i} style={{ width: 58, textAlign: "center", fontSize: 12, color: "#64748B", fontWeight: 600, padding: "4px 0" }}>{t}</div>
            ))}
          </div>
          {tokens.map((t, row) => (
            <div key={row} style={{ display: "flex", alignItems: "center" }}>
              <div style={{ width: 68, textAlign: "right", paddingRight: 6, fontSize: 12, color: "#94A3B8", fontWeight: 600 }}>{t}</div>
              {tokens.map((_, col) => {
                const allowed = col <= row;
                const isHover = hoverCell && hoverCell[0] === row && hoverCell[1] === col;
                return (
                  <div key={col}
                    onMouseEnter={() => setHoverCell([row, col])}
                    onMouseLeave={() => setHoverCell(null)}
                    style={{
                      width: 54, height: 42, margin: 2, borderRadius: 8,
                      display: "flex", alignItems: "center", justifyContent: "center",
                      background: allowed
                        ? isHover ? "rgba(16,185,129,0.35)" : "rgba(16,185,129,0.12)"
                        : isHover ? "rgba(239,68,68,0.35)" : "rgba(239,68,68,0.06)",
                      border: `1px solid ${allowed ? "rgba(16,185,129,0.25)" : "rgba(239,68,68,0.12)"}`,
                      cursor: "pointer", transition: "all .15s", fontSize: 18
                    }}>
                    {allowed ? "âœ“" : "âœ—"}
                  </div>
                );
              })}
            </div>
          ))}
        </div>
      </div>
      {hoverCell && (
        <div style={{ textAlign: "center", marginTop: 12, padding: "10px 16px", borderRadius: 10, background: "rgba(255,255,255,0.03)", fontSize: 13, color: "#CBD5E1" }}>
          {"\""}{tokens[hoverCell[0]]}{"\" â†’ \""}{tokens[hoverCell[1]]}{"\" : "}
          {hoverCell[1] <= hoverCell[0]
            ? <span style={{ color: "#10B981", fontWeight: 700 }}>{"âœ… BAKABÄ°LÄ°R"}</span>
            : <span style={{ color: "#EF4444", fontWeight: 700 }}>{"âŒ YASAK â€” gelecek kelimeye bakamaz!"}</span>}
        </div>
      )}
    </TEBox>
  );
};

// â•â•â• RESULTS TABLE (Rich â€” with more models & cost) â•â•â•
const TEResultsTable = () => {
  const data = [
    { model: "ByteNet", de: 23.75, fr: null, cost: "â€”", isT: false },
    { model: "GNMT + RL", de: 24.6, fr: 39.92, cost: "2.3Ã—10Â¹â¹", isT: false },
    { model: "ConvS2S", de: 25.16, fr: 40.46, cost: "9.6Ã—10Â¹â¸", isT: false },
    { model: "Transformer (base)", de: 27.3, fr: 38.1, cost: "3.3Ã—10Â¹â¸", isT: true },
    { model: "Transformer (big)", de: 28.4, fr: 41.8, cost: "2.3Ã—10Â¹â¹", isT: true },
  ];
  return (
    <TEBox>
      <TELabel color="#EF4444">{"ğŸ“Š BLEU SonuÃ§larÄ± â€” YÃ¼ksek = Daha iyi Ã§eviri"}</TELabel>
      <table style={{ width: "100%", borderCollapse: "collapse" }}>
        <thead>
          <tr>{["Model", "ENâ†’DE", "ENâ†’FR", "Maliyet"].map((h, i) => (
            <th key={i} style={{ padding: "10px 12px", textAlign: i === 0 ? "left" : "center", fontSize: 11, color: "#64748B", borderBottom: "1px solid rgba(255,255,255,0.08)" }}>{h}</th>
          ))}</tr>
        </thead>
        <tbody>
          {data.map((r, i) => (
            <tr key={i} style={{ background: r.isT ? "rgba(16,185,129,0.06)" : "transparent" }}>
              <td style={{ padding: "10px 12px", fontSize: 14, fontWeight: r.isT ? 700 : 400, color: r.isT ? "#10B981" : "#CBD5E1", borderBottom: "1px solid rgba(255,255,255,0.04)" }}>
                {r.isT ? "â­ " : ""}{r.model}
              </td>
              <td style={{ padding: "10px 12px", textAlign: "center", fontWeight: 700, color: "#E2E8F0", fontFamily: "'Fira Code', monospace", borderBottom: "1px solid rgba(255,255,255,0.04)" }}>{r.de}</td>
              <td style={{ padding: "10px 12px", textAlign: "center", fontWeight: 700, color: "#E2E8F0", fontFamily: "'Fira Code', monospace", borderBottom: "1px solid rgba(255,255,255,0.04)" }}>{r.fr ?? "â€”"}</td>
              <td style={{ padding: "10px 12px", textAlign: "center", fontSize: 12, color: "#94A3B8", fontFamily: "'Fira Code', monospace", borderBottom: "1px solid rgba(255,255,255,0.04)" }}>{r.cost}</td>
            </tr>
          ))}
        </tbody>
      </table>
    </TEBox>
  );
};

// â•â•â• TIMELINE (Rich â€” clickable with details) â•â•â•
const TETimeline = () => {
  const [active, setActive] = useState(0);
  const events = [
    { year: "2017", title: "Transformer", desc: "Bu makale yayÄ±nlandÄ±!", color: "#0EA5E9", icon: "ğŸ“„", detail: "8 GPU, 3.5 gÃ¼n eÄŸitim. BLEU rekorlarÄ± kÄ±rdÄ±." },
    { year: "2018", title: "BERT & GPT-1", desc: "Google BERT + OpenAI GPT-1", color: "#10B981", icon: "ğŸ§ ", detail: "BERT: 340M param. GPT-1: 117M param. Ä°kisi de Transformer tabanlÄ±." },
    { year: "2020", title: "GPT-3 & ViT", desc: "175B parametre + gÃ¶rselde Transformer", color: "#8B5CF6", icon: "ğŸš€", detail: "Few-shot learning. ViT: gÃ¶rÃ¼ntÃ¼leri Transformer ile iÅŸle." },
    { year: "2022", title: "ChatGPT", desc: "AI herkesin eline ulaÅŸtÄ±", color: "#EC4899", icon: "ğŸ’¬", detail: "GPT-3.5 + RLHF. Tarihin en hÄ±zlÄ± bÃ¼yÃ¼yen uygulamasÄ±." },
    { year: "2023+", title: "GPT-4, Claude, Gemini", desc: "Ã‡ok modlu dev modeller", color: "#6366F1", icon: "ğŸŒ", detail: "Metin + gÃ¶rÃ¼ntÃ¼ + ses. Trilyon parametreye yaklaÅŸÄ±lÄ±yor." },
  ];
  return (
    <TEBox>
      <TELabel color="#6366F1">{"ğŸŒ Zaman Ã‡izelgesi â€” Bir noktaya tÄ±kla!"}</TELabel>
      <div style={{ display: "flex", alignItems: "center", marginBottom: 16, padding: "0 10px" }}>
        {events.map((e, i) => (
          <React.Fragment key={i}>
            <button onClick={() => setActive(i)} style={{
              width: 42, height: 42, borderRadius: 21, border: active === i ? `3px solid ${e.color}` : "2px solid rgba(255,255,255,0.1)",
              background: active === i ? `${e.color}20` : "rgba(255,255,255,0.02)",
              display: "flex", alignItems: "center", justifyContent: "center",
              fontSize: 18, cursor: "pointer", transition: "all .3s", flexShrink: 0, fontFamily: "inherit",
              transform: active === i ? "scale(1.2)" : "scale(1)"
            }}>{e.icon}</button>
            {i < events.length - 1 && (
              <div style={{ flex: 1, height: 3, background: i < active ? events[active].color : "rgba(255,255,255,0.06)", borderRadius: 2, transition: "background .3s" }} />
            )}
          </React.Fragment>
        ))}
      </div>
      <div style={{ padding: 18, borderRadius: 14, background: `${events[active].color}0A`, border: `1px solid ${events[active].color}25` }}>
        <div style={{ fontSize: 14, fontWeight: 800, color: events[active].color }}>{events[active].year}</div>
        <div style={{ fontSize: 20, fontWeight: 800, color: "#E2E8F0", marginBottom: 6 }}>{events[active].title}</div>
        <div style={{ fontSize: 14, color: "#CBD5E1", lineHeight: 1.7, marginBottom: 8 }}>{events[active].desc}</div>
        <div style={{ fontSize: 13, color: "#94A3B8", padding: "8px 12px", borderRadius: 8, background: "rgba(0,0,0,0.15)" }}>{events[active].detail}</div>
      </div>
    </TEBox>
  );
};

// â•â•â• Section wrapper vizzes for Week B â•â•â•
const TEPaperGirisViz = () => (<div>
  <TEAnalojiBox emoji="ğŸ’" title={lang === "tr" ? "Okul Analojisi" : "School Analogy"}>{"Eski yÃ¶ntemde (RNN) Ã¶ÄŸretmen her Ã¶ÄŸrenciye SIRAYLA anlatÄ±r â€” Ã§ok yavaÅŸ! Yeni yÃ¶ntemde (Transformer) TÃœM sÄ±nÄ±fa aynÄ± anda anlatÄ±r ve her Ã¶ÄŸrenci kendine lazÄ±m olan bilgiye DÄ°KKAT eder."}</TEAnalojiBox>
  <TEInfoBox color="#0EA5E9" icon="ğŸ“„" title={lang === "tr" ? "Bu makale ne diyor?" : "What does this paper say?"}>{"2017'de Google araÅŸtÄ±rmacÄ±larÄ±, RNN ve CNN'leri atÄ±p sadece \"attention\" kullanan Transformer modelini yaptÄ±lar. Hem daha iyi sonuÃ§ hem Ã§ok daha hÄ±zlÄ±!"}</TEInfoBox>
  <TEInfoBox color="#10B981" icon="ğŸ†" title={lang === "tr" ? "SonuÃ§lar" : "Results"}>{"Ä°ngilizceâ†’Almanca: 28.4 BLEU (rekor!). Ä°ngilizceâ†’FransÄ±zca: 41.8 BLEU. Sadece 8 GPU'da 3.5 gÃ¼n eÄŸitim."}</TEInfoBox>
  <TEInfoBox color="#8B5CF6" icon="ğŸ’¡" title={lang === 'tr' ? 'Neden "Attention Is All You Need"?' : 'Why "Attention Is All You Need"?'}>{"Ã–nceki modellerde attention yardÄ±mcÄ±ydÄ±, asÄ±l iÅŸ RNN yapÄ±yordu. Bu makale RNN'yi tamamen kaldÄ±rÄ±p SADECE attention ile model yaptÄ±."}</TEInfoBox>
</div>);

const TEPaperEskiModViz = () => (<div>
  <TEAnalojiBox emoji="ğŸ“–" title={lang === "tr" ? "Kitap Okuma Analojisi" : "Reading a Book Analogy"}>{"RNN: Her kelimeyi okuyup Ã¶ncekini hatÄ±rlamaya Ã§alÄ±ÅŸÄ±yorsun. Sayfa 1'dekileri sayfa 100'de unutuyorsun! Transformer: TÃ¼m sayfalar Ã¶nÃ¼nde aÃ§Ä±k, istediÄŸin yere bakabiliyorsun."}</TEAnalojiBox>
  <TEInfoBox color="#F59E0B" icon="â³" title={lang === "tr" ? "RNN SorunlarÄ±" : "RNN Problems"}>{"1. SÄ±ralÄ±: Paralel Ã§alÄ±ÅŸamaz â†’ yavaÅŸ! 2. Unutkan: 100 kelime Ã¶ncesini hatÄ±rlayamaz. 3. Gradient kaybolmasÄ±."}</TEInfoBox>
  <div style={{display:"grid",gridTemplateColumns:"1fr 1fr",gap:12,marginBottom:16}}>
    <div style={{padding:18,borderRadius:14,background:"rgba(239,68,68,0.06)",border:"1px solid rgba(239,68,68,0.15)",textAlign:"center"}}>
      <div style={{fontSize:40}}>ğŸ¢</div><div style={{fontSize:18,fontWeight:800,color:"#EF4444"}}>RNN</div>
      <div style={{fontSize:12,color:"#94A3B8",marginTop:4,whiteSpace:"pre-line"}}>{lang === "tr" ? "SÄ±ralÄ± â†’ O(n) adÄ±m\nUzak kelimelere ulaÅŸmak zor" : "Sequential â†’ O(n) steps\nHard to reach distant words"}</div>
    </div>
    <div style={{padding:18,borderRadius:14,background:"rgba(16,185,129,0.06)",border:"1px solid rgba(16,185,129,0.15)",textAlign:"center"}}>
      <div style={{fontSize:40}}>ğŸš€</div><div style={{fontSize:18,fontWeight:800,color:"#10B981"}}>Transformer</div>
      <div style={{fontSize:12,color:"#94A3B8",marginTop:4,whiteSpace:"pre-line"}}>{lang === "tr" ? "Paralel â†’ O(1) adÄ±m\nHerkes herkesi gÃ¶rÃ¼r!" : "Parallel â†’ O(1) steps\nEveryone sees everyone!"}</div>
    </div>
  </div>
</div>);

const TEPaperAttentionViz = () => (<div>
  <TEAnalojiBox emoji="ğŸ”" title={lang === "tr" ? "Dikkat Analojisi" : "Attention Analogy"}>{"SÄ±nÄ±fta Ã¶ÄŸretmen konuÅŸurken bazÄ± kelimelere Ã§ok dikkat edersin. Attention mekanizmasÄ± da tam bunu yapÄ±yor!"}</TEAnalojiBox>
  <TEAttentionDemo />
  <TEInfoBox color="#10B981" icon="ğŸ”‘" title="Query, Key, Value">{"ğŸ” Query: Ne arÄ±yorum? ğŸ—ï¸ Key: Bende ne var? ğŸ“¦ Value: Bilgim bu. QÂ·K yÃ¼ksekse â†’ o kelimenin Value'sinden Ã§ok bilgi al!"}</TEInfoBox>
  <TEAnalojiBox emoji="ğŸ“š" title={lang === "tr" ? "KÃ¼tÃ¼phane Analojisi" : "Library Analogy"}>{"Query: Dinozorlar hakkÄ±nda kitap arÄ±yorum. Key: Her kitabÄ±n etiketi. Value: KitabÄ±n iÃ§eriÄŸi. Etiket sorunla ne kadar uyumluysa, o kitaptan o kadar Ã§ok bilgi alÄ±rsÄ±n!"}</TEAnalojiBox>
  <TEDotProduct />
</div>);

const TEPaperMatViz = () => (<div>
  <TEAnalojiBox emoji="ğŸ“" title={lang === "tr" ? "Matematik ZamanÄ±!" : "Math Time!"}>{"Korkma! Her formÃ¼lÃ¼ adÄ±m adÄ±m, gerÃ§ek sayÄ±larla aÃ§Ä±klayacaÄŸÄ±z. KaydÄ±rÄ±cÄ±larÄ± oyna!"}</TEAnalojiBox>
  <TESoftmax />
  <TEScaledAttentionPipeline />
  <TEMultiHead />
  <div style={{ padding: 18, borderRadius: 14, textAlign: "center", background: "rgba(139,92,246,0.06)", border: "1px solid rgba(139,92,246,0.15)" }}>
    <div style={{ fontSize: 15, fontWeight: 800, color: "#A78BFA", marginBottom: 8 }}>{lang === "tr" ? "ğŸ¯ Ã–zet: 3 Temel FormÃ¼l" : "ğŸ¯ Summary: 3 Key Formulas"}</div>
    <div style={{ fontSize: 14, color: "#CBD5E1", lineHeight: 2.2, fontFamily: "'Georgia', serif" }}>
      <div>{"â‘  Dot Product: QÂ·K = Î£ q"}<sub>i</sub>{"Ã—k"}<sub>i</sub></div>
      <div>{"â‘¡ Softmax: P(i) = e"}<sup>{"x"}<sub>i</sub></sup>{" / Î£ e"}<sup>{"x"}<sub>j</sub></sup></div>
      <div>{"â‘¢ Attention: softmax(QÂ·K"}<sup>T</sup>{"/âˆšd) Â· V"}</div>
    </div>
  </div>
</div>);

const TEPaperMimariViz = () => (<div>
  <TEAnalojiBox emoji="ğŸ—ï¸" title={lang === "tr" ? "Fabrika Analojisi" : "Factory Analogy"}>{"Encoder: Girdi cÃ¼mlesini anlayan bÃ¶lÃ¼m. Decoder: AnlaÅŸÄ±landan yeni cÃ¼mle Ã¼reten bÃ¶lÃ¼m. Her biri 6 katlÄ±!"}</TEAnalojiBox>
  <TEInfoBox color="#0EA5E9" icon="ğŸ“¥" title={lang === "tr" ? "Encoder (6 katman)" : "Encoder (6 layers)"}>{"Her katmanda: 1. Multi-Head Self-Attention + 2. Feed-Forward Network + Residual + LayerNorm"}</TEInfoBox>
  <TEInfoBox color="#EC4899" icon="ğŸ“¤" title={lang === "tr" ? "Decoder (6 katman)" : "Decoder (6 layers)"}>{"1. Masked Self-Attention + 2. Cross-Attention (encoder Ã§Ä±ktÄ±sÄ±na dikkat) + 3. Feed-Forward"}</TEInfoBox>
  <TECausalMask />
  <TEInfoBox color="#8B5CF6" icon="ğŸ”„" title="Residual + LayerNorm">{"Her alt-katman: Ã§Ä±ktÄ± = LayerNorm(x + Sublayer(x)). Residual baÄŸlantÄ± (+x) gradient'in kaybolmasÄ±nÄ± Ã¶nler!"}</TEInfoBox>
  <TEInfoBox color="#10B981" icon="ğŸ§®" title="Feed-Forward Network">{"FFN(x) = max(0, xÂ·W1 + b1)Â·W2 + b2. GeniÅŸlet (512â†’2048) â†’ ReLU â†’ Daralt (2048â†’512)"}</TEInfoBox>
</div>);

const TEPaperPozViz = () => (<div>
  <TEAnalojiBox emoji="ğŸ“" title={lang === "tr" ? "SÄ±ra Neden Ã–nemli?" : "Why Does Order Matter?"}>{"\"KÃ¶pek kediyi kovaladÄ±\" â‰  \"Kedi kÃ¶peÄŸi kovaladÄ±\" â€” aynÄ± kelimeler ama farklÄ± anlam! Transformer sÄ±rayÄ± bilmiyor, bu yÃ¼zden pozisyon bilgisi eklenmeli."}</TEAnalojiBox>
  <TEPosEncoding />
  <TEInfoBox color="#14B8A6" icon="ğŸŒŠ" title={lang === "tr" ? "Neden sin/cos?" : "Why sin/cos?"}>{"1. Benzersiz: Her pozisyon farklÄ± dalga deseni alÄ±r. 2. GÃ¶receli konum: PE(pos+k), PE(pos)'un lineer dÃ¶nÃ¼ÅŸÃ¼mÃ¼. 3. Genelleme: EÄŸitimde gÃ¶rmediÄŸi uzunluklara bile genellenebilir!"}</TEInfoBox>
  <TEAnalojiBox emoji="ğŸ¹" title={lang === "tr" ? "Piyano Analojisi" : "Piano Analogy"}>{"Her pozisyon bir akort gibi â€” farklÄ± frekanslarda dalgalarÄ±n bileÅŸimi. DÃ¼ÅŸÃ¼k boyutlar hÄ±zlÄ± deÄŸiÅŸir (tiz), yÃ¼ksek boyutlar yavaÅŸ (bas)."}</TEAnalojiBox>
</div>);

const TEPaperEgitimViz = () => (<div>
  <TEInfoBox color="#EF4444" icon="ğŸ’ª" title={lang === "tr" ? "EÄŸitim DetaylarÄ±" : "Training Details"}>{"Veri: 4.5M cÃ¼mle (EN-DE) + 36M cÃ¼mle (EN-FR). DonanÄ±m: 8Ã— NVIDIA P100 GPU. SÃ¼re: Base: 12 saat, Big: 3.5 gÃ¼n."}</TEInfoBox>
  <TEAnalojiBox emoji="ğŸƒ" title={lang === "tr" ? "Warmup Analojisi" : "Warmup Analogy"}>{"KoÅŸudan Ã¶nce Ä±sÄ±nma yaparsÄ±n. Model de Ã¶nce yavaÅŸ Ã¶ÄŸrenir (warmup), sonra hÄ±zlanÄ±r, en sonunda yavaÅŸlar."}</TEAnalojiBox>
  <TEInfoBox color="#F59E0B" icon="ğŸ¯" title={lang === "tr" ? "DÃ¼zenlileÅŸtirme" : "Regularization"}>{"Dropout (P=0.1): Rastgele nÃ¶ronlarÄ± kapat â†’ ezberlemeyi Ã¶nle. Label Smoothing (Îµ=0.1): %100 yerine %90 emin ol â†’ genelleme artar."}</TEInfoBox>
  <TEResultsTable />
</div>);

const TEPaperEtkiViz = () => (<div>
  <TEAnalojiBox emoji="ğŸ’¥" title={lang === "tr" ? "Bir makale nasÄ±l dÃ¼nyayÄ± deÄŸiÅŸtirir?" : "How does a paper change the world?"}>{"Bu 15 sayfalÄ±k makale, yapay zekanÄ±n tÃ¼m gidiÅŸatÄ±nÄ± deÄŸiÅŸtirdi. ChatGPT, Google Translate, gÃ¶rÃ¼ntÃ¼ AI'larÄ± â€” hepsi Transformer tabanlÄ±!"}</TEAnalojiBox>
  <TETimeline />
  <TEInfoBox color="#6366F1" icon="ğŸŒ" title={lang === "tr" ? "Sadece dil deÄŸil!" : "Not just language!"}>{"ğŸ–¼ï¸ GÃ¶rÃ¼ntÃ¼: ViT, DALL-E ğŸ§¬ Biyoloji: AlphaFold ğŸµ MÃ¼zik: MusicGen ğŸ’» Kod: Copilot"}</TEInfoBox>
  <div style={{display:"grid",gridTemplateColumns:"1fr 1fr 1fr 1fr",gap:10,marginBottom:16}}>
    {[{n:"90K+",l:lang === "tr" ? "AtÄ±f" : "Citations",c:"#6366F1"},{n:"8",l:lang === "tr" ? "Yazar" : "Authors",c:"#EC4899"},{n:"15",l:lang === "tr" ? "Sayfa" : "Pages",c:"#10B981"},{n:"2017",l:lang === "tr" ? lang === "tr" ? "YÄ±l" : "Year" : "Year",c:"#F59E0B"}].map((d,i) => (
      <div key={i} style={{padding:14,borderRadius:12,background:`${d.c}08`,border:`1px solid ${d.c}20`,textAlign:"center"}}>
        <div style={{fontSize:24,fontWeight:900,color:d.c}}>{d.n}</div><div style={{fontSize:11,color:"#94A3B8"}}>{d.l}</div>
      </div>
    ))}
  </div>
  <div style={{ padding: 20, borderRadius: 14, textAlign: "center", background: "linear-gradient(135deg, rgba(14,165,233,0.1), rgba(139,92,246,0.1), rgba(236,72,153,0.1))", border: "1px solid rgba(139,92,246,0.2)" }}>
    <div style={{ fontSize: 36, marginBottom: 10 }}>ğŸ“</div>
    <div style={{ fontSize: 18, fontWeight: 800, color: "#E2E8F0", marginBottom: 6 }}>{"Tebrikler!"}</div>
    <div style={{ fontSize: 14, color: "#94A3B8", lineHeight: 1.7 }}>{lang === "tr" ? "Attention, Multi-Head, Positional Encoding, Encoder-Decoder... ArtÄ±k senin iÃ§in sihir deÄŸil, anlaÅŸÄ±lÄ±r matematik!" : "Attention, Multi-Head, Positional Encoding, Encoder-Decoder... No longer magic, but understandable math!"}</div>
  </div>
</div>);


const VIZ_MAP = { tePaperGiris:TEPaperGirisViz, tePaperEskiMod:TEPaperEskiModViz, tePaperAttention:TEPaperAttentionViz, tePaperMat:TEPaperMatViz, tePaperMimari:TEPaperMimariViz, tePaperPoz:TEPaperPozViz, tePaperEgitim:TEPaperEgitimViz, tePaperEtki:TEPaperEtkiViz, coursePipeline:CoursePipelineViz, tokenFlow:TokenFlowViz, embeddingFlow:EmbeddingFlowViz, compGraph:CompGraphViz, opGradTable:OpGradTableViz, archPipeline:ArchPipelineViz, attentionFlow:AttentionFlowViz, causalMask:CausalMaskViz, mlpFlow:MLPFlowViz, paramDist:ParamDistViz, trainingCycle:TrainingCycleViz, lossTable:LossTableViz, adamEvolution:AdamEvolutionViz, inferenceTimeline:InferenceTimelineViz, temperatureViz:TemperatureViz, kvCache:KVCacheViz, gptFamily:GPTFamilyViz, residualViz:ResidualViz, softmaxViz:SoftmaxViz, neuralNetBasics:NeuralNetBasicsViz, langModelConcept:LangModelConceptViz, vectorConcept:VectorConceptViz, matrixMul:MatrixMulViz, derivative:DerivativeViz, topoSort:TopoSortViz, rnnToAttn:RnnToAttnViz, dotProduct:DotProductViz, normCompare:NormCompareViz, activation:ActivationViz, dimensionFlow:DimensionFlowViz, gradDescent:GradDescentViz, lrDecay:LrDecayViz, crossEntropyGraph:CrossEntropyGraphViz, samplingViz2:SamplingViz, whatsMissing:WhatsMissingViz, weightInit:WeightInitViz, trainingEvolution:TrainingEvolutionViz, gptScaleTower:GPTScaleTowerViz, frameworkCompare:FrameworkCompareViz, livePipeline:LivePipelineViz, tokenizerPlayground:TokenizerPlaygroundViz, autogradPlayground:AutogradPlaygroundViz, attentionPlayground:AttentionPlaygroundViz, transformerBlockFlow:TransformerBlockFlowViz, trainingSim:TrainingSimViz, generationPlayground:GenerationPlaygroundViz, scalingLaws:ScalingLawsViz, evolutionTimeline:EvolutionTimelineViz, hardwareEvolution:HardwareEvolutionViz, trainingPipeline:TrainingPipelineViz, tokenEvolution:TokenEvolutionViz, attentionEvolution:AttentionEvolutionViz, opensourceMap:OpensourceMapViz, trendsRadar:TrendsRadarViz };
const VizRenderer = ({ vizKey }) => { if (!vizKey) return null; const keys = Array.isArray(vizKey) ? vizKey : [vizKey]; return keys.map((k,i) => { const C = VIZ_MAP[k]; return C ? <C key={i}/> : null; }); };

// â”€â”€â”€ MAIN APP â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
export default function App() {
  const [lang, setLang] = useState('tr');
  const [tab, setTab] = useState("lecture");
  const [model] = useState(() => {
    const rng = (s) => () => { s = (s * 16807) % 2147483647; return (s - 1) / 2147483646; };
    const orig = Math.random; Math.random = rng(42); const m = createModel(); Math.random = orig; return m;
  });

  // Generate state
  const [gToks, setGToks] = useState([]);
  const [gStep, setGStep] = useState(-1);
  const [gDbg, setGDbg] = useState(null);
  const [gHist, setGHist] = useState([]);
  const [autoG, setAutoG] = useState(false);
  const [head, setHead] = useState(0);
  const [temp, setTemp] = useState(0.8);
  const [pStage, setPStage] = useState(-1);
  const [detail, setDetail] = useState("probs");

  // Train state
  const [tStep, setTStep] = useState(0);
  const [tLoss, setTLoss] = useState([]);
  const [tSamp, setTSamp] = useState([]);
  const [training, setTraining] = useState(false);
  const tRef = useRef(false);
  const [tSpeed, setTSpeed] = useState(1);

  // Architecture state
  const [archIdx, setArchIdx] = useState(0);

  // Lecture state
  const [weekIdx, setWeekIdx] = useState(0);
  const [sectionIdx, setSectionIdx] = useState(0);
  const [completedSections, setCompletedSections] = useState({});
  const [glossaryOpen, setGlossaryOpen] = useState(false);
  const [glossarySearch, setGlossarySearch] = useState("");
  const [showQuiz, setShowQuiz] = useState(false);
  const [codeMapOpen, setCodeMapOpen] = useState(false);
  const [instructorMode, setInstructorMode] = useState(false);
  const [showLessonPlan, setShowLessonPlan] = useState(false);
  const [showCheatSheet, setShowCheatSheet] = useState(false);

  // Track section completion
  useEffect(() => {
    if (tab === "lecture") {
      setCompletedSections(prev => {
        const wk = prev[weekIdx] || [];
        if (!wk.includes(sectionIdx)) return { ...prev, [weekIdx]: [...wk, sectionIdx] };
        return prev;
      });
    }
  }, [weekIdx, sectionIdx, tab]);

  // Generation step
  const doStep = useCallback(() => {
    if (gStep >= model.bs - 2) return null;
    const step = gStep + 1;
    const toks = step === 0 ? [BOS] : [...gToks];
    const K = [], V = [];
    let dbg = null;
    [0, 1, 2, 3, 4, 5].forEach((s, i) => setTimeout(() => setPStage(s), i * 100));
    for (let p = 0; p < toks.length; p++) {
      const r = fwd(model, toks[p], p, K, V);
      dbg = r.D;
    }
    const sL = dbg.logits.map(l => l / temp);
    const pr = softmax(sL);
    dbg.probs = pr;
    const next = smpl(pr);
    const newT = [...toks, next];
    setGToks(newT); setGStep(step); setGDbg(dbg);
    setGHist(h => [...h, { step, tok: itos[next], prob: pr[next], probs: [...pr] }]);
    if (next === EOS) setAutoG(false);
    return next;
  }, [gStep, gToks, model, temp]);

  useEffect(() => {
    if (!autoG) return;
    const t = setTimeout(() => {
      const tok = doStep();
      if (tok === null || tok === EOS || gStep >= model.bs - 3) setAutoG(false);
    }, 900);
    return () => clearTimeout(t);
  }, [autoG, doStep, gStep, model.bs]);

  const resetGen = () => { setGToks([]); setGStep(-1); setGDbg(null); setGHist([]); setAutoG(false); setPStage(-1); };

  // Training
  const startTrain = () => {
    const m = createModel(); setTStep(0); setTLoss([]); setTSamp([]); setTraining(true); tRef.current = true;
    let step = 0; const losses = [], samps = []; const params = [], mo = [], ve = [];
    for (const k of Object.keys(m.sd)) for (let r = 0; r < m.sd[k].length; r++) for (let c = 0; c < m.sd[k][r].length; c++) { params.push({ k, r, c }); mo.push(0); ve.push(0); }
    const genS = (mod, st) => {
      for (let s = 0; s < 3; s++) {
        const K2 = [], V2 = []; let tid = BOS; const g = [];
        for (let p = 0; p < mod.bs; p++) { const r = fwd(mod, tid, p, K2, V2); tid = smpl(softmax(r.logits.map(l => l / 0.8))); if (tid === EOS) break; g.push(itos[tid]); }
        samps.push({ step: st, name: g.join("") });
      }
      setTSamp([...samps]);
    };
    const doS = () => {
      if (!tRef.current || step >= 300) { setTraining(false); tRef.current = false; genS(m, step); return; }
      const doc = NAMES[step % NAMES.length];
      const toks = [BOS, ...doc.split("").map(c => stoi[c] || 0), EOS].slice(0, m.bs);
      const K = [], V = []; let loss = 0;
      for (let p = 0; p < toks.length - 1; p++) { const r = fwd(m, toks[p], p, K, V); loss += -Math.log(Math.max(1e-10, r.probs[toks[p + 1]])) / (toks.length - 1); }
      const eps = 1e-4, n = Math.min(40, params.length), lr = 0.01 * (1 - step / 300);
      for (let i = 0; i < n; i++) {
        const idx = Math.floor(Math.random() * params.length); const { k: pk, r: pr2, c: pc } = params[idx];
        const orig = m.sd[pk][pr2][pc]; m.sd[pk][pr2][pc] = orig + eps;
        const K2 = [], V2 = []; let l2 = 0;
        for (let p = 0; p < toks.length - 1; p++) { const r2 = fwd(m, toks[p], p, K2, V2); l2 += -Math.log(Math.max(1e-10, r2.probs[toks[p + 1]])) / (toks.length - 1); }
        const g = (l2 - loss) / eps; m.sd[pk][pr2][pc] = orig;
        mo[idx] = 0.9 * mo[idx] + 0.1 * g; ve[idx] = 0.95 * ve[idx] + 0.05 * g * g;
        const mh = mo[idx] / (1 - 0.9 ** (step + 1)), vh = ve[idx] / (1 - 0.95 ** (step + 1));
        m.sd[pk][pr2][pc] -= lr * mh / (Math.sqrt(vh) + 1e-8);
      }
      losses.push(loss); setTLoss([...losses]); setTStep(step + 1);
      if ((step + 1) % 40 === 0) genS(m, step + 1);
      step++; setTimeout(doS, tSpeed === 2 ? 2 : tSpeed === 0 ? 20 : 6);
    };
    doS();
  };

  const genWord = gHist.filter(h => h.tok !== "<BOS>" && h.tok !== "<EOS>").map(h => h.tok).join("");
  const currentWeek = WEEKS[weekIdx];
  const currentSection = currentWeek?.sections[sectionIdx];

  const TabBtn = ({ id, label, emoji }) => (
    <button onClick={() => setTab(id)} style={{
      padding: "10px 20px", borderRadius: 12, cursor: "pointer", fontSize: 16, fontWeight: 600,
      fontFamily: "'DM Sans', sans-serif", transition: "all .35s",
      border: tab === id ? "none" : "1px solid rgba(255,255,255,0.08)",
      background: tab === id ? "linear-gradient(135deg,#0EA5E9,#6366F1)" : "rgba(255,255,255,0.03)",
      color: tab === id ? "#fff" : "#64748B",
      boxShadow: tab === id ? "0 4px 24px rgba(14,165,233,.3)" : "none",
      transform: tab === id ? "scale(1.04)" : "scale(1)"
    }}>
      {emoji} {label}
    </button>
  );

  return (
    <LangContext.Provider value={lang}>
    <div style={{ minHeight: "100vh", background: "#030712", color: "#E2E8F0", fontFamily: "'DM Sans', sans-serif" }}>
      <link href="https://fonts.googleapis.com/css2?family=DM+Sans:wght@300;400;500;600;700;800&family=Fira+Code:wght@400;500;600;700&display=swap" rel="stylesheet" />

      {/* Background effects */}
      <div style={{ position: "fixed", inset: 0, pointerEvents: "none", zIndex: 0 }}>
        <div style={{ position: "absolute", top: "-15%", right: "-5%", width: "45%", height: "45%", background: "radial-gradient(circle,rgba(14,165,233,.06) 0%,transparent 70%)", filter: "blur(120px)" }} />
        <div style={{ position: "absolute", bottom: "-15%", left: "-5%", width: "40%", height: "40%", background: "radial-gradient(circle,rgba(99,102,241,.04) 0%,transparent 70%)", filter: "blur(120px)" }} />
      </div>

      <div style={{ position: "relative", zIndex: 1, maxWidth: 1280, margin: "0 auto", padding: "20px 28px" }}>

        {/* â”€â”€â”€ HEADER â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */}
        <div style={{ display: "flex", alignItems: "center", justifyContent: "space-between", marginBottom: 24, flexWrap: "wrap", gap: 12 }}>
          <div style={{ display: "flex", alignItems: "center", gap: 14 }}>
            <div style={{ width: 50, height: 50, borderRadius: 16, background: "linear-gradient(135deg,#0EA5E9,#6366F1)", display: "flex", alignItems: "center", justifyContent: "center", fontSize: 29, fontWeight: 800, boxShadow: "0 4px 28px rgba(14,165,233,.35)", color: "#fff" }}>Î¼</div>
            <div>
              <h1 style={{ fontSize: 27, fontWeight: 800, margin: 0, background: "linear-gradient(135deg,#F1F5F9,#0EA5E9)", WebkitBackgroundClip: "text", WebkitTextFillColor: "transparent" }}>{lang === 'tr' ? 'microGPT Akademi' : 'microGPT Academy'}</h1>
              <p style={{ margin: 0, fontSize: 15, color: "#64748B" }}>{lang === 'tr' ? 'SÄ±fÄ±rdan GPT â€” 243 satÄ±r saf Python â€¢ Ä°nteraktif Ders Notu & Laboratuvar' : 'GPT from Scratch â€” 243 lines of pure Python â€¢ Interactive Lecture Notes & Lab'}</p>
            </div>
          </div>
          <div style={{ display: "flex", gap: 6, flexWrap: "wrap" }}>
            <TabBtn id="lecture" label={lang === 'tr' ? "Ders NotlarÄ±" : "Lectures"} emoji="ğŸ“–" />
            <TabBtn id="generate" label={lang === 'tr' ? "Ãœretim Lab" : "Generation Lab"} emoji="âš¡" />
            <TabBtn id="train" label={lang === 'tr' ? "EÄŸitim Lab" : "Training Lab"} emoji="ğŸ“ˆ" />
            <TabBtn id="arch" label={lang === 'tr' ? "Mimari" : "Architecture"} emoji="ğŸ§ " />
            <button onClick={() => setLang(lang === 'tr' ? 'en' : 'tr')} style={{
              padding: "10px 16px", borderRadius: 12, cursor: "pointer", fontSize: 14, fontWeight: 600,
              fontFamily: "'DM Sans', sans-serif", transition: "all .35s",
              border: "1px solid rgba(255,255,255,0.15)",
              background: "rgba(255,255,255,0.05)",
              color: "#94A3B8",
            }}>
              {lang === 'tr' ? 'ğŸ‡¬ğŸ‡§ EN' : 'ğŸ‡¹ğŸ‡· TR'}
            </button>
            <button onClick={() => setGlossaryOpen(!glossaryOpen)} style={{
              padding: "10px 20px", borderRadius: 12, cursor: "pointer", fontSize: 16, fontWeight: 600,
              fontFamily: "'DM Sans', sans-serif", transition: "all .35s",
              border: glossaryOpen ? "none" : "1px solid rgba(255,255,255,0.08)",
              background: glossaryOpen ? "linear-gradient(135deg,#8B5CF6,#EC4899)" : "rgba(255,255,255,0.03)",
              color: glossaryOpen ? "#fff" : "#64748B",
              boxShadow: glossaryOpen ? "0 4px 24px rgba(139,92,246,.3)" : "none",
              transform: glossaryOpen ? "scale(1.04)" : "scale(1)"
            }}>
              {lang === 'tr' ? 'ğŸ“– SÃ¶zlÃ¼k' : 'ğŸ“– Glossary'}
            </button>
            <button onClick={() => setCodeMapOpen(true)} style={{
              padding: "10px 20px", borderRadius: 12, cursor: "pointer", fontSize: 16, fontWeight: 600,
              fontFamily: "'DM Sans', sans-serif", transition: "all .35s",
              border: "1px solid rgba(245,158,11,0.15)",
              background: "rgba(245,158,11,0.04)",
              color: "#F59E0B"
            }}>
              {lang === 'tr' ? 'ğŸ—ºï¸ Kod HaritasÄ±' : 'ğŸ—ºï¸ Code Map'}
            </button>
          </div>
        </div>

        {/* Glossary Panel Overlay */}
        {glossaryOpen && <GlossaryPanel searchTerm={glossarySearch} setSearchTerm={setGlossarySearch} onClose={() => setGlossaryOpen(false)} />}
        {/* Code Map Panel Overlay */}
        {codeMapOpen && <CodeMapPanel onClose={() => setCodeMapOpen(false)} />}

        {/* â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• */}
        {/* LECTURE TAB                                                */}
        {/* â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• */}
        {tab === "lecture" && (
          <div style={{ display: "flex", gap: 20 }}>
            {/* Week sidebar */}
            <div style={{ width: 220, flexShrink: 0 }}>
              {/* Overall progress */}
              {(() => {
                const totalSections = WEEKS.reduce((s, w) => s + w.sections.length, 0);
                const totalDone = Object.values(completedSections).reduce((s, arr) => s + arr.length, 0);
                const pct = totalSections > 0 ? Math.round((totalDone / totalSections) * 100) : 0;
                return (
                  <div style={{ marginBottom: 14, padding: "10px 12px", borderRadius: 10, background: "rgba(16,185,129,0.06)", border: "1px solid rgba(16,185,129,0.12)" }}>
                    <div style={{ display: "flex", justifyContent: "space-between", alignItems: "center", marginBottom: 6 }}>
                      <span style={{ fontSize: 13, color: "#10B981", fontWeight: 600 }}>{lang === "tr" ? "ğŸ“Š Ä°lerleme" : "ğŸ“Š Progress"}</span>
                      <span style={{ fontSize: 15, fontWeight: 800, color: "#10B981", fontFamily: "'Fira Code', monospace" }}>{pct}%</span>
                    </div>
                    <div style={{ height: 6, background: "rgba(255,255,255,0.05)", borderRadius: 3, overflow: "hidden" }}>
                      <div style={{ height: "100%", width: `${pct}%`, background: "linear-gradient(90deg,#10B981,#0EA5E9)", borderRadius: 3, transition: "width .6s" }} />
                    </div>
                    <div style={{ fontSize: 11, color: "#64748B", marginTop: 4 }}>{totalDone}/{totalSections} {lang === "tr" ? "bÃ¶lÃ¼m gÃ¶rÃ¼ldÃ¼" : "sections viewed"}</div>
                  </div>
                );
              })()}
              <div style={{ fontSize: 13, color: "#475569", textTransform: "uppercase", letterSpacing: ".14em", marginBottom: 10, fontWeight: 600 }}>{lang === "tr" ? "HaftalÄ±k Program" : "Weekly Program"}</div>
              <div style={{ display: "flex", flexDirection: "column", gap: 4 }}>
                {WEEKS.map((w, i) => {
                  const wDone = (completedSections[i] || []).length;
                  const wTotal = w.sections.length;
                  const wPct = wTotal > 0 ? (wDone / wTotal) * 100 : 0;
                  return (
                  <div key={w.id}>
                  <button onClick={() => { setWeekIdx(i); setSectionIdx(0); setShowQuiz(false); }} style={{
                    display: "flex", alignItems: "center", gap: 10, padding: "10px 12px", borderRadius: 10, border: "none", cursor: "pointer",
                    background: weekIdx === i ? `${w.color}15` : "transparent",
                    transition: "all .25s", textAlign: "left", fontFamily: "inherit", width: "100%"
                  }}>
                    <div style={{
                      width: 34, height: 34, borderRadius: 9, display: "flex", alignItems: "center", justifyContent: "center", fontSize: 19,
                      background: weekIdx === i ? w.color : "rgba(255,255,255,0.04)", color: weekIdx === i ? "#fff" : "#475569",
                      transition: "all .3s", flexShrink: 0, position: "relative"
                    }}>
                      {w.icon}
                      {wPct === 100 && <div style={{ position: "absolute", top: -3, right: -3, width: 12, height: 12, borderRadius: "50%", background: "#10B981", border: "2px solid #030712", display: "flex", alignItems: "center", justifyContent: "center", fontSize: 10, color: "#fff" }}>âœ“</div>}
                    </div>
                    <div style={{ flex: 1, minWidth: 0 }}>
                      <div style={{ fontSize: 11, color: "#475569", textTransform: "uppercase", letterSpacing: ".1em" }}>Hafta {w.week}</div>
                      <div style={{ fontSize: 15, fontWeight: 600, color: weekIdx === i ? w.color : "#94A3B8" }}>{tx(w.title, lang)}</div>
                    </div>
                  </button>
                  {/* Per-week progress bar */}
                  <div style={{ height: 3, background: "rgba(255,255,255,0.04)", borderRadius: 2, margin: "2px 12px 0", overflow: "hidden" }}>
                    <div style={{ height: "100%", width: `${wPct}%`, background: w.color, borderRadius: 2, transition: "width .5s" }} />
                  </div>
                  </div>
                  );
                })}
              </div>

              {/* Model summary card */}
              <div style={{ marginTop: 16, background: "rgba(255,255,255,0.02)", border: "1px solid rgba(255,255,255,0.06)", borderRadius: 14, padding: 14 }}>
                <div style={{ fontSize: 12, color: "#475569", textTransform: "uppercase", letterSpacing: ".12em", marginBottom: 8, fontWeight: 600 }}>{lang === "tr" ? "Model Ã–zeti" : "Model Summary"}</div>
                {[
                  { l: "Parametreler", v: "3,648", c: "#0EA5E9" },
                  { l: "Embedding", v: "16 boyut", c: "#8B5CF6" },
                  { l: "Attention", v: "4 head", c: "#10B981" },
                  { l: "Layer", v: "1 katman", c: "#F59E0B" },
                  { l: "Context", v: "8 token", c: "#EC4899" },
                  { l: "Vocabulary", v: "28 token", c: "#EF4444" },
                ].map((item, i) => (
                  <div key={i} style={{ display: "flex", justifyContent: "space-between", alignItems: "center", padding: "4px 0", borderBottom: i < 5 ? "1px solid rgba(255,255,255,0.03)" : "none" }}>
                    <span style={{ fontSize: 13, color: "#64748B" }}>{item.l}</span>
                    <span style={{ fontSize: 14, fontWeight: 600, color: item.c, fontFamily: "'Fira Code', monospace" }}>{item.v}</span>
                  </div>
                ))}
              </div>
            </div>

            {/* Main lecture content */}
            <div style={{ flex: 1, minWidth: 0 }}>
              {/* Week header */}
              <div style={{ background: `${currentWeek.color}08`, border: `1px solid ${currentWeek.color}20`, borderRadius: 18, padding: "20px 28px", marginBottom: 16 }}>
                <div style={{ display: "flex", alignItems: "center", gap: 14, marginBottom: 8 }}>
                  <div style={{ width: 52, height: 52, borderRadius: 16, background: currentWeek.color, display: "flex", alignItems: "center", justifyContent: "center", fontSize: 29, boxShadow: `0 4px 20px ${currentWeek.color}40`, flexShrink: 0 }}>
                    {currentWeek.icon}
                  </div>
                  <div>
                    <div style={{ fontSize: 13, color: "#64748B", textTransform: "uppercase", letterSpacing: ".1em" }}>{lang === "tr" ? "Hafta" : "Week"} {currentWeek.week}</div>
                    <h2 style={{ margin: 0, fontSize: 27, fontWeight: 800, color: currentWeek.color }}>{tx(currentWeek.title, lang)}</h2>
                    <p style={{ margin: "2px 0 0", fontSize: 15, color: "#94A3B8" }}>{tx(currentWeek.subtitle, lang)}</p>
                  </div>
                </div>

                {/* Section tabs */}
                <div style={{ display: "flex", gap: 6, marginTop: 12, overflowX: "auto", paddingBottom: 4, scrollbarWidth: "thin" }}>
                  {currentWeek.sections.map((s, i) => {
                    const ek = `week${currentWeek.week}_s${i}`;
                    const hasExtras = SECTION_EXTRAS[ek];
                    const hasTryIt = hasExtras?.tryIt;
                    const hasSteps = hasExtras?.stepByStep;
                    const hasRealCode = !!REAL_CODE[ek];
                    return (
                    <button key={i} onClick={() => setSectionIdx(i)} style={{
                      padding: "7px 14px", borderRadius: 8, border: "none", cursor: "pointer", fontSize: 13, fontWeight: 600,
                      background: sectionIdx === i ? currentWeek.color : "rgba(255,255,255,0.05)",
                      color: sectionIdx === i ? "#fff" : "#94A3B8", fontFamily: "inherit", transition: "all .25s",
                      whiteSpace: "nowrap", flexShrink: 0, position: "relative"
                    }}>
                      {i + 1}
                      {(hasTryIt || hasSteps) && <span style={{ position: "absolute", top: -2, right: -2, width: 8, height: 8, borderRadius: "50%", background: "#F59E0B", border: "2px solid #030712" }} title={lang === "tr" ? "Ä°nteraktif iÃ§erik" : "Interactive content"} />}
                      {hasRealCode && !hasTryIt && !hasSteps && <span style={{ position: "absolute", top: -2, right: -2, width: 8, height: 8, borderRadius: "50%", background: "#10B981", border: "2px solid #030712" }} title={lang === "tr" ? "GerÃ§ek microgpt.py kodu" : "Actual microgpt.py code"} />}
                      {hasExtras && !hasTryIt && !hasSteps && !hasRealCode && <span style={{ position: "absolute", top: -1, right: -1, width: 6, height: 6, borderRadius: "50%", background: "#8B5CF6", border: "1.5px solid #030712" }} title={lang === "tr" ? "Pedagojik iÃ§erik" : "Pedagogical content"} />}
                    </button>
                    );
                  })}
                </div>
                {/* Section title indicator */}
                <div style={{ display: "flex", justifyContent: "space-between", alignItems: "center", marginTop: 6, padding: "0 2px" }}>
                  <span style={{ fontSize: 14, color: currentWeek.color, fontWeight: 600 }}>{sectionIdx + 1}. {tx(currentSection?.title, lang)}</span>
                  <div style={{ display: "flex", alignItems: "center", gap: 8 }}>
                    <span style={{ display: "flex", alignItems: "center", gap: 3, fontSize: 11, color: "#F59E0B" }}><span style={{ width: 6, height: 6, borderRadius: "50%", background: "#F59E0B", display: "inline-block" }} /> kendin dene</span>
                    <span style={{ display: "flex", alignItems: "center", gap: 3, fontSize: 11, color: "#10B981" }}><span style={{ width: 6, height: 6, borderRadius: "50%", background: "#10B981", display: "inline-block" }} /> {lang === "tr" ? "gerÃ§ek kod" : "real code"}</span>
                    <span style={{ display: "flex", alignItems: "center", gap: 3, fontSize: 11, color: "#8B5CF6" }}><span style={{ width: 6, height: 6, borderRadius: "50%", background: "#8B5CF6", display: "inline-block" }} /> {lang === "tr" ? "kÃ¶prÃ¼/analoji" : "bridge/analogy"}</span>
                    <span style={{ fontSize: 12, color: "#475569" }}>{sectionIdx + 1}/{currentWeek.sections.length}</span>
                    <button onClick={() => setInstructorMode(!instructorMode)} style={{ fontSize: 11, padding: "2px 8px", borderRadius: 6, border: `1px solid ${instructorMode ? "rgba(251,191,36,0.4)" : "rgba(255,255,255,0.08)"}`, background: instructorMode ? "rgba(251,191,36,0.1)" : "transparent", color: instructorMode ? "#FBBF24" : "#475569", cursor: "pointer", fontFamily: "inherit", fontWeight: 600, marginLeft: 4 }}>
                      ğŸ“ {instructorMode ? (lang === "tr" ? "Hoca Modu âœ“" : "Instructor âœ“") : (lang === "tr" ? "Hoca Modu" : "Instructor")}
                    </button>
                  </div>
                </div>
              </div>

              {/* Section content */}
              {currentSection && (() => {
                const extraKey = `week${currentWeek.week}_s${sectionIdx}`;
                const extras = SECTION_EXTRAS[extraKey] || {};
                return (
                <div style={{ display: "flex", flexDirection: "column", gap: 16 }}>
                  <div style={{ background: "rgba(255,255,255,0.02)", border: "1px solid rgba(255,255,255,0.06)", borderRadius: 16, padding: 28 }}>
                    <h3 style={{ margin: "0 0 12px", fontSize: 23, fontWeight: 700, color: "#E2E8F0" }}>{tx(currentSection.title, lang)}</h3>

                    <SlideRefPanel weekIdx={currentWeek.week} sectionIdx={sectionIdx} />

                    {/* Instructor Mode Panels */}
                    {instructorMode && (
                      <div style={{ marginBottom: 16 }}>
                        <InstructorPanel weekIdx={currentWeek.week} sectionIdx={sectionIdx} weekColor={currentWeek.color} />
                        {sectionIdx === 0 && (
                          <div style={{ display: "flex", gap: 6, marginBottom: 8 }}>
                            <button onClick={() => setShowLessonPlan(!showLessonPlan)} style={{ flex: 1, fontSize: 13, padding: "6px 10px", borderRadius: 8, border: `1px solid ${showLessonPlan ? "rgba(99,102,241,0.3)" : "rgba(255,255,255,0.06)"}`, background: showLessonPlan ? "rgba(99,102,241,0.06)" : "transparent", color: showLessonPlan ? "#818CF8" : "#64748B", cursor: "pointer", fontFamily: "inherit", fontWeight: 600 }}>
                              ğŸ“‹ {showLessonPlan ? lang === "tr" ? "Ders PlanÄ±nÄ± Gizle" : "Hide Lesson Plan" : lang === "tr" ? "Ders PlanÄ±nÄ± GÃ¶ster" : "Show Lesson Plan"}
                            </button>
                            <button onClick={() => setShowCheatSheet(!showCheatSheet)} style={{ flex: 1, fontSize: 13, padding: "6px 10px", borderRadius: 8, border: `1px solid ${showCheatSheet ? "rgba(16,185,129,0.3)" : "rgba(255,255,255,0.06)"}`, background: showCheatSheet ? "rgba(16,185,129,0.06)" : "transparent", color: showCheatSheet ? "#10B981" : "#64748B", cursor: "pointer", fontFamily: "inherit", fontWeight: 600 }}>
                              ğŸ“ {showCheatSheet ? lang === "tr" ? "Kopya KaÄŸÄ±dÄ±nÄ± Gizle" : "Hide Cheat Sheet" : lang === "tr" ? "Kopya KaÄŸÄ±dÄ±nÄ± GÃ¶ster" : "Show Cheat Sheet"}
                            </button>
                          </div>
                        )}
                        {showLessonPlan && sectionIdx === 0 && <LessonPlanPanel weekIdx={currentWeek.week} />}
                        {showCheatSheet && sectionIdx === 0 && <CheatSheetPanel weekIdx={currentWeek.week} />}
                      </div>
                    )}

                    {/* Bridge Box â€” connection to previous content */}
                    {extras.bridge && <BridgeBox from={extras.bridge.from} to={extras.bridge.to} color={currentWeek.color} />}

                    {/* Why Box â€” motivation */}
                    {extras.why && <WhyBox color={currentWeek.color}>{extras.why}</WhyBox>}

                    {/* Analogy Box â€” real-world metaphor */}
                    {extras.analogy && <AnalogyBox title={extras.analogy.title} emoji={extras.analogy.emoji} color={currentWeek.color}>{extras.analogy.text}</AnalogyBox>}

                    {/* Concrete Box â€” abstractâ†’concrete */}
                    {extras.concrete && <ConcreteBox title={extras.concrete.title} color={currentWeek.color}><pre style={{ margin: 0, fontFamily: "'Fira Code', monospace", fontSize: 14, lineHeight: 1.6, color: "#E2E8F0", whiteSpace: "pre-wrap" }}>{extras.concrete.content}</pre></ConcreteBox>}

                    {currentSection.viz && <VizRenderer vizKey={currentSection.viz} />}

                    <p style={{ fontSize: 17, lineHeight: 1.8, color: "#CBD5E1", margin: 0 }}>{lang === 'en' && EN_CONTENT[currentWeek.id]?.[sectionIdx]?.content ? EN_CONTENT[currentWeek.id][sectionIdx].content : currentSection.content}</p>

                    {currentSection.highlight && (
                      <div style={{ marginTop: 16, padding: "14px 18px", borderRadius: 12, background: `${currentWeek.color}08`, borderLeft: `3px solid ${currentWeek.color}` }}>
                        <p style={{ margin: 0, fontSize: 16, lineHeight: 1.7, color: currentWeek.color, fontStyle: "italic" }}>{lang === 'en' && EN_CONTENT[currentWeek.id]?.[sectionIdx]?.highlight ? EN_CONTENT[currentWeek.id][sectionIdx].highlight : currentSection.highlight}</p>
                      </div>
                    )}

                    {currentSection.code && (
                      <div style={{ marginTop: 16 }}>
                        <CodeBlock code={currentSection.code} />
                      </div>
                    )}

                    {/* Real microgpt.py Code Block */}
                    {REAL_CODE[extraKey] && <RealCodeBlock data={REAL_CODE[extraKey]} weekColor={currentWeek.color} />}

                    {/* Step-by-Step Calculation */}
                    {extras.stepByStep && <StepByStepCalc title={extras.stepByStep.title} steps={extras.stepByStep.steps} color={currentWeek.color} />}

                    {/* Try It Yourself Widgets */}
                    {extras.tryIt === "tokenizer" && <TryItTokenizer />}
                    {extras.tryIt === "embedding" && <TryItEmbedding />}
                    {extras.tryIt === "softmax" && <TryItSoftmax />}
                    {extras.tryIt === "dotProduct" && <TryItDotProduct />}
                    {extras.tryIt === "gradient" && <TryItGradient />}
                    {extras.tryIt === "params" && <TryItParams />}

                    {/* Comparison Tables (shown for specific sections) */}
                    {weekIdx === 0 && sectionIdx === (currentWeek.sections.length - 1) && <ComparisonTableWidget data={COMPARISONS["model_scale"]} />}
                    {weekIdx === 3 && sectionIdx === 0 && <ConceptMapViz />}
                    {weekIdx === 4 && sectionIdx === 2 && <ComparisonTableWidget data={COMPARISONS["norm_compare"]} />}
                    {weekIdx === 4 && sectionIdx === 3 && <ComparisonTableWidget data={COMPARISONS["activation_compare"]} />}
                    {weekIdx === 5 && sectionIdx === 4 && <ComparisonTableWidget data={COMPARISONS["optimizer_compare"]} />}

                    {/* Common Mistakes (at last section of each week) */}
                    {COMMON_MISTAKES[currentWeek.week] && sectionIdx === currentWeek.sections.length - 1 && (
                      <MistakesList mistakes={COMMON_MISTAKES[currentWeek.week]} weekColor={currentWeek.color} />
                    )}

                    {/* Resources (at last section of each week) */}
                    {RESOURCES[currentWeek.week] && sectionIdx === currentWeek.sections.length - 1 && (
                      <ResourceLinks resources={RESOURCES[currentWeek.week]} />
                    )}
                  </div>

                  {/* Quiz toggle (shown at bottom after all sections) */}
                  {sectionIdx === currentWeek.sections.length - 1 && QUIZZES[currentWeek.week] && (
                    <div>
                      {!showQuiz ? (
                        <button onClick={() => setShowQuiz(true)} style={{
                          width: "100%", padding: "14px 20px", borderRadius: 14, border: "1px solid rgba(99,102,241,0.2)",
                          background: "rgba(99,102,241,0.06)", color: "#6366F1", fontSize: 17, fontWeight: 700,
                          cursor: "pointer", fontFamily: "inherit", display: "flex", alignItems: "center", justifyContent: "center", gap: 10
                        }}>
                          ğŸ§ª {lang === "tr" ? "Hafta" : "Week"} {currentWeek.week} {lang === "tr" ? "Quiz'ini Ã‡Ã¶z" : "Take Quiz"} ({QUIZZES[currentWeek.week].length} soru)
                        </button>
                      ) : (
                        <QuizWidget questions={QUIZZES[currentWeek.week]} weekColor={currentWeek.color} />
                      )}
                    </div>
                  )}

                  {/* Navigation */}
                  <div style={{ display: "flex", justifyContent: "space-between", alignItems: "center" }}>
                    <button
                      onClick={() => {
                        if (sectionIdx > 0) { setSectionIdx(sectionIdx - 1); setShowQuiz(false); }
                        else if (weekIdx > 0) { setWeekIdx(weekIdx - 1); setSectionIdx(WEEKS[weekIdx - 1].sections.length - 1); setShowQuiz(false); }
                      }}
                      disabled={weekIdx === 0 && sectionIdx === 0}
                      style={{ padding: "8px 18px", borderRadius: 10, border: "1px solid rgba(255,255,255,.08)", background: "transparent", color: (weekIdx === 0 && sectionIdx === 0) ? "#1E293B" : "#94A3B8", fontSize: 15, fontWeight: 600, cursor: (weekIdx === 0 && sectionIdx === 0) ? "not-allowed" : "pointer", fontFamily: "inherit" }}
                    >
                      â† Ã–nceki
                    </button>
                    <span style={{ fontSize: 13, color: "#475569" }}>
                      {lang === "tr" ? "Hafta" : "Week"} {currentWeek.week} â€¢ {lang === "tr" ? "BÃ¶lÃ¼m" : "Section"} {sectionIdx + 1}/{currentWeek.sections.length}
                    </span>
                    <button
                      onClick={() => {
                        if (sectionIdx < currentWeek.sections.length - 1) { setSectionIdx(sectionIdx + 1); setShowQuiz(false); }
                        else if (weekIdx < WEEKS.length - 1) { setWeekIdx(weekIdx + 1); setSectionIdx(0); setShowQuiz(false); }
                      }}
                      disabled={weekIdx === WEEKS.length - 1 && sectionIdx === currentWeek.sections.length - 1}
                      style={{
                        padding: "8px 18px", borderRadius: 10, border: "none", fontSize: 15, fontWeight: 600, fontFamily: "inherit",
                        background: (weekIdx === WEEKS.length - 1 && sectionIdx === currentWeek.sections.length - 1) ? "#1E293B" : currentWeek.color,
                        color: "#fff", cursor: (weekIdx === WEEKS.length - 1 && sectionIdx === currentWeek.sections.length - 1) ? "not-allowed" : "pointer"
                      }}
                    >
                      Sonraki â†’
                    </button>
                  </div>
                </div>
              );
              })()}
            </div>
          </div>
        )}

        {/* â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• */}
        {/* GENERATE TAB                                               */}
        {/* â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• */}
        {tab === "generate" && (
          <div style={{ display: "flex", flexDirection: "column", gap: 16 }}>
            {/* Explainer banner */}
            <div style={{ background: "rgba(14,165,233,0.06)", border: "1px solid rgba(14,165,233,0.15)", borderRadius: 14, padding: "12px 18px", display: "flex", alignItems: "center", gap: 12 }}>
              <span style={{ fontSize: 25 }}>ğŸ’¡</span>
              <div>
                <div style={{ fontSize: 16, fontWeight: 600, color: "#0EA5E9" }}>{lang === "tr" ? "Ãœretim LaboratuvarÄ±" : "Generation Laboratory"}</div>
                <div style={{ fontSize: 14, color: "#94A3B8" }}>{lang === "tr" ? "Model BOS token ile baÅŸlar, her adÄ±mda sonraki karakteri tahmin eder. Altta detaylÄ± gÃ¶rselleÅŸtirmeleri inceleyin." : "Model starts with BOS token, predicting the next character at each step. Explore detailed visualizations below."}</div>
              </div>
            </div>

            {/* Pipeline + Controls */}
            <div style={{ background: "rgba(255,255,255,0.02)", borderRadius: 16, border: "1px solid rgba(255,255,255,0.06)", padding: "14px 24px", display: "flex", alignItems: "center", justifyContent: "space-between", flexWrap: "wrap", gap: 10 }}>
              <Pipeline steps={ARCH_STEPS.map(s => ({ color: s.color, icon: s.icon }))} active={pStage} />
              <div style={{ display: "flex", alignItems: "center", gap: 10, flexWrap: "wrap" }}>
                <div style={{ display: "flex", alignItems: "center", gap: 6 }}>
                  <span style={{ fontSize: 13, color: "#475569" }}>T</span>
                  <input type="range" min="0.1" max="2.0" step="0.05" value={temp} onChange={e => setTemp(+e.target.value)} style={{ width: 70, accentColor: "#0EA5E9" }} />
                  <span style={{ fontSize: 15, color: "#0EA5E9", fontFamily: "'Fira Code', monospace", width: 32 }}>{temp.toFixed(1)}</span>
                </div>
                <button onClick={() => { resetGen(); setAutoG(true); }} style={{ padding: "7px 18px", borderRadius: 10, border: "none", background: "linear-gradient(135deg,#10B981,#059669)", color: "#fff", fontSize: 15, fontWeight: 600, cursor: "pointer", fontFamily: "inherit" }}>{lang === "tr" ? "â–¶ Otomatik" : "â–¶ Auto"}</button>
                <button onClick={doStep} disabled={autoG} style={{ padding: "7px 18px", borderRadius: 10, border: "1px solid rgba(14,165,233,.3)", background: "rgba(14,165,233,.08)", color: "#0EA5E9", fontSize: 15, fontWeight: 600, cursor: autoG ? "not-allowed" : "pointer", fontFamily: "inherit" }}>{lang === "tr" ? "â†’ AdÄ±m" : "â†’ Step"}</button>
                <button onClick={resetGen} style={{ padding: "7px 14px", borderRadius: 10, border: "1px solid rgba(239,68,68,.2)", background: "transparent", color: "#EF4444", fontSize: 15, fontWeight: 600, cursor: "pointer", fontFamily: "inherit" }}>â†»</button>
              </div>
            </div>

            {/* Main content grid */}
            <div style={{ display: "grid", gridTemplateColumns: "1fr 260px", gap: 16 }}>
              <div style={{ display: "flex", flexDirection: "column", gap: 16 }}>
                {/* Generated tokens */}
                <div style={{ background: "rgba(255,255,255,0.02)", borderRadius: 16, border: "1px solid rgba(255,255,255,0.06)", padding: 18 }}>
                  <div style={{ fontSize: 14, color: "#475569", textTransform: "uppercase", letterSpacing: ".1em", marginBottom: 10 }}>{lang === "tr" ? "Ãœretilen Tokenlar" : "Generated Tokens"}</div>
                  <div style={{ display: "flex", flexWrap: "wrap", gap: 5, minHeight: 48 }}>
                    {gHist.length === 0 && <span style={{ color: "#1E293B", fontSize: 16, fontStyle: "italic" }}>{lang === "tr" ? "â–¶ veya â†’ ile Ã¼retimi baÅŸlatÄ±n" : "Press â–¶ or â†’ to start generating"}</span>}
                    {gHist.map((h, i) => (
                      <div key={i} style={{ display: "flex", flexDirection: "column", alignItems: "center", gap: 2, animation: "popIn .35s cubic-bezier(.34,1.56,.64,1)" }}>
                        <div style={{
                          padding: "8px 12px", borderRadius: 10, fontSize: 23, fontWeight: 700, fontFamily: "'Fira Code', monospace",
                          background: h.tok === "<EOS>" ? "rgba(239,68,68,.12)" : "rgba(14,165,233,.1)",
                          color: h.tok === "<EOS>" ? "#EF4444" : "#E2E8F0",
                          border: `1.5px solid ${h.tok === "<EOS>" ? "rgba(239,68,68,.25)" : "rgba(14,165,233,.2)"}`
                        }}>
                          {h.tok === "<BOS>" ? "â—†" : h.tok === "<EOS>" ? "â– " : h.tok}
                        </div>
                        <span style={{ fontSize: 11, color: "#475569", fontFamily: "'Fira Code', monospace" }}>{(h.prob * 100).toFixed(0)}%</span>
                      </div>
                    ))}
                  </div>
                  {genWord && (
                    <div style={{ marginTop: 12, padding: "10px 14px", background: "rgba(14,165,233,.06)", borderRadius: 10, display: "flex", alignItems: "center", gap: 10 }}>
                      <span style={{ fontSize: 13, color: "#64748B" }}>{lang === "tr" ? "SonuÃ§:" : "Result:"}</span>
                      <span style={{ fontSize: 27, fontWeight: 700, fontFamily: "'Fira Code', monospace", color: "#0EA5E9" }}>{genWord}</span>
                    </div>
                  )}
                </div>

                {/* Detail panels */}
                <div style={{ background: "rgba(255,255,255,0.02)", borderRadius: 16, border: "1px solid rgba(255,255,255,0.06)", overflow: "hidden" }}>
                  <div style={{ display: "flex", borderBottom: "1px solid rgba(255,255,255,0.06)" }}>
                    {[
                      { id: "probs", l: lang === "tr" ? "OlasÄ±lÄ±klar" : "Probabilities", i: "ğŸ“Š", tip: lang === "tr" ? "Hangi token seÃ§ilecek?" : "Which token will be selected?" },
                      { id: "attn", l: "Attention", i: "ğŸ”", tip: lang === "tr" ? "Kim kime bakÄ±yor?" : "Who looks at whom?" },
                      { id: "mlp", l: "MLP NÃ¶ron", i: "ğŸ§¬", tip: lang === "tr" ? "Hangi nÃ¶ronlar aktif?" : "Which neurons are active?" },
                      { id: "embed", l: "Embedding", i: "ğŸ“", tip: lang === "tr" ? "VektÃ¶r deÄŸerleri" : "Vector values" }
                    ].map(d => (
                      <button key={d.id} onClick={() => setDetail(d.id)} style={{
                        flex: 1, padding: "10px 6px", border: "none", cursor: "pointer", fontFamily: "inherit", fontSize: 14, fontWeight: 600,
                        background: detail === d.id ? "rgba(14,165,233,.08)" : "transparent",
                        color: detail === d.id ? "#0EA5E9" : "#475569",
                        borderBottom: detail === d.id ? "2px solid #0EA5E9" : "2px solid transparent"
                      }}>
                        {d.i} {d.l}
                      </button>
                    ))}
                  </div>
                  <div style={{ padding: 20, minHeight: 200 }}>
                    {!gDbg && <div style={{ color: "#1E293B", fontSize: 16, textAlign: "center", paddingTop: 40 }}>{lang === "tr" ? "Bir adÄ±m Ã¼retin..." : "Generate a step..."}</div>}
                    {gDbg && detail === "probs" && <ProbDist probs={gDbg.probs} tgt={gToks[gToks.length - 1]} />}
                    {gDbg && detail === "attn" && <AttnMat weights={gDbg.AW} tokens={gToks.map(t => itos[t])} head={head} setHead={setHead} />}
                    {gDbg && detail === "mlp" && <MLPViz hidden={gDbg.mlpH} activated={gDbg.mlpAct} />}
                    {gDbg && detail === "embed" && <EmbedViz dbg={gDbg} />}
                  </div>
                </div>
              </div>

              {/* Right sidebar */}
              <div style={{ display: "flex", flexDirection: "column", gap: 10 }}>
                <InfoCard value={gHist.length} label={lang === "tr" ? "AdÄ±m" : "Step"} color="#0EA5E9" icon="âš¡" sub={`/ ${model.bs}`} />
                <InfoCard value={genWord || "â€”"} label={lang === "tr" ? "Ãœretilen" : "Generated"} color="#10B981" icon="âœ¦" />
                <InfoCard value={gDbg ? (Math.max(...gDbg.probs) * 100).toFixed(1) + "%" : "â€”"} label=lang === "tr" ? "Top-1 OlasÄ±lÄ±k" : "Top-1 Probability" color="#F59E0B" icon="ğŸ“Š" />
                <InfoCard value={temp.toFixed(2)} label="Temperature" color="#8B5CF6" icon="ğŸŒ¡" />
                <InfoCard value="3,648" label="Parametre" color="#EC4899" icon="ğŸ§®" sub="1 layer Ã— 4 heads" />
                <div style={{ background: "rgba(255,255,255,0.02)", border: "1px solid rgba(255,255,255,0.06)", borderRadius: 14, padding: 12 }}>
                  <div style={{ fontSize: 12, color: "#475569", textTransform: "uppercase", letterSpacing: ".12em", marginBottom: 6 }}>{lang === "tr" ? "ğŸ“œ GeÃ§miÅŸ" : "ğŸ“œ History"}</div>
                  <div style={{ display: "flex", flexDirection: "column", gap: 3, maxHeight: 160, overflowY: "auto" }}>
                    {gHist.map((h, i) => (
                      <div key={i} style={{ display: "flex", alignItems: "center", justifyContent: "space-between", padding: "3px 6px", borderRadius: 5, background: "rgba(0,0,0,.2)", fontSize: 13 }}>
                        <span style={{ color: "#475569", fontFamily: "'Fira Code', monospace" }}>#{i}</span>
                        <span style={{ fontWeight: 700, fontFamily: "'Fira Code', monospace", color: "#E2E8F0" }}>{h.tok === "<BOS>" ? "â—†" : h.tok === "<EOS>" ? "â– " : h.tok}</span>
                        <Spark data={h.probs.slice(2, 28)} w={50} h={14} />
                        <span style={{ color: "#475569", fontFamily: "'Fira Code', monospace", fontSize: 11 }}>{(h.prob * 100).toFixed(0)}%</span>
                      </div>
                    ))}
                  </div>
                </div>
              </div>
            </div>
          </div>
        )}

        {/* â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• */}
        {/* TRAIN TAB                                                  */}
        {/* â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• */}
        {tab === "train" && (
          <div style={{ display: "flex", flexDirection: "column", gap: 16 }}>
            {/* Explainer */}
            <div style={{ background: "rgba(16,185,129,0.06)", border: "1px solid rgba(16,185,129,0.15)", borderRadius: 14, padding: "12px 18px", display: "flex", alignItems: "center", gap: 12 }}>
              <span style={{ fontSize: 25 }}>ğŸ“</span>
              <div>
                <div style={{ fontSize: 16, fontWeight: 600, color: "#10B981" }}>{lang === "tr" ? "EÄŸitim LaboratuvarÄ±" : "Training Laboratory"}</div>
                <div style={{ fontSize: 14, color: "#94A3B8" }}>{lang === "tr" ? "Model 300 adÄ±mda isim kalÄ±plarÄ±nÄ± Ã¶ÄŸrenir. Loss dÃ¼ÅŸtÃ¼kÃ§e tahminler iyileÅŸir. Her 40 adÄ±mda Ã¼retilen Ã¶rnekleri gÃ¶zlemleyin." : "Model learns name patterns in 300 steps. Predictions improve as loss decreases. Observe generated samples every 40 steps."}</div>
              </div>
            </div>

            {/* Stats row */}
            <div style={{ display: "grid", gridTemplateColumns: "repeat(5,1fr)", gap: 10 }}>
              <InfoCard value={tStep} label={lang === "tr" ? "AdÄ±m" : "Step"} color="#0EA5E9" icon="â±" sub="/300" />
              <InfoCard value={tLoss.length ? tLoss[tLoss.length - 1].toFixed(3) : "â€”"} label="Loss" color="#F59E0B" icon="ğŸ“‰" />
              <InfoCard value={(0.01 * (1 - tStep / 300)).toFixed(4)} label="Learning Rate" color="#8B5CF6" icon="ğŸ¯" />
              <InfoCard value={tLoss.length >= 2 ? (tLoss[tLoss.length - 1] < tLoss[tLoss.length - 2] ? lang === "tr" ? "â†“ DÃ¼ÅŸÃ¼yor" : "â†“ Decreasing" : lang === "tr" ? "â†‘ ArtÄ±yor" : "â†‘ Increasing") : "â€”"} label="Trend" color={tLoss.length >= 2 && tLoss[tLoss.length - 1] < tLoss[tLoss.length - 2] ? "#10B981" : "#EF4444"} icon="ğŸ“ˆ" />
              <InfoCard value={tSamp.length} label={lang === "tr" ? "Ãœretilen" : "Generated"} color="#EC4899" icon="âœ¦" />
            </div>

            <div style={{ display: "grid", gridTemplateColumns: "5fr 2fr", gap: 16 }}>
              {/* Loss curve */}
              <div style={{ background: "rgba(255,255,255,0.02)", borderRadius: 16, border: "1px solid rgba(255,255,255,0.06)", padding: 20 }}>
                <div style={{ display: "flex", alignItems: "center", justifyContent: "space-between", marginBottom: 14 }}>
                  <div>
                    <h3 style={{ margin: 0, fontSize: 19, fontWeight: 700 }}>{lang === "tr" ? "Loss EÄŸrisi" : "Loss Curve"}</h3>
                    <p style={{ margin: "2px 0 0", fontSize: 13, color: "#64748B" }}>DÃ¼ÅŸen loss = model Ã¶ÄŸreniyor. SalÄ±nÄ±m normaldir (mini-batch).</p>
                  </div>
                  <div style={{ display: "flex", gap: 6 }}>
                    {!training ? (
                      <button onClick={startTrain} style={{ padding: "7px 18px", borderRadius: 10, border: "none", background: "linear-gradient(135deg,#10B981,#059669)", color: "#fff", fontSize: 15, fontWeight: 600, cursor: "pointer", fontFamily: "inherit" }}>{lang === "tr" ? "â–¶ BaÅŸlat" : "â–¶ Start"}</button>
                    ) : (
                      <button onClick={() => { tRef.current = false; setTraining(false); }} style={{ padding: "7px 18px", borderRadius: 10, border: "none", background: "#EF4444", color: "#fff", fontSize: 15, fontWeight: 600, cursor: "pointer", fontFamily: "inherit" }}>{lang === "tr" ? "â¹ Dur" : "â¹ Stop"}</button>
                    )}
                    <select value={tSpeed} onChange={e => setTSpeed(+e.target.value)} style={{ padding: "5px 8px", borderRadius: 7, background: "rgba(255,255,255,0.05)", border: "1px solid rgba(255,255,255,0.1)", color: "#94A3B8", fontSize: 13, fontFamily: "inherit" }}>
                      <option value={0}>{lang === "tr" ? "ğŸ¢ YavaÅŸ" : "ğŸ¢ Slow"}</option>
                      <option value={1}>{lang === "tr" ? "ğŸƒ Normal" : "ğŸƒ Normal"}</option>
                      <option value={2}>{lang === "tr" ? "ğŸš€ HÄ±zlÄ±" : "ğŸš€ Fast"}</option>
                    </select>
                  </div>
                </div>
                <div style={{ height: 220, background: "rgba(0,0,0,.2)", borderRadius: 12, overflow: "hidden", position: "relative" }}>
                  {tLoss.length > 1 ? (
                    <svg width="100%" height="100%" viewBox={`0 0 ${tLoss.length} 100`} preserveAspectRatio="none">
                      <defs><linearGradient id="lg1" x1="0" y1="0" x2="0" y2="1"><stop offset="0%" stopColor="#0EA5E9" stopOpacity=".25" /><stop offset="100%" stopColor="#0EA5E9" stopOpacity="0" /></linearGradient></defs>
                      <polygon points={`0,100 ${tLoss.map((l, i) => `${i},${Math.max(0, Math.min(100, (l - 1.5) * 30))}`).join(" ")} ${tLoss.length - 1},100`} fill="url(#lg1)" />
                      <polyline points={tLoss.map((l, i) => `${i},${Math.max(0, Math.min(100, (l - 1.5) * 30))}`).join(" ")} fill="none" stroke="#0EA5E9" strokeWidth="1.5" />
                      <line x1="0" y1={(3.33 - 1.5) * 30} x2={tLoss.length} y2={(3.33 - 1.5) * 30} stroke="#EF4444" strokeWidth=".5" strokeDasharray="4,4" opacity=".4" />
                    </svg>
                  ) : (
                    <div style={{ display: "flex", alignItems: "center", justifyContent: "center", height: "100%", color: "#1E293B", fontSize: 17 }}>{lang === "tr" ? "â–¶ BaÅŸlat" : "â–¶ Start"}</div>
                  )}
                  {tLoss.length > 1 && (
                    <div style={{ position: "absolute", top: 8, right: 12, fontSize: 12, color: "#475569" }}>
                      <span style={{ color: "#EF4444" }}>{lang==="tr"?"--- rastgele tahmin (3.33)":"--- random guess (3.33)"}</span>
                    </div>
                  )}
                </div>
              </div>

              {/* Generated names */}
              <div style={{ background: "rgba(255,255,255,0.02)", borderRadius: 16, border: "1px solid rgba(255,255,255,0.06)", padding: 16 }}>
                <h3 style={{ margin: "0 0 6px", fontSize: 17, fontWeight: 700 }}>{lang === "tr" ? "Ãœretilen Ä°simler" : "Generated Names"}</h3>
                <p style={{ margin: "0 0 10px", fontSize: 12, color: "#64748B" }}>{lang==="tr"?"Ä°lk Ã¶rnekler rastgele, adÄ±m arttÄ±kÃ§a gerÃ§ekÃ§i isimler oluÅŸur.":"First samples are random, names become realistic as steps increase."}</p>
                <div style={{ display: "flex", flexDirection: "column", gap: 3, maxHeight: 280, overflowY: "auto" }}>
                  {tSamp.length === 0 && <p style={{ color: "#1E293B", fontSize: 14, textAlign: "center", marginTop: 30 }}>{lang==="tr"?"Her 40 adÄ±mda Ã¶rnekler gÃ¶rÃ¼necek":"Samples will appear every 40 steps"}</p>}
                  {tSamp.map((s, i) => (
                    <div key={i} style={{ display: "flex", alignItems: "center", gap: 8, padding: "6px 10px", background: "rgba(0,0,0,.2)", borderRadius: 7 }}>
                      <div style={{ width: 34, height: 18, borderRadius: 4, background: `rgba(14,165,233,${Math.min(1, s.step / 300)})`, display: "flex", alignItems: "center", justifyContent: "center", fontSize: 10, color: "#fff", fontFamily: "'Fira Code', monospace", flexShrink: 0 }}>{s.step}</div>
                      <span style={{ fontSize: 17, fontWeight: 600, color: "#E2E8F0", fontFamily: "'Fira Code', monospace" }}>{s.name || "âˆ…"}</span>
                    </div>
                  ))}
                </div>
              </div>
            </div>
          </div>
        )}

        {/* â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• */}
        {/* ARCHITECTURE TAB                                           */}
        {/* â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• */}
        {tab === "arch" && (
          <div style={{ display: "flex", flexDirection: "column", gap: 16 }}>
            {/* Explainer */}
            <div style={{ background: "rgba(139,92,246,0.06)", border: "1px solid rgba(139,92,246,0.15)", borderRadius: 14, padding: "12px 18px", display: "flex", alignItems: "center", gap: 12 }}>
              <span style={{ fontSize: 25 }}>ğŸ§ </span>
              <div>
                <div style={{ fontSize: 16, fontWeight: 600, color: "#8B5CF6" }}>{lang === "tr" ? "Mimari KeÅŸfedici" : "Architecture Explorer"}</div>
                <div style={{ fontSize: 14, color: "#94A3B8" }}>{lang === "tr" ? "GPT'nin 6 temel bileÅŸenini adÄ±m adÄ±m keÅŸfedin. Her bileÅŸen hem kavramsal aÃ§Ä±klama hem de gerÃ§ek Python kodu ile sunulmuÅŸtur." : "Explore GPT's 6 core components step by step. Each component is presented with both conceptual explanation and real Python code."}</div>
              </div>
            </div>

            {/* Step tabs */}
            <div style={{ display: "flex", gap: 0, background: "rgba(255,255,255,0.02)", borderRadius: 16, border: "1px solid rgba(255,255,255,0.06)", overflow: "hidden" }}>
              {ARCH_STEPS.map((a, i) => (
                <button key={i} onClick={() => setArchIdx(i)} style={{ flex: 1, padding: "16px 6px 12px", border: "none", cursor: "pointer", fontFamily: "inherit", background: archIdx === i ? `${a.color}0D` : "transparent", position: "relative", transition: "all .2s" }}>
                  <div style={{
                    width: 38, height: 38, borderRadius: 11, margin: "0 auto 5px", display: "flex", alignItems: "center", justifyContent: "center",
                    fontSize: 18, fontWeight: 700, background: archIdx === i ? a.color : "rgba(255,255,255,0.04)",
                    color: archIdx === i ? "#fff" : "#475569", transform: archIdx === i ? "scale(1.15)" : "scale(1)",
                    boxShadow: archIdx === i ? `0 4px 16px ${a.color}40` : "none", transition: "all .3s"
                  }}>
                    {a.icon}
                  </div>
                  <div style={{ fontSize: 13, fontWeight: 600, color: archIdx === i ? a.color : "#475569" }}>{a.title.split(" ")[0]}</div>
                  {archIdx === i && <div style={{ position: "absolute", bottom: 0, left: "20%", right: "20%", height: 3, borderRadius: "3px 3px 0 0", background: a.color }} />}
                </button>
              ))}
            </div>

            {/* Content grid */}
            <div style={{ display: "grid", gridTemplateColumns: "1fr 1fr", gap: 16 }}>
              {/* Explanation */}
              <div style={{ background: "rgba(255,255,255,0.02)", borderRadius: 16, border: `1px solid ${ARCH_STEPS[archIdx].color}20`, padding: 28 }}>
                <div style={{ display: "flex", alignItems: "flex-start", gap: 12, marginBottom: 18 }}>
                  <div style={{ width: 50, height: 50, borderRadius: 14, background: ARCH_STEPS[archIdx].color, display: "flex", alignItems: "center", justifyContent: "center", fontSize: 27, fontWeight: 800, color: "#fff", flexShrink: 0, boxShadow: `0 4px 20px ${ARCH_STEPS[archIdx].color}40` }}>
                    {ARCH_STEPS[archIdx].icon}
                  </div>
                  <div>
                    <h2 style={{ margin: 0, fontSize: 25, fontWeight: 800, color: ARCH_STEPS[archIdx].color }}>{ARCH_STEPS[archIdx].title}</h2>
                    <p style={{ margin: "2px 0 0", fontSize: 15, color: "#94A3B8" }}>{tx(ARCH_STEPS[archIdx].sub, lang)}</p>
                  </div>
                </div>
                <p style={{ fontSize: 17, lineHeight: 1.8, color: "#CBD5E1", margin: "0 0 16px" }}>{ARCH_STEPS[archIdx].desc}</p>
                <div style={{ background: "rgba(0,0,0,.2)", borderRadius: 12, padding: 14, marginBottom: 16 }}>
                  <div style={{ fontSize: 13, color: ARCH_STEPS[archIdx].color, fontWeight: 600, marginBottom: 6, textTransform: "uppercase", letterSpacing: ".1em" }}>{lang==="tr"?"Detay":"Detail"}</div>
                  <p style={{ fontSize: 15, lineHeight: 1.7, color: "#94A3B8", margin: 0 }}>{ARCH_STEPS[archIdx].detail}</p>
                </div>
                <div style={{ display: "flex", gap: 6 }}>
                  <button onClick={() => setArchIdx(Math.max(0, archIdx - 1))} disabled={archIdx === 0} style={{ padding: "8px 16px", borderRadius: 8, border: "1px solid rgba(255,255,255,.08)", background: "transparent", color: archIdx > 0 ? "#94A3B8" : "#1E293B", fontSize: 14, fontWeight: 600, cursor: archIdx > 0 ? "pointer" : "not-allowed", fontFamily: "inherit" }}>â†</button>
                  <button onClick={() => setArchIdx(Math.min(5, archIdx + 1))} disabled={archIdx >= 5} style={{ padding: "8px 16px", borderRadius: 8, border: "none", background: archIdx < 5 ? ARCH_STEPS[Math.min(5, archIdx + 1)].color : "#1E293B", color: "#fff", fontSize: 14, fontWeight: 600, cursor: archIdx < 5 ? "pointer" : "not-allowed", fontFamily: "inherit" }}>â†’</button>
                </div>
              </div>

              {/* Code + dim flow */}
              <div style={{ display: "flex", flexDirection: "column", gap: 14 }}>
                <div style={{ flex: 1 }}>
                  <CodeBlock code={ARCH_STEPS[archIdx].code} />
                </div>
                <div style={{ background: "rgba(255,255,255,0.02)", borderRadius: 12, border: "1px solid rgba(255,255,255,0.06)", padding: 14 }}>
                  <div style={{ fontSize: 13, color: "#475569", marginBottom: 8, textTransform: "uppercase", letterSpacing: ".1em", fontWeight: 600 }}>{lang==="tr"?"Boyut AkÄ±ÅŸÄ± â€” Verinin YolculuÄŸu":"Dimension Flow â€” Data's Journey"}</div>
                  <DimFlow activeIdx={archIdx} />
                </div>
              </div>
            </div>
          </div>
        )}

        {/* Footer */}
        <div style={{ textAlign: "center", marginTop: 28, padding: "14px 0", borderTop: "1px solid rgba(255,255,255,0.04)" }}>
          <p style={{ margin: 0, fontSize: 13, color: "#1E293B" }}>{lang === 'tr' ? 'microGPT Akademi v21 â€” Ä°ki Dilli SÃ¼rÃ¼m' : 'microGPT Academy v21 â€” Bilingual Edition'}</p>
        </div>
      </div>

      <style>{`
        @keyframes popIn { from { opacity:0; transform:scale(.8) translateY(6px); } to { opacity:1; transform:scale(1) translateY(0); } }
        input[type="range"] { -webkit-appearance:none; height:4px; border-radius:2px; background:rgba(255,255,255,.08); outline:none; }
        input[type="range"]::-webkit-slider-thumb { -webkit-appearance:none; width:14px; height:14px; border-radius:50%; background:#0EA5E9; cursor:pointer; }
        select { cursor:pointer; }
        select option { background:#1E293B; color:#E2E8F0; }
        ::-webkit-scrollbar { width:4px; }
        ::-webkit-scrollbar-track { background:transparent; }
        ::-webkit-scrollbar-thumb { background:rgba(255,255,255,.08); border-radius:2px; }
        * { box-sizing: border-box; }
      `}</style>
    </div>
    </LangContext.Provider>
  );
}
