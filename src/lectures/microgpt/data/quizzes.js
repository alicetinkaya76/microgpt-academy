const QUIZZES = {
  0: [
    { q: {tr:"microGPT kaç satır koddan oluşur?", en:"How many lines of code is microGPT?"}, opts: ["243", "24300", "2430", "43"], ans: 0, explain: {tr:"Karpathy'nin saf Python implementasyonu tam 243 satır — hiçbir dış kütüphane kullanmadan.", en:"Karpathy's pure Python implementation is exactly 243 lines — without any external library."} },
    { q: {tr:"Bu model ne tür bir görev yapıyor?", en:"What type of task does this model perform?"}, opts: ["Çeviri", "Karakter düzeyinde isim üretme", "Ses tanıma", "Görüntü sınıflandırma"], ans: 1, explain: {tr:"32K İngilizce isim üzerinde eğitilmiş karakter düzeyinde dil modeli. Yeni, var olmayan isimler üretir.", en:"Character-level language model trained on 32K English names. Generates new, non-existent names."} },
    { q: {tr:"GPT 'autoregressive' ne demek?", en:"What does GPT 'autoregressive' mean?"}, opts: ["Sadece önceki tokenlara bakarak sırayla tahmin yapar", "Tüm cümleyi bir kerede üretir", "Paralel tüm tokenlara bakar", "Rastgele tokenlar seçer"], ans: 0, explain: {tr:"Autoregressive = her adımda kendi ürettiği çıktıyı girdi olarak kullanarak sırayla ilerler. Geleceği görmez.", en:"Autoregressive = progresses sequentially using its own output as input at each step. Cannot see the future."} },
    { q: {tr:"microGPT kaç parametre içerir?", en:"How many parameters does microGPT have?"}, opts: ["1 milyon", "1 milyar", "243", "3,648"], ans: 3, explain: {tr:"3,648 öğrenilebilir parametre. GPT-4'ün 1 trilyonun üzerinde parametresi var — aynı algoritma, farklı ölçek.", en:"3,648 learnable parameters. GPT-4 has over 1 trillion parameters — same algorithm, different scale."} },
    { q: {tr:"Forward pass ne yapar?", en:"What does forward pass do?"}, opts: ["Girdi → model → çıktı (tahmin) hesaplar", "Veri yükler", "Gradient hesaplar", "Parametreleri günceller"], ans: 0, explain: {tr:"Forward pass: girdi token'ı modelden geçirip 27 token üzerinde olasılık dağılımı (logits) üretir.", en:"Forward pass: passes input token through the model to produce probability distribution (logits) over 27 tokens."} },
    { q: {tr:"Bu kodda vocab (kelime dağarcığı) boyutu kaçtır?", en:"What is the vocab size in this code?"}, opts: ["27", "16", "8", "256"], ans: 0, explain: {tr:"a-z (26 harf) + BOS/EOS (1 özel token) = 27 token. Karakter düzeyinde tokenization.", en:"a-z (26 letters) + BOS/EOS (1 special token) = 27 tokens. Character-level tokenization."} },
    { q: {tr:"Neden PyTorch yerine sıfırdan yazılmış?", en:"Why is it written from scratch instead of PyTorch?"}, opts: ["Fark yok", "PyTorch pahalı", "PyTorch yavaş", "Her satırı ANLAYARAK öğrenmek — kara kutu olmasın"], ans: 3, explain: {tr:"PyTorch'ta 3 satırda yazılan şey burada 30+ satır. Ama her satır okunabilir ve anlaşılır — öğrenme amaçlı.", en:"What takes 3 lines in PyTorch is 30+ lines here. But every line is readable and understandable — for learning."} },
  ],
  1: [
    { q: {tr:"Tokenization ne işe yarar?", en:"What is tokenization for?"}, opts: ["Yazım hatalarını düzeltir", "Metni sıkıştırır", "Metni sayısal ID dizisine çevirir", "Metni renklendirir"], ans: 2, explain: {tr:"Bilgisayar metin işleyemez. Tokenization metni modelin anlayacağı sayılara çevirir.", en:"Computers can't process text. Tokenization converts text into numbers the model can understand."} },
    { q: {tr:"Embedding nedir?", en:"What is embedding?"}, opts: ["Dosya sıkıştırma", "Veri tabanı sorgusu", "Şifreleme yöntemi", "Token ID'yi çok boyutlu vektöre dönüştürme"], ans: 3, explain: {tr:"Embedding, bir ID'yi (ör: 5) anlamlı bir vektöre (ör: [0.2, -0.1, 0.5, ...]) dönüştürür. Benzer tokenlar yakın vektörlere sahip olur.", en:"Embedding converts an ID (e.g., 5) into a meaningful vector (e.g., [0.2, -0.1, 0.5, ...]). Similar tokens get similar vectors."} },
    { q: {tr:"BOS token ne işe yarar?", en:"What is the BOS token for?"}, opts: ["Boşluk karakteridir", "Dizinin başlangıcını/sonunu işaret eder", "En sık harfi temsil eder", "Hatayı gösterir"], ans: 1, explain: {tr:"BOS (Beginning of Sequence) modele 'yeni dizi başlıyor' ve 'dizi bitti' sinyali verir.", en:"BOS (Beginning of Sequence) signals 'new sequence starts' and 'sequence ended' to the model."} },
    { q: {tr:"Weight tying ne demek?", en:"What does weight tying mean?"}, opts: ["Giriş ve çıkış embedding matrisini paylaşma", "Eğitimi durdurma", "İki modeli birleştirme", "Ağırlıkları sıfırlama"], ans: 0, explain: {tr:"Aynı wte matrisi hem token→vektör (giriş) hem vektör→logit (çıkış) için kullanılır → parametre tasarrufu.", en:"The same wte matrix is used for both token→vector (input) and vector→logit (output) → parameter savings."} },
    { q: {tr:"'emma' tokenize edilirse kaç eğitim çifti oluşur?", en:"How many training pairs does tokenizing 'emma' create?"}, opts: ["5", "3", "6", "4"], ans: 0, explain: {tr:"BOS→e, e→m, m→m, m→a, a→BOS = 5 çift. Kural: harf sayısı + 1 (BOS→ilk harf) = eğitim çifti.", en:"BOS→e, e→m, m→m, m→a, a→BOS = 5 pairs. Rule: number of letters + 1 (BOS→first letter) = training pairs."} },
    { q: {tr:"Position embedding olmadan 'abc' ve 'cba' farkı ne olur?", en:"Without position embedding, what's the difference between 'abc' and 'cba'?"}, opts: ["Sadece son harf farklı", "Sadece ilk harf farklı", "Model ikisini AYNI görür", "Model farklı işler"], ans: 2, explain: {tr:"Transformer yapısal olarak sıra bilgisi içermez. Position embedding olmadan token sırası kaybolur!", en:"Transformer structurally contains no order information. Without position embedding, token order is lost!"} },
    { q: {tr:"Softmax çıktılarının toplamı kaçtır?", en:"What do softmax outputs sum to?"}, opts: ["1", "Değişir", "0", "0.5"], ans: 0, explain: {tr:"Softmax her zaman toplam=1 olan olasılık dağılımı üretir. P(i) = exp(xi)/Σexp(xj), tüm P'ler toplamı 1.", en:"Softmax always produces a probability distribution summing to 1. P(i) = exp(xi)/Σexp(xj), all P's sum to 1."} },
  ],
  2: [
    { q: {tr:"Türev (gradient) modele ne söyler?", en:"What does the derivative (gradient) tell the model?"}, opts: ["Kaç parametre var", "Modelin doğruluğu", "Her parametreyi hangi yönde değiştirince loss azalır", "Eğitim ne kadar sürer"], ans: 2, explain: {tr:"∂L/∂w = 'w'yi biraz artırırsam loss ne kadar değişir?' Negatif yönde güncelleme yaparak loss azaltılır.", en:"∂L/∂w = 'if I increase w slightly, how much does loss change?' Updating in the negative direction reduces loss."} },
    { q: {tr:"grad += kullanmak neden kritik? (= yerine)", en:"Why is grad += critical? (instead of =)"}, opts: ["Python kuralı", "Birden fazla yoldan gelen gradientler toplanmalı", "Daha hızlı", "Bellek tasarrufu"], ans: 1, explain: {tr:"Bir parametre birden fazla yoldan loss'u etkileyebilir (ör: weight tying). Tüm yolların gradientleri toplanmalıdır.", en:"A parameter can affect loss through multiple paths (e.g., weight tying). Gradients from all paths must be summed."} },
    { q: {tr:"Topological sort backward pass'te neden gerekli?", en:"Why is topological sort needed in backward pass?"}, opts: ["Düğümlerin doğru bağımlılık sırasında işlenmesi için", "Hız optimizasyonu", "Alfabetik sıralama için", "Bellek yönetimi"], ans: 0, explain: {tr:"Chain rule'ın doğru çalışması için bir düğümün gradientini hesaplamadan önce onu kullanan tüm düğümler hesaplanmış olmalı.", en:"For chain rule to work correctly, all nodes that use a node must be computed before computing that node's gradient."} },
    { q: {tr:"L = a×b ise ∂L/∂a kaçtır?", en:"If L = a×b, what is ∂L/∂a?"}, opts: ["a×b", "1", "b", "a"], ans: 2, explain: {tr:"Çarpmanın yerel türevi: ∂(a×b)/∂a = b (diğer girdiyi sabit tut, a katsayısı = b). Oyun alanında deneyin!", en:"Multiplication's local derivative: ∂(a×b)/∂a = b (hold the other input constant, coefficient of a = b). Try it!"} },
    { q: {tr:"Backward pass neden loss düğümünden (L) başlar?", en:"Why does backward pass start from the loss node (L)?"}, opts: ["∂L/∂L = 1 olduğu için — chain rule'un başlangıç noktası", "Rastgele seçim", "Alfabetik sıra", "En büyük değer olduğu için"], ans: 0, explain: {tr:"∂L/∂L = 1 (bir şeyin kendisine göre türevi = 1). Bu '1' chain rule ile çarpılarak tüm düğümlere yayılır.", en:"∂L/∂L = 1 (derivative of anything w.r.t. itself = 1). This '1' propagates to all nodes via chain rule multiplication."} },
    { q: {tr:"ReLU(x) fonksiyonunun x=-3'teki gradient'i kaçtır?", en:"What is the gradient of ReLU(x) at x=-3?"}, opts: ["3", "-3", "1", "0"], ans: 3, explain: {tr:"ReLU(x) = max(0,x). x<0 ise çıktı=0 ve gradient=0 (nöron 'ölü'). x>0 ise gradient=1 (geçir). -3<0 → 0.", en:"ReLU(x) = max(0,x). If x<0, output=0 and gradient=0 ('dead' neuron). If x>0, gradient=1 (pass through). -3<0 → 0."} },
    { q: {tr:"Bu koddaki Value sınıfı ile PyTorch Tensor farkı nedir?", en:"What's the difference between Value class and PyTorch Tensor?"}, opts: ["Farklı algoritma", "Value skaler, Tensor N-boyutlu — ama aynı gradient değerleri", "Value daha hızlı", "PyTorch daha doğru"], ans: 1, explain: {tr:"İkisi de aynı autograd algoritmasını çalıştırır. Fark: Value tek sayıyla, Tensor milyonlarca sayıyla paralel (GPU) çalışır.", en:"Both run the same autograd algorithm. Difference: Value works with single numbers, Tensor works with millions in parallel (GPU)."} },
  ],
  3: [
    { q: {tr:"Self-attention'da Q·K ne anlama gelir?", en:"What does Q·K mean in self-attention?"}, opts: ["Veri sıkıştırma", "İki token arasındaki uyum/benzerlik skoru", "Parametre sayısı", "Loss değeri"], ans: 1, explain: {tr:"Query (ne arıyorum?) ile Key (bende ne var?) arasındaki dot product = uyum skoru. Yüksek skor → daha çok dikkat.", en:"Query (what am I looking for?) and Key (what do I have?) dot product = compatibility score. High score → more attention."} },
    { q: {tr:"Neden √d_head'e bölüyoruz?", en:"Why do we divide by √d_head?"}, opts: ["Boyut artınca dot product büyür → softmax çok sivri → gradient kaybolur", "Bellekte yer açmak için", "Hız için", "Estetik sebep"], ans: 0, explain: {tr:"Scaling trick: d büyüdükçe dot product büyür, softmax dağılımı sivri (spike) yapar, gradient kaybolur. √d ile normalleştirme bunu önler.", en:"Scaling trick: as d grows, dot product grows, softmax becomes spiky, gradients vanish. Normalizing by √d prevents this."} },
    { q: {tr:"Multi-head attention neden kullanılır?", en:"Why is multi-head attention used?"}, opts: ["Sadece gelenek", "Her head farklı ilişki kalıpları öğrenebilir", "Parametre azaltma", "Hız artışı"], ans: 1, explain: {tr:"Her head bağımsız attention hesabı yapar: biri sesli-sessiz uyumunu, diğeri pozisyon yakınlığını öğrenebilir. Zenginlik sağlar.", en:"Each head computes independent attention: one can learn vowel-consonant patterns, another position proximity. Adds richness."} },
    { q: {tr:"Causal masking ne sağlar?", en:"What does causal masking provide?"}, opts: ["Daha iyi doğruluk", "Hız artışı", "Bellek tasarrufu", "Her token sadece ÖNCEKİ tokenlara bakabilir — geleceği göremez"], ans: 3, explain: {tr:"GPT causal modeldir: eğitimde 'kopya çekmeyi' önlemek için gelecek tokenlar maskelenir. Bu kodda KV cache doğal mask sağlar.", en:"GPT is causal: masking future tokens during training prevents 'cheating'. In this code, KV cache provides natural masking."} },
    { q: {tr:"Bu kodda head_dim kaçtır?", en:"What is head_dim in this code?"}, opts: ["8", "16", "4", "1"], ans: 2, explain: {tr:"16 boyutlu embedding ÷ 4 head = 4 boyut/head. Her head 4-boyutlu Q,K,V vektörleri ile çalışır.", en:"16-dim embedding ÷ 4 heads = 4 dims/head. Each head works with 4-dimensional Q,K,V vectors."} },
    { q: {tr:"Q, K, V'nin rolleri nedir?", en:"What are the roles of Q, K, V?"}, opts: ["Q=ne arıyorum, K=bende ne var, V=bilgi içeriği", "Hepsi aynı işi yapar", "Q=hız, K=yön, V=uzaklık", "Q=girdi, K=çıktı, V=hata"], ans: 0, explain: {tr:"Q·K = uyum skoru belirler, yüksek uyumlu token'ın V'si (bilgi içeriği) daha çok alınır.", en:"Q·K = determines compatibility score; high-compatibility token's V (information content) is taken more."} },
    { q: {tr:"Attention ağırlıklarının toplamı kaçtır?", en:"What do attention weights sum to?"}, opts: ["Değişir", "Head sayısı", "1", "0"], ans: 2, explain: {tr:"Softmax'ın çıktıları her zaman toplam=1 olur. Bu, bir olasılık dağılımı oluşturur — hangi token'a ne kadar dikkat?", en:"Softmax outputs always sum to 1. This forms a probability distribution — how much attention to each token?"} },
  ],
  4: [
    { q: {tr:"RMSNorm, LayerNorm'dan farkı nedir?", en:"How does RMSNorm differ from LayerNorm?"}, opts: ["Sonuçlar farklı", "Daha fazla parametre", "Ortalama çıkarmaz, sadece RMS ile normalize eder → ~%30 hızlı", "Daha yavaş"], ans: 2, explain: {tr:"RMSNorm, mean çıkarma adımını atlar → daha az hesaplama, eşdeğer kalite. Modern LLM'lerin (LLaMA, Mistral) standardı.", en:"RMSNorm skips the mean subtraction step → less computation, equivalent quality. Standard for modern LLMs (LLaMA, Mistral)."} },
    { q: {tr:"Residual connection (x + f(x)) neden şart?", en:"Why is residual connection (x + f(x)) essential?"}, opts: ["Kod basitliği", "Parametre azaltır", "Sadece GPT'de var", "Gradient doğrudan girişe akabilir, derin ağları eğitilebilir kılar"], ans: 3, explain: {tr:"+x terimi gradient'e 'kestirme yol' açar: ∂L/∂x = ∂L/∂out × (∂f/∂x + 1). +1 = gradient highway.", en:"The +x term creates a 'shortcut' for gradients: ∂L/∂x = ∂L/∂out × (∂f/∂x + 1). +1 = gradient highway."} },
    { q: {tr:"MLP'de ReLU² neden ~%40 nöronu 'öldürür'?", en:"Why does ReLU² in MLP 'kill' ~40% of neurons?"}, opts: ["Bozuk başlatma", "Negatif değerler sıfıra düşer (sparse), bu verimlilik ve genelleme artırır", "Bug", "Rastgele olur"], ans: 1, explain: {tr:"ReLU²: max(0,x)². Negatifler=0 → sparse aktivasyon. Bu, modelin bilgiyi yoğunlaştırmasına ve genellemesine yardımcı olur.", en:"Negative values become zero (sparse), which improves efficiency and generalization."} },
    { q: {tr:"Transformer bloğundaki 2 ana bileşen nedir?", en:"What are the 2 main components in a Transformer block?"}, opts: ["RNN + CNN", "Self-Attention + MLP (Feed-Forward)", "Encoder + Decoder", "Softmax + Loss"], ans: 1, explain: {tr:"Her Transformer katmanı: Attention (tokenlar arası bilgi akışı) + MLP (token içi dönüşüm). İkisi de residual ile sarmalanır.", en:"Each Transformer layer: Attention (inter-token info flow) + MLP (intra-token transformation). Both wrapped with residuals."} },
    { q: {tr:"Pre-norm ve post-norm farkı nedir?", en:"What's the difference between pre-norm and post-norm?"}, opts: ["İkisi de aynı", "Post-norm daha modern", "Pre-norm daha yavaş", "Pre-norm: norm → block → +res (daha kararlı eğitim)"], ans: 3, explain: {tr:"Pre-norm (bu kod): norm ÖNCE uygulanır → gradient akışı daha iyi → kararlı eğitim. GPT-2 post-norm, modern modeller pre-norm.", en:"Pre-norm (this code): norm applied BEFORE → better gradient flow → stable training. GPT-2 was post-norm, modern models use pre-norm."} },
    { q: {tr:"Aktivasyon fonksiyonu olmadan derin ağ ne olur?", en:"What happens to a deep network without activation?"}, opts: ["Daha hızlı olur", "Daha az parametre olur", "Tek bir matris çarpımına eşdeğer olur — katmanlar anlamsız", "Normal çalışır"], ans: 2, explain: {tr:"W₃×W₂×W₁×x = W×x. Non-linearity olmadan kaç katman olursa olsun tek lineer dönüşüm — öğrenme kapasitesi çok sınırlı.", en:"W₃×W₂×W₁×x = W×x. Without non-linearity, no matter how many layers, it's a single linear transform — very limited learning capacity."} },
    { q: {tr:"Wo ve fc2 neden sıfıra yakın başlatılır?", en:"Why are Wo and fc2 initialized near zero?"}, opts: ["Bellek tasarrufu", "Daha hızlı yakınsama", "Rastgele seçim", "Başta residual block ≈ identity → kararlı eğitim başlangıcı"], ans: 3, explain: {tr:"Wo≈0 → attention çıktısı≈0 → x + 0 = x (identity). Model yavaş yavaş block katkısını artırmayı öğrenir.", en:"Wo≈0 → attention output≈0 → x + 0 = x (identity). Model gradually learns to increase block contribution."} },
  ],
  5: [
    { q: {tr:"Cross-entropy loss = -log(P(doğru)). P=1/27 ise loss kaç?", en:"Cross-entropy loss = -log(P(correct)). If P=1/27, what's the loss?"}, opts: ["~3.33", "1.0", "27", "0"], ans: 0, explain: {tr:"-log(1/27) = log(27) ≈ 3.30. Bu, rastgele tahmin eden modelin loss'udur. Eğitimle bu değer düşer.", en:"-log(1/27) = log(27) ≈ 3.30. This is the loss of a randomly guessing model. Training brings this value down."} },
    { q: {tr:"Learning rate çok büyükse ne olur?", en:"What happens if learning rate is too large?"}, opts: ["Hiçbir etkisi yok", "Daha hızlı öğrenir", "Daha iyi geneller", "Minimum etrafında salınır veya patlar (diverge)"], ans: 3, explain: {tr:"Büyük LR → büyük adım → minimumu atlar → loss yükselir → model 'patlar'. Küçük LR güvenli ama yavaş.", en:"Large LR → large step → overshoots minimum → loss increases → model 'explodes'. Small LR is safe but slow."} },
    { q: {tr:"Adam optimizer'da momentum ne işe yarar?", en:"What does momentum do in Adam optimizer?"}, opts: ["Hız artışı", "Loss hesabı", "Bellek tasarrufu", "Önceki gradientleri hatırlayarak salınımı azaltır"], ans: 3, explain: {tr:"Momentum = gradient yönünün hareketli ortalaması. Gürültülü gradientleri düzleştirir, kararlı ilerlemedir.", en:"Momentum = moving average of gradient direction. Smooths noisy gradients for stable progress."} },
    { q: {tr:"Eğitim döngüsünün doğru sırası hangisidir?", en:"What is the correct order of the training loop?"}, opts: ["Loss → Backward → Forward", "Backward → Forward → Güncelle", "Forward → Loss → Backward → Güncelle → Grad sıfırla", "Güncelle → Forward → Loss"], ans: 2, explain: {tr:"Forward pass (tahmin) → loss hesapla → backward pass (gradient) → optimizer güncelle → gradient sıfırla → tekrarla.", en:"Forward pass (predict) → compute loss → backward pass (gradients) → optimizer update → zero gradients → repeat."} },
    { q: {tr:"Neden -log(p) kullanılır, neden sadece (1-p) değil?", en:"Why use -log(p) instead of just (1-p)?"}, opts: ["Düşük olasılığa ÇOK ağır ceza verir, bilgi teorisi ile uyumlu", "Geleneksel", "Daha hızlı hesaplanır", "Fark yok"], ans: 0, explain: {tr:"-log(0.01) = 4.6 ama 1-0.01 = 0.99. Log, düşük olasılıklara çok daha ağır ceza verir → model kesin yanlışlardan kaçınır.", en:"-log(0.01) = 4.6 but 1-0.01 = 0.99. Log penalizes low probabilities much more heavily → model avoids confident mistakes."} },
    { q: {tr:"Linear decay'de step=500 (toplam 1000) ise lr_t ne olur? (lr=0.01)", en:"In linear decay at step=500 (total 1000), what is lr_t? (lr=0.01)"}, opts: ["0", "0.001", "0.005", "0.01"], ans: 2, explain: {tr:"lr_t = 0.01 × (1 - 500/1000) = 0.01 × 0.5 = 0.005. Yarıda yarı hız — minimum'a yaklaştıkça daha küçük adımlar.", en:"lr_t = 0.01 × (1 - 500/1000) = 0.01 × 0.5 = 0.005. Half speed at halfway — smaller steps as approaching minimum."} },
    { q: {tr:"Gradient sıfırlanmazsa ne olur?", en:"What happens if gradients aren't zeroed?"}, opts: ["Daha iyi geneller", "Hiçbir etki yok", "Daha hızlı öğrenir", "Gradient birikir → sürekli büyür → model patlar"], ans: 3, explain: {tr:"+= ile gradient birikir: 0.5 → 0.8 → 1.5 → ... → ∞. Her adımda p.grad = 0 yapılmalı!", en:"+= accumulates gradients: 0.5 → 0.8 → 1.5 → ... → ∞. Must set p.grad = 0 every step!"} },
  ],
  6: [
    { q: {tr:"Inference'da backward pass yapılır mı?", en:"Is backward pass done during inference?"}, opts: ["Hayır — sadece forward pass yeterli", "Evet, her zaman", "Sadece ilk adımda", "Opsiyonel"], ans: 0, explain: {tr:"Inference'da parametre güncellemesi yok → gradient gerekmez → backward pass yok → daha hızlı, daha az bellek.", en:"No parameter updates during inference → no gradients needed → no backward pass → faster, less memory."} },
    { q: {tr:"Temperature=0.1 ile üretim nasıl olur?", en:"How does generation work with temperature=0.1?"}, opts: ["Tamamen rastgele", "Neredeyse deterministik — hep en olası token seçilir", "Çok yaratıcı", "Model çöker"], ans: 1, explain: {tr:"Düşük T → logitler/T büyür → softmax çok sivri → en yüksek olasılıklı token neredeyse %100 alır. Tekrarlara düşer.", en:"Low T → logits/T grows → softmax becomes very spiky → highest probability token gets nearly 100%. Falls into repetition."} },
    { q: {tr:"KV Cache ne sağlar?", en:"What does KV Cache provide?"}, opts: ["Daha fazla parametre", "Daha iyi sonuç", "Önceki tokenları yeniden hesaplamadan saklar → O(n²)→O(n)", "Sıkıştırma"], ans: 2, explain: {tr:"Her yeni token için sadece 1 K,V hesaplanır, öncekiler cache'ten okunur. Zaman: O(n²) → O(n).", en:"Each new token only needs 1 K,V computation, previous ones read from cache. Time: O(n²) → O(n)."} },
    { q: {tr:"Autoregressive üretim neden sıralı çalışır?", en:"Why does autoregressive generation work sequentially?"}, opts: ["Bellek yetersizliği", "Her token önceki token'a bağlıdır — paralel üretilemez", "GPU yetersizliği", "Tasarım hatası"], ans: 1, explain: {tr:"pos=3'ü üretmek için pos=2'nin çıktısı gerekir. Bu nedenle her token sırayla üretilmeli — paralellik mümkün değil.", en:"To generate pos=3, pos=2's output is needed. Therefore each token must be generated sequentially — parallelism isn't possible."} },
    { q: {tr:"Temperature=2.0 ile üretim nasıl olur?", en:"How does generation work with temperature=2.0?"}, opts: ["Çok yaratıcı — düşük olasılıklı tokenlar da seçilir", "Her zaman aynı isim", "Model çöker", "Sessiz kalır"], ans: 0, explain: {tr:"Yüksek T → logitler küçülür → softmax düzleşir → tüm tokenlar yakın olasılıkla → kaotik, anlamsız sonuçlar.", en:"High T → logits shrink → softmax flattens → all tokens get similar probability → chaotic, meaningless results."} },
    { q: {tr:"Üretim ne zaman durur?", en:"When does generation stop?"}, opts: ["Loss sıfır olunca", "Kullanıcı durdurna kadar", "8 harf üretince", "BOS/EOS token üretilince veya max uzunluğa ulaşınca"], ans: 3, explain: {tr:"İki duruş koşulu: BOS token üretilirse DUR (model 'bitti' diyor) veya block_size=8'e ulaşılırsa DUR (max uzunluk).", en:"Two stop conditions: if BOS token generated, STOP (model says 'done') or if block_size=8 reached, STOP (max length)."} },
    { q: {tr:"Bu kod ile GPT-4 arasındaki TEK fark nedir?", en:"What is the ONLY difference between this code and GPT-4?"}, opts: ["Farklı matematik", "Farklı algoritma", "Sadece ölçek ve mühendislik — temel matematik aynı", "Farklı programlama dili"], ans: 2, explain: {tr:"Birebir aynı algoritma! Fark: 3,648 vs 1T+ parametre, CPU vs 10K+ GPU, dakikalar vs aylar. Matematik = aynı.", en:"Exact same algorithm! Difference: 3,648 vs 1T+ parameters, CPU vs 10K+ GPUs, minutes vs months. Math = identical."} },
  ],
  7: [
    { q: {tr:"Scaling laws ne der?", en:"What do scaling laws say?"}, opts: ["Parametre/veri artınca loss güç yasasıyla düşer", "Küçük model her zaman yeterli", "Ölçek önemsiz", "Büyük model her zaman kötü"], ans: 0, explain: {tr:"Kaplanick et al.: loss ∝ 1/N^α. Daha fazla parametre VE veri → daha düşük loss. Güç yasası ilişkisi.", en:"Kaplanick et al.: loss ∝ 1/N^α. More parameters AND data → lower loss. Power law relationship."} },
    { q: {tr:"Pre-training → SFT → RLHF sıralamasının amacı nedir?", en:"What is the purpose of the Pre-training → SFT → RLHF order?"}, opts: ["Ham güç → yetenek → iyi davranış (hizalama)", "Hız artışı", "Maliyet azaltma", "Sadece gelenek"], ans: 0, explain: {tr:"Pre-training: genel bilgi öğren. SFT: assistant gibi davran. RLHF: zararsız ve yararlı ol. Her aşama bir katman ekler.", en:"Pre-training: learn general knowledge. SFT: behave like assistant. RLHF: be harmless and helpful. Each stage adds a layer."} },
    { q: {tr:"BPE tokenization'ın karakter düzeyine avantajı nedir?", en:"What advantage does BPE have over character-level?"}, opts: ["Aynı metin daha az token → daha uzun context", "Daha yavaş", "Daha basit", "Fark yok"], ans: 0, explain: {tr:"'playing' karakter: 7 token, BPE: 2 token. Aynı context window'a 3× daha fazla metin sığar → daha iyi anlama.", en:"'playing' character: 7 tokens, BPE: 2 tokens. 3× more text fits in same context window → better understanding."} },
    { q: {tr:"Flash Attention neyi değiştirir?", en:"What does Flash Attention change?"}, opts: ["Matematik formülünü", "Bellek erişim düzenini — sonuç aynı, 2-4× hızlı", "Attention'ı kaldırır", "Parametre sayısını"], ans: 1, explain: {tr:"Aynı softmax(QKᵀ/√d)V hesabı! Fark: GPU bellek hiyerarşisine uygun tiling → IO darboğazı çözülür → 2-4× hız.", en:"Same softmax(QKᵀ/√d)V computation! Difference: tiling optimized for GPU memory hierarchy → IO bottleneck solved → 2-4× speed."} },
    { q: {tr:"MoE (Mixture of Experts) nasıl verimlilik sağlar?", en:"How does MoE achieve efficiency?"}, opts: ["Tüm parametreleri kullanır", "Her token sadece 2/8 uzmanı aktive eder → az hesaplama", "Attention'ı kaldırır", "Parametre azaltır"], ans: 1, explain: {tr:"GPT-4 ~1.8T toplam parametre ama her token sadece ~280B aktif parametre kullanır. Büyük kapasite, verimli çalışma.", en:"GPT-4 ~1.8T total params but each token only uses ~280B active params. Large capacity, efficient operation."} },
    { q: {tr:"GPU neden AI eğitiminde CPU'dan çok daha iyi?", en:"Why is GPU much better than CPU for AI training?"}, opts: ["Daha az enerji", "Binlerce paralel çekirdek matris çarpımını aynı anda yapar", "Daha ucuz", "Daha basit mimari"], ans: 1, explain: {tr:"LLM = devasa matris çarpımları. GPU 6,912 CUDA çekirdeği ile bunları paralel yapar. CPU 8-16 çekirdek ile sıralı.", en:"LLM = massive matrix multiplications. GPU does these in parallel with 6,912 CUDA cores. CPU does sequential with 8-16 cores."} },
    { q: {tr:"microGPT ile GPT-4'ün ortak noktası nedir?", en:"What do microGPT and GPT-4 have in common?"}, opts: ["Parametre sayısı", "Donanım", "Temel Transformer algoritması: embedding + attention + MLP + softmax", "Eğitim verisi"], ans: 2, explain: {tr:"İkisi de aynı matematik: token embed → multi-head attention → MLP → softmax → next-token prediction. Fark = ölçek.", en:"Both use the same math: token embed → multi-head attention → MLP → softmax → next-token prediction. Difference = scale."} },
  ],
  8: [
    { q: {tr:"BPE'de en sık komşu çifti birleştirmenin bilgi-teorik gerekçesi nedir?", en:"What is the information-theoretic justification for BPE merging?"}, opts: ["Hız artışı", "Estetik sebep", "Bellek tasarrufu", "Entropy azaltma: sık çiftleri tek sembolle kodlamak toplam bit sayısını düşürür"], ans: 3, explain: {tr:"Shannon'ın kaynak kodlama teoremi: sık semboller kısa kod → ortalama uzunluk ≈ H(X). BPE buna yaklaşır.", en:"Shannon's source coding theorem: frequent symbols → short code → average length ≈ H(X). BPE approximates this."} },
    { q: {tr:"Hessian matrisi eğitimde ne bilgi verir?", en:"What information does the Hessian matrix provide in training?"}, opts: ["Parametre uzayındaki eğrilik — minimum'un keskin mi düz mü olduğunu gösterir", "Gradient yönü", "Parametre sayısı", "Loss değeri"], ans: 0, explain: {tr:"Hessian eigenvalue'ları: büyük = keskin minimum (genelleme kötü), küçük = düz (iyi genelleme). Newton yöntemi Hessian kullanır.", en:"Hessian eigenvalues: large = sharp minimum (poor generalization), small = flat (good generalization). Newton's method uses Hessian."} },
    { q: {tr:"Attention head pruning'de Taylor expansion skoru neyi ölçer?", en:"What does the Taylor expansion score measure in head pruning?"}, opts: ["Head'in kaldırılmasının loss'a etkisini birinci derece yaklaşımla tahmin eder", "Head renkliliğini", "Head boyutunu", "Head hızını"], ans: 0, explain: {tr:"I(h) = |α_h · ∂L/∂α_h| ≈ ΔL (head kaldırıldığında loss değişimi). Düşük skor = gereksiz head.", en:"I(h) = |α_h · ∂L/∂α_h| ≈ ΔL (loss change when head is removed). Low score = unnecessary head."} },
    { q: {tr:"Embedding isotropy neden önemlidir?", en:"Why is embedding isotropy important?"}, opts: ["Hız artışı", "Anisotropik uzayda tokenlar dar bir koniye sıkışır → benzerlik ölçümleri anlamsızlaşır", "Görsel güzellik", "Bellek tasarrufu"], ans: 1, explain: {tr:"Tüm vektörler aynı yöne bakıyorsa cosine similarity hep yüksek → ayırt edicilik kaybolur. İyi embedding isotropik.", en:"If all vectors point the same way, cosine similarity is always high → discriminability is lost. Good embedding is isotropic."} },
    { q: {tr:"Float16'da softmax overflow'u nasıl önlenir?", en:"How is softmax overflow prevented in Float16?"}, opts: ["max-trick: softmax(x) = softmax(x - max(x)) ile numerik kararlılık sağlanır", "Float64 kullanılır", "Softmax kullanılmaz", "Önlenemez"], ans: 0, explain: {tr:"exp(100) = overflow ama exp(100-100)=exp(0)=1. max çıkarma matematiği değiştirmez, numerik kararlılık sağlar.", en:"exp(100) = overflow but exp(100-100)=exp(0)=1. Max subtraction doesn't change the math, ensures numerical stability."} },
    { q: {tr:"Akademik raporda 'Related Work' bölümü neden zorunludur?", en:"Why is the 'Related Work' section mandatory in academic papers?"}, opts: ["Sayfa doldurmak", "Çalışmanızı mevcut literatüre konumlandırır ve katkınızın orijinalliğini gösterir", "Referans sayısını artırmak", "Gelenek"], ans: 1, explain: {tr:"Related work: 'daha önce ne yapıldı, benim farkım ne?' sorusuna cevap verir. Akademik katkının temeli.", en:"Related work: answers 'what was done before, how am I different?' This is the foundation of academic contribution."} },
    { q: {tr:"Kontrollü deneyde 'kontrol değişkeni' ne demektir?", en:"What does 'control variable' mean in controlled experiments?"}, opts: ["En önemli parametre", "Deneyde sabit tutulan değişken — sadece bir şeyi değiştirerek etkisini ölç", "Rastgele seçilen değer", "Sonuç değişkeni"], ans: 1, explain: {tr:"Örnek: BPE vs Unigram karşılaştırmasında vocab boyutu, veri seti, model mimarisi SABİT. Sadece tokenizer DEĞİŞİR.", en:"Example: in BPE vs Unigram comparison, vocab size, dataset, model architecture are FIXED. Only tokenizer CHANGES."} },
  ],
  9: [
    { q: {tr:"Neural Architecture Search'te Pareto frontı ne gösterir?", en:"What does the Pareto front show in Neural Architecture Search?"}, opts: ["En kötü modeller", "Rastgele noktalar", "Loss vs parametre trade-off'unda optimal noktaları — birini iyileştirmeden diğeri kötüleşmez", "En iyi model"], ans: 2, explain: {tr:"Pareto-optimal: A noktasından B'ye geçince ya loss artar ya parametre. İkisi birden azalmaz. Tasarım kararı gerektirir.", en:"Pareto-optimal: moving from A to B either increases loss or parameters. Both can't decrease. Design decision required."} },
    { q: {tr:"Knowledge distillation'da temperature T_distill neden yüksek tutulur?", en:"Why is temperature T_distill kept high in knowledge distillation?"}, opts: ["Hız için", "Bellek tasarrufu", "Soft targets daha bilgi içerir: düşük olasılıklı sınıflar arasındaki ilişkileri de aktarır", "Rastgele seçim"], ans: 2, explain: {tr:"T=1: [0.9, 0.05, 0.05] → sadece 'doğru cevap'. T=5: [0.4, 0.35, 0.25] → 'yanlışlar arasındaki benzerlik' bilgisi de aktarılır.", en:"T=1: [0.9, 0.05, 0.05] → only 'correct answer'. T=5: [0.4, 0.35, 0.25] → inter-class similarity info also transferred."} },
    { q: {tr:"RoPE neden context genellemede learned PE'den üstündür?", en:"Why is RoPE superior to learned PE for context generalization?"}, opts: ["Daha hızlı", "Göreceli pozisyon bilgisi: eğitim uzunluğu ötesinde de çalışır çünkü fark tabanlı", "Daha az parametre", "Daha basit"], ans: 1, explain: {tr:"Learned PE: pos=8'i hiç görmedi → bilinmeyen vektör. RoPE: pos(i)-pos(j) farkı önemli → uzun context'e geneller.", en:"Learned PE: never saw pos=8 → unknown vector. RoPE: pos(i)-pos(j) difference matters → generalizes to long context."} },
    { q: {tr:"Sparse attention'da %50 sparsity ne kadar FLOPs tasarrufu sağlar?", en:"How much FLOPs savings does 50% sparsity provide in sparse attention?"}, opts: ["Tasarruf yok", "%90", "%10", "Teorik %50, pratikte %30-40 (overhead nedeniyle)"], ans: 3, explain: {tr:"%50 token atlanır → QK^T'nin yarısı hesaplanmaz. Ama maskeleme + indexing overhead'i tam %50'ye ulaşmayı engeller.", en:"50% of tokens skipped → half of QK^T not computed. But masking + indexing overhead prevents reaching full 50%."} },
    { q: {tr:"Grokking fenomeni nedir?", en:"What is the grokking phenomenon?"}, opts: ["Overfitting", "Underfitting", "Hızlı öğrenme", "Eğitim loss≈0 olduktan ÇOK sonra aniden test loss'un da düşmesi — gecikmeli genelleme"], ans: 3, explain: {tr:"Küçük veri + uzun eğitim: model önce ezberler (train↓, test→), sonra aniden geneller (test↓). Neden olduğu hala araştırılıyor.", en:"Small data + long training: model first memorizes (train↓, test→), then suddenly generalizes (test↓). Why is still being researched."} },
    { q: {tr:"Loss landscape'te 'flat minimum' neden tercih edilir?", en:"Why is 'flat minimum' preferred in the loss landscape?"}, opts: ["Küçük parametre pertürbasyon'a karşı dayanıklı → daha iyi genelleme", "Daha düşük loss", "Daha hızlı eğitim", "Daha az parametre"], ans: 0, explain: {tr:"Sharp minimum: küçük w değişimi → büyük loss artışı (kırılgan). Flat: w±ε → loss stabil. Test veri dağılım kaymasına dayanıklı.", en:"Sharp minimum: small w change → large loss increase (fragile). Flat: w±ε → stable loss. Robust to test distribution shift."} },
    { q: {tr:"Ablation study nedir ve neden YL projelerinde zorunludur?", en:"What is an ablation study and why is it essential in ML projects?"}, opts: ["Hepsini ekle", "Kodu sil", "Her bileşeni tek tek çıkararak bireysel katkısını ölç — bilimsel yöntemin temelidir", "En iyi sonucu bul"], ans: 2, explain: {tr:"4 özellik eklediniz, toplam %15 iyileşme. Hangisi ne kadar katkı yaptı? Ablation olmadan bunu BİLEMEZSİNİZ.", en:"You added 4 features, total 15% improvement. Which contributed how much? Without ablation you CANNOT KNOW."} },
  ]
};
const COMMON_MISTAKES = {
  0: [
    { mistake: "\"GPT sadece büyük şirketler yapabilir\"", truth: "Bu 243 satırlık kod AYNI algoritmayı çalıştırır. Fark sadece ölçek ve donanımdır." },
    { mistake: "\"Derin öğrenme çok matematik gerektirir\"", truth: "Temel 4 işlem + türev yeterli. Bu derste göreceğiniz gibi her adım basit aritmetik." },
  ],
  1: [
    { mistake: "\"Embedding rastgele sayılardır, anlamsız\"", truth: "Başta rastgele ama eğitimle anlam kazanır. Benzer tokenlar yakın vektörlere sahip olur." },
    { mistake: "\"Token ID sırası önemli (a=0, b=1 → a ve b yakın)\"", truth: "ID sırası anlam taşımaz! Embedding zaten ilişkileri öğrenir. ID sadece indeks." },
    { mistake: "\"BOS ve EOS farklı tokenlar\"", truth: "Bu kodda ikisi de aynı token (ID=26). Bağlam farkını model öğrenir." },
  ],
  2: [
    { mistake: "\"grad = (eşittir) yeterli, += gerekmiyor\"", truth: "KRİTİK HATA! Bir parametre birden fazla yoldan loss'u etkiliyorsa (weight tying gibi) gradientler TOPLANMALI." },
    { mistake: "\"Her adımda gradient sıfırlamak gereksiz\"", truth: "Sıfırlanmazsa gradientler birikir → model patlar. p.grad = 0 her adımda ŞART." },
    { mistake: "\"Backward'da düğüm sırası önemli değil\"", truth: "Yanlış sırada gradient hesaplarsanız chain rule bozulur. Topological sort zorunlu." },
  ],
  3: [
    { mistake: "\"Q, K, V hep aynı — neden 3 ayrı matris?\"", truth: "Her biri farklı rol: Q=ne arıyorum, K=bende ne var, V=bilgi içeriği. Farklı projeksiyon farklı öğrenme." },
    { mistake: "\"Scaling (÷√d) sadece optimizasyon tricki\"", truth: "Hayır, kritik! Onsuz büyük boyutlarda softmax spike yapıp gradient kaybolur — model öğrenemez." },
  ],
  4: [
    { mistake: "\"Normalizasyon olmazsa da eğitilir\"", truth: "Derin ağlarda aktivasyonlar katman katman patlar veya kaybolur. Norm olmadan 2+ katmanlı model eğitilemez." },
    { mistake: "\"Residual sadece derin ağlar için lazım\"", truth: "Tek katmanlı bu kodda bile residual, kararlı eğitim ve identity başlatma sağlar." },
  ],
  5: [
    { mistake: "\"Loss her adımda düşmeli\"", truth: "Stochastic eğitimde (tek örnek/adım) loss salınır, bu NORMAL. Trend düşüyorsa model öğreniyor." },
    { mistake: "\"Learning rate yüksekse daha hızlı öğrenir\"", truth: "Belirli bir noktadan sonra LR artışı → patlama → loss NaN olur. İyi LR = denge." },
  ],
  6: [
    { mistake: "\"Temperature=0 en iyi sonuç verir\"", truth: "T≈0 deterministik → çeşitlilik yok, tekrarlara düşer. İyi üretim için T=0.7-1.0 dengeli." },
    { mistake: "\"Model her çalışmada aynı sonuç vermeli\"", truth: "Sampling stokastik → farklı rastgele tohum = farklı sonuç. Bu, özellik, hata değil." },
  ],
  7: [
    { mistake: "\"GPT-4 tamamen farklı bir teknoloji\"", truth: "Aynı Transformer temeli! Fark sadece ölçek (parametre, veri, donanım) ve mühendislik optimizasyonları." },
    { mistake: "\"Açık kaynak modeller zayıf\"", truth: "LLaMA 3.1 405B, DeepSeek-V3 birçok görevde GPT-4'e yakın veya eşit performans gösteriyor." },
    { mistake: "\"RLHF modeli akıllı yapar\"", truth: "RLHF hizalama (güvenlik, yararlılık) sağlar — temel yetenek pre-training'den gelir." },
  ],
  8: [
    { mistake: "\"Projeyi son güne bırakırım\"", truth: "Kod yazmak kolay, DEBUG etmek zor. İlk hafta çalışan bir şey olsun, ikinci hafta geliştirin." },
    { mistake: "\"ChatGPT ile tüm kodu yazarım, teslim ederim\"", truth: "Her satırı açıklayabilmelisiniz. Oral sınavda 'bunu AI yazdı' = sıfır puan." },
  ],
  9: [
    { mistake: "\"En karmaşık projeyi seçmeliyim\"", truth: "En ÇOK ÖĞRENECEĞİNİZ projeyi seçin. Basit ama iyi anlaşılmış > karmaşık ama yarım." },
    { mistake: "\"Rapor opsiyoneldir\"", truth: "Final'de analiz ve yorumlama %25 puan. Kod çalışsa bile raporsuz tam not alamazsınız." },
  ]
};


export { QUIZZES, COMMON_MISTAKES };
