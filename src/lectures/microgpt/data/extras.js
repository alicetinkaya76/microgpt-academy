const SECTION_EXTRAS = {
  "week0_s0": {
    why: {tr:"Bu dersin amacÄ± GPT'nin 'bÃ¼yÃ¼lÃ¼' gÃ¶rÃ¼nen davranÄ±ÅŸlarÄ±nÄ±n arkasÄ±ndaki matematiÄŸi anlamanÄ±zdÄ±r. ChatGPT kullandÄ±ÄŸÄ±nÄ±zda 'nasÄ±l yapÄ±yor?' diye merak ettiyseniz, bu ders tam size gÃ¶re.", en:"The goal of this course is to understand the math behind GPT's seemingly 'magical' behavior. If you've ever wondered 'how does it do that?' while using ChatGPT, this course is for you."}
  },
  "week0_s1": {
    why: {tr:"Yapay sinir aÄŸlarÄ±nÄ± anlamak ZORUNLU Ã§Ã¼nkÃ¼ GPT bir sinir aÄŸÄ±dÄ±r. Ama korkacak bir ÅŸey yok â€” Ã§arpma ve toplama biliyorsanÄ±z sinir aÄŸÄ±nÄ± anlayabilirsiniz.", en:"Understanding neural networks is ESSENTIAL because GPT is a neural network. But there's nothing to fear â€” if you know multiplication and addition, you can understand a neural network."},
    analogy: { title: {tr:"Excel FormÃ¼lÃ¼ Benzetmesi", en:"Excel Formula Analogy"}, emoji: "ğŸ“Š", text: {tr:"Bir Excel sayfasÄ± dÃ¼ÅŸÃ¼nÃ¼n: A1 hÃ¼cresine girdi yazÄ±yorsunuz, B1 hÃ¼cresinde =A1*0.5+0.3 formÃ¼lÃ¼ var, C1'de sonucu gÃ¶rÃ¼yorsunuz. Sinir aÄŸÄ± tam olarak bu â€” ama binlerce hÃ¼cre ve formÃ¼l. 'EÄŸitim' = Excel'in 0.5 ve 0.3 gibi katsayÄ±larÄ± otomatik bulmasÄ±. Veriyi gÃ¶steriyorsunuz, formÃ¼l kendini ayarlÄ±yor.", en:"Imagine an Excel sheet: you type input in cell A1, cell B1 has the formula =A1*0.5+0.3, and you see the result in C1. A neural network is exactly this â€” but with thousands of cells and formulas. 'Training' = Excel automatically finding coefficients like 0.5 and 0.3. You show it data, and the formula adjusts itself."} },
    concrete: { title: {tr:"Somut Ev FiyatÄ± Ã–rneÄŸi", en:"Concrete House Price Example"}, content: {tr:"Girdi: alan=120mÂ², oda=3\nModel: fiyat = wâ‚Ã—120 + wâ‚‚Ã—3 + b\n\nBaÅŸlangÄ±Ã§ (rastgele): wâ‚=0.001, wâ‚‚=0.5, b=0\nâ†’ fiyat = 0.12 + 1.5 + 0 = 1.62 TL (!)\n\n100 adÄ±m eÄŸitim sonrasÄ±: wâ‚=5000, wâ‚‚=20000, b=50000\nâ†’ fiyat = 600K + 60K + 50K = 710K TL âœ“", en:"Input: area=120mÂ², rooms=3\nModel: price = wâ‚Ã—120 + wâ‚‚Ã—3 + b\n\nInitial (random): wâ‚=0.001, wâ‚‚=0.5, b=0\nâ†’ price = 0.12 + 1.5 + 0 = 1.62 TL (!)\n\nAfter 100 training steps: wâ‚=5000, wâ‚‚=20000, b=50000\nâ†’ price = 600K + 60K + 50K = 710K TL âœ“"} }
  },
  "week0_s2": {
    analogy: { title: {tr:"CÃ¼mle Tamamlama Oyunu", en:"Sentence Completion Game"}, emoji: "ğŸ¯", text: {tr:"Dil modeli, arkadaÅŸlarÄ±nÄ±zla oynadÄ±ÄŸÄ±nÄ±z 'cÃ¼mleyi tamamla' oyununa benzer. Biri 'dÃ¼n okula gi...' deyince siz otomatik olarak 'ttim' veya 'deceÄŸim' gibi devamlar dÃ¼ÅŸÃ¼nÃ¼rsÃ¼nÃ¼z. Beyniniz binlerce cÃ¼mle duyduÄŸu iÃ§in 'olasÄ± devamlarÄ±' tahmin edebilir. GPT aynÄ± ÅŸeyi yapar â€” milyarlarca metin okumuÅŸ ve kalÄ±plarÄ± Ã¶ÄŸrenmiÅŸtir.", en:"A language model is like playing 'complete the sentence' with friends. When someone says 'yesterday I went to sch...', you automatically think of continuations like 'ool'. Your brain can predict 'likely continuations' because it has heard thousands of sentences. GPT does the same â€” it has read billions of texts and learned the patterns."} },
    why: {tr:"Dil modeli kavramÄ± bu dersin TEMELÄ°DÄ°R. TÃ¼m haftalarda Ã¶ÄŸreneceÄŸiniz her ÅŸey â€” embedding, attention, training â€” 'sonraki tokeni tahmin et' gÃ¶revine hizmet eder.", en:"The language model concept is the FOUNDATION of this course. Everything you'll learn â€” embedding, attention, training â€” serves the task of 'predict the next token'."}
  },
  "week0_s3": {
    bridge: { from: {tr:"Sinir aÄŸÄ± ve dil modeli kavramlarÄ±nÄ± Ã¶ÄŸrendik", en:"We learned neural network and language model concepts"}, to: {tr:"Åimdi somut olarak bu kodun ne yaptÄ±ÄŸÄ±nÄ± gÃ¶relim â€” 5 adÄ±mlÄ±k pipeline", en:"Now let's see concretely what this code does â€” the 5-step pipeline"} },
    concrete: { title: {tr:"Loss = 3.33 ne anlama geliyor?", en:"What does Loss = 3.33 mean?"}, content: {tr:"28 token arasÄ±ndan rastgele seÃ§im: P(doÄŸru) = 1/28\nLoss = -log(1/28) = log(28) â‰ˆ 3.33\n\nBu 'en kÃ¶tÃ¼' durum. EÄŸitimle:\nâ†’ P(doÄŸru) = 1/7 olursa: loss = log(7) â‰ˆ 1.95\nâ†’ Yani model rastgeleden 4Ã— daha iyi!", en:"Random selection among 28 tokens: P(correct) = 1/28\nLoss = -log(1/28) = log(28) â‰ˆ 3.33\n\nThis is the 'worst case'. With training:\nâ†’ If P(correct) = 1/7: loss = log(7) â‰ˆ 1.95\nâ†’ The model is 4Ã— better than random!"} }
  },
  "week0_s4": {
    analogy: { title: {tr:"Araba Mekanik vs SÃ¼rÃ¼cÃ¼", en:"Car Mechanic vs Driver"}, emoji: "ğŸ”§", text: {tr:"PyTorch kullanmak = araba kullanmak. microgpt.py okumak = motorun nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± anlamak. Ä°yi bir sÃ¼rÃ¼cÃ¼ iÃ§in motor bilgisi ÅŸart deÄŸil â€” ama Ä°YÄ° BÄ°R MÃœHENDÄ°S olmak istiyorsanÄ±z, motorun iÃ§ini bilmelisiniz. Bu ders sizi mÃ¼hendis yapÄ±yor.", en:"Using PyTorch = driving a car. Reading microgpt.py = understanding how the engine works. Motor knowledge isn't required to be a good driver â€” but if you want to be a GOOD ENGINEER, you need to know the engine internals. This course makes you an engineer."} },
    concrete: { title: {tr:"PyTorch vs microgpt.py", en:"PyTorch vs microgpt.py"}, content: {tr:"PyTorch'ta 3 satÄ±r:\nloss = criterion(output, target)\nloss.backward()\noptimizer.step()\n\nmicrogpt.py'de aynÄ± iÅŸlem 30+ satÄ±r.\nAma her satÄ±r OKUNABILIR ve ANLAÅILIR.\nPyTorch'un arkasÄ±nda ~2M satÄ±r C++/CUDA var.", en:"In PyTorch, 3 lines:\nloss = criterion(output, target)\nloss.backward()\noptimizer.step()\n\nIn microgpt.py the same operation is 30+ lines.\nBut every line is READABLE and UNDERSTANDABLE.\nBehind PyTorch there are ~2M lines of C++/CUDA."} }
  },
  "week0_s7": {
    tryIt: "params",
    why: {tr:"Bu 7 parametre modelin 'DNA'sÄ±dÄ±r. DeÄŸiÅŸtirdiÄŸinizde model tamamen farklÄ± davranÄ±r. Deney yaparak Ã¶ÄŸrenin!", en:"These 7 parameters are the model's 'DNA'. When you change them, the model behaves completely differently. Learn by experimenting!"},
    analogy: { title: {tr:"Araba Kontrol Paneli", en:"Car Dashboard"}, emoji: "ğŸ›ï¸", text: {tr:"n_embd = motor hacmi (bÃ¼yÃ¼k = gÃ¼Ã§lÃ¼ ama pahalÄ±). n_layer = vites sayÄ±sÄ± (Ã§ok = hassas kontrol). n_head = ayna sayÄ±sÄ± (Ã§ok = daha geniÅŸ gÃ¶rÃ¼ÅŸ). block_size = yakÄ±t deposu (bÃ¼yÃ¼k = uzun yol). learning_rate = gaz pedalÄ± hassasiyeti (Ã§ok = tehlikeli). num_steps = yol mesafesi. seed = baÅŸlangÄ±Ã§ noktasÄ±.", en:"n_embd = engine size (bigger = powerful but expensive). n_layer = number of gears (more = finer control). n_head = number of mirrors (more = wider view). block_size = fuel tank (bigger = longer range). learning_rate = gas pedal sensitivity (too much = dangerous). num_steps = distance traveled. seed = starting point."} }
  },
  "week0_s10": {
    analogy: { title: {tr:"Bisikletten Uzay MekiÄŸine", en:"From Bicycle to Space Shuttle"}, emoji: "ğŸš€", text: {tr:"microGPT bir bisiklet â€” pedal, direksiyon, fren hepsi var. GPT-4 bir uzay mekiÄŸi â€” aynÄ± fizik kurallarÄ± (Newton) ama milyonlarca kat daha karmaÅŸÄ±k mÃ¼hendislik. Bu derste bisikleti parÃ§alayÄ±p anlayacaksÄ±nÄ±z. Sonra mekiÄŸin %90'Ä±nÄ± da anlamÄ±ÅŸ olacaksÄ±nÄ±z.", en:"microGPT is a bicycle â€” pedals, handlebars, brakes are all there. GPT-4 is a space shuttle â€” same physics (Newton) but millions of times more complex engineering. In this course you'll take apart the bicycle. Then you'll understand 90% of the shuttle too."} },
    concrete: { title: {tr:"Ã–lÃ§ek KarÅŸÄ±laÅŸtÄ±rmasÄ±", en:"Scale Comparison"}, content: {tr:"microGPT:  3,648 parametre (~15 KB bellek)\nGPT-2:     1.5 milyar parametre (~6 GB)\nGPT-3:     175 milyar parametre (~700 GB)\nGPT-4:     ~1+ trilyon parametre (~4 TB)\n\nOran: GPT-4 / microGPT â‰ˆ 300,000,000Ã—\nAma temel algoritma AYNI.", en:"microGPT:  3,648 parameters (~15 KB memory)\nGPT-2:     1.5 billion parameters (~6 GB)\nGPT-3:     175 billion parameters (~700 GB)\nGPT-4:     ~1+ trillion parameters (~4 TB)\n\nRatio: GPT-4 / microGPT â‰ˆ 300,000,000Ã—\nBut the core algorithm is THE SAME."} }
  },
  "week1_s0": {
    why: {tr:"Bilgisayar sadece sayÄ±larÄ± iÅŸleyebilir. Dil modelinin metni anlamasÄ± iÃ§in Ã¶nce onu sayÄ±lara Ã§evirmeliyiz â€” tokenization tam olarak budur.", en:"Computers can only process numbers. For a language model to understand text, we first need to convert it to numbers â€” that's exactly what tokenization is."},
    bridge: { from: {tr:"GeÃ§en hafta GPT'nin ne yaptÄ±ÄŸÄ±nÄ± gÃ¶rdÃ¼k: isim alÄ±r, yeni isim Ã¼retir.", en:"Last week we saw what GPT does: takes a name, generates a new name."}, to: {tr:"Åimdi 'ismi alÄ±r' kÄ±smÄ±na odaklanÄ±yoruz. Model bir ismi nasÄ±l 'gÃ¶rÃ¼yor'? Cevap: tokenization.", en:"Now we focus on the 'takes a name' part. How does the model 'see' a name? Answer: tokenization."} }
  },
  "week1_s2": { tryIt: "tokenizer" },
  "week1_s3": {
    why: {tr:"Token ID'leri (0, 1, 2...) modele iliÅŸkileri sÃ¶yleyemez. Embedding her harfi Ã§ok boyutlu bir uzaya yerleÅŸtirerek bu sorunu Ã§Ã¶zer.", en:"Token IDs (0, 1, 2...) can't tell the model about relationships. Embedding solves this by placing each character in a multi-dimensional space."},
    analogy: { title: {tr:"Rehber Kitap Adresi", en:"Guidebook Address"}, emoji: "ğŸ“", text: {tr:"DÃ¼ÅŸÃ¼nÃ¼n ki her karakter bir ÅŸehir. Token ID = posta kodu (sadece numara). Embedding = GPS koordinatÄ±. Posta kodlarÄ± sÄ±ralÄ± ama coÄŸrafi yakÄ±nlÄ±ÄŸÄ± gÃ¶stermez. GPS koordinatlarÄ± ise gerÃ§ek mesafeyi verir. Embedding tÄ±pkÄ± GPS gibi, harflerin 'anlam uzayÄ±ndaki' gerÃ§ek konumunu verir.", en:"Think of each character as a city. Token ID = postal code (just a number). Embedding = GPS coordinates. Postal codes are sequential but don't show geographic proximity. GPS coordinates give real distance. Embedding works like GPS, giving the true position of characters in 'meaning space'."} },
    tryIt: "embedding"
  },
  "week1_s5": { tryIt: "softmax" },
  "week2_s0": {
    why: {tr:"5.000 parametrenin her birinin loss'a etkisini bilmemiz lazÄ±m. Autograd bunu TEK backward pass ile yapÄ±yor â€” hepsi bedava!", en:"We need to know the effect of each of 5,000 parameters on loss. Autograd does this in a SINGLE backward pass â€” all for free!"},
    bridge: { from: {tr:"GeÃ§en hafta modeli kurduk: embedding â†’ attention â†’ MLP â†’ Ã§Ä±ktÄ±. Ama bu model henÃ¼z 'cahil'.", en:"Last week we built the model: embedding â†’ attention â†’ MLP â†’ output. But this model is still 'ignorant'."}, to: {tr:"Åimdi 'nasÄ±l Ã¶ÄŸrenir?' sorusuna geÃ§iyoruz. Cevap: gradient hesaplama + parametre gÃ¼ncelleme.", en:"Now we ask 'how does it learn?' Answer: gradient computation + parameter update."} },
    analogy: { title: {tr:"KÃ¶r DaÄŸcÄ±", en:"Blind Mountain Climber"}, emoji: "ğŸ”ï¸", text: {tr:"Bir daÄŸda gÃ¶zÃ¼nÃ¼z baÄŸlÄ± duruyorsunuz ve en alÃ§ak noktaya inmeniz gerekiyor. TÃ¼rev tam olarak bu: 'bu yÃ¶nde ilerlersem yokuÅŸ aÅŸaÄŸÄ± mÄ± giderim?' Gradient ise tÃ¼m yÃ¶nlerdeki eÄŸimleri birden sÃ¶yler.", en:"You're on a mountain blindfolded and need to reach the lowest point. The derivative is exactly this: 'if I go this way, will I go downhill?' The gradient tells you the slope in ALL directions at once."} }
  },
  "week2_s3": {
    stepByStep: {
      title: {tr:"L = (a Ã— b) + c Hesaplama GrafÄ±", en:"L = (a Ã— b) + c Computation Graph"},
      steps: [
        { label: {tr:"DeÄŸerleri kur", en:"Set values"}, calc: "a = 2, b = 3, c = 1", note: {tr:"Bu deÄŸerler modelin parametreleri gibi dÃ¼ÅŸÃ¼nÃ¼n", en:"Think of these as model parameters"} },
        { label: {tr:"Ä°leri: d = a Ã— b", en:"Forward: d = a Ã— b"}, calc: "d = 2 Ã— 3 = 6", note: {tr:"Ã‡arpma â€” local_grads = (b=3, a=2)", en:"Multiplication â€” local_grads = (b=3, a=2)"} },
        { label: {tr:"Ä°leri: L = d + c", en:"Forward: L = d + c"}, calc: "L = 6 + 1 = 7", note: {tr:"Toplama â€” local_grads = (1, 1)", en:"Addition â€” local_grads = (1, 1)"} },
        { label: {tr:"Geri: âˆ‚L/âˆ‚L = 1", en:"Back: âˆ‚L/âˆ‚L = 1"}, calc: "L.grad = 1", note: {tr:"BaÅŸlangÄ±Ã§: loss'un tÃ¼revi her zaman 1", en:"Start: derivative of loss w.r.t. itself is always 1"} },
        { label: {tr:"Geri: âˆ‚L/âˆ‚d", en:"Back: âˆ‚L/âˆ‚d"}, calc: "d.grad += 1 Ã— 1 = 1", note: {tr:"chain rule: 1Ã—1", en:"chain rule: 1Ã—1"} },
        { label: {tr:"Geri: âˆ‚L/âˆ‚c", en:"Back: âˆ‚L/âˆ‚c"}, calc: "c.grad += 1 Ã— 1 = 1", note: {tr:"chain rule: 1Ã—1", en:"chain rule: 1Ã—1"} },
        { label: {tr:"Geri: âˆ‚L/âˆ‚a", en:"Back: âˆ‚L/âˆ‚a"}, calc: "a.grad += 3 Ã— 1 = 3", note: {tr:"local_grad=b=3 Ã— d.grad=1", en:"local_grad=b=3 Ã— d.grad=1"} },
        { label: {tr:"Geri: âˆ‚L/âˆ‚b", en:"Back: âˆ‚L/âˆ‚b"}, calc: "b.grad += 2 Ã— 1 = 2", note: {tr:"local_grad=a=2 Ã— d.grad=1", en:"local_grad=a=2 Ã— d.grad=1"} },
        { label: {tr:"DoÄŸrulama âœ“", en:"Verification âœ“"}, calc: "âˆ‚L/âˆ‚a = b = 3 âœ“, âˆ‚L/âˆ‚b = a = 2 âœ“", note: {tr:"Elle aynÄ± sonuÃ§!", en:"Same result as manual calculation!"} }
      ]
    }
  },
  "week3_s0": {
    bridge: { from: {tr:"Autograd ile gradient hesaplamayÄ± Ã¶ÄŸrendik.", en:"We learned gradient computation with autograd."}, to: {tr:"Ama modelin iÃ§inde ne oluyor? Token'lar nasÄ±l 'konuÅŸuyor'? Ä°ÅŸte attention â€” Transformer'Ä±n kalbi!", en:"But what happens inside the model? How do tokens 'talk'? Enter attention â€” the heart of the Transformer!"} }
  },
  "week3_s1": {
    analogy: { title: {tr:"ToplantÄ±da Not Alma", en:"Taking Notes in a Meeting"}, emoji: "ğŸ“‹", text: {tr:"Bir toplantÄ±dasÄ±nÄ±z. 5 kiÅŸi konuÅŸtu. Herkesi eÅŸit dinlemezsiniz: CEO'ya %40, proje liderine %30 dikkat edersiniz. Self-attention tam olarak bunu yapar: her token, Ã¶ncekilerden ne kadar bilgi alacaÄŸÄ±na dinamik karar verir.", en:"You're in a meeting. 5 people spoke. You don't listen equally: 40% attention to the CEO, 30% to the project lead. Self-attention does exactly this: each token dynamically decides how much info to take from previous tokens."} }
  },
  "week3_s2": {
    analogy: { title: {tr:"KÃ¼tÃ¼phane Arama", en:"Library Search"}, emoji: "ğŸ“š", text: {tr:"Query = aradÄ±ÄŸÄ±nÄ±z konu. Key = kitap baÅŸlÄ±klarÄ±. QÂ·K = uyum skoru. Value = kitap iÃ§eriÄŸi. Uyum yÃ¼ksekse Ã§ok alÄ±ntÄ± yaparsÄ±nÄ±z. Attention aynÄ± ÅŸekilde Ã§alÄ±ÅŸÄ±r!", en:"Query = your search topic. Key = book titles. QÂ·K = relevance score. Value = book content. High match â†’ quote a lot from that book. Attention works the same way!"} },
    tryIt: "dotProduct"
  },
  "week4_s0": {
    bridge: { from: {tr:"Self-attention ile tokenlar arasÄ± iletiÅŸimi Ã¶ÄŸrendik.", en:"We learned inter-token communication with self-attention."}, to: {tr:"Attention'dan sonra MLP bloÄŸu, normalizasyon ve residual baÄŸlantÄ±lar. Ä°ÅŸte tam Transformer!", en:"After attention comes the MLP block, normalization, and residual connections. The full Transformer!"} }
  },
  "week5_s0": {
    bridge: { from: {tr:"Model mimarisini tamamladÄ±k: Embedding â†’ Attention â†’ MLP â†’ Ã‡Ä±ktÄ±.", en:"We completed the architecture: Embedding â†’ Attention â†’ MLP â†’ Output."}, to: {tr:"Åimdi en kritik soru: bu model nasÄ±l Ã¶ÄŸrenir? Forward â†’ Loss â†’ Backward â†’ Update dÃ¶ngÃ¼sÃ¼.", en:"Now the most critical question: how does this model learn? The Forward â†’ Loss â†’ Backward â†’ Update loop."} },
    tryIt: "gradient"
  },
  "week5_s2": {
    stepByStep: {
      title: {tr:"Cross-Entropy Loss Hesaplama", en:"Cross-Entropy Loss Calculation"},
      steps: [
        { label: {tr:"Girdi", en:"Input"}, calc: "tokens = [BOS, h, e, l, l, o]", note: {tr:"'hello' tokenize edildi", en:"Tokenized 'hello'"} },
        { label: {tr:"Pozisyon 0: BOSâ†’h", en:"Position 0: BOSâ†’h"}, calc: "P('h') = 0.04", note: {tr:"Rastgele tahmine yakÄ±n", en:"Close to random guess"} },
        { label: {tr:"Loss hesapla", en:"Calculate loss"}, calc: "Lâ‚€ = -log(0.04) = 3.22", note: {tr:"DÃ¼ÅŸÃ¼k P â†’ yÃ¼ksek loss", en:"Low P â†’ high loss"} },
        { label: {tr:"Pozisyon 1: hâ†’e", en:"Position 1: hâ†’e"}, calc: "P('e') = 0.08", note: {tr:"Biraz daha iyi", en:"A bit better"} },
        { label: {tr:"Loss hesapla", en:"Calculate loss"}, calc: "Lâ‚ = -log(0.08) = 2.53", note: {tr:"Daha iyi P â†’ dÃ¼ÅŸÃ¼k loss", en:"Better P â†’ lower loss"} },
        { label: {tr:"Ortalama al", en:"Average"}, calc: "Loss = (3.22 + 2.53 + ...) / 5", note: {tr:"Modelin genel baÅŸarÄ±sÄ±", en:"Model's overall performance"} },
        { label: {tr:"KarÅŸÄ±laÅŸtÄ±r", en:"Compare"}, calc: {tr:"Rastgele: 3.33 | EÄŸitilmiÅŸ: ~2.0", en:"Random: 3.33 | Trained: ~2.0"}, note: {tr:"Loss dÃ¼ÅŸtÃ¼ = Ã¶ÄŸreniyor! ğŸ‰", en:"Loss dropped = learning! ğŸ‰"} }
      ]
    }
  },
  "week6_s2": { tryIt: "softmax" },
  "week7_s0": {
    why: {tr:"Scaling laws'u anlamak 'Ã¶lÃ§ek artÄ±rma' kararlarÄ±nÄ±n arkasÄ±ndaki bilimi gÃ¶sterir.", en:"Understanding scaling laws reveals the science behind 'scale up' decisions."},
    analogy: { title: {tr:"Fabrika Ãœretim HattÄ±", en:"Factory Production Line"}, emoji: "ğŸ­", text: {tr:"Ãœretim hattÄ±nÄ± 2Ã— bÃ¼yÃ¼tÃ¼nce Ã¼retim tam 2Ã— artmaz â€” gÃ¼Ã§ yasasÄ±yla artar. AI'da da aynÄ±: 10Ã— parametre â†’ ~3Ã— iyileÅŸme.", en:"Doubling the production line doesn't double output â€” it increases by power law. Same in AI: 10Ã— parameters â†’ ~3Ã— improvement."} }
  },
  "week7_s1": {
    bridge: { from: {tr:"Scaling laws'u Ã¶ÄŸrendik", en:"We learned scaling laws"}, to: {tr:"Åimdi somut tarihÃ§eyi gÃ¶relim â€” 2017'den bugÃ¼ne", en:"Now let's see the concrete history â€” from 2017 to today"} },
    concrete: { title: {tr:"Maliyet Evrimi", en:"Cost Evolution"}, content: {tr:"2017 Transformer: ~$10K\n2018 GPT-1: ~$50K\n2020 GPT-3: ~$5M\n2023 GPT-4: ~$100M+\n2024 Frontier: ~$200M+\n\n7 yÄ±lda 20,000Ã— maliyet artÄ±ÅŸÄ±\nAma performans 100Ã— iyileÅŸme", en:"2017 Transformer: ~$10K\n2018 GPT-1: ~$50K\n2020 GPT-3: ~$5M\n2023 GPT-4: ~$100M+\n2024 Frontier: ~$200M+\n\n20,000Ã— cost increase in 7 years\nBut 100Ã— performance improvement"} }
  },
  "week7_s3": {
    analogy: { title: {tr:"Ã‡Ä±rak â†’ Kalfa â†’ Usta", en:"Apprentice â†’ Journeyman â†’ Master"}, emoji: "ğŸ“", text: {tr:"Pre-training = Ã§Ä±raklÄ±k. SFT = kalfalÄ±k. RLHF = ustalÄ±k. Her aÅŸama bir Ã¶ncekinin Ã¼stÃ¼ne inÅŸa edilir.", en:"Pre-training = apprenticeship. SFT = journeyman phase. RLHF = mastery. Each stage builds on the previous one."} }
  },
};

export { SECTION_EXTRAS };
