import React, { useState, useEffect, useRef } from 'react';
import { useLang, tx } from '../../../core/i18n';
import { VB } from '../../../components/SharedComponents';

const INSTRUCTOR_NOTES = {
  // W0
  "week0_s0": { time: 10, difficulty: 1, prep: {tr:"microGPT'yi Ã¶nceden Ã§alÄ±ÅŸtÄ±rÄ±n, 2-3 isim Ã¼retin. Ã–ÄŸrencilere canlÄ± gÃ¶sterin.", en:"Run microGPT beforehand, generate 2-3 names. Show students live."}, emphasize: {tr:"243 satÄ±r = gerÃ§ek GPT. AynÄ± algoritma, sadece Ã¶lÃ§ek farkÄ±.", en:"243 lines = real GPT. Same algorithm, only difference is scale."}, studentQs: [
    { q: "Bu gerÃ§ek GPT mi?", a: "Evet! AynÄ± Transformer mimarisi. GPT-4 ile fark sadece parametre sayÄ±sÄ± (3,648 vs ~1.8T) ve eÄŸitim verisi." },
    { q: "Neden Python? Neden C++ deÄŸil?", a: "Okunabilirlik. AmaÃ§ Ã¶ÄŸrenmek, hÄ±z deÄŸil. Production'da PyTorch/C++ kullanÄ±lÄ±r." }
  ], cheatSheet: "microGPT: 243 satÄ±r, 3,648 param, 27 token vocab, 16-dim embedding, 4 head, 1 layer, block_size=8" },
  "week0_s1": { time: 5, difficulty: 1, prep: {tr:"Basit bir sinir aÄŸÄ± diyagramÄ± tahtaya Ã§izin (3 daire â†’ 2 daire â†’ 1 daire).", en:"Draw a simple neural network diagram on the board (3 circles â†’ 2 circles â†’ 1 circle)."}, emphasize: {tr:"Sinir aÄŸÄ± = Ã§arpma + toplama. Korkutucu deÄŸil.", en:"Neural network = multiplication + addition. Not scary."}, studentQs: [
    { q: "Biyolojik nÃ¶ronla ilgisi var mÄ±?", a: "Ä°sim oradan geliyor ama benzerlik yÃ¼zeysel. Matematiksel fonksiyon olarak dÃ¼ÅŸÃ¼nÃ¼n." }
  ], cheatSheet: "NÃ¶ron: output = activation(wâ‚xâ‚ + wâ‚‚xâ‚‚ + ... + b)" },
  "week0_s2": { time: 5, difficulty: 1, emphasize: {tr:"Dil modeli = P(sonraki token | Ã¶ncekiler). TÃ¼m ders bu TEK cÃ¼mle Ã¼zerine kurulu.", en:"Language model = P(next token | previous). The entire course is built on this SINGLE sentence."}, studentQs: [
    { q: "ChatGPT de aynÄ± ÅŸeyi mi yapÄ±yor?", a: "Evet! Her seferinde bir sonraki tokeni tahmin eder. 'AkÄ±llÄ±lÄ±k' Ã§ok bÃ¼yÃ¼k Ã¶lÃ§ekten geliyor." }
  ], cheatSheet: "Dil modeli: P(xâ‚œ | xâ‚, xâ‚‚, ..., xâ‚œâ‚‹â‚) â€” koÅŸullu olasÄ±lÄ±k" },
  "week0_s3": { time: 8, difficulty: 2, prep: {tr:"Pipeline diyagramÄ±nÄ± tahtaya Ã§izin. Her kutuyu renklendirin.", en:"Draw the pipeline diagram on the board. Color-code each box."}, emphasize: {tr:"Bu pipeline W1-W6'da detaylÄ± iÅŸlenecek. Åimdi bÃ¼yÃ¼k resmi gÃ¶rsÃ¼nler.", en:"This pipeline will be detailed in W1-W6. Let them see the big picture now."}, studentQs: [
    { q: "Her adÄ±m ne kadar sÃ¼rer?", a: "microGPT'de mikrosaniyeler. GPT-4'te bir token ~50ms. Ama milyarlarca parametre Ã§arpÄ±lÄ±yor." }
  ], cheatSheet: "Pipeline: Token â†’ Embed â†’ Pos â†’ Attention â†’ MLP â†’ Softmax â†’ Sample" },
  "week0_s4": { time: 3, difficulty: 1, emphasize: {tr:"Framework'ler kara kutu, biz cam kutu yapÄ±yoruz. Analoji: araba kullanmak vs motor anlamak.", en:"Frameworks are black boxes, we're making a glass box. Analogy: driving vs understanding the engine."} },
  "week0_s5": { time: 5, difficulty: 1, prep: {tr:"Python 3.10+ ve metin editÃ¶rÃ¼ hazÄ±r olsun. CanlÄ± kurulum gÃ¶sterin.", en:"Have Python 3.10+ and text editor ready. Show live setup."}, emphasize: {tr:"GPU gerekmez. Laptop yeterli. 3 dakikada eÄŸitim biter.", en:"No GPU needed. Laptop is enough. Training finishes in 3 minutes."} },
  "week0_s6": { time: 8, difficulty: 1, prep: {tr:"Terminalde python microgpt.py Ã§alÄ±ÅŸtÄ±rÄ±n. Loss dÃ¼ÅŸÃ¼ÅŸÃ¼nÃ¼ ve isim Ã¼retimini gÃ¶sterin.", en:"Run python microgpt.py in terminal. Show loss decrease and name generation."}, emphasize: {tr:"Ä°lk Ã§alÄ±ÅŸtÄ±rma anÄ± Ã¶ÄŸrenciler iÃ§in Ã§ok motivasyonel. Hep birlikte yapÄ±n.", en:"First run is very motivational for students. Do it together."}, studentQs: [
    { q: "Neden garip isimler Ã¼retiyor?", a: "Model Ä°ngilizce isim istatistiklerini Ã¶ÄŸreniyor. GerÃ§ek olmayan ama 'Ä°ngilizce gibi duran' isimler Ã¼retiyor." }
  ] },
  "week0_s7": { time: 10, difficulty: 2, prep: {tr:"7 parametreyi deÄŸiÅŸtirerek 2-3 farklÄ± sonuÃ§ hazÄ±rlayÄ±n.", en:"Prepare 2-3 different results by changing the 7 parameters."}, emphasize: {tr:"n_embd ve n_layer'Ä± deÄŸiÅŸtirerek loss farkÄ±nÄ± gÃ¶sterin. Ã–ÄŸrencilere de denetin.", en:"Show loss difference by changing n_embd and n_layer. Let students experiment too."}, studentQs: [
    { q: "En iyi parametreler ne?", a: "Harika soru â€” bunu sistematik olarak araÅŸtÄ±rabilirsinizacaÄŸÄ±z (NAS projesi)!" }
  ], cheatSheet: "7 param: n_embd=16, n_head=4, n_layer=1, block_size=8, batch=32, lr=0.01, steps=1000" },
  // W1
  "week1_s0": { time: 8, difficulty: 2, prep: {tr:"'emma' ismini tahtaya yazÄ±p tokenize edin: â†’ [BOS, e, m, m, a, BOS]", en:"Write 'emma' on the board and tokenize it: â†’ [BOS, e, m, m, a, BOS]"}, emphasize: {tr:"Token = modelin gÃ¶rdÃ¼ÄŸÃ¼ en kÃ¼Ã§Ã¼k birim. Karakter dÃ¼zeyinde = her harf bir token.", en:"Token = smallest unit the model sees. Character-level = each letter is a token."}, studentQs: [
    { q: "GPT-4 de karakter karakter mÄ± bakÄ±yor?", a: "HayÄ±r, BPE kullanÄ±yor: 'playing' â†’ ['play', 'ing']. Biz basitlik iÃ§in karakter dÃ¼zeyi kullanÄ±yoruz." },
    { q: "Neden 27 token?", a: "a-z (26) + Ã¶zel BOS/EOS tokeni (1) = 27. Ä°simler sadece kÃ¼Ã§Ã¼k harften oluÅŸuyor." }
  ], cheatSheet: "Vocab: a-z (26) + BOS (0) = 27 token. stoi: charâ†’int, itos: intâ†’char" },
  "week1_s1": { time: 5, difficulty: 2, emphasize: {tr:"Embedding = anlamsÄ±z ID'yi anlamlÄ± vektÃ¶re Ã§evirme. Tablo aramasÄ± (lookup), eÄŸitimle Ã¶ÄŸrenilir.", en:"Embedding = converting meaningless ID to meaningful vector. Table lookup, learned through training."}, cheatSheet: "wte: [27 Ã— 16] matris. embed('a') = wte[1] â†’ 16-boyutlu vektÃ¶r" },
  "week1_s2": { time: 5, difficulty: 2, emphasize: {tr:"Transformer sÄ±ra bilmez! Pozisyon embedding olmadan 'abc' = 'cba'. Bu Ã§ok ÅŸaÅŸÄ±rtÄ±cÄ±.", en:"Transformer doesn't know order! Without position embedding 'abc' = 'cba'. This is very surprising."}, cheatSheet: "wpe: [8 Ã— 16] matris. Toplam girdi = wte[token_id] + wpe[position]" },
  "week1_s3": { time: 5, difficulty: 3, emphasize: {tr:"Softmax = ham skorlarÄ± olasÄ±lÄ±ÄŸa Ã§evirme. Toplam her zaman 1.", en:"Softmax = converting raw scores to probabilities. Sum is always 1."}, studentQs: [
    { q: "Neden exp kullanÄ±yoruz?", a: "Negatif sayÄ±larÄ± pozitif yapmak + bÃ¼yÃ¼k farklarÄ± daha belirgin yapmak. exp(10)/exp(1) â‰ˆ 8100Ã—" }
  ], cheatSheet: "softmax(xáµ¢) = exp(xáµ¢) / Î£exp(xâ±¼). Max-trick: softmax(x) = softmax(x - max(x))" },
  // W2
  "week2_s0": { time: 10, difficulty: 3, prep: {tr:"Basit Ã¶rnek hazÄ±rlayÄ±n: f(x)=xÂ², df/dx=2x. x=3 â†’ f=9, df=6.", en:"Prepare simple example: f(x)=xÂ², df/dx=2x. x=3 â†’ f=9, df=6."}, emphasize: {tr:"Autograd olmadan Ã¶ÄŸrenme yok. Bu haftanÄ±n konusu dersin TEMELÄ°.", en:"No autograd, no learning. This week's topic is the FOUNDATION of the course."}, studentQs: [
    { q: "Bunun GPT ile ne ilgisi var?", a: "GPT parametrelerini nasÄ±l gÃ¼ncelliyor? Loss â†’ gradient â†’ gÃ¼ncelleme. Bu sÃ¼recin motoru autograd." }
  ], cheatSheet: "Autograd: forward(hesapla) â†’ backward(tÃ¼rev al) â†’ gÃ¼ncelle(w -= lr * grad)" },
  "week2_s1": { time: 8, difficulty: 3, emphasize: {tr:"Her Value: data + grad + backward fonksiyonu. 3 bileÅŸen, hepsi bu.", en:"Each Value: data + grad + backward function. 3 components, that's it."}, cheatSheet: "Value(data=3.0, grad=0.0, _backward=lambda: None)" },
  "week2_s2": { time: 8, difficulty: 4, prep: {tr:"Chain rule Ã¶rneÄŸi tahtada: f(g(x)) = (3x+1)Â². df/dx = 2(3x+1)Â·3", en:"Chain rule example on board: f(g(x)) = (3x+1)Â². df/dx = 2(3x+1)Â·3"}, emphasize: {tr:"Chain rule = autograd'Ä±n TEK sÄ±rrÄ±. Bunu anladÄ±klarÄ±nda geri kalanÄ± kolay.", en:"Chain rule = autograd's ONLY secret. Once they get this, the rest is easy."}, studentQs: [
    { q: "Birden fazla girdi olunca ne olur?", a: "Partial derivative: her girdi iÃ§in ayrÄ± ayrÄ± tÃ¼rev al, diÄŸerlerini sabit tut." }
  ], cheatSheet: "Chain rule: âˆ‚L/âˆ‚x = âˆ‚L/âˆ‚y Â· âˆ‚y/âˆ‚x. Multiply: âˆ‚(aÂ·b)/âˆ‚a = b, âˆ‚(aÂ·b)/âˆ‚b = a" },
  // W3
  "week3_s0": { time: 5, difficulty: 2, emphasize: {tr:"RNN â†’ sÄ±ralÄ± darboÄŸaz. Attention â†’ paralel + uzun mesafe. 2017 devrim.", en:"RNN â†’ sequential bottleneck. Attention â†’ parallel + long range. 2017 revolution."}, cheatSheet: "RNN: O(n) sÄ±ralÄ±. Attention: O(nÂ²) paralel â†’ GPU'da Ã§ok daha hÄ±zlÄ±" },
  "week3_s1": { time: 10, difficulty: 4, prep: {tr:"3 token Ã¶rneÄŸi hazÄ±rlayÄ±n: 'a','b','c'. Q,K,V matrislerini 2Ã—2 yapÄ±n. Elle hesaplayÄ±n.", en:"Prepare 3-token example: 'a','b','c'. Make Q,K,V matrices 2Ã—2. Compute by hand."}, emphasize: {tr:"Attention = her token tÃ¼m Ã¶nceki tokenlara bakÄ±p 'hangisi bana lazÄ±m?' diyor. KÃ¼tÃ¼phane analojisi.", en:"Attention = each token looks at all previous tokens and asks 'which one do I need?' Library analogy."}, studentQs: [
    { q: "Neden Q, K, V ayrÄ±?", a: "Q = 'ne arÄ±yorum', K = 'bende ne var', V = 'bilgim ne'. Rol ayrÄ±mÄ± â†’ esneklik." },
    { q: "Bu O(nÂ²) deÄŸil mi? YavaÅŸ olmaz mÄ±?", a: "Evet, ama GPU ile paralelize edilebilir. Ve Flash Attention gibi teknikler var (W7'de gÃ¶receÄŸiz)." }
  ], cheatSheet: "Attention(Q,K,V) = softmax(QKáµ€/âˆšd)Â·V. d=head_dim=n_embd/n_head=16/4=4" },
  "week3_s2": { time: 8, difficulty: 4, emphasize: {tr:"Scaled dot-product'Ä±n 'scaled' kÄ±smÄ± kritik. âˆšd olmadan gradientler Ã§ok bÃ¼yÃ¼k olur.", en:"The 'scaled' part of scaled dot-product is critical. Without âˆšd, gradients explode."}, cheatSheet: "score = QÂ·Káµ€ / âˆšd_k. d_k=4 â†’ /2. BÃ¼yÃ¼k d_k â†’ kÃ¼Ã§Ã¼k gradient â†’ daha kararlÄ±" },
  // W4
  "week4_s0": { time: 8, difficulty: 3, prep: {tr:"Transformer bloÄŸu diyagramÄ± Ã§izin: Input â†’ Norm â†’ Attention â†’ +Residual â†’ Norm â†’ MLP â†’ +Residual", en:"Draw Transformer block diagram: Input â†’ Norm â†’ Attention â†’ +Residual â†’ Norm â†’ MLP â†’ +Residual"}, emphasize: {tr:"Transformer = Lego. Attention + MLP bloklarÄ±nÄ± Ã¼st Ã¼ste koy.", en:"Transformer = Lego. Stack attention + MLP blocks on top of each other."}, cheatSheet: "x = x + Attention(Norm(x)). x = x + MLP(Norm(x)). Residual connection = toplama" },
  "week4_s1": { time: 5, difficulty: 3, emphasize: {tr:"RMSNorm: x/âˆš(mean(xÂ²)+Îµ). LayerNorm'dan %30 hÄ±zlÄ±, modern standart.", en:"RMSNorm: x/âˆš(mean(xÂ²)+Îµ). 30% faster than LayerNorm, modern standard."}, cheatSheet: "RMSNorm(x) = x Â· Î³ / âˆš(mean(xÂ²) + Îµ). Î³ Ã¶ÄŸrenilebilir, Îµ=1e-5" },
  "week4_s2": { time: 8, difficulty: 3, emphasize: {tr:"MLP: geniÅŸlet â†’ aktive et â†’ daralt. 16â†’64â†’16. Token iÃ§i bilgi iÅŸleme.", en:"MLP: expand â†’ activate â†’ compress. 16â†’64â†’16. Intra-token information processing."}, cheatSheet: "MLP(x) = Wâ‚‚ Â· activation(Wâ‚ Â· x + bâ‚) + bâ‚‚. Hidden=4Ã—n_embd=64" },
  // W5
  "week5_s0": { time: 5, difficulty: 2, emphasize: {tr:"EÄŸitim = loss'u minimize et. Loss dÃ¼ÅŸÃ¼yorsa model Ã¶ÄŸreniyor.", en:"Training = minimize loss. If loss is decreasing, model is learning."}, cheatSheet: "EÄŸitim dÃ¶ngÃ¼sÃ¼: forward â†’ loss â†’ backward â†’ step â†’ zero_grad â†’ tekrarla" },
  "week5_s1": { time: 8, difficulty: 3, emphasize: {tr:"Cross-entropy: -log(P(doÄŸru)). P=1 â†’ loss=0, P=0.01 â†’ loss=4.6. Log Ã§ok sert cezalandÄ±rÄ±r.", en:"Cross-entropy: -log(P(correct)). P=1 â†’ loss=0, P=0.01 â†’ loss=4.6. Log penalizes harshly."}, studentQs: [
    { q: "Neden MSE deÄŸil de cross-entropy?", a: "OlasÄ±lÄ±k daÄŸÄ±lÄ±mlarÄ± iÃ§in cross-entropy daha uygun. MSE gradient'i kÃ¼Ã§Ã¼k olasÄ±lÄ±klarda Ã§ok yavaÅŸ." }
  ], cheatSheet: "CE = -log(P(doÄŸru)). Rastgele: -log(1/27)=3.33. Ä°yi model: -log(0.3)â‰ˆ1.2" },
  "week5_s2": { time: 10, difficulty: 4, prep: {tr:"2D loss landscape Ã§izimi hazÄ±rlayÄ±n (vadi + top analojisi).", en:"Prepare 2D loss landscape drawing (valley + ball analogy)."}, emphasize: {tr:"GD: gradient'in tersi yÃ¶nÃ¼nde adÄ±m at. LR Ã§ok bÃ¼yÃ¼k â†’ patlama, Ã§ok kÃ¼Ã§Ã¼k â†’ yavaÅŸ.", en:"GD: step in opposite direction of gradient. LR too large â†’ explosion, too small â†’ slow."}, cheatSheet: "w = w - lr Ã— âˆ‚L/âˆ‚w. lr=0.01. Adam: momentum + adaptive LR per parameter" },
  // W6
  "week6_s0": { time: 8, difficulty: 2, prep: {tr:"CanlÄ± demo: temperature=0.1 vs 1.0 vs 2.0 ile isim Ã¼retin.", en:"Live demo: generate names with temperature=0.1 vs 1.0 vs 2.0."}, emphasize: {tr:"Ãœretim = eÄŸitimin tersi. Forward pass + sample. Temperature ile Ã§eÅŸitlilik ayarÄ±.", en:"Generation = reverse of training. Forward pass + sample. Temperature adjusts diversity."}, studentQs: [
    { q: "Temperature neden 'sÄ±caklÄ±k' deniyor?", a: "Fizikten geliyor: yÃ¼ksek sÄ±caklÄ±k â†’ daha kaotik parÃ§acÄ±klar â†’ daha rastgele daÄŸÄ±lÄ±m." }
  ], cheatSheet: "logits/T â†’ softmax â†’ sample. T=0.1: deterministik, T=1: normal, T=2: kaotik" },
  "week6_s1": { time: 5, difficulty: 3, emphasize: {tr:"KV cache: Ã¶nceki pozisyonlarÄ± tekrar hesaplama â†’ O(n) yerine O(1) per token.", en:"KV cache: don't recompute previous positions â†’ O(1) per token instead of O(n)."}, cheatSheet: "Cache K,V her pozisyonda. Yeni token: sadece 1 Q hesapla, cache'ten K,V al" },
  // W7
  "week7_s0": { time: 8, difficulty: 2, emphasize: {tr:"Scaling laws = AI'Ä±n Moore YasasÄ±. 10Ã— param â†’ belirli miktarda loss dÃ¼ÅŸÃ¼ÅŸÃ¼.", en:"Scaling laws = AI's Moore's Law. 10Ã— params â†’ specific amount of loss decrease."}, cheatSheet: "L(N) = a/N^b. Chinchilla optimal: D â‰ˆ 20N (20 token per parametre)" },
  "week7_s1": { time: 10, difficulty: 1, prep: {tr:"Timeline'Ä± ekranda gÃ¶sterip her dÃ¶nemi tek tek geÃ§in.", en:"Show the timeline on screen and walk through each era one by one."}, emphasize: {tr:"2017â†’2024: 7 yÄ±lda dÃ¼nya deÄŸiÅŸti. Transformer tek makale ile baÅŸladÄ±.", en:"2017â†’2024: world changed in 7 years. Transformer started from a single paper."} },
  "week7_s3": { time: 8, difficulty: 2, emphasize: {tr:"Pre-training (%95 maliyet) â†’ SFT â†’ RLHF. RLHF akÄ±l vermez, davranÄ±ÅŸ dÃ¼zeltir.", en:"Pre-training (95% cost) â†’ SFT â†’ RLHF. RLHF doesn't add intelligence, it corrects behavior."}, studentQs: [
    { q: "ChatGPT neden bazen yanlÄ±ÅŸ sÃ¶ylÃ¼yor?", a: "Pre-training'de yanlÄ±ÅŸ bilgi de Ã¶ÄŸreniyor. RLHF sadece FORMAT'Ä± (kibarlÄ±k, yapÄ±) dÃ¼zeltir, BÄ°LGÄ°'yi dÃ¼zeltmez." }
  ] },
  // W8-W9
  // W0 remaining
  "week0_s8": { time: 5, difficulty: 1, prep: {tr:"Terminal aÃ§Ä±k olsun. python microgpt.py komutunu birlikte Ã§alÄ±ÅŸtÄ±rÄ±n.", en:"Have terminal open. Run python microgpt.py together."}, emphasize: {tr:"Ä°lk Ã§alÄ±ÅŸtÄ±rma Ã¶ÄŸrenciler iÃ§in bÃ¼yÃ¼lÃ¼ an. Hep birlikte yapÄ±n!", en:"First run is a magical moment for students. Do it together!"}, studentQs: [
    { q: "Hata aldÄ±m?", a: "Python versiyonunu kontrol edin (3.8+). Dosya yolunu kontrol edin. En yaygÄ±n hata: yanlÄ±ÅŸ dizin." }
  ] },
  "week0_s9": { time: 10, difficulty: 2, prep: {tr:"n_embd=8 vs 32, steps=100 vs 1000 sonuÃ§larÄ±nÄ± Ã¶nceden hazÄ±rlayÄ±n.", en:"Prepare results for n_embd=8 vs 32, steps=100 vs 1000 beforehand."}, emphasize: {tr:"Parametreleri deÄŸiÅŸtirmek = deney yapmak. Bu bilimsel sÃ¼recin baÅŸlangÄ±cÄ±.", en:"Changing parameters = experimenting. This is the beginning of the scientific process."}, studentQs: [
    { q: "Hangi parametre en Ã¶nemli?", a: "n_embd ve n_layer loss'a en Ã§ok etki eder. Bunu sistematik deneylerle araÅŸtÄ±rabilirsiniz." }
  ] },
  "week0_s10": { time: 5, difficulty: 1, emphasize: {tr:"TÃ¼rkÃ§e isimler, ÅŸehir adlarÄ±, kelimeler... veri deÄŸiÅŸtirmek Ã§ok kolay.", en:"Turkish names, city names, words... changing data is very easy."}, studentQs: [
    { q: "TÃ¼rkÃ§e Ã§alÄ±ÅŸÄ±r mÄ±?", a: "Evet ama TÃ¼rkÃ§e harfler (ÄŸ,Ã¼,ÅŸ,Ä±,Ã¶,Ã§) vocab'a eklenmeli. Vocab 27â†’33 olur." }
  ] },
  "week0_s11": { time: 5, difficulty: 1, emphasize: {tr:"EÄŸitim ilerledikÃ§e isimler daha gerÃ§ekÃ§i olur. Loss dÃ¼ÅŸÃ¼ÅŸÃ¼nÃ¼ gÃ¶sterin.", en:"Names become more realistic as training progresses. Show the loss decrease."} },
  "week0_s12": { time: 5, difficulty: 1, emphasize: {tr:"microGPT â†’ GPT-4: aynÄ± algoritma, farklÄ± Ã¶lÃ§ek. Bu ders o kÃ¶prÃ¼yÃ¼ kuruyor.", en:"microGPT â†’ GPT-4: same algorithm, different scale. This course builds that bridge."} },
  // W1 remaining
  "week1_s4": { time: 10, difficulty: 2, prep: {tr:"Tokenizer playground'u aÃ§Ä±n. 'emma', 'michael', 'x' yazarak farklarÄ± gÃ¶sterin.", en:"Open tokenizer playground. Type 'emma', 'michael', 'x' to show differences."}, emphasize: {tr:"Ä°nteraktif deney: Ã¶ÄŸrenciler kendi isimlerini tokenize etsin.", en:"Interactive experiment: have students tokenize their own names."} },
  "week1_s5": { time: 5, difficulty: 2, emphasize: {tr:"VektÃ¶r = yÃ¶nlÃ¼ bÃ¼yÃ¼klÃ¼k. [0.3, -0.1, 0.8] = 3 boyutlu uzayda nokta.", en:"Vector = directed magnitude. [0.3, -0.1, 0.8] = point in 3D space."}, cheatSheet: "VektÃ¶r: v âˆˆ â„â¿. microGPT: n=16. Benzerlik: cos(a,b) = aÂ·b / (|a||b|)" },
  "week1_s6": { time: 5, difficulty: 2, emphasize: {tr:"Embedding tablosu = Ã¶ÄŸrenilebilir sÃ¶zlÃ¼k. wte[5] = 'e' harfinin vektÃ¶rÃ¼.", en:"Embedding table = learnable dictionary. wte[5] = vector for letter 'e'."}, cheatSheet: "wte: [27Ã—16]. Lookup: embed(token_id) = wte[token_id]. EÄŸitimle gÃ¼ncellenir" },
  "week1_s7": { time: 5, difficulty: 2, emphasize: {tr:"'abc' ve 'cba' position embedding olmadan AYNI gÃ¶rÃ¼nÃ¼r. Bu Ã§ok ÅŸaÅŸÄ±rtÄ±cÄ±.", en:"'abc' and 'cba' look THE SAME without position embedding. This is very surprising."}, cheatSheet: "wpe: [8Ã—16]. x = wte[tok] + wpe[pos]. block_size=8 â†’ max 8 pozisyon" },
  "week1_s8": { time: 5, difficulty: 3, emphasize: {tr:"Matris Ã§arpÄ±mÄ± = embedding'den sonraki HER adÄ±mÄ±n temeli. y = Wx + b", en:"Matrix multiplication = foundation of EVERY step after embedding. y = Wx + b"}, cheatSheet: "[MÃ—K] Â· [KÃ—N] = [MÃ—N]. microGPT: [batchÃ—16] Â· [16Ã—64] = [batchÃ—64]" },
  "week1_s9": { time: 5, difficulty: 2, emphasize: {tr:"Weight tying: aynÄ± matris giriÅŸ+Ã§Ä±kÄ±ÅŸta â†’ parametre tasarrufu + tutarlÄ±lÄ±k.", en:"Weight tying: same matrix for input+output â†’ parameter savings + consistency."}, cheatSheet: "logits = x @ wte.T (transpoz). 3,648 parametrenin Ã¶nemli kÄ±smÄ± wte'de" },
  "week1_s10": { time: 5, difficulty: 2, emphasize: {tr:"Softmax: ham skor â†’ olasÄ±lÄ±k. Toplam=1. exp kullanarak negatifi pozitife Ã§evirir.", en:"Softmax: raw score â†’ probability. Sum=1. Uses exp to convert negatives to positives."}, cheatSheet: "softmax(xáµ¢) = exp(xáµ¢)/Î£exp(xâ±¼). Max-trick: overflow Ã¶nleme. Î£=1 her zaman" },
  // W2 remaining
  "week2_s3": { time: 5, difficulty: 3, emphasize: {tr:"KÄ±smi tÃ¼rev: birden fazla deÄŸiÅŸken olunca her birini ayrÄ± tÃ¼revle.", en:"Partial derivative: with multiple variables, take derivative w.r.t. each separately."}, cheatSheet: "âˆ‚f/âˆ‚x: x'e gÃ¶re tÃ¼rev, y sabit. Gradient: âˆ‡f = [âˆ‚f/âˆ‚x, âˆ‚f/âˆ‚y, ...]" },
  "week2_s4": { time: 10, difficulty: 3, prep: {tr:"Autograd playground'u aÃ§Ä±n. Basit bir graf oluÅŸturup backward Ã§alÄ±ÅŸtÄ±rÄ±n.", en:"Open autograd playground. Create a simple graph and run backward."}, emphasize: {tr:"CanlÄ± deney: Ã¶ÄŸrenciler a=2, b=3, c=a*b+a grafÄ±nÄ± oluÅŸtursun.", en:"Live experiment: students create a=2, b=3, c=a*b+a graph."} },
  "week2_s5": { time: 5, difficulty: 3, emphasize: {tr:"Value = autograd'Ä±n atom'u. data, grad, _children, _backward.", en:"Value = autograd's atom. data, grad, _children, _backward."}, cheatSheet: "Value(2.0).data=2.0, .grad=0.0. Backward sonrasÄ± .grad dolacak" },
  "week2_s6": { time: 5, difficulty: 3, emphasize: {tr:"__add__, __mul__ overload: a+b yazdÄ±ÄŸÄ±nÄ±zda Python otomatik graf oluÅŸturur.", en:"__add__, __mul__ overload: when you write a+b, Python automatically builds the graph."}, cheatSheet: "a + b â†’ Value.__add__(a,b) â†’ yeni node + backward fonksiyonu kaydeder" },
  "week2_s7": { time: 8, difficulty: 4, emphasize: {tr:"Chain rule: âˆ‚L/âˆ‚x = âˆ‚L/âˆ‚y Â· âˆ‚y/âˆ‚x. TÃ¼m backward pass bu TEK kurala dayanÄ±r.", en:"Chain rule: âˆ‚L/âˆ‚x = âˆ‚L/âˆ‚y Â· âˆ‚y/âˆ‚x. The entire backward pass relies on this SINGLE rule."}, cheatSheet: "Add backward: grad += 1 Ã— out.grad. Mul backward: grad += other.data Ã— out.grad" },
  "week2_s8": { time: 5, difficulty: 3, prep: {tr:"L = (aÃ—b)+c Ã¶rneÄŸini tahtada Ã§izin, elle backward yapÄ±n.", en:"Draw L = (aÃ—b)+c example on board, do backward by hand."}, emphasize: {tr:"Somut Ã¶rnek: a=2, b=-3, c=10. L=(2Ã—-3)+10=4. âˆ‚L/âˆ‚a=-3, âˆ‚L/âˆ‚b=2, âˆ‚L/âˆ‚c=1", en:"Concrete example: a=2, b=-3, c=10. L=(2Ã—-3)+10=4. âˆ‚L/âˆ‚a=-3, âˆ‚L/âˆ‚b=2, âˆ‚L/âˆ‚c=1"} },
  "week2_s9": { time: 5, difficulty: 3, emphasize: {tr:"grad += (topla), grad = (ata) DEÄÄ°L! AynÄ± deÄŸiÅŸken birden fazla yerde kullanÄ±lÄ±rsa gradientler toplanÄ±r.", en:"grad += (accumulate), NOT grad = (assign)! If same variable used multiple places, gradients must sum"}, studentQs: [
    { q: "Neden += kullanÄ±yoruz?", a: "y = x+x olsun. âˆ‚y/âˆ‚x = 2, ama iki ayrÄ± yoldan 1+1=2. Toplama yapmazsak 1 buluruz â€” yanlÄ±ÅŸ!" }
  ] },
  "week2_s10": { time: 5, difficulty: 2, emphasize: {tr:"Bizim Value sÄ±nÄ±fÄ± = PyTorch'un autograd'Ä±nÄ±n mini versiyonu. AynÄ± mantÄ±k, farklÄ± Ã¶lÃ§ek.", en:"Our Value class = mini version of PyTorch's autograd. Same logic, different scale."} },
  // W3 remaining
  "week3_s3": { time: 8, difficulty: 3, emphasize: {tr:"Her token 'soru soruyor': Ben kim olmalÄ±yÄ±m? Cevap iÃ§in tÃ¼m Ã¶nceki tokenlara bakÄ±yor.", en:"Each token 'asks a question': Who should I be? It looks at all previous tokens for the answer."}, cheatSheet: "Attention weight Î±[i][j] = token i'nin token j'ye ne kadar dikkat ettiÄŸi" },
  "week3_s4": { time: 8, difficulty: 3, prep: {tr:"KÃ¼tÃ¼phane analojisi: Q=soru, K=kitap etiketi, V=kitap iÃ§eriÄŸi. Tahtaya Ã§izin.", en:"Library analogy: Q=question, K=book label, V=book content. Draw on board."}, emphasize: {tr:"QÂ·K = uyum skoru. YÃ¼ksek skor = 'bu kitap bana lazÄ±m'. V = o kitabÄ±n bilgisi.", en:"QÂ·K = compatibility score. High score = 'I need this book'. V = that book's information."} },
  "week3_s5": { time: 10, difficulty: 3, prep: {tr:"Attention playground'u aÃ§Ä±n. 'abc' yazÄ±p head kalÄ±plarÄ±nÄ± inceleyin.", en:"Open attention playground. Type 'abc' and examine head patterns."}, emphasize: {tr:"Her head farklÄ± kalÄ±p Ã¶ÄŸrenir: biri Ã¶nceki harfe bakar, biri sesli harflere.", en:"Each head learns different patterns: one looks at previous letter, another at vowels."} },
  "week3_s6": { time: 8, difficulty: 4, prep: {tr:"3 token, 2 boyutlu Q,K,V ile elle hesaplama hazÄ±rlayÄ±n.", en:"Prepare hand computation with 3 tokens, 2-dim Q,K,V."}, emphasize: {tr:"Tam formÃ¼l: softmax(QKáµ€/âˆšd)Â·V. âˆšd olmazsa gradient patlar.", en:"Full formula: softmax(QKáµ€/âˆšd)Â·V. Without âˆšd, gradients explode."}, cheatSheet: "Q,K,V: [seqÃ—d_k]. QKáµ€: [seqÃ—seq]. softmax: satÄ±r bazlÄ±. Ã—V: [seqÃ—d_k]" },
  "week3_s7": { time: 5, difficulty: 2, emphasize: {tr:"Dot product = benzerlik Ã¶lÃ§Ã¼sÃ¼. aÂ·b bÃ¼yÃ¼k â†’ aynÄ± yÃ¶n, kÃ¼Ã§Ã¼k â†’ farklÄ± yÃ¶n.", en:"Dot product = similarity measure. aÂ·b large â†’ same direction, small â†’ different direction."}, cheatSheet: "aÂ·b = Î£aáµ¢báµ¢. Geometric: |a||b|cos(Î¸). cos(Î¸)=1: aynÄ± yÃ¶n, 0: dik, -1: ters" },
  "week3_s8": { time: 8, difficulty: 3, emphasize: {tr:"Multi-head: 4 farklÄ± bakÄ±ÅŸ aÃ§Ä±sÄ±. Causal mask: gelecek tokenlarÄ± -âˆ yaparak gizle.", en:"Multi-head: 4 different perspectives. Causal mask: hide future tokens by setting to -âˆ."}, cheatSheet: "n_head=4, d_k=16/4=4. Mask: attn[i][j>i] = -âˆ â†’ softmax sonrasÄ± 0" },
  "week3_s9": { time: 5, difficulty: 3, emphasize: {tr:"Head Ã§Ä±ktÄ±larÄ± concat â†’ Wo ile projeksiyon. 4Ã—4=16 boyuta geri dÃ¶n.", en:"Head outputs concat â†’ Wo projection. Return to 16 dims from 4Ã—4."}, cheatSheet: "MultiHead = Concat(head1,...,head4) Â· Wo. Wo: [16Ã—16]" },
  // W4 remaining
  "week4_s3": { time: 10, difficulty: 3, prep: {tr:"Transformer flow viz'i aÃ§Ä±n. AdÄ±m adÄ±m geÃ§in.", en:"Open Transformer flow viz. Walk through step by step."}, emphasize: {tr:"Her adÄ±mda veri nasÄ±l deÄŸiÅŸiyor? GiriÅŸ â†’ Norm â†’ Attention â†’ +Residual â†’ Norm â†’ MLP â†’ +Residual", en:"How does data change at each step? Input â†’ Norm â†’ Attention â†’ +Residual â†’ Norm â†’ MLP â†’ +Residual"} },
  "week4_s4": { time: 5, difficulty: 3, emphasize: {tr:"RMSNorm: mean Ã§Ä±karma yok, sadece Ã¶lÃ§ekleme. Daha hÄ±zlÄ±, modern standart.", en:"RMSNorm: no mean subtraction, just scaling. Faster, modern standard."}, cheatSheet: "RMSNorm(x) = xÂ·Î³/âˆš(mean(xÂ²)+Îµ). vs LayerNorm: (x-Î¼)Â·Î³/Ïƒ + Î²" },
  "week4_s5": { time: 5, difficulty: 3, emphasize: {tr:"MLP = token iÃ§i bilgi iÅŸleme. Attention token arasÄ±, MLP token iÃ§i.", en:"MLP = intra-token processing. Attention is inter-token, MLP is intra-token."}, cheatSheet: "MLP: 16â†’64(Ã—4)â†’16. W1:[16Ã—64], W2:[64Ã—16]. ReLUÂ²(x) = max(0,x)Â²" },
  "week4_s6": { time: 5, difficulty: 2, emphasize: {tr:"Aktivasyon olmadan derin aÄŸ = sÄ±ÄŸ aÄŸ. Non-linearity = Ã¶ÄŸrenme kapasitesi.", en:"Deep network without activation = shallow network. Non-linearity = learning capacity."}, cheatSheet: "ReLU: max(0,x). ReLUÂ²: max(0,x)Â². GELU: xÂ·Î¦(x). Tanh: (eÂ²Ë£-1)/(eÂ²Ë£+1)" },
  "week4_s7": { time: 5, difficulty: 3, emphasize: {tr:"Residual = x + f(x). Gradient highway: derin aÄŸlarda gradient serbest akÄ±yor.", en:"Residual = x + f(x). Gradient highway: gradients flow freely in deep networks."}, studentQs: [
    { q: "Neden sadece topluyoruz?", a: "Skip connection gradientlerin katmanlar boyunca akmasÄ±nÄ± saÄŸlar. Olmasa 10+ katmanda gradient kaybolur." }
  ] },
  "week4_s8": { time: 5, difficulty: 3, emphasize: {tr:"BaÅŸlatma kritik: sÄ±fÄ±r = Ã¶ÄŸrenmeme, bÃ¼yÃ¼k = patlama, kÃ¼Ã§Ã¼k = kaybolma.", en:"Initialization is critical: zero = no learning, large = explosion, small = vanishing."}, cheatSheet: "Xavier: std=1/âˆšn. Kaiming: std=âˆš(2/n). microGPT: 0.02 std normal" },
  "week4_s9": { time: 5, difficulty: 2, emphasize: {tr:"RMSNorm vs LayerNorm: pratik fark kÃ¼Ã§Ã¼k ama hÄ±z farkÄ± %30.", en:"RMSNorm vs LayerNorm: practical difference is small but speed difference is 30%."}, cheatSheet: "LayerNorm: (x-Î¼)/ÏƒÂ·Î³+Î² (4 op). RMSNorm: x/âˆš(mean(xÂ²)+Îµ)Â·Î³ (3 op)" },
  // W5 remaining
  "week5_s3": { time: 8, difficulty: 3, prep: {tr:"Vadi + top analojisi Ã§izin. Top = model, vadi = minimum, eÄŸim = gradient.", en:"Draw valley + ball analogy. Ball = model, valley = minimum, slope = gradient."}, emphasize: {tr:"GD: gradient yokuÅŸ aÅŸaÄŸÄ±yÄ± gÃ¶sterir. AdÄ±m boyutu = learning rate.", en:"GD: gradient points downhill. Step size = learning rate."}, cheatSheet: "w_new = w_old - lr Ã— âˆ‚L/âˆ‚w. lr=0.01. BÃ¼yÃ¼k lr â†’ salÄ±nÄ±m, kÃ¼Ã§Ã¼k lr â†’ yavaÅŸ" },
  "week5_s4": { time: 10, difficulty: 3, prep: {tr:"Training sim'i aÃ§Ä±n. LR slider'Ä± 0.001 â†’ 0.1 arasÄ±nda gezdirin.", en:"Open training sim. Slide LR between 0.001 â†’ 0.1."}, emphasize: {tr:"CanlÄ± deney: LR=0.001 Ã§ok yavaÅŸ, LR=0.1 patlÄ±yor, LR=0.01 ideal.", en:"Live experiment: LR=0.001 too slow, LR=0.1 explodes, LR=0.01 ideal."} },
  "week5_s5": { time: 5, difficulty: 3, emphasize: {tr:"CE = -log(P). P yÃ¼ksek â†’ loss dÃ¼ÅŸÃ¼k. P dÃ¼ÅŸÃ¼k â†’ loss Ã§ok yÃ¼ksek.", en:"CE = -log(P). P high â†’ loss low. P low â†’ loss very high."}, cheatSheet: "P=1: loss=0. P=0.5: loss=0.69. P=0.1: loss=2.3. P=0.01: loss=4.6" },
  "week5_s6": { time: 5, difficulty: 2, emphasize: {tr:"Log neden kullanÄ±lÄ±yor? DÃ¼ÅŸÃ¼k olasÄ±lÄ±ÄŸa Ã‡OK aÄŸÄ±r ceza verir.", en:"Why use log? It penalizes low probabilities VERY heavily."}, cheatSheet: "-log(0.5)=0.69 ama -(1-0.5)=0.5. -log(0.01)=4.6 ama -(1-0.01)=0.99. Log daha sert" },
  "week5_s7": { time: 5, difficulty: 3, emphasize: {tr:"Adam: momentum (geÃ§miÅŸ gradientler) + adaptive (her parametre kendi lr'si).", en:"Adam: momentum (past gradients) + adaptive (each parameter gets its own lr)."}, cheatSheet: "Adam: m = Î²â‚m + (1-Î²â‚)g, v = Î²â‚‚v + (1-Î²â‚‚)gÂ². w -= lrÂ·mÌ‚/âˆšvÌ‚+Îµ. Î²â‚=0.9, Î²â‚‚=0.999" },
  "week5_s8": { time: 5, difficulty: 2, emphasize: {tr:"Cosine decay: baÅŸta bÃ¼yÃ¼k adÄ±m (keÅŸif), sonda kÃ¼Ã§Ã¼k (hassas ayar).", en:"Cosine decay: large steps at start (exploration), small at end (fine-tuning)."}, cheatSheet: "lr_t = lr_min + 0.5(lr_max-lr_min)(1+cos(Ï€t/T)). Warmup: ilk N adÄ±m lineer artÄ±ÅŸ" },
  "week5_s9": { time: 3, difficulty: 2, emphasize: {tr:"p.grad = 0 her adÄ±mda ÅART. Yoksa Ã¶nceki adÄ±mÄ±n gradienti birikir â†’ felaket.", en:"p.grad = 0 every step is MANDATORY. Otherwise previous gradient accumulates â†’ disaster."}, studentQs: [
    { q: "Neden otomatik sÄ±fÄ±rlanmÄ±yor?", a: "Bazen kasÄ±tlÄ± olarak biriktirmek istersiniz (gradient accumulation). PyTorch da aynÄ±: optimizer.zero_grad()" }
  ] },
  // W6 remaining
  "week6_s2": { time: 5, difficulty: 2, emphasize: {tr:"EÄŸitim: forward+backward+update. Inference: sadece forward. Dropout OFF, BatchNorm fixed.", en:"Training: forward+backward+update. Inference: forward only. Dropout OFF, BatchNorm fixed."}, cheatSheet: "EÄŸitim: loss hesapla â†’ backprop â†’ gÃ¼ncelle. Inference: tahmin yap â†’ bitir" },
  "week6_s3": { time: 8, difficulty: 2, emphasize: {tr:"Autoregressive: BOS â†’ 'e' â†’ 'em' â†’ 'emm' â†’ 'emma' â†’ BOS. Her adÄ±m 1 token.", en:"Autoregressive: BOS â†’ 'e' â†’ 'em' â†’ 'emm' â†’ 'emma' â†’ BOS. Each step adds 1 token."}, cheatSheet: "Loop: token = BOS. while token != BOS: logits = forward(tokens). token = sample(softmax(logits/T))" },
  "week6_s4": { time: 10, difficulty: 2, prep: {tr:"Generation playground'u aÃ§Ä±n. Temperature'Ä± deÄŸiÅŸtirerek farkÄ± gÃ¶sterin.", en:"Open generation playground. Change temperature to show the difference."}, emphasize: {tr:"T=0.1: hep aynÄ± isimler. T=1.0: Ã§eÅŸitli. T=2.0: saÃ§ma isimler. CanlÄ± gÃ¶sterin.", en:"T=0.1: always same names. T=1.0: diverse. T=2.0: nonsense names. Show live."} },
  "week6_s5": { time: 5, difficulty: 2, emphasize: {tr:"Temperature = softmax'Ä± keskinleÅŸtirme/dÃ¼zleÅŸtirme. Matematik basit: logits/T.", en:"Temperature = sharpening/flattening softmax. Math is simple: logits/T."}, cheatSheet: "T<1: [0.1,0.8,0.1]â†’[0.01,0.98,0.01] (keskin). T>1: [0.1,0.8,0.1]â†’[0.2,0.6,0.2] (dÃ¼z)" },
  "week6_s6": { time: 5, difficulty: 2, emphasize: {tr:"Greedy = her zaman en yÃ¼ksek. Top-k = ilk k'dan sample. Nucleus = toplam %p'ye kadar.", en:"Greedy = always highest. Top-k = sample from top k. Nucleus = cumulative up to p%."}, cheatSheet: "Greedy: argmax. Top-k: en yÃ¼ksek k seÃ§, diÄŸerleri 0. Top-p: kÃ¼mÃ¼latif â‰¤ p olanlar" },
  "week6_s7": { time: 5, difficulty: 3, emphasize: {tr:"KV cache: tekrar hesaplama yok. Yeni token iÃ§in sadece 1 Q hesapla.", en:"KV cache: no recomputation. For new token, compute only 1 Q."}, cheatSheet: "Without cache: n token â†’ O(nÂ²). With cache: n token â†’ O(n). Bellek: O(nÃ—dÃ—layers)" },
  "week6_s8": { time: 5, difficulty: 2, emphasize: {tr:"UÃ§tan uca: isim girin, her adÄ±mÄ± takip edin: token â†’ embed â†’ attend â†’ MLP â†’ softmax â†’ sample", en:"End-to-end: enter a name, follow each step: token â†’ embed â†’ attend â†’ MLP â†’ softmax â†’ sample"} },
  "week6_s9": { time: 5, difficulty: 1, emphasize: {tr:"microGPT vs production: aynÄ± algoritma. Fark: veri Ã¶lÃ§eÄŸi, donanÄ±m, optimizasyon, RLHF.", en:"microGPT vs production: same algorithm. Difference: data scale, hardware, optimization, RLHF."} },
  // W7 remaining
  "week7_s2": { time: 8, difficulty: 2, emphasize: {tr:"Ä°nteraktif scatter plot'u gÃ¶sterin. microGPT â†’ GPT-4 noktalarÄ±nÄ± tÄ±klayÄ±n.", en:"Show the interactive scatter plot. Click microGPT â†’ GPT-4 points."}, cheatSheet: "microGPT: 3.6K param, lossâ‰ˆ2.0. GPT-3: 175B, lossâ‰ˆ0.5. GPT-4: ~1.8T, lossâ‰ˆ0.3" },
  "week7_s4": { time: 5, difficulty: 1, prep: {tr:"Hardware kartlarÄ±nÄ± tÄ±klayarak specs'leri gÃ¶sterin.", en:"Click hardware cards to show specs."}, emphasize: {tr:"GPU 312 TFLOPS vs CPU 0.5 TFLOPS = 624Ã— hÄ±z farkÄ±. AI = paralel matris Ã§arpÄ±mÄ±.", en:"GPU 312 TFLOPS vs CPU 0.5 TFLOPS = 624Ã— speed difference. AI = parallel matrix multiplication."}, cheatSheet: "A100: 6912 CUDA core, 312 TFLOPS, 80GB HBM3, ~$10K" },
  "week7_s5": { time: 8, difficulty: 2, emphasize: {tr:"3 aÅŸama: pre-training (%95) â†’ SFT (%3) â†’ RLHF (%2). AsÄ±l gÃ¼Ã§ pre-training'den gelir.", en:"3 stages: pre-training (95%) â†’ SFT (3%) â†’ RLHF (2%). Real power comes from pre-training."}, studentQs: [
    { q: "RLHF olmadan ChatGPT olur mu?", a: "Model bilgili ama kaba, tutarsÄ±z, bazen tehlikeli olur. RLHF 'kibarlÄ±k + gÃ¼venlik' ekler, zeka eklemez." }
  ] },
  "week7_s6": { time: 5, difficulty: 2, emphasize: {tr:"Karakterâ†’BPEâ†’SentencePieceâ†’tiktoken. Her adÄ±m daha verimli tokenization.", en:"Characterâ†’BPEâ†’SentencePieceâ†’tiktoken. Each step is more efficient tokenization."}, cheatSheet: "Karakter: 27 vocab. BPE(GPT-2): 50K. tiktoken(GPT-4): 100K. Daha bÃ¼yÃ¼k vocab = daha az token" },
  "week7_s7": { time: 5, difficulty: 3, emphasize: {tr:"Vanilla O(nÂ²) bellek â†’ Flash O(n) bellek. AynÄ± matematik, farklÄ± hesaplama sÄ±rasÄ±.", en:"Vanilla O(nÂ²) memory â†’ Flash O(n) memory. Same math, different computation order."}, cheatSheet: "Flash Attention: IO-aware tiling. HBMâ†’SRAM blok blok. 2-4Ã— hÄ±zlanma, sonuÃ§ identik" },
  "week7_s8": { time: 5, difficulty: 1, emphasize: {tr:"Open source devrim: LLaMA 3.1 405B, DeepSeek-V3 671B MoE. GPT-4'e yakÄ±n, Ã¼cretsiz.", en:"Open source revolution: LLaMA 3.1 405B, DeepSeek-V3 671B MoE. Near GPT-4, free."}, cheatSheet: "LLaMA: Meta, 405B. Mistral: 7-22B+MoE. DeepSeek-V3: 671B (37B active). Qwen: Alibaba. Gemma: Google" },
  "week7_s9": { time: 8, difficulty: 2, emphasize: {tr:"5 trend: MoE (verimlilik), RAG (bilgi), Agent (araÃ§), Multimodal (Ã§ok mod), Reasoning (dÃ¼ÅŸÃ¼nce zinciri).", en:"5 trends: MoE (efficiency), RAG (knowledge), Agent (tools), Multimodal (multi-mode), Reasoning (chain of thought)"}, studentQs: [
    { q: "Bunlardan hangisi en Ã¶nemli?", a: "Hepsi birbirini tamamlÄ±yor. GPT-4 = MoE + Multimodal. o1 = Reasoning. Perplexity = RAG. Claude = Agent." }
  ] },
};

// â”€â”€â”€ LESSON PLAN â€” HaftalÄ±k Ders PlanÄ± â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const LESSON_PLANS = {
  0: { title: { tr: "GiriÅŸ & CanlÄ± Demo", en: "Introduction & Live Demo" }, totalMin: 75, plan: [
    { phase: "AÃ§Ä±lÄ±ÅŸ", min: 5, desc: "Ders tanÄ±tÄ±mÄ±, beklentiler, 'GPT nedir?' tartÄ±ÅŸmasÄ±" },
    { phase: "CanlÄ± Demo", min: 15, desc: "microGPT'yi Ã§alÄ±ÅŸtÄ±rÄ±n, isim Ã¼retin, Ã¶ÄŸrencilerle birlikte deneyin" },
    { phase: "Ders AnlatÄ±mÄ±", min: 30, desc: "S0-S7: Pipeline, parametreler, vocab. Her bÃ¶lÃ¼mde viz'i gÃ¶sterin" },
    { phase: "Hands-on Lab", min: 15, desc: "Ã–ÄŸrenciler kendi bilgisayarlarÄ±nda Ã§alÄ±ÅŸtÄ±rsÄ±n, parametreleri deÄŸiÅŸtirsin" },
    { phase: "KapanÄ±ÅŸ & Quiz", min: 10, desc: "7 soruluk quiz + gelecek haftaya hazÄ±rlÄ±k" }
  ]},
  1: { title: "Tokenization & Embedding", totalMin: 75, plan: [
    { phase: "Tekrar", min: 5, desc: "GeÃ§en haftanÄ±n pipeline'Ä±nÄ± tekrar edin. 'BugÃ¼n ilk kutuyu aÃ§Ä±yoruz'" },
    { phase: "Token Demo", min: 10, desc: "'emma' â†’ [BOS,e,m,m,a,BOS] tahtada gÃ¶sterin. Tokenizer playground" },
    { phase: "Embedding Ders", min: 20, desc: "ID â†’ vektÃ¶r dÃ¶nÃ¼ÅŸÃ¼mÃ¼, position embedding, weight tying" },
    { phase: "Hands-on", min: 15, desc: "Tokenizer Playground viz ile deney. FarklÄ± isimler deneyin" },
    { phase: "Softmax + Quiz", min: 15, desc: "Softmax aÃ§Ä±klamasÄ± + 7 soruluk quiz" },
    { phase: "KapanÄ±ÅŸ", min: 10, desc: "BPE vs karakter tartÄ±ÅŸmasÄ±, gelecek hafta: autograd" }
  ]},
  2: { title: "Autograd Engine", totalMin: 75, plan: [
    { phase: "Motivasyon", min: 10, desc: "Neden tÃ¼rev lazÄ±m? Basit Ã¶rnek: f(x)=xÂ², x=3 â†’ yokuÅŸ aÅŸaÄŸÄ± gitme" },
    { phase: "Value SÄ±nÄ±fÄ±", min: 15, desc: "data + grad + backward. Tahtada elle hesaplama" },
    { phase: "Chain Rule", min: 20, desc: "EN KRÄ°TÄ°K BÃ–LÃœM. BileÅŸik fonksiyon Ã¶rneÄŸi. YavaÅŸ gidin" },
    { phase: "Autograd Playground", min: 15, desc: "Ä°nteraktif viz ile graf oluÅŸturun, backward Ã§alÄ±ÅŸtÄ±rÄ±n" },
    { phase: "DoÄŸrulama + Quiz", min: 15, desc: "PyTorch ile gradient karÅŸÄ±laÅŸtÄ±rma + quiz" }
  ]},
  3: { title: "Attention Mechanism", totalMin: 75, plan: [
    { phase: "RNN â†’ Attention", min: 10, desc: "RNN'in sÄ±ralÄ± darboÄŸazÄ±nÄ± aÃ§Ä±klayÄ±n, attention neden icat edildi" },
    { phase: "Q, K, V Sezgisel", min: 15, desc: "KÃ¼tÃ¼phane analojisi: Q=soru, K=etiket, V=kitap. Tahtada 3 token Ã¶rneÄŸi" },
    { phase: "Scaled Dot-Product", min: 15, desc: "FormÃ¼l: softmax(QKáµ€/âˆšd)Â·V. Elle hesaplama yaptÄ±rÄ±n" },
    { phase: "Multi-Head + Causal", min: 10, desc: "Neden birden fazla head? Causal mask neden gerekli?" },
    { phase: "Attention Playground", min: 15, desc: "Ä°nteraktif viz ile attention aÄŸÄ±rlÄ±klarÄ±nÄ± inceleyin" },
    { phase: "Quiz", min: 10, desc: "7 soruluk quiz" }
  ]},
  4: { title: "Transformer Block", totalMin: 75, plan: [
    { phase: "BÃ¼yÃ¼k Resim", min: 10, desc: "Transformer = Attention + MLP + Residual + Norm. Lego analojisi" },
    { phase: "RMSNorm & Residual", min: 15, desc: "Neden normalize? Neden residual connection?" },
    { phase: "MLP & Aktivasyon", min: 15, desc: "GeniÅŸlet â†’ aktive et â†’ daralt. ReLUÂ² ve GELU karÅŸÄ±laÅŸtÄ±rma" },
    { phase: "Transformer Flow Viz", min: 15, desc: "Ä°nteraktif bileÅŸen ile veri akÄ±ÅŸÄ±nÄ± takip edin" },
    { phase: "Weight Init + Quiz", min: 20, desc: "Neden baÅŸlatma Ã¶nemli? + quiz" }
  ]},
  5: { title: "Training Loop", totalMin: 75, plan: [
    { phase: "GiriÅŸ", min: 5, desc: "Ã–ÄŸrenme = loss'u minimize etme. Basit tepe/vadi analojisi" },
    { phase: "Cross-Entropy", min: 15, desc: "-log(P). Tahtada hesaplama: P=0.5 â†’ loss=0.69, P=0.01 â†’ loss=4.6" },
    { phase: "Gradient Descent", min: 15, desc: "w -= lr Ã— grad. LR etkisi: bÃ¼yÃ¼k â†’ patlama, kÃ¼Ã§Ã¼k â†’ yavaÅŸ" },
    { phase: "Adam + LR Decay", min: 10, desc: "Momentum + adaptive. Cosine decay" },
    { phase: "Training Sim", min: 15, desc: "Ä°nteraktif eÄŸitim simÃ¼lasyonu: LR slider ile canlÄ± deney" },
    { phase: "Quiz + KapanÄ±ÅŸ", min: 15, desc: "Quiz + gelecek hafta: inference" }
  ]},
  6: { title: "Inference & Generation", totalMin: 75, plan: [
    { phase: "Demo Ã–nce", min: 10, desc: "Temperature 0.1 vs 2.0 canlÄ± gÃ¶sterin. Ã–ÄŸrenciler tahmin etsin" },
    { phase: "Sampling Stratejileri", min: 15, desc: "Greedy, random, top-k. Temperature etkisi" },
    { phase: "KV Cache", min: 15, desc: "Neden cache? O(nÂ²) â†’ O(n). Bellekte ne saklanÄ±yor?" },
    { phase: "Generation Playground", min: 15, desc: "Ä°nteraktif viz ile Ã¼retim deneyleri" },
    { phase: "Quiz + YarÄ± DÃ¶nem Ã–zeti", min: 20, desc: "Quiz + W0-W6 Ã¶zet. Genel Ã¶zet" }
  ]},
  7: { title: "Modern AI Evrimi", totalMin: 75, plan: [
    { phase: "Scaling Laws", min: 10, desc: "microGPT â†’ GPT-4 grafiÄŸi. GÃ¼Ã§ yasasÄ±. Chinchilla" },
    { phase: "Timeline", min: 15, desc: "2017-2024 interaktif timeline. Her dÃ¶neme 2 dk" },
    { phase: "DonanÄ±m & Pipeline", min: 15, desc: "CPUâ†’GPUâ†’TPU. Pre-trainingâ†’SFTâ†’RLHF" },
    { phase: "Open Source & Trendler", min: 15, desc: "LLaMA, Mistral, DeepSeek. MoE, RAG, Agent" },
    { phase: "TartÄ±ÅŸma + Quiz", min: 20, desc: "AI'Ä±n geleceÄŸi tartÄ±ÅŸmasÄ± + quiz" }
  ]},
};

// â”€â”€â”€ INSTRUCTOR CHEAT SHEETS â€” Her Hafta Ä°Ã§in Kopya KaÄŸÄ±dÄ± â”€â”€â”€â”€â”€
const WEEK_CHEAT_SHEETS = {
  0: { title: "W0: GiriÅŸ Kopya KaÄŸÄ±dÄ±", formulas: ["Pipeline: Tokenâ†’Embedâ†’Posâ†’Attnâ†’MLPâ†’Softmaxâ†’Sample", "Vocab=27 (a-z + BOS), n_embd=16, n_head=4, n_layer=1", "Parametre: 3,648. Block_size=8 (context window)", "Autoregressive: P(xâ‚œ | xâ‚...xâ‚œâ‚‹â‚)"], keyPoints: ["microGPT = gerÃ§ek GPT, sadece kÃ¼Ã§Ã¼k", "243 satÄ±r, 0 baÄŸÄ±mlÄ±lÄ±k", "Ä°sim Ã¼retir, karakter karakter"] },
  1: { title: "W1: Token Kopya KaÄŸÄ±dÄ±", formulas: ["stoi: charâ†’int, itos: intâ†’char", "wte: [27Ã—16] embed matris, wpe: [8Ã—16] pos matris", "x = wte[token_id] + wpe[position]", "softmax(xáµ¢) = exp(xáµ¢) / Î£exp(xâ±¼)"], keyPoints: ["Token = modelin atom'u", "Embedding: IDâ†’vektÃ¶r (Ã¶ÄŸrenilebilir)", "Weight tying: wte giriÅŸ+Ã§Ä±kÄ±ÅŸta paylaÅŸÄ±lÄ±r"] },
  2: { title: "W2: Autograd Kopya KaÄŸÄ±dÄ±", formulas: ["Value: data + grad + _backward()", "Chain rule: âˆ‚L/âˆ‚x = âˆ‚L/âˆ‚y Â· âˆ‚y/âˆ‚x", "Add: âˆ‚(a+b)/âˆ‚a = 1", "Mul: âˆ‚(aÂ·b)/âˆ‚a = b", "Topological sort â†’ backward sÄ±ra"], keyPoints: ["Autograd = otomatik tÃ¼rev hesaplama", "Forward: graf oluÅŸtur, Backward: gradient hesapla", "Her operasyon kendi tÃ¼revini bilir"] },
  3: { title: "W3: Attention Kopya KaÄŸÄ±dÄ±", formulas: ["Attention(Q,K,V) = softmax(QKáµ€/âˆšd)Â·V", "Q = xÂ·Wq, K = xÂ·Wk, V = xÂ·Wv", "head_dim = n_embd/n_head = 16/4 = 4", "Causal mask: score[i][j>i] = -âˆ"], keyPoints: ["Q=soru, K=etiket, V=bilgi", "Multi-head: 4 farklÄ± bakÄ±ÅŸ aÃ§Ä±sÄ±", "Causal: gelecek tokenlarÄ± gÃ¶rmez"] },
  4: { title: "W4: Transformer Kopya KaÄŸÄ±dÄ±", formulas: ["x = x + Attention(Norm(x))", "x = x + MLP(Norm(x))", "RMSNorm(x) = xÂ·Î³ / âˆš(mean(xÂ²)+Îµ)", "MLP: Wâ‚‚Â·act(Wâ‚Â·x+bâ‚)+bâ‚‚, hidden=4Ã—16=64"], keyPoints: ["Residual: bilgi kaybÄ±nÄ± Ã¶nler", "Pre-norm: modern standart", "MLP: token iÃ§i bilgi iÅŸleme"] },
  5: { title: "W5: Training Kopya KaÄŸÄ±dÄ±", formulas: ["CE Loss = -log(P(doÄŸru))", "Rastgele loss = -log(1/27) = 3.33", "GD: w = w - lr Ã— âˆ‚L/âˆ‚w", "Adam: momentum + adaptive per-param"], keyPoints: ["Loss dÃ¼ÅŸÃ¼yorsa model Ã¶ÄŸreniyor", "LR Ã§ok kritik: 0.01 iyi baÅŸlangÄ±Ã§", "Her adÄ±mda grad sÄ±fÄ±rla!"] },
  6: { title: "W6: Inference Kopya KaÄŸÄ±dÄ±", formulas: ["logits/T â†’ softmax â†’ sample", "T<1: keskin, T=1: normal, T>1: dÃ¼z", "KV Cache: O(nÂ²) â†’ O(n) per token", "Top-k: sadece en yÃ¼ksek k olasÄ±lÄ±ktan seÃ§"], keyPoints: ["Ãœretim = forward + sample dÃ¶ngÃ¼sÃ¼", "Temperature = Ã§eÅŸitlilik kontrolÃ¼", "BOS ile baÅŸla, BOS gelince dur"] },
  7: { title: "W7: Evrim Kopya KaÄŸÄ±dÄ±", formulas: ["L(N) = a/N^b (scaling law)", "Chinchilla: D â‰ˆ 20N", "Flash Attn: O(nÂ²) compute, O(n) memory", "MoE: 8 expert, 2 active per token"], keyPoints: ["2017 Transformer â†’ 2024 Frontier", "Pre-trainingâ†’SFTâ†’RLHF pipeline", "Open source: LLaMA, Mistral, DeepSeek"] },
};

// â”€â”€â”€ INSTRUCTOR UI COMPONENTS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const InstructorPanel = ({ weekIdx, sectionIdx, weekColor }) => {
  const lang = useLang();
  const key = `week${weekIdx}_s${sectionIdx}`;
  const notes = INSTRUCTOR_NOTES[key];
  const [showQs, setShowQs] = useState(false);
  if (!notes) return null;
  return (
    <div style={{ background: "rgba(251,191,36,0.04)", border: "1px solid rgba(251,191,36,0.15)", borderRadius: 14, padding: 16, marginBottom: 12 }}>
      <div style={{ display: "flex", alignItems: "center", gap: 8, marginBottom: 10 }}>
        <span style={{ fontSize: 19 }}>ğŸ“</span>
        <span style={{ fontSize: 15, fontWeight: 700, color: "#FBBF24" }}>{lang==="tr"?"Hoca NotlarÄ±":"Instructor Notes"}</span>
        {notes.time && <span style={{ fontSize: 12, padding: "2px 8px", borderRadius: 6, background: "rgba(251,191,36,0.1)", color: "#FBBF24", marginLeft: "auto" }}>â±ï¸ {notes.time} dk</span>}
        {notes.difficulty && <span style={{ fontSize: 12, padding: "2px 8px", borderRadius: 6, background: notes.difficulty >= 4 ? "rgba(239,68,68,0.1)" : notes.difficulty >= 3 ? "rgba(251,191,36,0.1)" : "rgba(34,197,94,0.1)", color: notes.difficulty >= 4 ? "#EF4444" : notes.difficulty >= 3 ? "#FBBF24" : "#22C55E" }}>{"â­".repeat(notes.difficulty)} {lang==="tr"?"zorluk":"difficulty"}</span>}
      </div>

      {notes.prep && (
        <div style={{ fontSize: 14, color: "#FDE68A", marginBottom: 8, padding: "6px 10px", borderRadius: 8, background: "rgba(251,191,36,0.06)" }}>
          ğŸ“‹ <strong>{lang==="tr"?"HazÄ±rlÄ±k":"Prep"}:</strong> {tx(notes.prep, lang)}
        </div>
      )}

      {notes.emphasize && (
        <div style={{ fontSize: 14, color: "#FCD34D", marginBottom: 8, padding: "6px 10px", borderRadius: 8, background: "rgba(251,191,36,0.04)" }}>
          ğŸ¯ <strong>{lang==="tr"?"Vurgula":"Emphasize"}:</strong> {tx(notes.emphasize, lang)}
        </div>
      )}

      {notes.cheatSheet && (
        <div style={{ fontSize: 13, color: "#D1D5DB", marginBottom: 8, padding: "6px 10px", borderRadius: 8, background: "rgba(255,255,255,0.03)", fontFamily: "'Fira Code', monospace" }}>
          ğŸ“ {tx(notes.cheatSheet, lang)}
        </div>
      )}

      {notes.studentQs && notes.studentQs.length > 0 && (
        <div>
          <button onClick={() => setShowQs(!showQs)} style={{ fontSize: 13, color: "#F59E0B", background: "none", border: "none", cursor: "pointer", fontFamily: "inherit", padding: 0, fontWeight: 600 }}>
            {showQs ? "â–¾" : "â–¸"} {lang==="tr"?`ğŸ™‹ Ã–ÄŸrenci bunu soracak (${notes.studentQs.length} soru)`:`ğŸ™‹ Students will ask (${notes.studentQs.length} questions)`}
          </button>
          {showQs && notes.studentQs.map((sq, i) => (
            <div key={i} style={{ marginTop: 6, marginLeft: 12, padding: "6px 10px", borderRadius: 8, background: "rgba(255,255,255,0.02)", borderLeft: "2px solid rgba(251,191,36,0.3)" }}>
              <div style={{ fontSize: 13, fontWeight: 600, color: "#FBBF24", marginBottom: 2 }}>â“ {tx(sq.q, lang)}</div>
              <div style={{ fontSize: 13, color: "#94A3B8" }}>ğŸ’¬ {tx(sq.a, lang)}</div>
            </div>
          ))}
        </div>
      )}
    </div>
  );
};

const LessonPlanPanel = ({ weekIdx }) => {
  const lang = useLang();
  const plan = LESSON_PLANS[weekIdx];
  const [elapsed, setElapsed] = useState(0);
  const [running, setRunning] = useState(false);
  const [currentPhase, setCurrentPhase] = useState(0);
  const timerRef = useRef(null);

  useEffect(() => {
    if (running) {
      timerRef.current = setInterval(() => setElapsed(e => e + 1), 1000);
    } else {
      clearInterval(timerRef.current);
    }
    return () => clearInterval(timerRef.current);
  }, [running]);

  if (!plan) return null;
  const elapsedMin = Math.floor(elapsed / 60);
  const elapsedSec = elapsed % 60;

  // Calculate cumulative time
  let cumulative = 0;
  const phases = plan.plan.map(p => { cumulative += p.min; return { ...p, cumEnd: cumulative }; });

  return (
    <div style={{ background: "rgba(99,102,241,0.04)", border: "1px solid rgba(99,102,241,0.15)", borderRadius: 14, padding: 16, marginBottom: 12 }}>
      <div style={{ display: "flex", alignItems: "center", gap: 8, marginBottom: 10 }}>
        <span style={{ fontSize: 19 }}>ğŸ“‹</span>
        <span style={{ fontSize: 15, fontWeight: 700, color: "#818CF8" }}>{lang==="tr"?"Ders PlanÄ±":"Lesson Plan"} â€” {typeof plan.title === "object" ? tx(plan.title, lang) : plan.title}</span>
        <span style={{ fontSize: 13, color: "#6366F1", marginLeft: "auto" }}>{plan.totalMin} {lang==="tr"?"dk toplam":"min total"}</span>
      </div>

      {/* Timer */}
      <div style={{ display: "flex", alignItems: "center", gap: 8, marginBottom: 10, padding: "8px 12px", borderRadius: 10, background: "rgba(99,102,241,0.06)" }}>
        <button onClick={() => setRunning(!running)} style={{ fontSize: 19, background: "none", border: "none", cursor: "pointer", padding: 0 }}>
          {running ? "â¸ï¸" : "â–¶ï¸"}
        </button>
        <span style={{ fontSize: 23, fontWeight: 800, color: running ? "#818CF8" : "#475569", fontFamily: "'Fira Code', monospace" }}>
          {String(elapsedMin).padStart(2,"0")}:{String(elapsedSec).padStart(2,"0")}
        </span>
        <span style={{ fontSize: 13, color: "#475569" }}>/ {plan.totalMin}:00</span>
        <button onClick={() => { setElapsed(0); setRunning(false); setCurrentPhase(0); }} style={{ fontSize: 13, color: "#6366F1", background: "rgba(99,102,241,0.1)", border: "none", borderRadius: 6, padding: "2px 8px", cursor: "pointer", marginLeft: "auto", fontFamily: "inherit" }}>{lang === "tr" ? "SÄ±fÄ±rla" : "Reset"}</button>
      </div>

      {/* Progress bar */}
      <div style={{ display: "flex", gap: 2, height: 6, borderRadius: 4, overflow: "hidden", marginBottom: 8 }}>
        {phases.map((p, i) => (
          <div key={i} style={{ flex: p.min, background: i <= currentPhase ? "#6366F1" : "rgba(99,102,241,0.15)", transition: "background .3s", cursor: "pointer", borderRadius: 2 }} onClick={() => setCurrentPhase(i)} />
        ))}
      </div>

      {/* Phase list */}
      {phases.map((p, i) => (
        <div key={i} onClick={() => setCurrentPhase(i)} style={{ display: "flex", alignItems: "center", gap: 8, padding: "5px 8px", borderRadius: 8, cursor: "pointer", marginBottom: 2,
          background: i === currentPhase ? "rgba(99,102,241,0.08)" : "transparent",
          borderLeft: i === currentPhase ? "3px solid #6366F1" : "3px solid transparent",
          opacity: i < currentPhase ? 0.5 : 1, transition: "all .2s" }}>
          <span style={{ fontSize: 12, fontWeight: 700, color: i === currentPhase ? "#818CF8" : "#475569", minWidth: 35 }}>{p.min} {lang==="tr"?"dk":"m"}</span>
          <span style={{ fontSize: 13, fontWeight: i === currentPhase ? 700 : 400, color: i === currentPhase ? "#E2E8F0" : "#94A3B8" }}>{p.phase}</span>
          <span style={{ fontSize: 12, color: "#475569", marginLeft: "auto" }}>{p.desc.substring(0, 50)}{p.desc.length > 50 ? "..." : ""}</span>
        </div>
      ))}
    </div>
  );
};

const CheatSheetPanel = ({ weekIdx }) => {
  const lang = useLang();
  const sheet = WEEK_CHEAT_SHEETS[weekIdx];
  if (!sheet) return null;
  return (
    <div style={{ background: "rgba(16,185,129,0.04)", border: "1px solid rgba(16,185,129,0.15)", borderRadius: 14, padding: 16, marginBottom: 12 }}>
      <div style={{ display: "flex", alignItems: "center", gap: 8, marginBottom: 10 }}>
        <span style={{ fontSize: 19 }}>ğŸ“</span>
        <span style={{ fontSize: 15, fontWeight: 700, color: "#10B981" }}>{sheet.title}</span>
      </div>
      <div style={{ marginBottom: 8 }}>
        <div style={{ fontSize: 12, color: "#6EE7B7", fontWeight: 600, marginBottom: 4 }}>{lang==="tr"?"FormÃ¼ller & SayÄ±lar":"Formulas & Numbers"}:</div>
        {sheet.formulas.map((f, i) => (
          <div key={i} style={{ fontSize: 13, color: "#D1D5DB", padding: "2px 0", fontFamily: "'Fira Code', monospace" }}>â†’ {f}</div>
        ))}
      </div>
      <div>
        <div style={{ fontSize: 12, color: "#6EE7B7", fontWeight: 600, marginBottom: 4 }}>{lang==="tr"?"Kilit Noktalar":"Key Points"}:</div>
        {sheet.keyPoints.map((kp, i) => (
          <div key={i} style={{ fontSize: 13, color: "#94A3B8", padding: "2px 0" }}>âœ“ {kp}</div>
        ))}
      </div>
    </div>
  );
};


export { INSTRUCTOR_NOTES, LESSON_PLANS, WEEK_CHEAT_SHEETS, InstructorPanel, LessonPlanPanel, CheatSheetPanel };
